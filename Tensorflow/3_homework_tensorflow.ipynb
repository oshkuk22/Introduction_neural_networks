{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1. Постройте нейронную сеть(берем простую линейную сеть, которую разбирали на уроке: меняем число слоев, число нейронов , типы активации, тип оптимизатора)  на датасет from sklearn.datasets import load_boston. \n",
    "####  2. Измените функцию потерь и метрику для этой задачи. Постройте 10-15 вариантов и сведите результаты их работы в таблицу  Опишите, какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доступные GPU : []\n"
     ]
    }
   ],
   "source": [
    "print(f'доступные GPU : {tf.config.experimental.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_hidden_layers = [2, 3, 5]\n",
    "setting_neurons = [128, 256, 512]\n",
    "activate_fn = ['relu', 'sigmoid']\n",
    "optim_= ['adam', 'rmsprop', 'nadam']\n",
    "loss_fn = ['mse', 'mae']\n",
    "validation_split_ = 0.20\n",
    "batch_size_ = 8\n",
    "\n",
    "dict_history_model_boston_house_train = {}\n",
    "dict_evaluate = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_boston_house(count_layers, count_neurons, activate_fn,  optim_, loss_fn_, epochs_):\n",
    "    \n",
    "    if loss_fn_ == 'mse':\n",
    "        loss_ = tf.keras.losses.MeanSquaredError()\n",
    "    elif loss_fn_ == 'mae':\n",
    "        loss_ = tf.keras.losses.MeanAbsoluteError()\n",
    "        \n",
    "\n",
    "    inputs_ = Input(shape=(13,))\n",
    "    x = inputs_\n",
    "\n",
    "\n",
    "    for i in range(count_layers):\n",
    "        x = Dense(count_neurons, activation=activate_fn, name='layer' + str(i))(x)\n",
    "\n",
    "    outputs_ = Dense(1, activation=None, name='predictions')(x) \n",
    "\n",
    "    model_boston_house = Model(inputs=inputs_, outputs=outputs_) \n",
    "\n",
    "    model_boston_house.compile(optimizer=optimizer_, loss=loss_, metrics=['mae'])\n",
    "\n",
    "    history_model_boston_house = model_boston_house.fit(X_train, y_train, batch_size=batch_size_, \n",
    "                                                        validation_split=validation_split_, epochs=epochs_)\n",
    "    \n",
    "    loss_mae = model_boston_house.evaluate(X_test, y_test)\n",
    "    \n",
    "    model_boston_house.save_weights( 'MODEL_BOSTON_HOUSE' + \n",
    "                                    '_' + str(count_layers) + \n",
    "                                    '_' + str(count_neurons) +  \n",
    "                                    '_' + optim_ + \n",
    "                                    '_' + activate_fn + \n",
    "                                    '_' + loss_fn_+ '.h5')\n",
    "    \n",
    "    dict_history_model_boston_house_train['MODEL_BOSTON_HOUSE' + \n",
    "                                          '_' + str(count_layers) + \n",
    "                                          '_' + str(count_neurons) +  \n",
    "                                          '_' + optim_ + \n",
    "                                          '_' + activate_fn + \n",
    "                                          '_' + loss_fn_] = history_model_boston_house.history\n",
    "    dict_evaluate['MODEL_BOSTON_HOUSE' + \n",
    "                  '_' + str(count_layers) + \n",
    "                  '_' + str(count_neurons) +  \n",
    "                  '_' + optim_ + \n",
    "                  '_' + activate_fn + \n",
    "                  '_' + loss_fn_] = loss_mae\n",
    "\n",
    "    return dict_history_model_boston_house_train, dict_evaluate\n",
    "# plot_model(model_boston_house,to_file='new_model-all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 452.9961 - mae: 19.1770 - val_loss: 319.3002 - val_mae: 15.3364\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 200.4684 - mae: 11.7783 - val_loss: 119.2722 - val_mae: 8.6807\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.8914 - mae: 6.9900 - val_loss: 70.6782 - val_mae: 6.4228\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.7610 - mae: 5.6126 - val_loss: 53.2337 - val_mae: 5.4297\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0232 - mae: 4.8724 - val_loss: 42.9935 - val_mae: 4.8017\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8810 - mae: 4.3976 - val_loss: 36.4340 - val_mae: 4.3821\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2547 - mae: 4.0565 - val_loss: 32.4149 - val_mae: 4.1133\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.3530 - mae: 3.8464 - val_loss: 29.8257 - val_mae: 3.9546\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.1429 - mae: 3.6726 - val_loss: 27.7131 - val_mae: 3.7508\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.5550 - mae: 3.5342 - val_loss: 26.3381 - val_mae: 3.6395\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.4719 - mae: 3.4415 - val_loss: 25.1690 - val_mae: 3.5625\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.5488 - mae: 3.3695 - val_loss: 24.3582 - val_mae: 3.4990\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.7507 - mae: 3.2846 - val_loss: 23.5804 - val_mae: 3.4257\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.0782 - mae: 3.2084 - val_loss: 22.8422 - val_mae: 3.4029\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.4816 - mae: 3.1499 - val_loss: 22.3850 - val_mae: 3.3664\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.8786 - mae: 3.1186 - val_loss: 21.9511 - val_mae: 3.3555\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.3534 - mae: 3.0645 - val_loss: 21.5006 - val_mae: 3.3082\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9755 - mae: 3.0075 - val_loss: 21.0932 - val_mae: 3.2619\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.6789 - mae: 3.0141 - val_loss: 20.8297 - val_mae: 3.2656\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.3279 - mae: 2.9460 - val_loss: 20.5036 - val_mae: 3.2321\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.8618 - mae: 2.9134 - val_loss: 20.2428 - val_mae: 3.1969\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.5557 - mae: 2.8790 - val_loss: 20.0832 - val_mae: 3.1831\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.2992 - mae: 2.8512 - val_loss: 19.7527 - val_mae: 3.1486\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.0034 - mae: 2.8201 - val_loss: 19.6122 - val_mae: 3.1456\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.7042 - mae: 2.7981 - val_loss: 19.3429 - val_mae: 3.1275\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.4673 - mae: 2.7790 - val_loss: 19.1744 - val_mae: 3.1041\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2685 - mae: 2.7515 - val_loss: 18.9558 - val_mae: 3.0785\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0733 - mae: 2.7377 - val_loss: 18.8052 - val_mae: 3.0629\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8427 - mae: 2.7102 - val_loss: 18.6933 - val_mae: 3.0415\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7314 - mae: 2.6999 - val_loss: 18.4403 - val_mae: 3.0444\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4607 - mae: 2.6746 - val_loss: 18.3647 - val_mae: 3.0349\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3459 - mae: 2.6474 - val_loss: 18.2077 - val_mae: 2.9959\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1075 - mae: 2.6356 - val_loss: 18.1284 - val_mae: 3.0138\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0133 - mae: 2.6414 - val_loss: 18.0667 - val_mae: 3.0032\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.7964 - mae: 2.6108 - val_loss: 17.9176 - val_mae: 2.9860\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6680 - mae: 2.5956 - val_loss: 17.7865 - val_mae: 2.9780\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6367 - mae: 2.5795 - val_loss: 17.6733 - val_mae: 2.9726\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.3942 - mae: 2.5819 - val_loss: 17.4880 - val_mae: 2.9575\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2550 - mae: 2.5598 - val_loss: 17.4503 - val_mae: 2.9524\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2180 - mae: 2.5631 - val_loss: 17.3432 - val_mae: 2.9369\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0932 - mae: 2.5310 - val_loss: 17.2856 - val_mae: 2.9323\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.9188 - mae: 2.5293 - val_loss: 17.1278 - val_mae: 2.9160\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8639 - mae: 2.5279 - val_loss: 17.0903 - val_mae: 2.9118\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6875 - mae: 2.4943 - val_loss: 17.0060 - val_mae: 2.8862\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.6081 - mae: 2.4897 - val_loss: 16.8834 - val_mae: 2.8844\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.6302 - mae: 2.5065 - val_loss: 16.8359 - val_mae: 2.8934\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4124 - mae: 2.4626 - val_loss: 16.8528 - val_mae: 2.8750\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3006 - mae: 2.4712 - val_loss: 16.6582 - val_mae: 2.8685\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1789 - mae: 2.4500 - val_loss: 16.6503 - val_mae: 2.8513\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1356 - mae: 2.4519 - val_loss: 16.5908 - val_mae: 2.8545\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0572 - mae: 2.4526 - val_loss: 16.5426 - val_mae: 2.8490\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9496 - mae: 2.4256 - val_loss: 16.4404 - val_mae: 2.8198\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8434 - mae: 2.4184 - val_loss: 16.3824 - val_mae: 2.8372\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7624 - mae: 2.4160 - val_loss: 16.2665 - val_mae: 2.8123\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7390 - mae: 2.4097 - val_loss: 16.1948 - val_mae: 2.8076\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6424 - mae: 2.4089 - val_loss: 16.1528 - val_mae: 2.8023\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6115 - mae: 2.4062 - val_loss: 16.1174 - val_mae: 2.8155\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4457 - mae: 2.3764 - val_loss: 16.0483 - val_mae: 2.7886\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3728 - mae: 2.3753 - val_loss: 15.9129 - val_mae: 2.7750\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2965 - mae: 2.3748 - val_loss: 15.8435 - val_mae: 2.7728\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.2606 - mae: 2.3606 - val_loss: 15.8789 - val_mae: 2.7898\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1749 - mae: 2.3491 - val_loss: 15.8394 - val_mae: 2.7762\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0990 - mae: 2.3567 - val_loss: 15.7985 - val_mae: 2.7784\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.0112 - mae: 2.3456 - val_loss: 15.6818 - val_mae: 2.7539\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9820 - mae: 2.3333 - val_loss: 15.6774 - val_mae: 2.7514\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9051 - mae: 2.3406 - val_loss: 15.5922 - val_mae: 2.7436\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8451 - mae: 2.3333 - val_loss: 15.5044 - val_mae: 2.7335\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8178 - mae: 2.3217 - val_loss: 15.5464 - val_mae: 2.7445\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7157 - mae: 2.3329 - val_loss: 15.4541 - val_mae: 2.7318\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6391 - mae: 2.2958 - val_loss: 15.4856 - val_mae: 2.7257\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5865 - mae: 2.2947 - val_loss: 15.4073 - val_mae: 2.7220\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6096 - mae: 2.3300 - val_loss: 15.2720 - val_mae: 2.7157\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4741 - mae: 2.2843 - val_loss: 15.2785 - val_mae: 2.6978\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4377 - mae: 2.2738 - val_loss: 15.2247 - val_mae: 2.7011\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3280 - mae: 2.2853 - val_loss: 15.1727 - val_mae: 2.6953\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3406 - mae: 2.2794 - val_loss: 15.2039 - val_mae: 2.6959\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2719 - mae: 2.2745 - val_loss: 15.2076 - val_mae: 2.6926\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2673 - mae: 2.2696 - val_loss: 15.0653 - val_mae: 2.6784\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1617 - mae: 2.2553 - val_loss: 15.0736 - val_mae: 2.6728\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0889 - mae: 2.2475 - val_loss: 14.9596 - val_mae: 2.6748\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0392 - mae: 2.2324 - val_loss: 15.0140 - val_mae: 2.6694\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0326 - mae: 2.2340 - val_loss: 14.8708 - val_mae: 2.6614\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9173 - mae: 2.2350 - val_loss: 14.8266 - val_mae: 2.6522\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9144 - mae: 2.2236 - val_loss: 14.8351 - val_mae: 2.6510\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9057 - mae: 2.2275 - val_loss: 14.8886 - val_mae: 2.6519\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8228 - mae: 2.2330 - val_loss: 14.6805 - val_mae: 2.6483\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7773 - mae: 2.2138 - val_loss: 14.7203 - val_mae: 2.6412\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7343 - mae: 2.2242 - val_loss: 14.6903 - val_mae: 2.6288\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6461 - mae: 2.1961 - val_loss: 14.7054 - val_mae: 2.6364\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6470 - mae: 2.1945 - val_loss: 14.6267 - val_mae: 2.6276\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5625 - mae: 2.2064 - val_loss: 14.5589 - val_mae: 2.6250\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4944 - mae: 2.1816 - val_loss: 14.5423 - val_mae: 2.6188\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4494 - mae: 2.1855 - val_loss: 14.5094 - val_mae: 2.6075\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3979 - mae: 2.1663 - val_loss: 14.5353 - val_mae: 2.6004\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3583 - mae: 2.1701 - val_loss: 14.4727 - val_mae: 2.5983\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3512 - mae: 2.1634 - val_loss: 14.4194 - val_mae: 2.6045\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2934 - mae: 2.1710 - val_loss: 14.3490 - val_mae: 2.5895\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2444 - mae: 2.1518 - val_loss: 14.4049 - val_mae: 2.5935\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2070 - mae: 2.1454 - val_loss: 14.3244 - val_mae: 2.5821\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2278 - mae: 2.1704 - val_loss: 14.3933 - val_mae: 2.5932\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.7299 - mae: 3.7693\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 20.0659 - mae: 20.0659 - val_loss: 16.9484 - val_mae: 16.9484\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5054 - mae: 13.5054 - val_loss: 9.8533 - val_mae: 9.8533\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6331 - mae: 7.6331 - val_loss: 6.3855 - val_mae: 6.3855\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5369 - mae: 5.5369 - val_loss: 4.9720 - val_mae: 4.9720\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5971 - mae: 4.5971 - val_loss: 4.1860 - val_mae: 4.1860\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0980 - mae: 4.0980 - val_loss: 3.7970 - val_mae: 3.7970\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8144 - mae: 3.8144 - val_loss: 3.5989 - val_mae: 3.5989\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6488 - mae: 3.6488 - val_loss: 3.5015 - val_mae: 3.5015\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5358 - mae: 3.5358 - val_loss: 3.4489 - val_mae: 3.4489\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4594 - mae: 3.4594 - val_loss: 3.3709 - val_mae: 3.3709\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3481 - mae: 3.3481 - val_loss: 3.3245 - val_mae: 3.3245\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2705 - mae: 3.2705 - val_loss: 3.2587 - val_mae: 3.2587\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2003 - mae: 3.2003 - val_loss: 3.2184 - val_mae: 3.2184\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1323 - mae: 3.1323 - val_loss: 3.2152 - val_mae: 3.2152\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0684 - mae: 3.0684 - val_loss: 3.1639 - val_mae: 3.1639\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0173 - mae: 3.0173 - val_loss: 3.1059 - val_mae: 3.1059\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 3.1150 - mae: 3.115 - 0s 2ms/step - loss: 2.9732 - mae: 2.9732 - val_loss: 3.1234 - val_mae: 3.1234\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9301 - mae: 2.9301 - val_loss: 3.0629 - val_mae: 3.0629\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8733 - mae: 2.8733 - val_loss: 3.0418 - val_mae: 3.0418\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8389 - mae: 2.8389 - val_loss: 2.9954 - val_mae: 2.9954\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8032 - mae: 2.8032 - val_loss: 2.9896 - val_mae: 2.9896\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7630 - mae: 2.7630 - val_loss: 2.9710 - val_mae: 2.9710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7296 - mae: 2.7296 - val_loss: 2.9601 - val_mae: 2.9601\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7054 - mae: 2.7054 - val_loss: 2.9518 - val_mae: 2.9518\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6832 - mae: 2.6832 - val_loss: 2.9265 - val_mae: 2.9265\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6632 - mae: 2.6632 - val_loss: 2.9325 - val_mae: 2.9325\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6384 - mae: 2.6384 - val_loss: 2.9215 - val_mae: 2.9215\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6011 - mae: 2.6011 - val_loss: 2.9199 - val_mae: 2.9199\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5767 - mae: 2.5767 - val_loss: 2.9154 - val_mae: 2.9154\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5569 - mae: 2.5569 - val_loss: 2.8876 - val_mae: 2.8876\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5468 - mae: 2.5468 - val_loss: 2.8761 - val_mae: 2.8761\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5219 - mae: 2.5219 - val_loss: 2.8599 - val_mae: 2.8599\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4985 - mae: 2.4985 - val_loss: 2.8500 - val_mae: 2.8500\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4821 - mae: 2.4821 - val_loss: 2.8451 - val_mae: 2.8451\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4599 - mae: 2.4599 - val_loss: 2.8072 - val_mae: 2.8072\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4388 - mae: 2.4388 - val_loss: 2.8029 - val_mae: 2.8029\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4381 - mae: 2.4381 - val_loss: 2.7968 - val_mae: 2.7968\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4213 - mae: 2.4213 - val_loss: 2.7929 - val_mae: 2.7929\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4056 - mae: 2.4056 - val_loss: 2.7785 - val_mae: 2.7785\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3883 - mae: 2.3883 - val_loss: 2.7662 - val_mae: 2.7662\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3736 - mae: 2.3736 - val_loss: 2.7360 - val_mae: 2.7360\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3691 - mae: 2.3691 - val_loss: 2.7414 - val_mae: 2.7414\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3607 - mae: 2.3607 - val_loss: 2.7367 - val_mae: 2.7367\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3366 - mae: 2.3366 - val_loss: 2.7126 - val_mae: 2.7126\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3223 - mae: 2.3223 - val_loss: 2.6990 - val_mae: 2.6990\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3213 - mae: 2.3213 - val_loss: 2.6963 - val_mae: 2.6963\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3057 - mae: 2.3057 - val_loss: 2.7021 - val_mae: 2.7021\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2881 - mae: 2.2881 - val_loss: 2.6713 - val_mae: 2.6713\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2856 - mae: 2.2856 - val_loss: 2.6765 - val_mae: 2.6765\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2673 - mae: 2.2673 - val_loss: 2.6472 - val_mae: 2.6472\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2691 - mae: 2.2691 - val_loss: 2.6539 - val_mae: 2.6539\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2513 - mae: 2.2513 - val_loss: 2.6375 - val_mae: 2.6375\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2351 - mae: 2.2351 - val_loss: 2.6458 - val_mae: 2.6458\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2436 - mae: 2.2436 - val_loss: 2.6185 - val_mae: 2.6185\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2223 - mae: 2.2223 - val_loss: 2.6079 - val_mae: 2.6079\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2183 - mae: 2.2183 - val_loss: 2.6083 - val_mae: 2.6083\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2092 - mae: 2.2092 - val_loss: 2.6079 - val_mae: 2.6079\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2055 - mae: 2.2055 - val_loss: 2.5928 - val_mae: 2.5928\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1933 - mae: 2.1933 - val_loss: 2.5952 - val_mae: 2.5952\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1845 - mae: 2.1845 - val_loss: 2.5715 - val_mae: 2.5715\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1744 - mae: 2.1744 - val_loss: 2.5837 - val_mae: 2.5837\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1823 - mae: 2.1823 - val_loss: 2.5823 - val_mae: 2.5823\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1711 - mae: 2.1711 - val_loss: 2.5789 - val_mae: 2.5789\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1633 - mae: 2.1633 - val_loss: 2.5650 - val_mae: 2.5650\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1685 - mae: 2.1685 - val_loss: 2.5362 - val_mae: 2.5362\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1541 - mae: 2.1541 - val_loss: 2.5466 - val_mae: 2.5466\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1473 - mae: 2.1473 - val_loss: 2.5424 - val_mae: 2.5424\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1363 - mae: 2.1363 - val_loss: 2.5480 - val_mae: 2.5480\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1297 - mae: 2.1297 - val_loss: 2.5077 - val_mae: 2.5077\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1232 - mae: 2.1232 - val_loss: 2.5282 - val_mae: 2.5282\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1222 - mae: 2.1222 - val_loss: 2.5216 - val_mae: 2.5216\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1042 - mae: 2.1042 - val_loss: 2.5150 - val_mae: 2.5150\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1066 - mae: 2.1066 - val_loss: 2.5313 - val_mae: 2.5313\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0981 - mae: 2.0981 - val_loss: 2.4922 - val_mae: 2.4922\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0976 - mae: 2.0976 - val_loss: 2.4898 - val_mae: 2.4898\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0964 - mae: 2.0964 - val_loss: 2.4966 - val_mae: 2.4966\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0799 - mae: 2.0799 - val_loss: 2.4871 - val_mae: 2.4871\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0878 - mae: 2.0878 - val_loss: 2.4838 - val_mae: 2.4838\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0753 - mae: 2.0753 - val_loss: 2.4860 - val_mae: 2.4860\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0753 - mae: 2.0753 - val_loss: 2.4759 - val_mae: 2.4759\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0668 - mae: 2.0668 - val_loss: 2.4690 - val_mae: 2.4690\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0612 - mae: 2.0612 - val_loss: 2.4743 - val_mae: 2.4743\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0653 - mae: 2.0653 - val_loss: 2.4818 - val_mae: 2.4818\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0576 - mae: 2.0576 - val_loss: 2.4626 - val_mae: 2.4626\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0523 - mae: 2.0523 - val_loss: 2.4587 - val_mae: 2.4587\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0454 - mae: 2.0454 - val_loss: 2.4608 - val_mae: 2.4608\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0381 - mae: 2.0381 - val_loss: 2.4468 - val_mae: 2.4468\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0397 - mae: 2.0397 - val_loss: 2.4589 - val_mae: 2.4589\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0291 - mae: 2.0291 - val_loss: 2.4400 - val_mae: 2.4400\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0220 - mae: 2.0220 - val_loss: 2.4408 - val_mae: 2.4408\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0171 - mae: 2.0171 - val_loss: 2.4452 - val_mae: 2.4452\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0172 - mae: 2.0172 - val_loss: 2.4289 - val_mae: 2.4289\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0158 - mae: 2.0158 - val_loss: 2.4393 - val_mae: 2.4393\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0097 - mae: 2.0097 - val_loss: 2.4409 - val_mae: 2.4409\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9949 - mae: 1.9949 - val_loss: 2.4389 - val_mae: 2.4389\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0123 - mae: 2.0123 - val_loss: 2.4278 - val_mae: 2.4278\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0017 - mae: 2.0017 - val_loss: 2.4359 - val_mae: 2.4359\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9891 - mae: 1.9891 - val_loss: 2.4158 - val_mae: 2.4158\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9995 - mae: 1.9995 - val_loss: 2.4242 - val_mae: 2.4242\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9893 - mae: 1.9893 - val_loss: 2.4278 - val_mae: 2.4278\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7543 - mae: 3.7543\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 480.2487 - mae: 19.8868 - val_loss: 365.6686 - val_mae: 16.6451\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 250.5408 - mae: 13.4208 - val_loss: 158.0938 - val_mae: 10.0518\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.0218 - mae: 7.9546 - val_loss: 76.6642 - val_mae: 6.6836\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.6443 - mae: 5.9354 - val_loss: 56.2165 - val_mae: 5.5974\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5193 - mae: 5.1183 - val_loss: 43.6604 - val_mae: 4.8302\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.9970 - mae: 4.5268 - val_loss: 37.1805 - val_mae: 4.3837\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.5990 - mae: 4.1605 - val_loss: 32.9165 - val_mae: 4.1054\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0993 - mae: 3.8853 - val_loss: 29.8454 - val_mae: 3.8311\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9013 - mae: 3.7086 - val_loss: 27.8708 - val_mae: 3.6899\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1537 - mae: 3.5663 - val_loss: 26.3967 - val_mae: 3.5522\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.8000 - mae: 3.4462 - val_loss: 25.4406 - val_mae: 3.4937\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.7924 - mae: 3.3578 - val_loss: 24.4823 - val_mae: 3.4340\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.0699 - mae: 3.2926 - val_loss: 23.7835 - val_mae: 3.3949\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.2648 - mae: 3.2275 - val_loss: 23.1621 - val_mae: 3.3788\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.6261 - mae: 3.1741 - val_loss: 22.6593 - val_mae: 3.3547\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.1919 - mae: 3.1220 - val_loss: 22.1632 - val_mae: 3.3274\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.7194 - mae: 3.0811 - val_loss: 21.8809 - val_mae: 3.3204\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.3036 - mae: 3.0409 - val_loss: 21.4560 - val_mae: 3.2785\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9661 - mae: 2.9988 - val_loss: 21.1242 - val_mae: 3.2541\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.6986 - mae: 2.9837 - val_loss: 20.8568 - val_mae: 3.2574\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2962 - mae: 2.9420 - val_loss: 20.5648 - val_mae: 3.2436\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.9527 - mae: 2.9083 - val_loss: 20.3459 - val_mae: 3.2197\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7238 - mae: 2.8845 - val_loss: 20.1490 - val_mae: 3.2089\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.4751 - mae: 2.8452 - val_loss: 19.9253 - val_mae: 3.1644\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2035 - mae: 2.8335 - val_loss: 19.6852 - val_mae: 3.1939\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9945 - mae: 2.8320 - val_loss: 19.5076 - val_mae: 3.1658\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9171 - mae: 2.7943 - val_loss: 19.2357 - val_mae: 3.1329\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6275 - mae: 2.7679 - val_loss: 19.1269 - val_mae: 3.1190\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4076 - mae: 2.7523 - val_loss: 18.9593 - val_mae: 3.1196\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.1999 - mae: 2.7357 - val_loss: 18.8364 - val_mae: 3.1225\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9911 - mae: 2.7108 - val_loss: 18.6953 - val_mae: 3.0871\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8143 - mae: 2.6907 - val_loss: 18.4805 - val_mae: 3.0643\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7183 - mae: 2.6839 - val_loss: 18.3714 - val_mae: 3.0550\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4321 - mae: 2.6543 - val_loss: 18.2366 - val_mae: 3.0385\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3559 - mae: 2.6519 - val_loss: 18.1556 - val_mae: 3.0429\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1820 - mae: 2.6306 - val_loss: 18.0697 - val_mae: 3.0297\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0072 - mae: 2.6156 - val_loss: 17.8558 - val_mae: 3.0001\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9304 - mae: 2.6130 - val_loss: 17.8075 - val_mae: 2.9905\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8182 - mae: 2.5959 - val_loss: 17.6455 - val_mae: 2.9840\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6559 - mae: 2.5825 - val_loss: 17.5478 - val_mae: 2.9673\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6077 - mae: 2.5778 - val_loss: 17.4495 - val_mae: 2.9724\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4616 - mae: 2.5645 - val_loss: 17.2834 - val_mae: 2.9532\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4261 - mae: 2.5617 - val_loss: 17.2607 - val_mae: 2.9489\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1712 - mae: 2.5355 - val_loss: 17.1934 - val_mae: 2.9196\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1200 - mae: 2.5304 - val_loss: 17.0598 - val_mae: 2.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0046 - mae: 2.5287 - val_loss: 16.9926 - val_mae: 2.9205\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8886 - mae: 2.4990 - val_loss: 16.9663 - val_mae: 2.9137\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7723 - mae: 2.4912 - val_loss: 16.7998 - val_mae: 2.8984\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6999 - mae: 2.4846 - val_loss: 16.7277 - val_mae: 2.8997\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5312 - mae: 2.4803 - val_loss: 16.6706 - val_mae: 2.8899\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4561 - mae: 2.4732 - val_loss: 16.5799 - val_mae: 2.8806\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4048 - mae: 2.4735 - val_loss: 16.4794 - val_mae: 2.8798\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3645 - mae: 2.4487 - val_loss: 16.4636 - val_mae: 2.8565\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2103 - mae: 2.4533 - val_loss: 16.3895 - val_mae: 2.8536\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.3168 - mae: 2.4463 - val_loss: 16.2938 - val_mae: 2.8463\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0290 - mae: 2.4391 - val_loss: 16.2410 - val_mae: 2.8541\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9380 - mae: 2.4211 - val_loss: 16.1420 - val_mae: 2.8294\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9628 - mae: 2.4236 - val_loss: 16.0402 - val_mae: 2.8359\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8726 - mae: 2.4026 - val_loss: 16.0518 - val_mae: 2.8123\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7364 - mae: 2.3992 - val_loss: 15.9236 - val_mae: 2.8036\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6517 - mae: 2.4059 - val_loss: 15.8801 - val_mae: 2.8064\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5646 - mae: 2.3914 - val_loss: 15.7854 - val_mae: 2.8026\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4884 - mae: 2.3844 - val_loss: 15.6900 - val_mae: 2.7820\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4410 - mae: 2.3734 - val_loss: 15.6800 - val_mae: 2.7899\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3765 - mae: 2.3842 - val_loss: 15.6493 - val_mae: 2.7815\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3530 - mae: 2.3477 - val_loss: 15.5331 - val_mae: 2.7649\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1775 - mae: 2.3501 - val_loss: 15.4494 - val_mae: 2.7635\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1560 - mae: 2.3481 - val_loss: 15.4237 - val_mae: 2.7561\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0779 - mae: 2.3476 - val_loss: 15.3397 - val_mae: 2.7473\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0157 - mae: 2.3341 - val_loss: 15.2572 - val_mae: 2.7430\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0618 - mae: 2.3381 - val_loss: 15.2069 - val_mae: 2.7323\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9028 - mae: 2.3174 - val_loss: 15.2364 - val_mae: 2.7280\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7984 - mae: 2.3141 - val_loss: 15.1940 - val_mae: 2.7423\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7449 - mae: 2.3209 - val_loss: 15.1575 - val_mae: 2.7237\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6938 - mae: 2.2968 - val_loss: 15.0166 - val_mae: 2.7152\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7172 - mae: 2.2999 - val_loss: 14.9643 - val_mae: 2.6991\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6063 - mae: 2.2959 - val_loss: 15.0088 - val_mae: 2.7178\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5066 - mae: 2.2931 - val_loss: 14.9671 - val_mae: 2.7077\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4555 - mae: 2.2796 - val_loss: 14.8355 - val_mae: 2.6925\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4312 - mae: 2.2790 - val_loss: 14.8987 - val_mae: 2.6937\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3829 - mae: 2.2825 - val_loss: 14.8287 - val_mae: 2.6865\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2720 - mae: 2.2613 - val_loss: 14.7145 - val_mae: 2.6728\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2631 - mae: 2.2565 - val_loss: 14.6879 - val_mae: 2.6714\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1994 - mae: 2.2480 - val_loss: 14.6736 - val_mae: 2.6641\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1444 - mae: 2.2583 - val_loss: 14.5563 - val_mae: 2.6521\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0531 - mae: 2.2325 - val_loss: 14.5735 - val_mae: 2.6517\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9979 - mae: 2.2348 - val_loss: 14.5091 - val_mae: 2.6495\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9547 - mae: 2.2285 - val_loss: 14.4732 - val_mae: 2.6418\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8861 - mae: 2.2222 - val_loss: 14.4724 - val_mae: 2.6371\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8414 - mae: 2.2140 - val_loss: 14.3353 - val_mae: 2.6264\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8577 - mae: 2.2093 - val_loss: 14.4076 - val_mae: 2.6329\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7233 - mae: 2.2037 - val_loss: 14.2733 - val_mae: 2.6202\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7652 - mae: 2.2057 - val_loss: 14.2999 - val_mae: 2.6183\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6066 - mae: 2.1937 - val_loss: 14.2331 - val_mae: 2.6154\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6002 - mae: 2.1914 - val_loss: 14.2068 - val_mae: 2.6138\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5641 - mae: 2.1840 - val_loss: 14.1652 - val_mae: 2.6099\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4772 - mae: 2.1841 - val_loss: 14.1163 - val_mae: 2.6043\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5130 - mae: 2.1738 - val_loss: 14.1232 - val_mae: 2.6041\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4197 - mae: 2.1823 - val_loss: 14.1150 - val_mae: 2.6048\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3631 - mae: 2.1678 - val_loss: 14.0524 - val_mae: 2.6014\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.5610 - mae: 4.0709\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.8587 - mae: 19.8587 - val_loss: 16.5723 - val_mae: 16.5723\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3417 - mae: 13.3417 - val_loss: 9.6974 - val_mae: 9.6974\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2648 - mae: 7.2648 - val_loss: 5.8768 - val_mae: 5.8768\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3795 - mae: 5.3795 - val_loss: 4.5832 - val_mae: 4.5832\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5571 - mae: 4.5571 - val_loss: 3.9463 - val_mae: 3.9463\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0816 - mae: 4.0816 - val_loss: 3.5426 - val_mae: 3.5426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7356 - mae: 3.7356 - val_loss: 3.3512 - val_mae: 3.3512\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5464 - mae: 3.5464 - val_loss: 3.2685 - val_mae: 3.2685\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3908 - mae: 3.3908 - val_loss: 3.2151 - val_mae: 3.2151\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2950 - mae: 3.2950 - val_loss: 3.1807 - val_mae: 3.1807\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2159 - mae: 3.2159 - val_loss: 3.1441 - val_mae: 3.1441\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1344 - mae: 3.1344 - val_loss: 3.1345 - val_mae: 3.1345\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0651 - mae: 3.0651 - val_loss: 3.1195 - val_mae: 3.1195\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0240 - mae: 3.0240 - val_loss: 3.0651 - val_mae: 3.0651\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9614 - mae: 2.9614 - val_loss: 3.0395 - val_mae: 3.0395\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9257 - mae: 2.9257 - val_loss: 3.0374 - val_mae: 3.0374\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8856 - mae: 2.8856 - val_loss: 2.9559 - val_mae: 2.9559\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8401 - mae: 2.8401 - val_loss: 2.9147 - val_mae: 2.9147\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8138 - mae: 2.8138 - val_loss: 2.9627 - val_mae: 2.9627\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7917 - mae: 2.7917 - val_loss: 2.8980 - val_mae: 2.8980\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7684 - mae: 2.7684 - val_loss: 2.8988 - val_mae: 2.8988\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7332 - mae: 2.7332 - val_loss: 2.9020 - val_mae: 2.9020\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7100 - mae: 2.7100 - val_loss: 2.8555 - val_mae: 2.8555\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6859 - mae: 2.6859 - val_loss: 2.8653 - val_mae: 2.8653\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6705 - mae: 2.6705 - val_loss: 2.8277 - val_mae: 2.8277\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6526 - mae: 2.6526 - val_loss: 2.8283 - val_mae: 2.8283\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6360 - mae: 2.6360 - val_loss: 2.8283 - val_mae: 2.8283\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6109 - mae: 2.6109 - val_loss: 2.8187 - val_mae: 2.8187\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5946 - mae: 2.5946 - val_loss: 2.8019 - val_mae: 2.8019\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5896 - mae: 2.5896 - val_loss: 2.8069 - val_mae: 2.8069\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5737 - mae: 2.5737 - val_loss: 2.7692 - val_mae: 2.7692\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5631 - mae: 2.5631 - val_loss: 2.7735 - val_mae: 2.7735\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5505 - mae: 2.5505 - val_loss: 2.7532 - val_mae: 2.7532\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5364 - mae: 2.5364 - val_loss: 2.7384 - val_mae: 2.7384\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5269 - mae: 2.5269 - val_loss: 2.7201 - val_mae: 2.7201\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5161 - mae: 2.5161 - val_loss: 2.7188 - val_mae: 2.7188\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5034 - mae: 2.5034 - val_loss: 2.7235 - val_mae: 2.7235\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4951 - mae: 2.4951 - val_loss: 2.7030 - val_mae: 2.7030\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4727 - mae: 2.4727 - val_loss: 2.6962 - val_mae: 2.6962\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4738 - mae: 2.4738 - val_loss: 2.6994 - val_mae: 2.6994\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4701 - mae: 2.4701 - val_loss: 2.6527 - val_mae: 2.6527\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4474 - mae: 2.4474 - val_loss: 2.6377 - val_mae: 2.6377\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4387 - mae: 2.4387 - val_loss: 2.6263 - val_mae: 2.6263\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4456 - mae: 2.4456 - val_loss: 2.6399 - val_mae: 2.6399\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4155 - mae: 2.4155 - val_loss: 2.6138 - val_mae: 2.6138\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4050 - mae: 2.4050 - val_loss: 2.6258 - val_mae: 2.6258\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4158 - mae: 2.4158 - val_loss: 2.6031 - val_mae: 2.6031\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3906 - mae: 2.3906 - val_loss: 2.5822 - val_mae: 2.5822\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3894 - mae: 2.3894 - val_loss: 2.5731 - val_mae: 2.5731\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3756 - mae: 2.3756 - val_loss: 2.5729 - val_mae: 2.5729\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3657 - mae: 2.3657 - val_loss: 2.5628 - val_mae: 2.5628\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3578 - mae: 2.3578 - val_loss: 2.5356 - val_mae: 2.5356\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3522 - mae: 2.3522 - val_loss: 2.5425 - val_mae: 2.5425\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3373 - mae: 2.3373 - val_loss: 2.5197 - val_mae: 2.5197\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3344 - mae: 2.3344 - val_loss: 2.5133 - val_mae: 2.5133\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3313 - mae: 2.3313 - val_loss: 2.5111 - val_mae: 2.5111\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3215 - mae: 2.3215 - val_loss: 2.5104 - val_mae: 2.5104\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3146 - mae: 2.3146 - val_loss: 2.4844 - val_mae: 2.4844\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3087 - mae: 2.3087 - val_loss: 2.5030 - val_mae: 2.5030\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2978 - mae: 2.2978 - val_loss: 2.4789 - val_mae: 2.4789\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2941 - mae: 2.2941 - val_loss: 2.4739 - val_mae: 2.4739\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2810 - mae: 2.2810 - val_loss: 2.4751 - val_mae: 2.4751\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2874 - mae: 2.2874 - val_loss: 2.4949 - val_mae: 2.4949\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2740 - mae: 2.2740 - val_loss: 2.4714 - val_mae: 2.4714\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2694 - mae: 2.2694 - val_loss: 2.4705 - val_mae: 2.4705\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2629 - mae: 2.2629 - val_loss: 2.4460 - val_mae: 2.4460\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2545 - mae: 2.2545 - val_loss: 2.4497 - val_mae: 2.4497\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2530 - mae: 2.2530 - val_loss: 2.4395 - val_mae: 2.4395\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2365 - mae: 2.2365 - val_loss: 2.4472 - val_mae: 2.4472\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2399 - mae: 2.2399 - val_loss: 2.4329 - val_mae: 2.4329\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2312 - mae: 2.2312 - val_loss: 2.4244 - val_mae: 2.4244\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2268 - mae: 2.2268 - val_loss: 2.4263 - val_mae: 2.4263\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2133 - mae: 2.2133 - val_loss: 2.4206 - val_mae: 2.4206\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2172 - mae: 2.2172 - val_loss: 2.4037 - val_mae: 2.4037\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2127 - mae: 2.2127 - val_loss: 2.4180 - val_mae: 2.4180\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1991 - mae: 2.1991 - val_loss: 2.4344 - val_mae: 2.4344\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2024 - mae: 2.2024 - val_loss: 2.4023 - val_mae: 2.4023\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1892 - mae: 2.1892 - val_loss: 2.3927 - val_mae: 2.3927\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1865 - mae: 2.1865 - val_loss: 2.4137 - val_mae: 2.4137\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1864 - mae: 2.1864 - val_loss: 2.3960 - val_mae: 2.3960\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1827 - mae: 2.1827 - val_loss: 2.3926 - val_mae: 2.3926\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1734 - mae: 2.1734 - val_loss: 2.4211 - val_mae: 2.4211\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1742 - mae: 2.1742 - val_loss: 2.4010 - val_mae: 2.4010\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1680 - mae: 2.1680 - val_loss: 2.4074 - val_mae: 2.4074\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1555 - mae: 2.1555 - val_loss: 2.4019 - val_mae: 2.4019\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1672 - mae: 2.1672 - val_loss: 2.4169 - val_mae: 2.4169\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1635 - mae: 2.1635 - val_loss: 2.3964 - val_mae: 2.3964\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1489 - mae: 2.1489 - val_loss: 2.3952 - val_mae: 2.3952\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1414 - mae: 2.1414 - val_loss: 2.4052 - val_mae: 2.4052\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1350 - mae: 2.1350 - val_loss: 2.4065 - val_mae: 2.4065\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1268 - mae: 2.1268 - val_loss: 2.3882 - val_mae: 2.3882\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1240 - mae: 2.1240 - val_loss: 2.3926 - val_mae: 2.3926\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1170 - mae: 2.1170 - val_loss: 2.3826 - val_mae: 2.3826\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1185 - mae: 2.1185 - val_loss: 2.3921 - val_mae: 2.3921\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1113 - mae: 2.1113 - val_loss: 2.3848 - val_mae: 2.3848\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1141 - mae: 2.1141 - val_loss: 2.4004 - val_mae: 2.4004\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1113 - mae: 2.1113 - val_loss: 2.3911 - val_mae: 2.3911\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1175 - mae: 2.1175 - val_loss: 2.3866 - val_mae: 2.3866\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0922 - mae: 2.0922 - val_loss: 2.3773 - val_mae: 2.3773\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0945 - mae: 2.0945 - val_loss: 2.3756 - val_mae: 2.3756\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8544 - mae: 3.8544\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 476.4818 - mae: 19.9223 - val_loss: 365.5820 - val_mae: 16.8540\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 249.5735 - mae: 13.5347 - val_loss: 148.5730 - val_mae: 9.8227\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.8978 - mae: 7.7541 - val_loss: 70.5775 - val_mae: 6.4259\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0457 - mae: 5.4581 - val_loss: 50.1116 - val_mae: 5.2899\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.1917 - mae: 4.6353 - val_loss: 40.2352 - val_mae: 4.6496\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.5177 - mae: 4.1220 - val_loss: 34.4034 - val_mae: 4.2272\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5196 - mae: 3.8149 - val_loss: 30.9600 - val_mae: 3.9753\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.9548 - mae: 3.5894 - val_loss: 28.5326 - val_mae: 3.7983\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2827 - mae: 3.4362 - val_loss: 26.7247 - val_mae: 3.6517\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.9483 - mae: 3.3115 - val_loss: 25.2418 - val_mae: 3.5294\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.0892 - mae: 3.2122 - val_loss: 24.3288 - val_mae: 3.4840\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.2413 - mae: 3.1483 - val_loss: 23.5341 - val_mae: 3.4023\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.6207 - mae: 3.0776 - val_loss: 22.8643 - val_mae: 3.3509\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.1086 - mae: 3.0308 - val_loss: 22.2837 - val_mae: 3.3452\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.6716 - mae: 3.0030 - val_loss: 21.8804 - val_mae: 3.3160\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2334 - mae: 2.9423 - val_loss: 21.3683 - val_mae: 3.2627\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.9358 - mae: 2.9170 - val_loss: 21.0230 - val_mae: 3.2494\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6004 - mae: 2.8794 - val_loss: 20.5801 - val_mae: 3.2141\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2206 - mae: 2.8560 - val_loss: 20.3121 - val_mae: 3.2175\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9615 - mae: 2.8139 - val_loss: 19.9763 - val_mae: 3.1640\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.7572 - mae: 2.7908 - val_loss: 19.7021 - val_mae: 3.1529\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.4952 - mae: 2.7721 - val_loss: 19.4259 - val_mae: 3.1286\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2943 - mae: 2.7469 - val_loss: 19.3802 - val_mae: 3.1313\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.1063 - mae: 2.7306 - val_loss: 19.1111 - val_mae: 3.1114\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8357 - mae: 2.7029 - val_loss: 18.9048 - val_mae: 3.0683\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.6780 - mae: 2.6871 - val_loss: 18.7665 - val_mae: 3.0565\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5110 - mae: 2.6738 - val_loss: 18.6064 - val_mae: 3.0364\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3546 - mae: 2.6619 - val_loss: 18.3862 - val_mae: 3.0274\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1934 - mae: 2.6387 - val_loss: 18.3177 - val_mae: 3.0065\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0178 - mae: 2.6315 - val_loss: 18.1330 - val_mae: 3.0053\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.9593 - mae: 2.6173 - val_loss: 18.0099 - val_mae: 2.9963\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7468 - mae: 2.6093 - val_loss: 17.8934 - val_mae: 2.9733\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6631 - mae: 2.5922 - val_loss: 17.7540 - val_mae: 2.9691\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7433 - mae: 2.5729 - val_loss: 17.6147 - val_mae: 2.9382\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3419 - mae: 2.5710 - val_loss: 17.5046 - val_mae: 2.9364\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2711 - mae: 2.5616 - val_loss: 17.4617 - val_mae: 2.9277\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1244 - mae: 2.5440 - val_loss: 17.3237 - val_mae: 2.9016\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0212 - mae: 2.5481 - val_loss: 17.1922 - val_mae: 2.9001\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8978 - mae: 2.5206 - val_loss: 17.1478 - val_mae: 2.8911\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7951 - mae: 2.5130 - val_loss: 17.0073 - val_mae: 2.8713\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6931 - mae: 2.4984 - val_loss: 16.8488 - val_mae: 2.8512\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5704 - mae: 2.4977 - val_loss: 16.8546 - val_mae: 2.8655\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4792 - mae: 2.4812 - val_loss: 16.7490 - val_mae: 2.8432\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5457 - mae: 2.4907 - val_loss: 16.5789 - val_mae: 2.8198\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2758 - mae: 2.4606 - val_loss: 16.5254 - val_mae: 2.8218\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2387 - mae: 2.4524 - val_loss: 16.4673 - val_mae: 2.8229\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1026 - mae: 2.4491 - val_loss: 16.3866 - val_mae: 2.8026\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0428 - mae: 2.4428 - val_loss: 16.2694 - val_mae: 2.7834\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8881 - mae: 2.4306 - val_loss: 16.1784 - val_mae: 2.7899\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8701 - mae: 2.4378 - val_loss: 16.1947 - val_mae: 2.7865\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7710 - mae: 2.4232 - val_loss: 16.0793 - val_mae: 2.7716\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7816 - mae: 2.4093 - val_loss: 16.0034 - val_mae: 2.7624\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6207 - mae: 2.3974 - val_loss: 15.8761 - val_mae: 2.7428\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6516 - mae: 2.3928 - val_loss: 15.8879 - val_mae: 2.7596\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4966 - mae: 2.3918 - val_loss: 15.7642 - val_mae: 2.7403\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3727 - mae: 2.3802 - val_loss: 15.6771 - val_mae: 2.7264\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3574 - mae: 2.3760 - val_loss: 15.5938 - val_mae: 2.7247\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2352 - mae: 2.3643 - val_loss: 15.6208 - val_mae: 2.7222\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2039 - mae: 2.3636 - val_loss: 15.4631 - val_mae: 2.7132\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1666 - mae: 2.3470 - val_loss: 15.3779 - val_mae: 2.6885\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0298 - mae: 2.3501 - val_loss: 15.3376 - val_mae: 2.7026\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9775 - mae: 2.3504 - val_loss: 15.2854 - val_mae: 2.6934\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9396 - mae: 2.3345 - val_loss: 15.2443 - val_mae: 2.6792\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9078 - mae: 2.3338 - val_loss: 15.2732 - val_mae: 2.6902\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7790 - mae: 2.3236 - val_loss: 15.1947 - val_mae: 2.6736\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7414 - mae: 2.3029 - val_loss: 15.1375 - val_mae: 2.6666\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7122 - mae: 2.3155 - val_loss: 15.0303 - val_mae: 2.6640\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5885 - mae: 2.2887 - val_loss: 15.0237 - val_mae: 2.6565\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6338 - mae: 2.3134 - val_loss: 14.9854 - val_mae: 2.6568\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5117 - mae: 2.2813 - val_loss: 14.9808 - val_mae: 2.6472\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4770 - mae: 2.2925 - val_loss: 14.8121 - val_mae: 2.6521\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3752 - mae: 2.2864 - val_loss: 14.8341 - val_mae: 2.6450\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3095 - mae: 2.2659 - val_loss: 14.8008 - val_mae: 2.6473\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2433 - mae: 2.2558 - val_loss: 14.6739 - val_mae: 2.6343\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2046 - mae: 2.2673 - val_loss: 14.6438 - val_mae: 2.6447\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1645 - mae: 2.2494 - val_loss: 14.6927 - val_mae: 2.6379\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0775 - mae: 2.2506 - val_loss: 14.5605 - val_mae: 2.6253\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1204 - mae: 2.2525 - val_loss: 14.5401 - val_mae: 2.6322\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9470 - mae: 2.2352 - val_loss: 14.5486 - val_mae: 2.6242\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9756 - mae: 2.2510 - val_loss: 14.4487 - val_mae: 2.6259\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8913 - mae: 2.2337 - val_loss: 14.4216 - val_mae: 2.6098\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7917 - mae: 2.2140 - val_loss: 14.4116 - val_mae: 2.6156\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7407 - mae: 2.2115 - val_loss: 14.3601 - val_mae: 2.6024\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6927 - mae: 2.2088 - val_loss: 14.3500 - val_mae: 2.6106\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6685 - mae: 2.2101 - val_loss: 14.3071 - val_mae: 2.6023\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6684 - mae: 2.1940 - val_loss: 14.3129 - val_mae: 2.6056\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5992 - mae: 2.1989 - val_loss: 14.1875 - val_mae: 2.5965\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5251 - mae: 2.1948 - val_loss: 14.1612 - val_mae: 2.5988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4521 - mae: 2.1808 - val_loss: 14.1091 - val_mae: 2.5922\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3842 - mae: 2.1740 - val_loss: 14.1424 - val_mae: 2.5889\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3580 - mae: 2.1651 - val_loss: 14.0915 - val_mae: 2.5806\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3079 - mae: 2.1710 - val_loss: 13.9809 - val_mae: 2.5887\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2573 - mae: 2.1659 - val_loss: 13.9547 - val_mae: 2.5759\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2716 - mae: 2.1620 - val_loss: 13.9248 - val_mae: 2.5745\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2299 - mae: 2.1570 - val_loss: 13.8453 - val_mae: 2.5765\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0884 - mae: 2.1480 - val_loss: 13.8965 - val_mae: 2.5626\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1117 - mae: 2.1314 - val_loss: 13.8735 - val_mae: 2.5621\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0414 - mae: 2.1359 - val_loss: 13.7995 - val_mae: 2.5481\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9491 - mae: 2.1282 - val_loss: 13.8184 - val_mae: 2.5747\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9108 - mae: 2.1261 - val_loss: 13.7568 - val_mae: 2.5581\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5230 - mae: 3.8533\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.7179 - mae: 18.7179 - val_loss: 14.3231 - val_mae: 14.3231\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2259 - mae: 10.2259 - val_loss: 7.0010 - val_mae: 7.0010\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2974 - mae: 6.2974 - val_loss: 5.5274 - val_mae: 5.5274\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1525 - mae: 5.1525 - val_loss: 4.5345 - val_mae: 4.5345\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4272 - mae: 4.4272 - val_loss: 3.8494 - val_mae: 3.8494\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9715 - mae: 3.9715 - val_loss: 3.5263 - val_mae: 3.5263\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6950 - mae: 3.6950 - val_loss: 3.3411 - val_mae: 3.3411\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5011 - mae: 3.5011 - val_loss: 3.2671 - val_mae: 3.2671\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3707 - mae: 3.3707 - val_loss: 3.2402 - val_mae: 3.2402\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2761 - mae: 3.2761 - val_loss: 3.2182 - val_mae: 3.2182\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1734 - mae: 3.1734 - val_loss: 3.1668 - val_mae: 3.1668\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0944 - mae: 3.0944 - val_loss: 3.1206 - val_mae: 3.1206\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0252 - mae: 3.0252 - val_loss: 3.0443 - val_mae: 3.0443\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9605 - mae: 2.9605 - val_loss: 3.0296 - val_mae: 3.0296\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8938 - mae: 2.8938 - val_loss: 2.9866 - val_mae: 2.9866\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8455 - mae: 2.8455 - val_loss: 2.9677 - val_mae: 2.9677\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7977 - mae: 2.7977 - val_loss: 2.9247 - val_mae: 2.9247\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7536 - mae: 2.7536 - val_loss: 2.9090 - val_mae: 2.9090\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7262 - mae: 2.7262 - val_loss: 2.9053 - val_mae: 2.9053\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6853 - mae: 2.6853 - val_loss: 2.8480 - val_mae: 2.8480\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6578 - mae: 2.6578 - val_loss: 2.8543 - val_mae: 2.8543\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6238 - mae: 2.6238 - val_loss: 2.8423 - val_mae: 2.8423\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5789 - mae: 2.5789 - val_loss: 2.8489 - val_mae: 2.8489\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5749 - mae: 2.5749 - val_loss: 2.8140 - val_mae: 2.8140\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5537 - mae: 2.5537 - val_loss: 2.7986 - val_mae: 2.7986\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5110 - mae: 2.5110 - val_loss: 2.7990 - val_mae: 2.7990\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4937 - mae: 2.4937 - val_loss: 2.7843 - val_mae: 2.7843\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4763 - mae: 2.4763 - val_loss: 2.7668 - val_mae: 2.7668\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4635 - mae: 2.4635 - val_loss: 2.7702 - val_mae: 2.7702\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4369 - mae: 2.4369 - val_loss: 2.7655 - val_mae: 2.7655\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4366 - mae: 2.4366 - val_loss: 2.7492 - val_mae: 2.7492\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4155 - mae: 2.4155 - val_loss: 2.7560 - val_mae: 2.7560\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4024 - mae: 2.4024 - val_loss: 2.7234 - val_mae: 2.7234\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3848 - mae: 2.3848 - val_loss: 2.7075 - val_mae: 2.7075\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3840 - mae: 2.3840 - val_loss: 2.7262 - val_mae: 2.7262\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3699 - mae: 2.3699 - val_loss: 2.6901 - val_mae: 2.6901\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3596 - mae: 2.3596 - val_loss: 2.6885 - val_mae: 2.6885\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3530 - mae: 2.3530 - val_loss: 2.6636 - val_mae: 2.6636\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3262 - mae: 2.3262 - val_loss: 2.6741 - val_mae: 2.6741\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3226 - mae: 2.3226 - val_loss: 2.6571 - val_mae: 2.6571\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3109 - mae: 2.3109 - val_loss: 2.6571 - val_mae: 2.6571\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2952 - mae: 2.2952 - val_loss: 2.6505 - val_mae: 2.6505\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2850 - mae: 2.2850 - val_loss: 2.6501 - val_mae: 2.6501\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2794 - mae: 2.2794 - val_loss: 2.6355 - val_mae: 2.6355\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2677 - mae: 2.2677 - val_loss: 2.6356 - val_mae: 2.6356\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2711 - mae: 2.2711 - val_loss: 2.6345 - val_mae: 2.6345\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2659 - mae: 2.2659 - val_loss: 2.6039 - val_mae: 2.6039\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2517 - mae: 2.2517 - val_loss: 2.6181 - val_mae: 2.6181\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2412 - mae: 2.2412 - val_loss: 2.5949 - val_mae: 2.5949\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2389 - mae: 2.2389 - val_loss: 2.6005 - val_mae: 2.6005\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2181 - mae: 2.2181 - val_loss: 2.6013 - val_mae: 2.6013\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2292 - mae: 2.2292 - val_loss: 2.5934 - val_mae: 2.5934\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2172 - mae: 2.2172 - val_loss: 2.5924 - val_mae: 2.5924\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2138 - mae: 2.2138 - val_loss: 2.5723 - val_mae: 2.5723\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1968 - mae: 2.1968 - val_loss: 2.5567 - val_mae: 2.5567\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1857 - mae: 2.1857 - val_loss: 2.5487 - val_mae: 2.5487\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1977 - mae: 2.1977 - val_loss: 2.5631 - val_mae: 2.5631\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1827 - mae: 2.1827 - val_loss: 2.5496 - val_mae: 2.5496\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1693 - mae: 2.1693 - val_loss: 2.5621 - val_mae: 2.5621\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1745 - mae: 2.1745 - val_loss: 2.5407 - val_mae: 2.5407\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1644 - mae: 2.1644 - val_loss: 2.5414 - val_mae: 2.5414\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1606 - mae: 2.1606 - val_loss: 2.5479 - val_mae: 2.5479\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1566 - mae: 2.1566 - val_loss: 2.5271 - val_mae: 2.5271\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1544 - mae: 2.1544 - val_loss: 2.5290 - val_mae: 2.5290\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1425 - mae: 2.1425 - val_loss: 2.5328 - val_mae: 2.5328\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1470 - mae: 2.1470 - val_loss: 2.5240 - val_mae: 2.5240\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1399 - mae: 2.1399 - val_loss: 2.5239 - val_mae: 2.5239\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1319 - mae: 2.1319 - val_loss: 2.5217 - val_mae: 2.5217\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1251 - mae: 2.1251 - val_loss: 2.5239 - val_mae: 2.5239\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1152 - mae: 2.1152 - val_loss: 2.5108 - val_mae: 2.5108\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1164 - mae: 2.1164 - val_loss: 2.5205 - val_mae: 2.5205\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1117 - mae: 2.1117 - val_loss: 2.5348 - val_mae: 2.5348\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1136 - mae: 2.1136 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1021 - mae: 2.1021 - val_loss: 2.5121 - val_mae: 2.5121\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1042 - mae: 2.1042 - val_loss: 2.5134 - val_mae: 2.5134\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0907 - mae: 2.0907 - val_loss: 2.4992 - val_mae: 2.4992\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0861 - mae: 2.0861 - val_loss: 2.4930 - val_mae: 2.4930\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0942 - mae: 2.0942 - val_loss: 2.5083 - val_mae: 2.5083\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0817 - mae: 2.0817 - val_loss: 2.5054 - val_mae: 2.5054\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0855 - mae: 2.0855 - val_loss: 2.5101 - val_mae: 2.5101\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0909 - mae: 2.0909 - val_loss: 2.5038 - val_mae: 2.5038\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0774 - mae: 2.0774 - val_loss: 2.4974 - val_mae: 2.4974\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0611 - mae: 2.0611 - val_loss: 2.4803 - val_mae: 2.4803\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0704 - mae: 2.0704 - val_loss: 2.4815 - val_mae: 2.4815\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0595 - mae: 2.0595 - val_loss: 2.4879 - val_mae: 2.4879\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0604 - mae: 2.0604 - val_loss: 2.4951 - val_mae: 2.4951\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0507 - mae: 2.0507 - val_loss: 2.4782 - val_mae: 2.4782\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0482 - mae: 2.0482 - val_loss: 2.4967 - val_mae: 2.4967\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0399 - mae: 2.0399 - val_loss: 2.4849 - val_mae: 2.4849\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0351 - mae: 2.0351 - val_loss: 2.4841 - val_mae: 2.4841\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0324 - mae: 2.0324 - val_loss: 2.4783 - val_mae: 2.4783\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0386 - mae: 2.0386 - val_loss: 2.4792 - val_mae: 2.4792\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0309 - mae: 2.0309 - val_loss: 2.4869 - val_mae: 2.4869\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0236 - mae: 2.0236 - val_loss: 2.4905 - val_mae: 2.4905\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0276 - mae: 2.0276 - val_loss: 2.4851 - val_mae: 2.4851\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0177 - mae: 2.0177 - val_loss: 2.4848 - val_mae: 2.4848\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0183 - mae: 2.0183 - val_loss: 2.4876 - val_mae: 2.4876\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0222 - mae: 2.0222 - val_loss: 2.4822 - val_mae: 2.4822\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0065 - mae: 2.0065 - val_loss: 2.4963 - val_mae: 2.4963\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0065 - mae: 2.0065 - val_loss: 2.4750 - val_mae: 2.4750\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.9683 - mae: 3.9683\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 461.9847 - mae: 19.4602 - val_loss: 372.5602 - val_mae: 16.8678\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 320.4854 - mae: 15.5376 - val_loss: 295.2379 - val_mae: 14.4418\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 265.6489 - mae: 13.7599 - val_loss: 255.8393 - val_mae: 13.0630\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 233.1540 - mae: 12.6403 - val_loss: 229.2827 - val_mae: 12.0925\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 210.1882 - mae: 11.7670 - val_loss: 208.9352 - val_mae: 11.3106\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 191.9669 - mae: 11.0578 - val_loss: 192.6727 - val_mae: 10.6537\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 177.1687 - mae: 10.4421 - val_loss: 179.0090 - val_mae: 10.0919\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 164.7875 - mae: 9.9151 - val_loss: 167.7397 - val_mae: 9.6166\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 154.3399 - mae: 9.4689 - val_loss: 158.3522 - val_mae: 9.2280\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.4845 - mae: 9.0791 - val_loss: 149.7822 - val_mae: 8.8758\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 137.5520 - mae: 8.7342 - val_loss: 142.5165 - val_mae: 8.5740\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 130.6094 - mae: 8.4336 - val_loss: 135.7300 - val_mae: 8.3001\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 124.3224 - mae: 8.1570 - val_loss: 129.7930 - val_mae: 8.0619\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 118.6989 - mae: 7.9052 - val_loss: 124.3318 - val_mae: 7.8568\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 113.5394 - mae: 7.6717 - val_loss: 119.2295 - val_mae: 7.6620\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.9103 - mae: 7.4515 - val_loss: 114.9796 - val_mae: 7.4928\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 104.8922 - mae: 7.2692 - val_loss: 111.0724 - val_mae: 7.3413\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.3281 - mae: 7.0994 - val_loss: 107.6435 - val_mae: 7.2018\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.1296 - mae: 6.9426 - val_loss: 104.5248 - val_mae: 7.0785\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.2123 - mae: 6.7960 - val_loss: 101.6510 - val_mae: 6.9586\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.6126 - mae: 6.6627 - val_loss: 99.0425 - val_mae: 6.8429\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.2390 - mae: 6.5463 - val_loss: 96.6119 - val_mae: 6.7364\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.0312 - mae: 6.4365 - val_loss: 94.3679 - val_mae: 6.6373\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.9883 - mae: 6.3374 - val_loss: 92.1261 - val_mae: 6.5331\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.0039 - mae: 6.2434 - val_loss: 90.1787 - val_mae: 6.4365\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.1963 - mae: 6.1515 - val_loss: 88.3047 - val_mae: 6.3612\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4461 - mae: 6.0679 - val_loss: 86.4412 - val_mae: 6.2873\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.8072 - mae: 5.9855 - val_loss: 84.8388 - val_mae: 6.2155\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.2953 - mae: 5.9106 - val_loss: 83.1123 - val_mae: 6.1482\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.7806 - mae: 5.8430 - val_loss: 81.6213 - val_mae: 6.0925\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.3706 - mae: 5.7757 - val_loss: 80.1426 - val_mae: 6.0319\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.0307 - mae: 5.7123 - val_loss: 78.7223 - val_mae: 5.9806\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.7284 - mae: 5.6464 - val_loss: 77.4305 - val_mae: 5.9285\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.5060 - mae: 5.5869 - val_loss: 76.1326 - val_mae: 5.8854\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.3353 - mae: 5.5325 - val_loss: 74.9005 - val_mae: 5.8377\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.2483 - mae: 5.4819 - val_loss: 73.7618 - val_mae: 5.7932\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.1490 - mae: 5.4224 - val_loss: 72.6757 - val_mae: 5.7344\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.1311 - mae: 5.3685 - val_loss: 71.6555 - val_mae: 5.6883\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.1754 - mae: 5.3202 - val_loss: 70.7172 - val_mae: 5.6392\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.3199 - mae: 5.2859 - val_loss: 69.7281 - val_mae: 5.6025\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.4174 - mae: 5.2351 - val_loss: 68.8674 - val_mae: 5.5529\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.6150 - mae: 5.1981 - val_loss: 68.0392 - val_mae: 5.5219\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.8361 - mae: 5.1655 - val_loss: 67.2407 - val_mae: 5.4821\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.1041 - mae: 5.1271 - val_loss: 66.5582 - val_mae: 5.4422\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.4243 - mae: 5.0978 - val_loss: 65.8186 - val_mae: 5.4146\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.7554 - mae: 5.0713 - val_loss: 65.1676 - val_mae: 5.3756\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.1115 - mae: 5.0408 - val_loss: 64.5154 - val_mae: 5.3450\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.5019 - mae: 5.0202 - val_loss: 63.8750 - val_mae: 5.3151\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9107 - mae: 4.9934 - val_loss: 63.3057 - val_mae: 5.2872\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.3727 - mae: 4.9718 - val_loss: 62.7591 - val_mae: 5.2583\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.8418 - mae: 4.9527 - val_loss: 62.1975 - val_mae: 5.2432\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.3580 - mae: 4.9381 - val_loss: 61.6427 - val_mae: 5.2249\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.8356 - mae: 4.9155 - val_loss: 61.1692 - val_mae: 5.1922\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.3981 - mae: 4.8951 - val_loss: 60.7015 - val_mae: 5.1601\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.9447 - mae: 4.8760 - val_loss: 60.2709 - val_mae: 5.1486\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.5178 - mae: 4.8761 - val_loss: 59.8129 - val_mae: 5.1373\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.1072 - mae: 4.8674 - val_loss: 59.3764 - val_mae: 5.1212\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.6991 - mae: 4.8399 - val_loss: 59.0095 - val_mae: 5.0869\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.3203 - mae: 4.8227 - val_loss: 58.5743 - val_mae: 5.0751\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.9263 - mae: 4.8198 - val_loss: 58.2052 - val_mae: 5.0661\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.5700 - mae: 4.8056 - val_loss: 57.8449 - val_mae: 5.0441\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.2066 - mae: 4.7814 - val_loss: 57.4658 - val_mae: 5.0254\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.8481 - mae: 4.7685 - val_loss: 57.1149 - val_mae: 4.9981\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.5027 - mae: 4.7536 - val_loss: 56.7548 - val_mae: 4.9897\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.1727 - mae: 4.7510 - val_loss: 56.4083 - val_mae: 4.9808\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.8387 - mae: 4.7288 - val_loss: 56.0983 - val_mae: 4.9692\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.5257 - mae: 4.7089 - val_loss: 55.7941 - val_mae: 4.9372\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.1953 - mae: 4.7050 - val_loss: 55.4350 - val_mae: 4.9434\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.8563 - mae: 4.6922 - val_loss: 55.1152 - val_mae: 4.9375\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.5411 - mae: 4.6721 - val_loss: 54.7994 - val_mae: 4.9089\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.2271 - mae: 4.6511 - val_loss: 54.5024 - val_mae: 4.8866\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8991 - mae: 4.6515 - val_loss: 54.1829 - val_mae: 4.8899\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6092 - mae: 4.6399 - val_loss: 53.8535 - val_mae: 4.8829\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 48.2683 - mae: 4.6247 - val_loss: 53.5591 - val_mae: 4.8572\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.9585 - mae: 4.6098 - val_loss: 53.2715 - val_mae: 4.8262\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.6383 - mae: 4.5839 - val_loss: 52.9649 - val_mae: 4.8131\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3147 - mae: 4.5657 - val_loss: 52.6476 - val_mae: 4.8042\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0007 - mae: 4.5630 - val_loss: 52.3313 - val_mae: 4.7824\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.6854 - mae: 4.5263 - val_loss: 52.0160 - val_mae: 4.7703\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3678 - mae: 4.5328 - val_loss: 51.7059 - val_mae: 4.7832\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0893 - mae: 4.4977 - val_loss: 51.4115 - val_mae: 4.7475\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.7227 - mae: 4.5054 - val_loss: 51.0733 - val_mae: 4.7598\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.3856 - mae: 4.4788 - val_loss: 50.8051 - val_mae: 4.7088\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.1037 - mae: 4.4818 - val_loss: 50.4746 - val_mae: 4.7101\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7410 - mae: 4.4293 - val_loss: 50.1853 - val_mae: 4.6745\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.3779 - mae: 4.4376 - val_loss: 49.8422 - val_mae: 4.6853\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0907 - mae: 4.4183 - val_loss: 49.5417 - val_mae: 4.6350\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.7287 - mae: 4.3961 - val_loss: 49.2134 - val_mae: 4.6274\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.3640 - mae: 4.3633 - val_loss: 48.9150 - val_mae: 4.5980\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0398 - mae: 4.3482 - val_loss: 48.5649 - val_mae: 4.5895\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6768 - mae: 4.3353 - val_loss: 48.2612 - val_mae: 4.5785\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3908 - mae: 4.3261 - val_loss: 47.9359 - val_mae: 4.5540\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0033 - mae: 4.2844 - val_loss: 47.6342 - val_mae: 4.5254\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.7518 - mae: 4.2890 - val_loss: 47.2920 - val_mae: 4.5483\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.3033 - mae: 4.2556 - val_loss: 47.0090 - val_mae: 4.4821\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.0354 - mae: 4.2356 - val_loss: 46.6818 - val_mae: 4.4531\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7045 - mae: 4.1816 - val_loss: 46.3683 - val_mae: 4.4669\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.3219 - mae: 4.2041 - val_loss: 46.0477 - val_mae: 4.4608\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9795 - mae: 4.1543 - val_loss: 45.7977 - val_mae: 4.4030\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.6548 - mae: 4.1451 - val_loss: 45.4760 - val_mae: 4.4188\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 63.6351 - mae: 5.0686\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.4887 - mae: 18.4887 - val_loss: 15.4465 - val_mae: 15.4465\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0260 - mae: 14.0260 - val_loss: 12.8400 - val_mae: 12.8400\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1870 - mae: 12.1870 - val_loss: 11.4725 - val_mae: 11.4725\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0610 - mae: 11.0610 - val_loss: 10.5348 - val_mae: 10.5348\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2008 - mae: 10.2008 - val_loss: 9.7672 - val_mae: 9.7672\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4901 - mae: 9.4901 - val_loss: 9.1728 - val_mae: 9.1728\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9396 - mae: 8.9396 - val_loss: 8.7071 - val_mae: 8.7071\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5044 - mae: 8.5044 - val_loss: 8.3391 - val_mae: 8.3391\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1480 - mae: 8.1480 - val_loss: 8.0499 - val_mae: 8.0499\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8365 - mae: 7.8365 - val_loss: 7.7974 - val_mae: 7.7974\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5574 - mae: 7.5574 - val_loss: 7.5692 - val_mae: 7.5692\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3129 - mae: 7.3129 - val_loss: 7.3643 - val_mae: 7.3643\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0801 - mae: 7.0801 - val_loss: 7.1811 - val_mae: 7.1811\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8657 - mae: 6.8657 - val_loss: 7.0127 - val_mae: 7.0127\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6690 - mae: 6.6690 - val_loss: 6.8458 - val_mae: 6.8458\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5108 - mae: 6.5108 - val_loss: 6.7031 - val_mae: 6.7031\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3771 - mae: 6.3771 - val_loss: 6.5710 - val_mae: 6.5710\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2541 - mae: 6.2541 - val_loss: 6.4407 - val_mae: 6.4407\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1351 - mae: 6.1351 - val_loss: 6.3231 - val_mae: 6.3231\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0224 - mae: 6.0224 - val_loss: 6.2210 - val_mae: 6.2210\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9162 - mae: 5.9162 - val_loss: 6.1123 - val_mae: 6.1123\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8125 - mae: 5.8125 - val_loss: 6.0083 - val_mae: 6.0083\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7183 - mae: 5.7183 - val_loss: 5.9064 - val_mae: 5.9064\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6322 - mae: 5.6322 - val_loss: 5.8151 - val_mae: 5.8151\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5501 - mae: 5.5501 - val_loss: 5.7178 - val_mae: 5.7178\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4694 - mae: 5.4694 - val_loss: 5.6375 - val_mae: 5.6375\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3945 - mae: 5.3945 - val_loss: 5.5535 - val_mae: 5.5535\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3308 - mae: 5.3308 - val_loss: 5.4701 - val_mae: 5.4701\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2614 - mae: 5.2614 - val_loss: 5.4036 - val_mae: 5.4036\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2012 - mae: 5.2012 - val_loss: 5.3410 - val_mae: 5.3410\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1417 - mae: 5.1417 - val_loss: 5.2809 - val_mae: 5.2809\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0893 - mae: 5.0893 - val_loss: 5.2281 - val_mae: 5.2281\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0405 - mae: 5.0405 - val_loss: 5.1753 - val_mae: 5.1753\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9915 - mae: 4.9915 - val_loss: 5.1030 - val_mae: 5.1030\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9468 - mae: 4.9468 - val_loss: 5.0491 - val_mae: 5.0491\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9102 - mae: 4.9102 - val_loss: 5.0137 - val_mae: 5.0137\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8693 - mae: 4.8693 - val_loss: 4.9416 - val_mae: 4.9416\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8347 - mae: 4.8347 - val_loss: 4.9065 - val_mae: 4.9065\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8019 - mae: 4.8019 - val_loss: 4.8717 - val_mae: 4.8717\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7724 - mae: 4.7724 - val_loss: 4.8341 - val_mae: 4.8341\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7479 - mae: 4.7479 - val_loss: 4.8159 - val_mae: 4.8159\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7161 - mae: 4.7161 - val_loss: 4.7744 - val_mae: 4.7744\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6948 - mae: 4.6948 - val_loss: 4.7611 - val_mae: 4.7611\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6744 - mae: 4.6744 - val_loss: 4.7333 - val_mae: 4.7333\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6501 - mae: 4.6501 - val_loss: 4.7056 - val_mae: 4.7056\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6275 - mae: 4.6275 - val_loss: 4.6895 - val_mae: 4.6895\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6076 - mae: 4.6076 - val_loss: 4.6720 - val_mae: 4.6720\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5868 - mae: 4.5868 - val_loss: 4.6560 - val_mae: 4.6560\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5726 - mae: 4.5726 - val_loss: 4.6420 - val_mae: 4.6420\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5524 - mae: 4.5524 - val_loss: 4.6321 - val_mae: 4.6321\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5359 - mae: 4.5359 - val_loss: 4.6244 - val_mae: 4.6244\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5208 - mae: 4.5208 - val_loss: 4.6072 - val_mae: 4.6072\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5057 - mae: 4.5057 - val_loss: 4.5929 - val_mae: 4.5929\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4901 - mae: 4.4901 - val_loss: 4.5720 - val_mae: 4.5720\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4743 - mae: 4.4743 - val_loss: 4.5661 - val_mae: 4.5661\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4565 - mae: 4.4565 - val_loss: 4.5429 - val_mae: 4.5429\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4486 - mae: 4.4486 - val_loss: 4.5274 - val_mae: 4.5274\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4256 - mae: 4.4256 - val_loss: 4.5256 - val_mae: 4.5256\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4124 - mae: 4.4124 - val_loss: 4.5135 - val_mae: 4.5135\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4006 - mae: 4.4006 - val_loss: 4.4991 - val_mae: 4.4991\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3865 - mae: 4.3865 - val_loss: 4.4881 - val_mae: 4.4881\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3721 - mae: 4.3721 - val_loss: 4.4769 - val_mae: 4.4769\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3573 - mae: 4.3573 - val_loss: 4.4651 - val_mae: 4.4651\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3430 - mae: 4.3430 - val_loss: 4.4547 - val_mae: 4.4547\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3304 - mae: 4.3304 - val_loss: 4.4404 - val_mae: 4.4404\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3126 - mae: 4.3126 - val_loss: 4.4326 - val_mae: 4.4326\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2997 - mae: 4.2997 - val_loss: 4.4243 - val_mae: 4.4243\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2854 - mae: 4.2854 - val_loss: 4.4108 - val_mae: 4.4108\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2692 - mae: 4.2692 - val_loss: 4.4016 - val_mae: 4.4016\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2557 - mae: 4.2557 - val_loss: 4.3922 - val_mae: 4.3922\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2485 - mae: 4.2485 - val_loss: 4.3863 - val_mae: 4.3863\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2311 - mae: 4.2311 - val_loss: 4.3756 - val_mae: 4.3756\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2149 - mae: 4.2149 - val_loss: 4.3706 - val_mae: 4.3706\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1994 - mae: 4.1994 - val_loss: 4.3633 - val_mae: 4.3633\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1880 - mae: 4.1880 - val_loss: 4.3547 - val_mae: 4.3547\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1705 - mae: 4.1705 - val_loss: 4.3481 - val_mae: 4.3481\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1560 - mae: 4.1560 - val_loss: 4.3424 - val_mae: 4.3424\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1444 - mae: 4.1444 - val_loss: 4.3344 - val_mae: 4.3344\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1317 - mae: 4.1317 - val_loss: 4.3295 - val_mae: 4.3295\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1176 - mae: 4.1176 - val_loss: 4.3215 - val_mae: 4.3215\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1051 - mae: 4.1051 - val_loss: 4.3130 - val_mae: 4.3130\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0903 - mae: 4.0903 - val_loss: 4.3047 - val_mae: 4.3047\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0781 - mae: 4.0781 - val_loss: 4.2978 - val_mae: 4.2978\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0678 - mae: 4.0678 - val_loss: 4.2895 - val_mae: 4.2895\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0578 - mae: 4.0578 - val_loss: 4.2817 - val_mae: 4.2817\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0483 - mae: 4.0483 - val_loss: 4.2757 - val_mae: 4.2757\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0371 - mae: 4.0371 - val_loss: 4.2688 - val_mae: 4.2688\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0311 - mae: 4.0311 - val_loss: 4.2607 - val_mae: 4.2607\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0196 - mae: 4.0196 - val_loss: 4.2532 - val_mae: 4.2532\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0132 - mae: 4.0132 - val_loss: 4.2474 - val_mae: 4.2474\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0002 - mae: 4.0002 - val_loss: 4.2385 - val_mae: 4.2385\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9933 - mae: 3.9933 - val_loss: 4.2297 - val_mae: 4.2297\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9840 - mae: 3.9840 - val_loss: 4.2213 - val_mae: 4.2213\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9745 - mae: 3.9745 - val_loss: 4.2130 - val_mae: 4.2130\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9646 - mae: 3.9646 - val_loss: 4.2095 - val_mae: 4.2095\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9552 - mae: 3.9552 - val_loss: 4.2043 - val_mae: 4.2043\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9464 - mae: 3.9464 - val_loss: 4.1997 - val_mae: 4.1997\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9367 - mae: 3.9367 - val_loss: 4.1901 - val_mae: 4.1901\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9288 - mae: 3.9288 - val_loss: 4.1863 - val_mae: 4.1863\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9225 - mae: 3.9225 - val_loss: 4.1763 - val_mae: 4.1763\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3898 - mae: 5.3898\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 435.3991 - mae: 18.8218 - val_loss: 347.2845 - val_mae: 16.1160\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 298.3364 - mae: 14.8734 - val_loss: 277.2118 - val_mae: 13.8220\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 249.0509 - mae: 13.2240 - val_loss: 241.3550 - val_mae: 12.5335\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 219.9557 - mae: 12.1295 - val_loss: 216.2753 - val_mae: 11.5881\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 198.1273 - mae: 11.2846 - val_loss: 197.2782 - val_mae: 10.8317\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 180.6413 - mae: 10.5808 - val_loss: 181.4435 - val_mae: 10.1789\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 166.5152 - mae: 9.9830 - val_loss: 168.7555 - val_mae: 9.6462\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 154.8035 - mae: 9.4861 - val_loss: 158.2139 - val_mae: 9.2066\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.0629 - mae: 9.0532 - val_loss: 149.0571 - val_mae: 8.8300\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 136.7662 - mae: 8.6857 - val_loss: 141.1443 - val_mae: 8.5022\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 129.5760 - mae: 8.3678 - val_loss: 134.4457 - val_mae: 8.2307\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 123.3523 - mae: 8.1060 - val_loss: 128.6775 - val_mae: 8.0011\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 117.9269 - mae: 7.8654 - val_loss: 123.5980 - val_mae: 7.8116\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 113.1539 - mae: 7.6496 - val_loss: 118.9846 - val_mae: 7.6339\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.8905 - mae: 7.4508 - val_loss: 114.9497 - val_mae: 7.4729\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.0819 - mae: 7.2729 - val_loss: 111.1874 - val_mae: 7.3282\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.6345 - mae: 7.1030 - val_loss: 107.7480 - val_mae: 7.1903\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.5461 - mae: 6.9503 - val_loss: 104.8386 - val_mae: 7.0746\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.8051 - mae: 6.8161 - val_loss: 101.8649 - val_mae: 6.9524\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.1576 - mae: 6.6843 - val_loss: 99.3663 - val_mae: 6.8393\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.7721 - mae: 6.5656 - val_loss: 96.9001 - val_mae: 6.7281\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.5474 - mae: 6.4510 - val_loss: 94.5570 - val_mae: 6.6259\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.3941 - mae: 6.3473 - val_loss: 92.4336 - val_mae: 6.5258\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.3761 - mae: 6.2513 - val_loss: 90.3795 - val_mae: 6.4278\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.5372 - mae: 6.1638 - val_loss: 88.4155 - val_mae: 6.3471\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.7837 - mae: 6.0750 - val_loss: 86.6606 - val_mae: 6.2779\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.1632 - mae: 5.9966 - val_loss: 84.9073 - val_mae: 6.2095\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.5935 - mae: 5.9210 - val_loss: 83.3279 - val_mae: 6.1451\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.1439 - mae: 5.8543 - val_loss: 81.7676 - val_mae: 6.0814\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.7553 - mae: 5.7845 - val_loss: 80.3032 - val_mae: 6.0263\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.3983 - mae: 5.7193 - val_loss: 78.9546 - val_mae: 5.9717\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.1387 - mae: 5.6605 - val_loss: 77.5878 - val_mae: 5.9226\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.9084 - mae: 5.6004 - val_loss: 76.2935 - val_mae: 5.8716\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.7255 - mae: 5.5437 - val_loss: 75.0860 - val_mae: 5.8296\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.6054 - mae: 5.4833 - val_loss: 73.9581 - val_mae: 5.7761\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5345 - mae: 5.4331 - val_loss: 72.9268 - val_mae: 5.7325\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.5620 - mae: 5.3799 - val_loss: 71.8118 - val_mae: 5.6813\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5777 - mae: 5.3349 - val_loss: 70.8263 - val_mae: 5.6411\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6524 - mae: 5.2869 - val_loss: 69.9154 - val_mae: 5.5957\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.8311 - mae: 5.2567 - val_loss: 69.0403 - val_mae: 5.5695\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.9818 - mae: 5.2094 - val_loss: 68.2090 - val_mae: 5.5233\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.1983 - mae: 5.1714 - val_loss: 67.4173 - val_mae: 5.4756\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.4647 - mae: 5.1391 - val_loss: 66.6763 - val_mae: 5.4435\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.7659 - mae: 5.1037 - val_loss: 65.9913 - val_mae: 5.4036\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.1117 - mae: 5.0722 - val_loss: 65.3017 - val_mae: 5.3676\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4763 - mae: 5.0500 - val_loss: 64.6574 - val_mae: 5.3430\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.8576 - mae: 5.0178 - val_loss: 64.0631 - val_mae: 5.3080\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.2863 - mae: 4.9969 - val_loss: 63.4408 - val_mae: 5.2710\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.7272 - mae: 4.9768 - val_loss: 62.8524 - val_mae: 5.2508\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.1905 - mae: 4.9471 - val_loss: 62.3354 - val_mae: 5.2207\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.6819 - mae: 4.9329 - val_loss: 61.8448 - val_mae: 5.2069\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.1897 - mae: 4.9137 - val_loss: 61.3318 - val_mae: 5.1833\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.7282 - mae: 4.9022 - val_loss: 60.8675 - val_mae: 5.1640\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2925 - mae: 4.8817 - val_loss: 60.4164 - val_mae: 5.1410\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.8509 - mae: 4.8610 - val_loss: 59.9826 - val_mae: 5.1200\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.4381 - mae: 4.8589 - val_loss: 59.5214 - val_mae: 5.1145\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 53.9987 - mae: 4.8444 - val_loss: 59.1131 - val_mae: 5.0916\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.5998 - mae: 4.8190 - val_loss: 58.7146 - val_mae: 5.0552\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2659 - mae: 4.8157 - val_loss: 58.3378 - val_mae: 5.0426\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.8552 - mae: 4.7920 - val_loss: 57.9370 - val_mae: 5.0192\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.5061 - mae: 4.7570 - val_loss: 57.6157 - val_mae: 4.9920\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.1332 - mae: 4.7644 - val_loss: 57.1938 - val_mae: 4.9990\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7848 - mae: 4.7405 - val_loss: 56.8739 - val_mae: 4.9548\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4123 - mae: 4.7294 - val_loss: 56.5053 - val_mae: 4.9618\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.1080 - mae: 4.7200 - val_loss: 56.1745 - val_mae: 4.9613\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.7409 - mae: 4.7095 - val_loss: 55.8426 - val_mae: 4.9431\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.3965 - mae: 4.6986 - val_loss: 55.5442 - val_mae: 4.9130\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0652 - mae: 4.6653 - val_loss: 55.2085 - val_mae: 4.9015\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7258 - mae: 4.6615 - val_loss: 54.8708 - val_mae: 4.8953\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.3995 - mae: 4.6612 - val_loss: 54.5317 - val_mae: 4.8864\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.0873 - mae: 4.6538 - val_loss: 54.1886 - val_mae: 4.8884\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.7754 - mae: 4.6216 - val_loss: 53.9106 - val_mae: 4.8492\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4556 - mae: 4.6147 - val_loss: 53.6076 - val_mae: 4.8235\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1105 - mae: 4.5905 - val_loss: 53.2816 - val_mae: 4.8239\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7807 - mae: 4.5860 - val_loss: 52.9864 - val_mae: 4.8077\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.4544 - mae: 4.5621 - val_loss: 52.6784 - val_mae: 4.7894\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1587 - mae: 4.5403 - val_loss: 52.4097 - val_mae: 4.7565\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8160 - mae: 4.5311 - val_loss: 52.0730 - val_mae: 4.7580\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.4922 - mae: 4.5275 - val_loss: 51.7429 - val_mae: 4.7585\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.1873 - mae: 4.4853 - val_loss: 51.4518 - val_mae: 4.7183\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.8357 - mae: 4.4785 - val_loss: 51.1709 - val_mae: 4.7135\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5377 - mae: 4.4905 - val_loss: 50.8191 - val_mae: 4.7172\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.2178 - mae: 4.4410 - val_loss: 50.5383 - val_mae: 4.6758\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.8356 - mae: 4.4277 - val_loss: 50.2500 - val_mae: 4.6633\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.5436 - mae: 4.4123 - val_loss: 49.9054 - val_mae: 4.6626\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1706 - mae: 4.3952 - val_loss: 49.6228 - val_mae: 4.6317\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8177 - mae: 4.3751 - val_loss: 49.2953 - val_mae: 4.6135\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.4940 - mae: 4.3486 - val_loss: 48.9916 - val_mae: 4.5995\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1749 - mae: 4.3725 - val_loss: 48.6580 - val_mae: 4.5996\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.8061 - mae: 4.3368 - val_loss: 48.3551 - val_mae: 4.5749\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4598 - mae: 4.2977 - val_loss: 48.0896 - val_mae: 4.5380\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.1210 - mae: 4.2754 - val_loss: 47.7502 - val_mae: 4.5282\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.7688 - mae: 4.2671 - val_loss: 47.4272 - val_mae: 4.5245\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4788 - mae: 4.2566 - val_loss: 47.1288 - val_mae: 4.5370\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.1183 - mae: 4.2433 - val_loss: 46.8236 - val_mae: 4.5053\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7762 - mae: 4.2228 - val_loss: 46.5820 - val_mae: 4.4494\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.4696 - mae: 4.1780 - val_loss: 46.2773 - val_mae: 4.4311\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1304 - mae: 4.1633 - val_loss: 45.9769 - val_mae: 4.4376\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8117 - mae: 4.1399 - val_loss: 45.6804 - val_mae: 4.4297\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.4835 - mae: 4.1368 - val_loss: 45.3970 - val_mae: 4.4057\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 63.8246 - mae: 5.1250\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.6723 - mae: 18.6723 - val_loss: 15.7250 - val_mae: 15.7250\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.3194 - mae: 14.3194 - val_loss: 13.1032 - val_mae: 13.1032\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4397 - mae: 12.4397 - val_loss: 11.7068 - val_mae: 11.7068\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2604 - mae: 11.2604 - val_loss: 10.7172 - val_mae: 10.7172\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3949 - mae: 10.3949 - val_loss: 9.9786 - val_mae: 9.9786\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7101 - mae: 9.7101 - val_loss: 9.3777 - val_mae: 9.3777\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1479 - mae: 9.1479 - val_loss: 8.9130 - val_mae: 8.9130\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6922 - mae: 8.6922 - val_loss: 8.5072 - val_mae: 8.5072\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3072 - mae: 8.3072 - val_loss: 8.1908 - val_mae: 8.1908\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9851 - mae: 7.9851 - val_loss: 7.9398 - val_mae: 7.9398\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7031 - mae: 7.7031 - val_loss: 7.7164 - val_mae: 7.7164\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4553 - mae: 7.4553 - val_loss: 7.5125 - val_mae: 7.5125\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2289 - mae: 7.2289 - val_loss: 7.3354 - val_mae: 7.3354\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0273 - mae: 7.0273 - val_loss: 7.1791 - val_mae: 7.1791\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8457 - mae: 6.8457 - val_loss: 7.0292 - val_mae: 7.0292\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6767 - mae: 6.6767 - val_loss: 6.8812 - val_mae: 6.8812\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5371 - mae: 6.5371 - val_loss: 6.7525 - val_mae: 6.7525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4090 - mae: 6.4090 - val_loss: 6.6248 - val_mae: 6.6248\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2896 - mae: 6.2896 - val_loss: 6.4946 - val_mae: 6.4946\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1743 - mae: 6.1743 - val_loss: 6.3678 - val_mae: 6.3678\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0596 - mae: 6.0596 - val_loss: 6.2471 - val_mae: 6.2471\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9466 - mae: 5.9466 - val_loss: 6.1295 - val_mae: 6.1295\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8407 - mae: 5.8407 - val_loss: 6.0229 - val_mae: 6.0229\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7405 - mae: 5.7405 - val_loss: 5.9135 - val_mae: 5.9135\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6453 - mae: 5.6453 - val_loss: 5.8050 - val_mae: 5.8050\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5631 - mae: 5.5631 - val_loss: 5.7137 - val_mae: 5.7137\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4825 - mae: 5.4825 - val_loss: 5.6309 - val_mae: 5.6309\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4068 - mae: 5.4068 - val_loss: 5.5425 - val_mae: 5.5425\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3352 - mae: 5.3352 - val_loss: 5.4721 - val_mae: 5.4721\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2692 - mae: 5.2692 - val_loss: 5.4119 - val_mae: 5.4119\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2067 - mae: 5.2067 - val_loss: 5.3425 - val_mae: 5.3425\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1477 - mae: 5.1477 - val_loss: 5.2994 - val_mae: 5.2994\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0933 - mae: 5.0933 - val_loss: 5.2149 - val_mae: 5.2149\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0417 - mae: 5.0417 - val_loss: 5.1597 - val_mae: 5.1597\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9899 - mae: 4.9899 - val_loss: 5.1063 - val_mae: 5.1063\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9434 - mae: 4.9434 - val_loss: 5.0455 - val_mae: 5.0455\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9036 - mae: 4.9036 - val_loss: 5.0044 - val_mae: 5.0044\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8696 - mae: 4.8696 - val_loss: 4.9621 - val_mae: 4.9621\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8358 - mae: 4.8358 - val_loss: 4.9182 - val_mae: 4.9182\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8042 - mae: 4.8042 - val_loss: 4.8867 - val_mae: 4.8867\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7740 - mae: 4.7740 - val_loss: 4.8540 - val_mae: 4.8540\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7447 - mae: 4.7447 - val_loss: 4.8176 - val_mae: 4.8176\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7180 - mae: 4.7180 - val_loss: 4.8026 - val_mae: 4.8026\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6974 - mae: 4.6974 - val_loss: 4.7732 - val_mae: 4.7732\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6743 - mae: 4.6743 - val_loss: 4.7545 - val_mae: 4.7545\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6503 - mae: 4.6503 - val_loss: 4.7361 - val_mae: 4.7361\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6317 - mae: 4.6317 - val_loss: 4.7105 - val_mae: 4.7105\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6091 - mae: 4.6091 - val_loss: 4.6971 - val_mae: 4.6971\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5925 - mae: 4.5925 - val_loss: 4.6805 - val_mae: 4.6805\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5744 - mae: 4.5744 - val_loss: 4.6652 - val_mae: 4.6652\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5577 - mae: 4.5577 - val_loss: 4.6570 - val_mae: 4.6570\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5403 - mae: 4.5403 - val_loss: 4.6413 - val_mae: 4.6413\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5238 - mae: 4.5238 - val_loss: 4.6359 - val_mae: 4.6359\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5119 - mae: 4.5119 - val_loss: 4.6180 - val_mae: 4.6180\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4985 - mae: 4.4985 - val_loss: 4.6034 - val_mae: 4.6034\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4831 - mae: 4.4831 - val_loss: 4.6024 - val_mae: 4.6024\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4650 - mae: 4.4650 - val_loss: 4.5734 - val_mae: 4.5734\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4551 - mae: 4.4551 - val_loss: 4.5731 - val_mae: 4.5731\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4344 - mae: 4.4344 - val_loss: 4.5541 - val_mae: 4.5541\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4206 - mae: 4.4206 - val_loss: 4.5388 - val_mae: 4.5388\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4058 - mae: 4.4058 - val_loss: 4.5326 - val_mae: 4.5326\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3948 - mae: 4.3948 - val_loss: 4.5207 - val_mae: 4.5207\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3797 - mae: 4.3797 - val_loss: 4.5105 - val_mae: 4.5105\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3663 - mae: 4.3663 - val_loss: 4.5002 - val_mae: 4.5002\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3568 - mae: 4.3568 - val_loss: 4.4909 - val_mae: 4.4909\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3451 - mae: 4.3451 - val_loss: 4.4787 - val_mae: 4.4787\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3258 - mae: 4.3258 - val_loss: 4.4778 - val_mae: 4.4778\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3140 - mae: 4.3140 - val_loss: 4.4652 - val_mae: 4.4652\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2999 - mae: 4.2999 - val_loss: 4.4493 - val_mae: 4.4493\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2897 - mae: 4.2897 - val_loss: 4.4391 - val_mae: 4.4391\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2703 - mae: 4.2703 - val_loss: 4.4275 - val_mae: 4.4275\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2577 - mae: 4.2577 - val_loss: 4.4179 - val_mae: 4.4179\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2432 - mae: 4.2432 - val_loss: 4.4114 - val_mae: 4.4114\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2301 - mae: 4.2301 - val_loss: 4.4043 - val_mae: 4.4043\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2208 - mae: 4.2208 - val_loss: 4.3954 - val_mae: 4.3954\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2032 - mae: 4.2032 - val_loss: 4.3887 - val_mae: 4.3887\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1898 - mae: 4.1898 - val_loss: 4.3811 - val_mae: 4.3811\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1746 - mae: 4.1746 - val_loss: 4.3759 - val_mae: 4.3759\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1634 - mae: 4.1634 - val_loss: 4.3686 - val_mae: 4.3686\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1492 - mae: 4.1492 - val_loss: 4.3623 - val_mae: 4.3623\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1356 - mae: 4.1356 - val_loss: 4.3543 - val_mae: 4.3543\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1208 - mae: 4.1208 - val_loss: 4.3475 - val_mae: 4.3475\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1077 - mae: 4.1077 - val_loss: 4.3413 - val_mae: 4.3413\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0998 - mae: 4.0998 - val_loss: 4.3340 - val_mae: 4.3340\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0846 - mae: 4.0846 - val_loss: 4.3286 - val_mae: 4.3286\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0796 - mae: 4.0796 - val_loss: 4.3237 - val_mae: 4.3237\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0722 - mae: 4.0722 - val_loss: 4.3115 - val_mae: 4.3115\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0583 - mae: 4.0583 - val_loss: 4.3103 - val_mae: 4.3103\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0469 - mae: 4.0469 - val_loss: 4.3009 - val_mae: 4.3009\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0406 - mae: 4.0406 - val_loss: 4.2934 - val_mae: 4.2934\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0333 - mae: 4.0333 - val_loss: 4.2857 - val_mae: 4.2857\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0210 - mae: 4.0210 - val_loss: 4.2795 - val_mae: 4.2795\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0148 - mae: 4.0148 - val_loss: 4.2720 - val_mae: 4.2720\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0034 - mae: 4.0034 - val_loss: 4.2630 - val_mae: 4.2630\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9997 - mae: 3.9997 - val_loss: 4.2557 - val_mae: 4.2557\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9871 - mae: 3.9871 - val_loss: 4.2450 - val_mae: 4.2450\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9784 - mae: 3.9784 - val_loss: 4.2373 - val_mae: 4.2373\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9683 - mae: 3.9683 - val_loss: 4.2289 - val_mae: 4.2289\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9588 - mae: 3.9588 - val_loss: 4.2211 - val_mae: 4.2211\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9533 - mae: 3.9533 - val_loss: 4.2139 - val_mae: 4.2139\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3836 - mae: 5.3836\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 442.5506 - mae: 18.9600 - val_loss: 348.1559 - val_mae: 16.1649\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 296.9767 - mae: 14.8284 - val_loss: 273.4794 - val_mae: 13.7211\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 245.8033 - mae: 13.1073 - val_loss: 237.6237 - val_mae: 12.4217\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 216.8427 - mae: 12.0276 - val_loss: 213.8407 - val_mae: 11.5219\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 196.4319 - mae: 11.2256 - val_loss: 196.0827 - val_mae: 10.8096\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 180.6080 - mae: 10.6012 - val_loss: 182.2836 - val_mae: 10.2353\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 167.9103 - mae: 10.0631 - val_loss: 170.5128 - val_mae: 9.7388\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 157.1889 - mae: 9.6059 - val_loss: 161.0330 - val_mae: 9.3334\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 148.1914 - mae: 9.2051 - val_loss: 152.3942 - val_mae: 8.9791\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 140.1919 - mae: 8.8483 - val_loss: 144.9658 - val_mae: 8.6655\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 133.2767 - mae: 8.5422 - val_loss: 138.0289 - val_mae: 8.3823\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 126.9685 - mae: 8.2736 - val_loss: 132.3603 - val_mae: 8.1482\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 121.3969 - mae: 8.0199 - val_loss: 126.9860 - val_mae: 7.9320\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 116.4256 - mae: 7.7890 - val_loss: 122.0460 - val_mae: 7.7474\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.8035 - mae: 7.5851 - val_loss: 117.7925 - val_mae: 7.5796\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.7344 - mae: 7.3922 - val_loss: 113.6660 - val_mae: 7.4135\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 104.0480 - mae: 7.2158 - val_loss: 110.0820 - val_mae: 7.2741\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.7331 - mae: 7.0512 - val_loss: 106.7753 - val_mae: 7.1364\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.7109 - mae: 6.9056 - val_loss: 103.7872 - val_mae: 7.0171\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.9222 - mae: 6.7723 - val_loss: 100.9377 - val_mae: 6.8949\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.3160 - mae: 6.6336 - val_loss: 98.3325 - val_mae: 6.7734\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.9198 - mae: 6.5157 - val_loss: 96.0476 - val_mae: 6.6697\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.7800 - mae: 6.4036 - val_loss: 93.7266 - val_mae: 6.5670\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.7320 - mae: 6.3091 - val_loss: 91.6006 - val_mae: 6.4664\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.7902 - mae: 6.2128 - val_loss: 89.7002 - val_mae: 6.3724\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.0311 - mae: 6.1235 - val_loss: 87.7958 - val_mae: 6.2883\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.3507 - mae: 6.0436 - val_loss: 86.1115 - val_mae: 6.2213\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.7564 - mae: 5.9639 - val_loss: 84.4534 - val_mae: 6.1521\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.2744 - mae: 5.8918 - val_loss: 82.8371 - val_mae: 6.0878\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.8073 - mae: 5.8177 - val_loss: 81.3911 - val_mae: 6.0245\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.4307 - mae: 5.7464 - val_loss: 80.0016 - val_mae: 5.9654\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.1151 - mae: 5.6859 - val_loss: 78.6066 - val_mae: 5.9140\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.8732 - mae: 5.6256 - val_loss: 77.3031 - val_mae: 5.8648\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.6989 - mae: 5.5691 - val_loss: 76.0979 - val_mae: 5.8168\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.5755 - mae: 5.5133 - val_loss: 74.9509 - val_mae: 5.7747\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.5035 - mae: 5.4586 - val_loss: 73.8816 - val_mae: 5.7275\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.4807 - mae: 5.4089 - val_loss: 72.7819 - val_mae: 5.6820\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.5093 - mae: 5.3584 - val_loss: 71.8721 - val_mae: 5.6331\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5790 - mae: 5.3156 - val_loss: 70.8636 - val_mae: 5.6072\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 64.7028 - mae: 5.2764 - val_loss: 69.9842 - val_mae: 5.5665\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.8825 - mae: 5.2319 - val_loss: 69.1473 - val_mae: 5.5254\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.0914 - mae: 5.1962 - val_loss: 68.3466 - val_mae: 5.4884\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.3296 - mae: 5.1618 - val_loss: 67.5963 - val_mae: 5.4476\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.6108 - mae: 5.1280 - val_loss: 66.8707 - val_mae: 5.4206\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.9216 - mae: 5.1017 - val_loss: 66.1664 - val_mae: 5.3882\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2547 - mae: 5.0690 - val_loss: 65.4669 - val_mae: 5.3513\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.6228 - mae: 5.0384 - val_loss: 64.8657 - val_mae: 5.3268\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.0371 - mae: 5.0104 - val_loss: 64.2840 - val_mae: 5.2944\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.5034 - mae: 4.9804 - val_loss: 63.6923 - val_mae: 5.2579\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9480 - mae: 4.9709 - val_loss: 63.1401 - val_mae: 5.2426\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.3985 - mae: 4.9426 - val_loss: 62.6155 - val_mae: 5.2070\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.9071 - mae: 4.9299 - val_loss: 62.1008 - val_mae: 5.1900\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.3862 - mae: 4.9083 - val_loss: 61.6000 - val_mae: 5.1747\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.9136 - mae: 4.8926 - val_loss: 61.1454 - val_mae: 5.1532\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.4808 - mae: 4.8798 - val_loss: 60.6597 - val_mae: 5.1376\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.0217 - mae: 4.8645 - val_loss: 60.2243 - val_mae: 5.1146\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.6273 - mae: 4.8399 - val_loss: 59.7830 - val_mae: 5.0892\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.1965 - mae: 4.8293 - val_loss: 59.3619 - val_mae: 5.0788\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.8102 - mae: 4.8224 - val_loss: 59.0006 - val_mae: 5.0581\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.4162 - mae: 4.8012 - val_loss: 58.6146 - val_mae: 5.0369\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.0632 - mae: 4.7861 - val_loss: 58.2373 - val_mae: 5.0158\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.6822 - mae: 4.7768 - val_loss: 57.8502 - val_mae: 5.0098\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.3534 - mae: 4.7708 - val_loss: 57.5130 - val_mae: 4.9831\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.9841 - mae: 4.7445 - val_loss: 57.1623 - val_mae: 4.9754\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.6487 - mae: 4.7167 - val_loss: 56.8520 - val_mae: 4.9395\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.2822 - mae: 4.7055 - val_loss: 56.4900 - val_mae: 4.9415\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.9540 - mae: 4.7064 - val_loss: 56.1396 - val_mae: 4.9366\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6168 - mae: 4.6961 - val_loss: 55.8185 - val_mae: 4.9193\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.2958 - mae: 4.6699 - val_loss: 55.4854 - val_mae: 4.9049\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.9549 - mae: 4.6565 - val_loss: 55.1559 - val_mae: 4.8861\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.6238 - mae: 4.6378 - val_loss: 54.8318 - val_mae: 4.8857\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.3019 - mae: 4.6468 - val_loss: 54.4891 - val_mae: 4.8795\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9794 - mae: 4.6140 - val_loss: 54.1680 - val_mae: 4.8475\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.6515 - mae: 4.5968 - val_loss: 53.8607 - val_mae: 4.8199\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.3158 - mae: 4.5841 - val_loss: 53.5495 - val_mae: 4.8293\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.9933 - mae: 4.5785 - val_loss: 53.2478 - val_mae: 4.8050\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.6737 - mae: 4.5546 - val_loss: 52.9209 - val_mae: 4.7980\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3474 - mae: 4.5404 - val_loss: 52.6208 - val_mae: 4.7860\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0120 - mae: 4.5350 - val_loss: 52.2906 - val_mae: 4.7646\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.6860 - mae: 4.5133 - val_loss: 51.9955 - val_mae: 4.7443\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3667 - mae: 4.4789 - val_loss: 51.6879 - val_mae: 4.7269\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0823 - mae: 4.5160 - val_loss: 51.3365 - val_mae: 4.7421\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.7161 - mae: 4.4693 - val_loss: 51.0175 - val_mae: 4.7156\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.3630 - mae: 4.4306 - val_loss: 50.7437 - val_mae: 4.6851\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.0051 - mae: 4.4159 - val_loss: 50.4460 - val_mae: 4.6542\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7099 - mae: 4.4340 - val_loss: 50.0986 - val_mae: 4.6737\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.3716 - mae: 4.3761 - val_loss: 49.8259 - val_mae: 4.6031\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.9824 - mae: 4.3580 - val_loss: 49.4913 - val_mae: 4.6134\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6612 - mae: 4.3556 - val_loss: 49.1663 - val_mae: 4.6141\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.3158 - mae: 4.3351 - val_loss: 48.8547 - val_mae: 4.5773\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.9650 - mae: 4.3148 - val_loss: 48.5439 - val_mae: 4.5741\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6076 - mae: 4.3007 - val_loss: 48.2230 - val_mae: 4.5560\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3087 - mae: 4.2674 - val_loss: 47.9001 - val_mae: 4.5397\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.9355 - mae: 4.2536 - val_loss: 47.6157 - val_mae: 4.5177\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6039 - mae: 4.2458 - val_loss: 47.3070 - val_mae: 4.4961\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.2649 - mae: 4.2327 - val_loss: 46.9791 - val_mae: 4.5086\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.9057 - mae: 4.1871 - val_loss: 46.6763 - val_mae: 4.4679\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.5930 - mae: 4.1576 - val_loss: 46.4115 - val_mae: 4.4425\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2836 - mae: 4.1673 - val_loss: 46.1015 - val_mae: 4.4292\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.9445 - mae: 4.1460 - val_loss: 45.8047 - val_mae: 4.4183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 64.6821 - mae: 5.1173\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.7096 - mae: 18.7096 - val_loss: 15.7959 - val_mae: 15.7959\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4420 - mae: 14.4420 - val_loss: 13.2708 - val_mae: 13.2708\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6246 - mae: 12.6246 - val_loss: 11.9190 - val_mae: 11.9190\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4661 - mae: 11.4661 - val_loss: 10.9324 - val_mae: 10.9324\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5817 - mae: 10.5817 - val_loss: 10.1345 - val_mae: 10.1345\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8459 - mae: 9.8459 - val_loss: 9.4776 - val_mae: 9.4776\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2389 - mae: 9.2389 - val_loss: 8.9899 - val_mae: 8.9899\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7757 - mae: 8.7757 - val_loss: 8.5940 - val_mae: 8.5940\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4070 - mae: 8.4070 - val_loss: 8.2730 - val_mae: 8.2730\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0794 - mae: 8.0794 - val_loss: 8.0191 - val_mae: 8.0191\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7989 - mae: 7.7989 - val_loss: 7.7833 - val_mae: 7.7833\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5439 - mae: 7.5439 - val_loss: 7.5868 - val_mae: 7.5868\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3247 - mae: 7.3247 - val_loss: 7.4088 - val_mae: 7.4088\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1230 - mae: 7.1230 - val_loss: 7.2531 - val_mae: 7.2531\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9484 - mae: 6.9484 - val_loss: 7.1113 - val_mae: 7.1113\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7869 - mae: 6.7869 - val_loss: 6.9766 - val_mae: 6.9766\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6423 - mae: 6.6423 - val_loss: 6.8418 - val_mae: 6.8418\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5149 - mae: 6.5149 - val_loss: 6.7228 - val_mae: 6.7228\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4004 - mae: 6.4004 - val_loss: 6.6023 - val_mae: 6.6023\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2928 - mae: 6.2928 - val_loss: 6.4809 - val_mae: 6.4809\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1862 - mae: 6.1862 - val_loss: 6.3618 - val_mae: 6.3618\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0795 - mae: 6.0795 - val_loss: 6.2479 - val_mae: 6.2479\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9744 - mae: 5.9744 - val_loss: 6.1357 - val_mae: 6.1357\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8701 - mae: 5.8701 - val_loss: 6.0374 - val_mae: 6.0374\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7764 - mae: 5.7764 - val_loss: 5.9387 - val_mae: 5.9387\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6864 - mae: 5.6864 - val_loss: 5.8348 - val_mae: 5.8348\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6009 - mae: 5.6009 - val_loss: 5.7336 - val_mae: 5.7336\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5205 - mae: 5.5205 - val_loss: 5.6483 - val_mae: 5.6483\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4497 - mae: 5.4497 - val_loss: 5.5644 - val_mae: 5.5644\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3802 - mae: 5.3802 - val_loss: 5.5054 - val_mae: 5.5054\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3159 - mae: 5.3159 - val_loss: 5.4281 - val_mae: 5.4281\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2544 - mae: 5.2544 - val_loss: 5.3709 - val_mae: 5.3709\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1976 - mae: 5.1976 - val_loss: 5.3017 - val_mae: 5.3017\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1421 - mae: 5.1421 - val_loss: 5.2451 - val_mae: 5.2451\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0890 - mae: 5.0890 - val_loss: 5.1921 - val_mae: 5.1921\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0417 - mae: 5.0417 - val_loss: 5.1311 - val_mae: 5.1311\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9939 - mae: 4.9939 - val_loss: 5.0743 - val_mae: 5.0743\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9505 - mae: 4.9505 - val_loss: 5.0346 - val_mae: 5.0346\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9093 - mae: 4.9093 - val_loss: 4.9882 - val_mae: 4.9882\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8765 - mae: 4.8765 - val_loss: 4.9330 - val_mae: 4.9330\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8399 - mae: 4.8399 - val_loss: 4.9075 - val_mae: 4.9075\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8099 - mae: 4.8099 - val_loss: 4.8799 - val_mae: 4.8799\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7808 - mae: 4.7808 - val_loss: 4.8439 - val_mae: 4.8439\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7524 - mae: 4.7524 - val_loss: 4.8282 - val_mae: 4.8282\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7265 - mae: 4.7265 - val_loss: 4.7955 - val_mae: 4.7955\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7046 - mae: 4.7046 - val_loss: 4.7688 - val_mae: 4.7688\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6806 - mae: 4.6806 - val_loss: 4.7453 - val_mae: 4.7453\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6581 - mae: 4.6581 - val_loss: 4.7131 - val_mae: 4.7131\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6359 - mae: 4.6359 - val_loss: 4.6994 - val_mae: 4.6994\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6163 - mae: 4.6163 - val_loss: 4.6892 - val_mae: 4.6892\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5949 - mae: 4.5949 - val_loss: 4.6744 - val_mae: 4.6744\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5823 - mae: 4.5823 - val_loss: 4.6645 - val_mae: 4.6645\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5632 - mae: 4.5632 - val_loss: 4.6496 - val_mae: 4.6496\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5467 - mae: 4.5467 - val_loss: 4.6281 - val_mae: 4.6281\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5308 - mae: 4.5308 - val_loss: 4.6205 - val_mae: 4.6205\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5154 - mae: 4.5154 - val_loss: 4.6062 - val_mae: 4.6062\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4998 - mae: 4.4998 - val_loss: 4.5968 - val_mae: 4.5968\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4941 - mae: 4.4941 - val_loss: 4.6054 - val_mae: 4.6054\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4664 - mae: 4.4664 - val_loss: 4.5699 - val_mae: 4.5699\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4537 - mae: 4.4537 - val_loss: 4.5617 - val_mae: 4.5617\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4389 - mae: 4.4389 - val_loss: 4.5524 - val_mae: 4.5524\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4263 - mae: 4.4263 - val_loss: 4.5395 - val_mae: 4.5395\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4118 - mae: 4.4118 - val_loss: 4.5285 - val_mae: 4.5285\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3984 - mae: 4.3984 - val_loss: 4.5175 - val_mae: 4.5175\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3838 - mae: 4.3838 - val_loss: 4.5054 - val_mae: 4.5054\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3699 - mae: 4.3699 - val_loss: 4.5003 - val_mae: 4.5003\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3603 - mae: 4.3603 - val_loss: 4.4855 - val_mae: 4.4855\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3413 - mae: 4.3413 - val_loss: 4.4799 - val_mae: 4.4799\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3285 - mae: 4.3285 - val_loss: 4.4696 - val_mae: 4.4696\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3147 - mae: 4.3147 - val_loss: 4.4550 - val_mae: 4.4550\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3078 - mae: 4.3078 - val_loss: 4.4470 - val_mae: 4.4470\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2911 - mae: 4.2911 - val_loss: 4.4363 - val_mae: 4.4363\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2750 - mae: 4.2750 - val_loss: 4.4317 - val_mae: 4.4317\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2612 - mae: 4.2612 - val_loss: 4.4217 - val_mae: 4.4217\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2496 - mae: 4.2496 - val_loss: 4.4127 - val_mae: 4.4127\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2357 - mae: 4.2357 - val_loss: 4.4076 - val_mae: 4.4076\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2220 - mae: 4.2220 - val_loss: 4.3940 - val_mae: 4.3940\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2091 - mae: 4.2091 - val_loss: 4.3892 - val_mae: 4.3892\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2012 - mae: 4.2012 - val_loss: 4.3826 - val_mae: 4.3826\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1812 - mae: 4.1812 - val_loss: 4.3758 - val_mae: 4.3758\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1674 - mae: 4.1674 - val_loss: 4.3682 - val_mae: 4.3682\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1557 - mae: 4.1557 - val_loss: 4.3645 - val_mae: 4.3645\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1437 - mae: 4.1437 - val_loss: 4.3568 - val_mae: 4.3568\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1287 - mae: 4.1287 - val_loss: 4.3503 - val_mae: 4.3503\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1162 - mae: 4.1162 - val_loss: 4.3448 - val_mae: 4.3448\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1062 - mae: 4.1062 - val_loss: 4.3370 - val_mae: 4.3370\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0914 - mae: 4.0914 - val_loss: 4.3311 - val_mae: 4.3311\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0810 - mae: 4.0810 - val_loss: 4.3243 - val_mae: 4.3243\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0710 - mae: 4.0710 - val_loss: 4.3204 - val_mae: 4.3204\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0606 - mae: 4.0606 - val_loss: 4.3119 - val_mae: 4.3119\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0528 - mae: 4.0528 - val_loss: 4.3065 - val_mae: 4.3065\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0429 - mae: 4.0429 - val_loss: 4.3004 - val_mae: 4.3004\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0377 - mae: 4.0377 - val_loss: 4.2946 - val_mae: 4.2946\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0272 - mae: 4.0272 - val_loss: 4.2870 - val_mae: 4.2870\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0159 - mae: 4.0159 - val_loss: 4.2803 - val_mae: 4.2803\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0102 - mae: 4.0102 - val_loss: 4.2730 - val_mae: 4.2730\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0005 - mae: 4.0005 - val_loss: 4.2670 - val_mae: 4.2670\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9935 - mae: 3.9935 - val_loss: 4.2619 - val_mae: 4.2619\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9849 - mae: 3.9849 - val_loss: 4.2520 - val_mae: 4.2520\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9771 - mae: 3.9771 - val_loss: 4.2439 - val_mae: 4.2439\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4536 - mae: 5.4536\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 390.2610 - mae: 17.5498 - val_loss: 172.2637 - val_mae: 10.5929\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.3380 - mae: 6.8587 - val_loss: 49.5851 - val_mae: 5.1542\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.2921 - mae: 4.5507 - val_loss: 33.9087 - val_mae: 4.0526\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.7258 - mae: 3.9247 - val_loss: 28.5259 - val_mae: 3.6805\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.7292 - mae: 3.5754 - val_loss: 25.8397 - val_mae: 3.5358\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.3093 - mae: 3.3552 - val_loss: 24.0167 - val_mae: 3.4147\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.7052 - mae: 3.2243 - val_loss: 22.9499 - val_mae: 3.3495\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.3918 - mae: 3.1052 - val_loss: 22.3086 - val_mae: 3.3104\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.5806 - mae: 3.0326 - val_loss: 21.6847 - val_mae: 3.3066\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.6479 - mae: 2.9412 - val_loss: 21.1330 - val_mae: 3.2601\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.1840 - mae: 2.8938 - val_loss: 20.7608 - val_mae: 3.2514\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.5384 - mae: 2.8673 - val_loss: 20.3820 - val_mae: 3.2036\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.0996 - mae: 2.7957 - val_loss: 20.0431 - val_mae: 3.1799\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6197 - mae: 2.7628 - val_loss: 19.6119 - val_mae: 3.1593\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2866 - mae: 2.7243 - val_loss: 19.3711 - val_mae: 3.1208\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.8939 - mae: 2.6898 - val_loss: 19.1555 - val_mae: 3.0978\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7301 - mae: 2.6853 - val_loss: 18.9035 - val_mae: 3.0754\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4329 - mae: 2.6421 - val_loss: 18.6699 - val_mae: 3.0761\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2104 - mae: 2.6129 - val_loss: 18.5566 - val_mae: 3.0450\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8976 - mae: 2.6266 - val_loss: 18.2124 - val_mae: 3.0205\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6079 - mae: 2.5808 - val_loss: 18.1272 - val_mae: 2.9942\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4998 - mae: 2.5734 - val_loss: 17.9773 - val_mae: 2.9705\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3266 - mae: 2.5425 - val_loss: 17.7971 - val_mae: 2.9909\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0273 - mae: 2.5256 - val_loss: 17.6584 - val_mae: 2.9229\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8204 - mae: 2.5039 - val_loss: 17.3506 - val_mae: 2.9053\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7623 - mae: 2.5034 - val_loss: 17.2656 - val_mae: 2.8967\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6019 - mae: 2.4879 - val_loss: 17.1682 - val_mae: 2.8864\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6188 - mae: 2.4729 - val_loss: 16.9675 - val_mae: 2.8554\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4283 - mae: 2.4563 - val_loss: 16.9465 - val_mae: 2.8511\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1550 - mae: 2.4337 - val_loss: 16.6801 - val_mae: 2.8314\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0243 - mae: 2.4322 - val_loss: 16.7094 - val_mae: 2.8391\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0420 - mae: 2.4392 - val_loss: 16.5625 - val_mae: 2.8217\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8622 - mae: 2.4059 - val_loss: 16.4978 - val_mae: 2.8024\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6667 - mae: 2.3990 - val_loss: 16.4697 - val_mae: 2.7809\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5807 - mae: 2.3690 - val_loss: 16.3721 - val_mae: 2.7895\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5646 - mae: 2.3902 - val_loss: 16.4396 - val_mae: 2.7810\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3966 - mae: 2.3376 - val_loss: 16.0439 - val_mae: 2.7630\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2607 - mae: 2.3538 - val_loss: 16.0965 - val_mae: 2.7641\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1789 - mae: 2.3392 - val_loss: 15.9520 - val_mae: 2.7517\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0748 - mae: 2.3317 - val_loss: 15.9245 - val_mae: 2.7306\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0041 - mae: 2.3112 - val_loss: 15.8457 - val_mae: 2.7053\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.8326 - mae: 2.3078 - val_loss: 15.8878 - val_mae: 2.7531\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8427 - mae: 2.3100 - val_loss: 15.6649 - val_mae: 2.7072\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7243 - mae: 2.3194 - val_loss: 15.5105 - val_mae: 2.6829\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6317 - mae: 2.2760 - val_loss: 15.5016 - val_mae: 2.6826\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.6206 - mae: 2.2812 - val_loss: 15.3718 - val_mae: 2.6832\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4118 - mae: 2.2550 - val_loss: 15.4306 - val_mae: 2.6709\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3312 - mae: 2.2542 - val_loss: 15.3555 - val_mae: 2.6805\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.2646 - mae: 2.2657 - val_loss: 15.1694 - val_mae: 2.6664\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3430 - mae: 2.2555 - val_loss: 15.2525 - val_mae: 2.6613\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0977 - mae: 2.2467 - val_loss: 15.1255 - val_mae: 2.6504\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9754 - mae: 2.2193 - val_loss: 15.1356 - val_mae: 2.6461\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9596 - mae: 2.2166 - val_loss: 15.0979 - val_mae: 2.6299\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8949 - mae: 2.2168 - val_loss: 14.9958 - val_mae: 2.6347\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9067 - mae: 2.2208 - val_loss: 14.9100 - val_mae: 2.6046\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7780 - mae: 2.1787 - val_loss: 14.8650 - val_mae: 2.6002\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6575 - mae: 2.1852 - val_loss: 14.8397 - val_mae: 2.6108\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5580 - mae: 2.1675 - val_loss: 14.7698 - val_mae: 2.6113\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4693 - mae: 2.1647 - val_loss: 14.6905 - val_mae: 2.5962\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4811 - mae: 2.1591 - val_loss: 14.7190 - val_mae: 2.5811\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3172 - mae: 2.1504 - val_loss: 14.7243 - val_mae: 2.5953\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2505 - mae: 2.1460 - val_loss: 14.5661 - val_mae: 2.5867\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2785 - mae: 2.1305 - val_loss: 14.5083 - val_mae: 2.5819\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1702 - mae: 2.1332 - val_loss: 14.6004 - val_mae: 2.5790\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1068 - mae: 2.1254 - val_loss: 14.4944 - val_mae: 2.5874\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0394 - mae: 2.1371 - val_loss: 14.3511 - val_mae: 2.5661\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0019 - mae: 2.1047 - val_loss: 14.3183 - val_mae: 2.5573\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0513 - mae: 2.1209 - val_loss: 14.3256 - val_mae: 2.5491\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8918 - mae: 2.1016 - val_loss: 14.3089 - val_mae: 2.5555\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7950 - mae: 2.0807 - val_loss: 14.2410 - val_mae: 2.5538\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7560 - mae: 2.0831 - val_loss: 14.3625 - val_mae: 2.5633\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6693 - mae: 2.0829 - val_loss: 14.1511 - val_mae: 2.5510\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6848 - mae: 2.1160 - val_loss: 14.2879 - val_mae: 2.5646\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6156 - mae: 2.0781 - val_loss: 14.1236 - val_mae: 2.5412\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4471 - mae: 2.0477 - val_loss: 14.1444 - val_mae: 2.5266\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5114 - mae: 2.0732 - val_loss: 14.0758 - val_mae: 2.5330\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4914 - mae: 2.0320 - val_loss: 14.1082 - val_mae: 2.5381\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3099 - mae: 2.0390 - val_loss: 14.0269 - val_mae: 2.5385\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4062 - mae: 2.0564 - val_loss: 14.0484 - val_mae: 2.5541\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2985 - mae: 2.0491 - val_loss: 13.9635 - val_mae: 2.5315\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1836 - mae: 2.0156 - val_loss: 14.0880 - val_mae: 2.5225\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1540 - mae: 2.0385 - val_loss: 14.1484 - val_mae: 2.5133\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0992 - mae: 2.0246 - val_loss: 13.9134 - val_mae: 2.5288\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9676 - mae: 2.0049 - val_loss: 13.8473 - val_mae: 2.5165\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9102 - mae: 1.9947 - val_loss: 13.9163 - val_mae: 2.5140\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.8766 - mae: 2.0052 - val_loss: 13.7693 - val_mae: 2.5111\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8326 - mae: 1.9867 - val_loss: 13.8845 - val_mae: 2.5058\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8002 - mae: 1.9824 - val_loss: 13.8464 - val_mae: 2.5166\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7189 - mae: 1.9864 - val_loss: 13.8263 - val_mae: 2.5139\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6674 - mae: 1.9637 - val_loss: 13.9532 - val_mae: 2.5087\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7293 - mae: 1.9825 - val_loss: 13.8989 - val_mae: 2.5118\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6212 - mae: 1.9635 - val_loss: 13.7349 - val_mae: 2.5033\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4821 - mae: 1.9509 - val_loss: 13.6245 - val_mae: 2.4820\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4236 - mae: 1.9468 - val_loss: 13.5974 - val_mae: 2.4891\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4630 - mae: 1.9578 - val_loss: 13.7228 - val_mae: 2.5028\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3839 - mae: 1.9379 - val_loss: 13.7257 - val_mae: 2.4993\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3761 - mae: 1.9398 - val_loss: 13.5583 - val_mae: 2.4940\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3071 - mae: 1.9399 - val_loss: 13.8634 - val_mae: 2.4863\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1416 - mae: 1.9259 - val_loss: 13.6065 - val_mae: 2.4994\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3631 - mae: 1.9297 - val_loss: 13.5794 - val_mae: 2.4918\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.5174 - mae: 3.7399\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 17.9482 - mae: 17.9482 - val_loss: 11.7571 - val_mae: 11.7571\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4832 - mae: 7.4832 - val_loss: 5.5739 - val_mae: 5.5739\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5646 - mae: 4.5646 - val_loss: 4.0871 - val_mae: 4.0871\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6796 - mae: 3.6796 - val_loss: 3.5020 - val_mae: 3.5020\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3175 - mae: 3.3175 - val_loss: 3.2899 - val_mae: 3.2899\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1050 - mae: 3.1050 - val_loss: 3.2387 - val_mae: 3.2387\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9534 - mae: 2.9534 - val_loss: 3.1161 - val_mae: 3.1161\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8753 - mae: 2.8753 - val_loss: 3.0134 - val_mae: 3.0134\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8128 - mae: 2.8128 - val_loss: 3.0056 - val_mae: 3.0056\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7380 - mae: 2.7380 - val_loss: 3.0108 - val_mae: 3.0108\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6852 - mae: 2.6852 - val_loss: 2.9925 - val_mae: 2.9925\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6555 - mae: 2.6555 - val_loss: 2.9555 - val_mae: 2.9555\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6040 - mae: 2.6040 - val_loss: 2.8956 - val_mae: 2.8956\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5880 - mae: 2.5880 - val_loss: 2.9114 - val_mae: 2.9114\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5575 - mae: 2.5575 - val_loss: 2.8843 - val_mae: 2.8843\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5195 - mae: 2.5195 - val_loss: 2.8393 - val_mae: 2.8393\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4949 - mae: 2.4949 - val_loss: 2.8599 - val_mae: 2.8599\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4722 - mae: 2.4722 - val_loss: 2.7994 - val_mae: 2.7994\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4589 - mae: 2.4589 - val_loss: 2.7342 - val_mae: 2.7342\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4398 - mae: 2.4398 - val_loss: 2.7852 - val_mae: 2.7852\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4144 - mae: 2.4144 - val_loss: 2.7270 - val_mae: 2.7270\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4011 - mae: 2.4011 - val_loss: 2.7302 - val_mae: 2.7302\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3813 - mae: 2.3813 - val_loss: 2.7414 - val_mae: 2.7414\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3727 - mae: 2.3727 - val_loss: 2.7309 - val_mae: 2.7309\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3494 - mae: 2.3494 - val_loss: 2.6859 - val_mae: 2.6859\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3334 - mae: 2.3334 - val_loss: 2.6615 - val_mae: 2.6615\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3453 - mae: 2.3453 - val_loss: 2.6792 - val_mae: 2.6792\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3035 - mae: 2.3035 - val_loss: 2.6746 - val_mae: 2.6746\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3195 - mae: 2.3195 - val_loss: 2.6844 - val_mae: 2.6844\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2929 - mae: 2.2929 - val_loss: 2.6792 - val_mae: 2.6792\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2732 - mae: 2.2732 - val_loss: 2.6299 - val_mae: 2.6299\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2683 - mae: 2.2683 - val_loss: 2.6582 - val_mae: 2.6582\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2750 - mae: 2.2750 - val_loss: 2.6469 - val_mae: 2.6469\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2369 - mae: 2.2369 - val_loss: 2.6012 - val_mae: 2.6012\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2397 - mae: 2.2397 - val_loss: 2.6154 - val_mae: 2.6154\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2571 - mae: 2.2571 - val_loss: 2.5921 - val_mae: 2.5921\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2398 - mae: 2.2398 - val_loss: 2.5722 - val_mae: 2.5722\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2071 - mae: 2.2071 - val_loss: 2.5701 - val_mae: 2.5701\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2126 - mae: 2.2126 - val_loss: 2.5530 - val_mae: 2.5530\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1981 - mae: 2.1981 - val_loss: 2.5453 - val_mae: 2.5453\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1959 - mae: 2.1959 - val_loss: 2.5389 - val_mae: 2.5389\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1643 - mae: 2.1643 - val_loss: 2.5093 - val_mae: 2.5093\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1708 - mae: 2.1708 - val_loss: 2.5415 - val_mae: 2.5415\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1597 - mae: 2.1597 - val_loss: 2.5002 - val_mae: 2.5002\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1485 - mae: 2.1485 - val_loss: 2.5088 - val_mae: 2.5088\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1395 - mae: 2.1395 - val_loss: 2.5193 - val_mae: 2.5193\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1326 - mae: 2.1326 - val_loss: 2.5161 - val_mae: 2.5161\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1306 - mae: 2.1306 - val_loss: 2.5271 - val_mae: 2.5271\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1239 - mae: 2.1239 - val_loss: 2.4617 - val_mae: 2.4617\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1192 - mae: 2.1192 - val_loss: 2.5134 - val_mae: 2.5134\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1287 - mae: 2.1287 - val_loss: 2.4978 - val_mae: 2.4978\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1155 - mae: 2.1155 - val_loss: 2.4805 - val_mae: 2.4805\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0996 - mae: 2.0996 - val_loss: 2.4658 - val_mae: 2.4658\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1023 - mae: 2.1023 - val_loss: 2.4475 - val_mae: 2.4475\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0967 - mae: 2.0967 - val_loss: 2.4614 - val_mae: 2.4614\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0762 - mae: 2.0762 - val_loss: 2.4302 - val_mae: 2.4302\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0792 - mae: 2.0792 - val_loss: 2.4322 - val_mae: 2.4322\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0712 - mae: 2.0712 - val_loss: 2.4725 - val_mae: 2.4725\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0611 - mae: 2.0611 - val_loss: 2.4310 - val_mae: 2.4310\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0682 - mae: 2.0682 - val_loss: 2.4156 - val_mae: 2.4156\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0598 - mae: 2.0598 - val_loss: 2.4275 - val_mae: 2.4275\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0408 - mae: 2.0408 - val_loss: 2.4454 - val_mae: 2.4454\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0541 - mae: 2.0541 - val_loss: 2.4449 - val_mae: 2.4449\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0479 - mae: 2.0479 - val_loss: 2.4333 - val_mae: 2.4333\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0406 - mae: 2.0406 - val_loss: 2.4245 - val_mae: 2.4245\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0533 - mae: 2.0533 - val_loss: 2.3915 - val_mae: 2.3915\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0313 - mae: 2.0313 - val_loss: 2.4030 - val_mae: 2.4030\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0334 - mae: 2.0334 - val_loss: 2.4126 - val_mae: 2.4126\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0284 - mae: 2.0284 - val_loss: 2.4003 - val_mae: 2.4003\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0240 - mae: 2.0240 - val_loss: 2.3937 - val_mae: 2.3937\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0054 - mae: 2.0054 - val_loss: 2.3928 - val_mae: 2.3928\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0104 - mae: 2.0104 - val_loss: 2.3689 - val_mae: 2.3689\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9915 - mae: 1.9915 - val_loss: 2.3938 - val_mae: 2.3938\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9912 - mae: 1.9912 - val_loss: 2.3917 - val_mae: 2.3917\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9858 - mae: 1.9858 - val_loss: 2.3521 - val_mae: 2.3521\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9862 - mae: 1.9862 - val_loss: 2.4061 - val_mae: 2.4061\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9845 - mae: 1.9845 - val_loss: 2.4012 - val_mae: 2.4012\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9812 - mae: 1.9812 - val_loss: 2.3859 - val_mae: 2.3859\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9733 - mae: 1.9733 - val_loss: 2.3953 - val_mae: 2.3953\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9568 - mae: 1.9568 - val_loss: 2.3808 - val_mae: 2.3808\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9677 - mae: 1.9677 - val_loss: 2.3739 - val_mae: 2.3739\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9732 - mae: 1.9732 - val_loss: 2.3650 - val_mae: 2.3650\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9551 - mae: 1.9551 - val_loss: 2.3821 - val_mae: 2.3821\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9685 - mae: 1.9685 - val_loss: 2.3895 - val_mae: 2.3895\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9682 - mae: 1.9682 - val_loss: 2.3753 - val_mae: 2.3753\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9503 - mae: 1.9503 - val_loss: 2.4283 - val_mae: 2.4283\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9446 - mae: 1.9446 - val_loss: 2.3471 - val_mae: 2.3471\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9368 - mae: 1.9368 - val_loss: 2.3842 - val_mae: 2.3842\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9238 - mae: 1.9238 - val_loss: 2.3776 - val_mae: 2.3776\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9254 - mae: 1.9254 - val_loss: 2.3765 - val_mae: 2.3765\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9147 - mae: 1.9147 - val_loss: 2.3547 - val_mae: 2.3547\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9111 - mae: 1.9111 - val_loss: 2.3830 - val_mae: 2.3830\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9064 - mae: 1.9064 - val_loss: 2.3396 - val_mae: 2.3396\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9090 - mae: 1.9090 - val_loss: 2.3470 - val_mae: 2.3470\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9030 - mae: 1.9030 - val_loss: 2.3540 - val_mae: 2.3540\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9059 - mae: 1.9059 - val_loss: 2.3312 - val_mae: 2.3312\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8895 - mae: 1.8895 - val_loss: 2.3461 - val_mae: 2.3461\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8884 - mae: 1.8884 - val_loss: 2.3372 - val_mae: 2.3372\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8749 - mae: 1.8749 - val_loss: 2.3719 - val_mae: 2.3719\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8840 - mae: 1.8840 - val_loss: 2.3509 - val_mae: 2.3509\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6925 - mae: 3.6925\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 380.2024 - mae: 17.2516 - val_loss: 168.6147 - val_mae: 10.5561\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.9964 - mae: 7.1133 - val_loss: 62.0954 - val_mae: 5.8001\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.7958 - mae: 4.9770 - val_loss: 40.4836 - val_mae: 4.5189\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.7488 - mae: 4.1487 - val_loss: 32.9078 - val_mae: 4.0185\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.5210 - mae: 3.8051 - val_loss: 28.9716 - val_mae: 3.7401\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 23.5537 - mae: 3.5466 - val_loss: 26.2509 - val_mae: 3.5617\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.6994 - mae: 3.3688 - val_loss: 24.5612 - val_mae: 3.4535\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.5459 - mae: 3.2873 - val_loss: 23.3749 - val_mae: 3.3732\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 19.1989 - mae: 3.1493 - val_loss: 22.3987 - val_mae: 3.3307\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.4063 - mae: 3.0565 - val_loss: 21.8135 - val_mae: 3.2951\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.7252 - mae: 2.9945 - val_loss: 21.0156 - val_mae: 3.2428\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.1582 - mae: 2.9408 - val_loss: 20.6622 - val_mae: 3.2075\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.5674 - mae: 2.8670 - val_loss: 20.1926 - val_mae: 3.1814\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.4843 - mae: 2.8770 - val_loss: 19.7375 - val_mae: 3.1558\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.7284 - mae: 2.7816 - val_loss: 19.3966 - val_mae: 3.1182\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.3310 - mae: 2.7571 - val_loss: 19.0807 - val_mae: 3.1005\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.9471 - mae: 2.7183 - val_loss: 18.7572 - val_mae: 3.0718\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7328 - mae: 2.7053 - val_loss: 18.5555 - val_mae: 3.0320\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2977 - mae: 2.6627 - val_loss: 18.3241 - val_mae: 3.0328\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1301 - mae: 2.6431 - val_loss: 18.0919 - val_mae: 2.9975\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.8714 - mae: 2.6237 - val_loss: 17.8023 - val_mae: 3.0022\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.6762 - mae: 2.6085 - val_loss: 17.6514 - val_mae: 2.9627\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.4736 - mae: 2.5832 - val_loss: 17.5186 - val_mae: 2.9658\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.3533 - mae: 2.5609 - val_loss: 17.3764 - val_mae: 2.9428\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1236 - mae: 2.5544 - val_loss: 17.1565 - val_mae: 2.9160\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9394 - mae: 2.5385 - val_loss: 16.9488 - val_mae: 2.8880\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7619 - mae: 2.5327 - val_loss: 16.6289 - val_mae: 2.8568\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5820 - mae: 2.4815 - val_loss: 16.7368 - val_mae: 2.8611\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4205 - mae: 2.4932 - val_loss: 16.5969 - val_mae: 2.8534\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3089 - mae: 2.4789 - val_loss: 16.3912 - val_mae: 2.8387\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0967 - mae: 2.4446 - val_loss: 16.2572 - val_mae: 2.8280\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9449 - mae: 2.4333 - val_loss: 16.1687 - val_mae: 2.7941\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8796 - mae: 2.4317 - val_loss: 16.0932 - val_mae: 2.7941\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7775 - mae: 2.4211 - val_loss: 15.8794 - val_mae: 2.7946\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5968 - mae: 2.4068 - val_loss: 15.8418 - val_mae: 2.7747\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6476 - mae: 2.4049 - val_loss: 15.6958 - val_mae: 2.7735\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4133 - mae: 2.4050 - val_loss: 15.5797 - val_mae: 2.7587\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.4053 - mae: 2.3840 - val_loss: 15.5816 - val_mae: 2.7294\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.2972 - mae: 2.3874 - val_loss: 15.4175 - val_mae: 2.7258\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.0992 - mae: 2.3639 - val_loss: 15.3737 - val_mae: 2.6944\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0215 - mae: 2.3264 - val_loss: 15.2980 - val_mae: 2.6910\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.8653 - mae: 2.3256 - val_loss: 15.1785 - val_mae: 2.7007\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7760 - mae: 2.3381 - val_loss: 14.9873 - val_mae: 2.6634\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.6612 - mae: 2.2992 - val_loss: 15.0192 - val_mae: 2.6582\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5883 - mae: 2.3057 - val_loss: 14.9871 - val_mae: 2.6669\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5445 - mae: 2.3031 - val_loss: 14.9757 - val_mae: 2.6565\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4223 - mae: 2.2668 - val_loss: 14.8619 - val_mae: 2.6461\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.3475 - mae: 2.2789 - val_loss: 14.7665 - val_mae: 2.6359\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3491 - mae: 2.2694 - val_loss: 14.7758 - val_mae: 2.6489\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.2290 - mae: 2.2758 - val_loss: 14.6538 - val_mae: 2.6234\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1722 - mae: 2.2399 - val_loss: 14.6470 - val_mae: 2.6276\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0576 - mae: 2.2416 - val_loss: 14.6131 - val_mae: 2.6156\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9677 - mae: 2.2388 - val_loss: 14.5114 - val_mae: 2.5981\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0271 - mae: 2.2306 - val_loss: 14.5097 - val_mae: 2.6122\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9115 - mae: 2.2229 - val_loss: 14.3672 - val_mae: 2.5920\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.8389 - mae: 2.2233 - val_loss: 14.3277 - val_mae: 2.5749\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7670 - mae: 2.2093 - val_loss: 14.4079 - val_mae: 2.5952\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.7386 - mae: 2.2249 - val_loss: 14.4038 - val_mae: 2.5817\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4886 - mae: 2.1845 - val_loss: 14.2759 - val_mae: 2.5733\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4317 - mae: 2.1750 - val_loss: 14.1521 - val_mae: 2.5671\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4619 - mae: 2.1800 - val_loss: 14.2659 - val_mae: 2.5671\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3887 - mae: 2.1721 - val_loss: 14.1872 - val_mae: 2.5699\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3809 - mae: 2.1631 - val_loss: 14.1926 - val_mae: 2.5722\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2102 - mae: 2.1693 - val_loss: 14.0449 - val_mae: 2.5480\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2034 - mae: 2.1517 - val_loss: 14.1210 - val_mae: 2.5508\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0496 - mae: 2.1293 - val_loss: 14.0239 - val_mae: 2.5608\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0438 - mae: 2.1292 - val_loss: 14.0902 - val_mae: 2.5422\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.9249 - mae: 2.1200 - val_loss: 13.9703 - val_mae: 2.5402\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8375 - mae: 2.1104 - val_loss: 13.9345 - val_mae: 2.5426\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8080 - mae: 2.1070 - val_loss: 13.7634 - val_mae: 2.5318\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8583 - mae: 2.1342 - val_loss: 13.8413 - val_mae: 2.5436\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7131 - mae: 2.0901 - val_loss: 13.8582 - val_mae: 2.5383\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6036 - mae: 2.0806 - val_loss: 13.9108 - val_mae: 2.5173\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4824 - mae: 2.0797 - val_loss: 13.7524 - val_mae: 2.5155\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5287 - mae: 2.0798 - val_loss: 13.8018 - val_mae: 2.5195\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4254 - mae: 2.0571 - val_loss: 13.6425 - val_mae: 2.5148\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3929 - mae: 2.0564 - val_loss: 13.7629 - val_mae: 2.4981\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4096 - mae: 2.0645 - val_loss: 13.6012 - val_mae: 2.5097\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2330 - mae: 2.0335 - val_loss: 13.6713 - val_mae: 2.4966\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1910 - mae: 2.0334 - val_loss: 13.5797 - val_mae: 2.4911\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1813 - mae: 2.0351 - val_loss: 13.4145 - val_mae: 2.4928\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2206 - mae: 2.0230 - val_loss: 13.5931 - val_mae: 2.4830\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0728 - mae: 2.0263 - val_loss: 13.4438 - val_mae: 2.4805\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0389 - mae: 2.0293 - val_loss: 13.4929 - val_mae: 2.4953\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9164 - mae: 2.0037 - val_loss: 13.5575 - val_mae: 2.4817\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9456 - mae: 1.9987 - val_loss: 13.3773 - val_mae: 2.4850\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8621 - mae: 1.9992 - val_loss: 13.4180 - val_mae: 2.4817\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7464 - mae: 1.9853 - val_loss: 13.3448 - val_mae: 2.4709\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7392 - mae: 1.9879 - val_loss: 13.4796 - val_mae: 2.4735\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6596 - mae: 1.9644 - val_loss: 13.4757 - val_mae: 2.4693\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5701 - mae: 1.9617 - val_loss: 13.4144 - val_mae: 2.4669\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5005 - mae: 1.9604 - val_loss: 13.4794 - val_mae: 2.4662\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5293 - mae: 1.9450 - val_loss: 13.3619 - val_mae: 2.4617\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4545 - mae: 1.9517 - val_loss: 13.2991 - val_mae: 2.4694\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4063 - mae: 1.9418 - val_loss: 13.4766 - val_mae: 2.4684\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3173 - mae: 1.9401 - val_loss: 13.4286 - val_mae: 2.4852\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3437 - mae: 1.9308 - val_loss: 13.1748 - val_mae: 2.4569\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2521 - mae: 1.9248 - val_loss: 13.3772 - val_mae: 2.4607\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2314 - mae: 1.9197 - val_loss: 13.2030 - val_mae: 2.4504\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1324 - mae: 1.9142 - val_loss: 13.1750 - val_mae: 2.4674\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.0315 - mae: 3.9046\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 17.4437 - mae: 17.4437 - val_loss: 10.7936 - val_mae: 10.7936\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1622 - mae: 7.1622 - val_loss: 5.2675 - val_mae: 5.2675\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3781 - mae: 4.3781 - val_loss: 3.5475 - val_mae: 3.5475\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5174 - mae: 3.5174 - val_loss: 3.2221 - val_mae: 3.2221\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1925 - mae: 3.1925 - val_loss: 3.0790 - val_mae: 3.0790\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0461 - mae: 3.0461 - val_loss: 2.9189 - val_mae: 2.9189\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8975 - mae: 2.8975 - val_loss: 2.8968 - val_mae: 2.8968\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8091 - mae: 2.8091 - val_loss: 2.7913 - val_mae: 2.7913\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7315 - mae: 2.7315 - val_loss: 2.8021 - val_mae: 2.8021\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7012 - mae: 2.7012 - val_loss: 2.7407 - val_mae: 2.7407\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6505 - mae: 2.6505 - val_loss: 2.7537 - val_mae: 2.7537\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5878 - mae: 2.5878 - val_loss: 2.6910 - val_mae: 2.6910\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5811 - mae: 2.5811 - val_loss: 2.7029 - val_mae: 2.7029\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5263 - mae: 2.5263 - val_loss: 2.6780 - val_mae: 2.6780\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4952 - mae: 2.4952 - val_loss: 2.6715 - val_mae: 2.6715\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4932 - mae: 2.4932 - val_loss: 2.6387 - val_mae: 2.6387\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4673 - mae: 2.4673 - val_loss: 2.6457 - val_mae: 2.6457\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4489 - mae: 2.4489 - val_loss: 2.6315 - val_mae: 2.6315\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4148 - mae: 2.4148 - val_loss: 2.6638 - val_mae: 2.6638\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4108 - mae: 2.4108 - val_loss: 2.6189 - val_mae: 2.6189\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3803 - mae: 2.3803 - val_loss: 2.5893 - val_mae: 2.5893\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3600 - mae: 2.3600 - val_loss: 2.6067 - val_mae: 2.6067\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3409 - mae: 2.3409 - val_loss: 2.5677 - val_mae: 2.5677\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3386 - mae: 2.3386 - val_loss: 2.5642 - val_mae: 2.5642\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3176 - mae: 2.3176 - val_loss: 2.5470 - val_mae: 2.5470\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3028 - mae: 2.3028 - val_loss: 2.5625 - val_mae: 2.5625\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2927 - mae: 2.2927 - val_loss: 2.5687 - val_mae: 2.5687\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2739 - mae: 2.2739 - val_loss: 2.5402 - val_mae: 2.5402\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2744 - mae: 2.2744 - val_loss: 2.5497 - val_mae: 2.5497\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2559 - mae: 2.2559 - val_loss: 2.5363 - val_mae: 2.5363\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2464 - mae: 2.2464 - val_loss: 2.5431 - val_mae: 2.5431\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2292 - mae: 2.2292 - val_loss: 2.5195 - val_mae: 2.5195\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2234 - mae: 2.2234 - val_loss: 2.5180 - val_mae: 2.5180\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2160 - mae: 2.2160 - val_loss: 2.5272 - val_mae: 2.5272\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2166 - mae: 2.2166 - val_loss: 2.5158 - val_mae: 2.5158\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1903 - mae: 2.1903 - val_loss: 2.5128 - val_mae: 2.5128\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1992 - mae: 2.1992 - val_loss: 2.5166 - val_mae: 2.5166\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1896 - mae: 2.1896 - val_loss: 2.4869 - val_mae: 2.4869\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1764 - mae: 2.1764 - val_loss: 2.5042 - val_mae: 2.5042\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1897 - mae: 2.1897 - val_loss: 2.4881 - val_mae: 2.4881\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1612 - mae: 2.1612 - val_loss: 2.4809 - val_mae: 2.4809\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1449 - mae: 2.1449 - val_loss: 2.5439 - val_mae: 2.5439\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1631 - mae: 2.1631 - val_loss: 2.4821 - val_mae: 2.4821\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1395 - mae: 2.1395 - val_loss: 2.4448 - val_mae: 2.4448\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1386 - mae: 2.1386 - val_loss: 2.4999 - val_mae: 2.4999\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1361 - mae: 2.1361 - val_loss: 2.4546 - val_mae: 2.4546\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1431 - mae: 2.1431 - val_loss: 2.4559 - val_mae: 2.4559\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1140 - mae: 2.1140 - val_loss: 2.4730 - val_mae: 2.4730\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1125 - mae: 2.1125 - val_loss: 2.4236 - val_mae: 2.4236\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1003 - mae: 2.1003 - val_loss: 2.4457 - val_mae: 2.4457\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1055 - mae: 2.1055 - val_loss: 2.4775 - val_mae: 2.4775\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1024 - mae: 2.1024 - val_loss: 2.4488 - val_mae: 2.4488\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0971 - mae: 2.0971 - val_loss: 2.4383 - val_mae: 2.4383\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0971 - mae: 2.0971 - val_loss: 2.4659 - val_mae: 2.4659\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0946 - mae: 2.0946 - val_loss: 2.4564 - val_mae: 2.4564\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0646 - mae: 2.0646 - val_loss: 2.4370 - val_mae: 2.4370\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0755 - mae: 2.0755 - val_loss: 2.4569 - val_mae: 2.4569\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0733 - mae: 2.0733 - val_loss: 2.4358 - val_mae: 2.4358\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0666 - mae: 2.0666 - val_loss: 2.4245 - val_mae: 2.4245\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0638 - mae: 2.0638 - val_loss: 2.4140 - val_mae: 2.4140\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0462 - mae: 2.0462 - val_loss: 2.4179 - val_mae: 2.4179\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0383 - mae: 2.0383 - val_loss: 2.4253 - val_mae: 2.4253\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0430 - mae: 2.0430 - val_loss: 2.4442 - val_mae: 2.4442\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0294 - mae: 2.0294 - val_loss: 2.3922 - val_mae: 2.3922\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0171 - mae: 2.0171 - val_loss: 2.4012 - val_mae: 2.4012\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0281 - mae: 2.0281 - val_loss: 2.4335 - val_mae: 2.4335\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0138 - mae: 2.0138 - val_loss: 2.3819 - val_mae: 2.3819\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0061 - mae: 2.0061 - val_loss: 2.4150 - val_mae: 2.4150\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0181 - mae: 2.0181 - val_loss: 2.4024 - val_mae: 2.4024\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0008 - mae: 2.0008 - val_loss: 2.3760 - val_mae: 2.3760\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9878 - mae: 1.9878 - val_loss: 2.3790 - val_mae: 2.3790\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9906 - mae: 1.9906 - val_loss: 2.3714 - val_mae: 2.3714\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9798 - mae: 1.9798 - val_loss: 2.4098 - val_mae: 2.4098\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9822 - mae: 1.9822 - val_loss: 2.4133 - val_mae: 2.4133\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9746 - mae: 1.9746 - val_loss: 2.3823 - val_mae: 2.3823\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9629 - mae: 1.9629 - val_loss: 2.4042 - val_mae: 2.4042\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9608 - mae: 1.9608 - val_loss: 2.3821 - val_mae: 2.3821\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9488 - mae: 1.9488 - val_loss: 2.3719 - val_mae: 2.3719\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9565 - mae: 1.9565 - val_loss: 2.3892 - val_mae: 2.3892\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9427 - mae: 1.9427 - val_loss: 2.3846 - val_mae: 2.3846\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9383 - mae: 1.9383 - val_loss: 2.3913 - val_mae: 2.3913\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9212 - mae: 1.9212 - val_loss: 2.3664 - val_mae: 2.3664\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9261 - mae: 1.9261 - val_loss: 2.3630 - val_mae: 2.3630\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9213 - mae: 1.9213 - val_loss: 2.4038 - val_mae: 2.4038\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9305 - mae: 1.9305 - val_loss: 2.3856 - val_mae: 2.3856\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9340 - mae: 1.9340 - val_loss: 2.3900 - val_mae: 2.3900\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9132 - mae: 1.9132 - val_loss: 2.3654 - val_mae: 2.3654\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9251 - mae: 1.9251 - val_loss: 2.3496 - val_mae: 2.3496\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9090 - mae: 1.9090 - val_loss: 2.3475 - val_mae: 2.3475\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9042 - mae: 1.9042 - val_loss: 2.3653 - val_mae: 2.3653\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8956 - mae: 1.8956 - val_loss: 2.3589 - val_mae: 2.3589\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8938 - mae: 1.8938 - val_loss: 2.3617 - val_mae: 2.3617\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9015 - mae: 1.9015 - val_loss: 2.3651 - val_mae: 2.3651\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8908 - mae: 1.8908 - val_loss: 2.3467 - val_mae: 2.3467\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8798 - mae: 1.8798 - val_loss: 2.3537 - val_mae: 2.3537\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8794 - mae: 1.8794 - val_loss: 2.3531 - val_mae: 2.3531\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8781 - mae: 1.8781 - val_loss: 2.3571 - val_mae: 2.3571\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8611 - mae: 1.8611 - val_loss: 2.3549 - val_mae: 2.3549\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8565 - mae: 1.8565 - val_loss: 2.3901 - val_mae: 2.3901\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8536 - mae: 1.8536 - val_loss: 2.3698 - val_mae: 2.3698\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7042 - mae: 3.7042\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 397.4600 - mae: 17.6539 - val_loss: 188.3748 - val_mae: 11.2774\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.9639 - mae: 7.5183 - val_loss: 59.2235 - val_mae: 5.7394\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6300 - mae: 4.9196 - val_loss: 38.0562 - val_mae: 4.4422\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.6376 - mae: 4.0946 - val_loss: 30.1835 - val_mae: 3.8459\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.3438 - mae: 3.6641 - val_loss: 26.1566 - val_mae: 3.5544\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.4029 - mae: 3.4237 - val_loss: 24.1726 - val_mae: 3.4034\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.5927 - mae: 3.2565 - val_loss: 22.6710 - val_mae: 3.3277\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.2807 - mae: 3.1490 - val_loss: 21.7433 - val_mae: 3.3067\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 18.2442 - mae: 3.0500 - val_loss: 21.1042 - val_mae: 3.1855\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.4888 - mae: 2.9300 - val_loss: 20.4278 - val_mae: 3.1986\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.6647 - mae: 2.8837 - val_loss: 19.9911 - val_mae: 3.1733\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.2889 - mae: 2.8620 - val_loss: 19.7265 - val_mae: 3.1736\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6304 - mae: 2.7899 - val_loss: 19.2131 - val_mae: 3.1399\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.2136 - mae: 2.7449 - val_loss: 18.8335 - val_mae: 3.1155\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7888 - mae: 2.7131 - val_loss: 18.7479 - val_mae: 3.0854\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4847 - mae: 2.6915 - val_loss: 18.4568 - val_mae: 3.0691\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2642 - mae: 2.6741 - val_loss: 18.1822 - val_mae: 3.0465\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.0482 - mae: 2.6345 - val_loss: 17.9356 - val_mae: 3.0238\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6497 - mae: 2.6103 - val_loss: 17.7275 - val_mae: 2.9979\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4643 - mae: 2.5950 - val_loss: 17.5162 - val_mae: 2.9910\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2076 - mae: 2.5577 - val_loss: 17.4101 - val_mae: 2.9465\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0360 - mae: 2.5421 - val_loss: 17.3887 - val_mae: 2.9316\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8551 - mae: 2.5465 - val_loss: 17.0838 - val_mae: 2.9307\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6879 - mae: 2.5381 - val_loss: 16.9845 - val_mae: 2.8823\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5528 - mae: 2.5017 - val_loss: 16.8742 - val_mae: 2.9204\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3543 - mae: 2.4738 - val_loss: 16.7477 - val_mae: 2.8679\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1888 - mae: 2.4508 - val_loss: 16.5593 - val_mae: 2.8600\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0578 - mae: 2.4486 - val_loss: 16.6318 - val_mae: 2.8591\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9522 - mae: 2.4444 - val_loss: 16.4569 - val_mae: 2.8477\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8098 - mae: 2.4246 - val_loss: 16.2958 - val_mae: 2.8427\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.7025 - mae: 2.4106 - val_loss: 16.2095 - val_mae: 2.8127\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6557 - mae: 2.4268 - val_loss: 16.0977 - val_mae: 2.7967\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4651 - mae: 2.3835 - val_loss: 16.0860 - val_mae: 2.7989\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4175 - mae: 2.3843 - val_loss: 15.9573 - val_mae: 2.7807\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2446 - mae: 2.3750 - val_loss: 15.7753 - val_mae: 2.7716\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1588 - mae: 2.3431 - val_loss: 15.7278 - val_mae: 2.7548\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1421 - mae: 2.3797 - val_loss: 15.6614 - val_mae: 2.7493\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9762 - mae: 2.3231 - val_loss: 15.6189 - val_mae: 2.7406\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8443 - mae: 2.3293 - val_loss: 15.5283 - val_mae: 2.7362\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7633 - mae: 2.3084 - val_loss: 15.4592 - val_mae: 2.7286\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.7022 - mae: 2.3008 - val_loss: 15.3413 - val_mae: 2.7258\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5572 - mae: 2.2923 - val_loss: 15.1879 - val_mae: 2.7043\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5271 - mae: 2.2837 - val_loss: 15.2053 - val_mae: 2.6953\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.4062 - mae: 2.2828 - val_loss: 15.2506 - val_mae: 2.7155\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3467 - mae: 2.2748 - val_loss: 15.0429 - val_mae: 2.6976\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3285 - mae: 2.2783 - val_loss: 15.1208 - val_mae: 2.6976\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1876 - mae: 2.2498 - val_loss: 15.0152 - val_mae: 2.6887\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0833 - mae: 2.2524 - val_loss: 14.9903 - val_mae: 2.7005\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9966 - mae: 2.2419 - val_loss: 14.9686 - val_mae: 2.6847\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9914 - mae: 2.2253 - val_loss: 14.9991 - val_mae: 2.6758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8878 - mae: 2.2238 - val_loss: 14.7237 - val_mae: 2.6583\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8718 - mae: 2.2124 - val_loss: 14.7627 - val_mae: 2.6538\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7930 - mae: 2.2079 - val_loss: 14.6858 - val_mae: 2.6505\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7043 - mae: 2.2011 - val_loss: 14.7217 - val_mae: 2.6535\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6141 - mae: 2.2117 - val_loss: 14.5163 - val_mae: 2.6404\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5268 - mae: 2.1935 - val_loss: 14.6315 - val_mae: 2.6347\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5911 - mae: 2.1919 - val_loss: 14.5432 - val_mae: 2.6356\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4409 - mae: 2.1756 - val_loss: 14.4715 - val_mae: 2.6269\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4621 - mae: 2.1952 - val_loss: 14.4816 - val_mae: 2.6259\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2905 - mae: 2.1545 - val_loss: 14.3775 - val_mae: 2.6164\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2924 - mae: 2.1649 - val_loss: 14.4931 - val_mae: 2.6248\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2236 - mae: 2.1538 - val_loss: 14.4155 - val_mae: 2.6158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1176 - mae: 2.1481 - val_loss: 14.2569 - val_mae: 2.5983\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1255 - mae: 2.1433 - val_loss: 14.2689 - val_mae: 2.6075\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0300 - mae: 2.1439 - val_loss: 14.2512 - val_mae: 2.5982\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0513 - mae: 2.1451 - val_loss: 14.3676 - val_mae: 2.6001\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8806 - mae: 2.1082 - val_loss: 14.2586 - val_mae: 2.5933\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8637 - mae: 2.1205 - val_loss: 14.1304 - val_mae: 2.5888\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8370 - mae: 2.1334 - val_loss: 14.1027 - val_mae: 2.5755\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8125 - mae: 2.1166 - val_loss: 14.2000 - val_mae: 2.5883\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7309 - mae: 2.1063 - val_loss: 14.1074 - val_mae: 2.5886\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6449 - mae: 2.1028 - val_loss: 14.0754 - val_mae: 2.5651\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6236 - mae: 2.0975 - val_loss: 13.9445 - val_mae: 2.5791\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5626 - mae: 2.0888 - val_loss: 14.0532 - val_mae: 2.5743\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5356 - mae: 2.0948 - val_loss: 13.9730 - val_mae: 2.5818\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3964 - mae: 2.0766 - val_loss: 14.1221 - val_mae: 2.5625\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4000 - mae: 2.0759 - val_loss: 13.9251 - val_mae: 2.5563\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3728 - mae: 2.0713 - val_loss: 13.9517 - val_mae: 2.5594\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3339 - mae: 2.0742 - val_loss: 13.9367 - val_mae: 2.5517\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2837 - mae: 2.0617 - val_loss: 13.9418 - val_mae: 2.5609\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2118 - mae: 2.0592 - val_loss: 13.7791 - val_mae: 2.5483\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1224 - mae: 2.0474 - val_loss: 13.8673 - val_mae: 2.5461\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1084 - mae: 2.0376 - val_loss: 13.8610 - val_mae: 2.5349\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0723 - mae: 2.0341 - val_loss: 13.8556 - val_mae: 2.5523\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0448 - mae: 2.0283 - val_loss: 13.9088 - val_mae: 2.5395\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9642 - mae: 2.0273 - val_loss: 13.8005 - val_mae: 2.5537\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9581 - mae: 2.0229 - val_loss: 13.9489 - val_mae: 2.5333\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8857 - mae: 2.0174 - val_loss: 13.7541 - val_mae: 2.5411\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8207 - mae: 2.0152 - val_loss: 13.8326 - val_mae: 2.5358\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7983 - mae: 2.0058 - val_loss: 13.7762 - val_mae: 2.5290\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7549 - mae: 2.0025 - val_loss: 13.7593 - val_mae: 2.5363\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7199 - mae: 2.0032 - val_loss: 13.8563 - val_mae: 2.5268\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6788 - mae: 1.9925 - val_loss: 13.6201 - val_mae: 2.5332\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5795 - mae: 1.9786 - val_loss: 13.7512 - val_mae: 2.5211\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5384 - mae: 1.9774 - val_loss: 13.5828 - val_mae: 2.5309\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5014 - mae: 1.9742 - val_loss: 13.6758 - val_mae: 2.5229\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5359 - mae: 1.9837 - val_loss: 13.6226 - val_mae: 2.5377\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4993 - mae: 1.9756 - val_loss: 13.5424 - val_mae: 2.5129\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3978 - mae: 1.9602 - val_loss: 13.7528 - val_mae: 2.5214\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3488 - mae: 1.9561 - val_loss: 13.6722 - val_mae: 2.5212\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.0436 - mae: 3.5409\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 17.5079 - mae: 17.5079 - val_loss: 11.1586 - val_mae: 11.1586\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1114 - mae: 7.1114 - val_loss: 5.4351 - val_mae: 5.4351\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5566 - mae: 4.5566 - val_loss: 3.8774 - val_mae: 3.8774\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7290 - mae: 3.7290 - val_loss: 3.3560 - val_mae: 3.3560\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3285 - mae: 3.3285 - val_loss: 3.2385 - val_mae: 3.2385\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1193 - mae: 3.1193 - val_loss: 3.1121 - val_mae: 3.1121\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9860 - mae: 2.9860 - val_loss: 3.0120 - val_mae: 3.0120\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8995 - mae: 2.8995 - val_loss: 2.9599 - val_mae: 2.9599\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7956 - mae: 2.7956 - val_loss: 2.9044 - val_mae: 2.9044\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7348 - mae: 2.7348 - val_loss: 2.9083 - val_mae: 2.9083\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7190 - mae: 2.7190 - val_loss: 2.8807 - val_mae: 2.8807\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6526 - mae: 2.6526 - val_loss: 2.8566 - val_mae: 2.8566\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6248 - mae: 2.6248 - val_loss: 2.7922 - val_mae: 2.7922\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5781 - mae: 2.5781 - val_loss: 2.8248 - val_mae: 2.8248\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5596 - mae: 2.5596 - val_loss: 2.7511 - val_mae: 2.7511\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5517 - mae: 2.5517 - val_loss: 2.7871 - val_mae: 2.7871\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4904 - mae: 2.4904 - val_loss: 2.7463 - val_mae: 2.7463\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4664 - mae: 2.4664 - val_loss: 2.7684 - val_mae: 2.7684\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4517 - mae: 2.4517 - val_loss: 2.7294 - val_mae: 2.7294\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4351 - mae: 2.4351 - val_loss: 2.7104 - val_mae: 2.7104\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4222 - mae: 2.4222 - val_loss: 2.6917 - val_mae: 2.6917\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3986 - mae: 2.3986 - val_loss: 2.6719 - val_mae: 2.6719\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4082 - mae: 2.4082 - val_loss: 2.6592 - val_mae: 2.6592\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3759 - mae: 2.3759 - val_loss: 2.6821 - val_mae: 2.6821\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3527 - mae: 2.3527 - val_loss: 2.6443 - val_mae: 2.6443\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3428 - mae: 2.3428 - val_loss: 2.6642 - val_mae: 2.6642\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3376 - mae: 2.3376 - val_loss: 2.6938 - val_mae: 2.6938\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3302 - mae: 2.3302 - val_loss: 2.6405 - val_mae: 2.6405\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3040 - mae: 2.3040 - val_loss: 2.6418 - val_mae: 2.6418\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2950 - mae: 2.2950 - val_loss: 2.6242 - val_mae: 2.6242\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2813 - mae: 2.2813 - val_loss: 2.6174 - val_mae: 2.6174\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2785 - mae: 2.2785 - val_loss: 2.6446 - val_mae: 2.6446\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2917 - mae: 2.2917 - val_loss: 2.6369 - val_mae: 2.6369\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2691 - mae: 2.2691 - val_loss: 2.5943 - val_mae: 2.5943\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2505 - mae: 2.2505 - val_loss: 2.6133 - val_mae: 2.6133\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2428 - mae: 2.2428 - val_loss: 2.5913 - val_mae: 2.5913\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2337 - mae: 2.2337 - val_loss: 2.6348 - val_mae: 2.6348\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2358 - mae: 2.2358 - val_loss: 2.5825 - val_mae: 2.5825\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2221 - mae: 2.2221 - val_loss: 2.5979 - val_mae: 2.5979\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2146 - mae: 2.2146 - val_loss: 2.6094 - val_mae: 2.6094\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2078 - mae: 2.2078 - val_loss: 2.5712 - val_mae: 2.5712\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1977 - mae: 2.1977 - val_loss: 2.5864 - val_mae: 2.5864\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1918 - mae: 2.1918 - val_loss: 2.5975 - val_mae: 2.5975\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2003 - mae: 2.2003 - val_loss: 2.5644 - val_mae: 2.5644\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1868 - mae: 2.1868 - val_loss: 2.5573 - val_mae: 2.5573\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1786 - mae: 2.1786 - val_loss: 2.5277 - val_mae: 2.5277\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1708 - mae: 2.1708 - val_loss: 2.5515 - val_mae: 2.5515\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1541 - mae: 2.1541 - val_loss: 2.5447 - val_mae: 2.5447\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1450 - mae: 2.1450 - val_loss: 2.5204 - val_mae: 2.5204\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1556 - mae: 2.1556 - val_loss: 2.4848 - val_mae: 2.4848\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1566 - mae: 2.1566 - val_loss: 2.5545 - val_mae: 2.5545\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1408 - mae: 2.1408 - val_loss: 2.4891 - val_mae: 2.4891\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1380 - mae: 2.1380 - val_loss: 2.5043 - val_mae: 2.5043\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1194 - mae: 2.1194 - val_loss: 2.4796 - val_mae: 2.4796\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1141 - mae: 2.1141 - val_loss: 2.4812 - val_mae: 2.4812\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1085 - mae: 2.1085 - val_loss: 2.4963 - val_mae: 2.4963\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1297 - mae: 2.1297 - val_loss: 2.4985 - val_mae: 2.4985\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0918 - mae: 2.0918 - val_loss: 2.4719 - val_mae: 2.4719\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0882 - mae: 2.0882 - val_loss: 2.4779 - val_mae: 2.4779\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0882 - mae: 2.0882 - val_loss: 2.4552 - val_mae: 2.4552\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0700 - mae: 2.0700 - val_loss: 2.5146 - val_mae: 2.5146\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0730 - mae: 2.0730 - val_loss: 2.4787 - val_mae: 2.4787\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0731 - mae: 2.0731 - val_loss: 2.4727 - val_mae: 2.4727\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0580 - mae: 2.0580 - val_loss: 2.4739 - val_mae: 2.4739\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0585 - mae: 2.0585 - val_loss: 2.4682 - val_mae: 2.4682\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0595 - mae: 2.0595 - val_loss: 2.4479 - val_mae: 2.4479\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0452 - mae: 2.0452 - val_loss: 2.4362 - val_mae: 2.4362\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0375 - mae: 2.0375 - val_loss: 2.4478 - val_mae: 2.4478\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0358 - mae: 2.0358 - val_loss: 2.4734 - val_mae: 2.4734\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0278 - mae: 2.0278 - val_loss: 2.4740 - val_mae: 2.4740\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0217 - mae: 2.0217 - val_loss: 2.4491 - val_mae: 2.4491\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0215 - mae: 2.0215 - val_loss: 2.4398 - val_mae: 2.4398\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0091 - mae: 2.0091 - val_loss: 2.4407 - val_mae: 2.4407\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0267 - mae: 2.0267 - val_loss: 2.4695 - val_mae: 2.4695\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0095 - mae: 2.0095 - val_loss: 2.4393 - val_mae: 2.4393\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9968 - mae: 1.9968 - val_loss: 2.4368 - val_mae: 2.4368\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9881 - mae: 1.9881 - val_loss: 2.4459 - val_mae: 2.4459\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9909 - mae: 1.9909 - val_loss: 2.4413 - val_mae: 2.4413\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9873 - mae: 1.9873 - val_loss: 2.4357 - val_mae: 2.4357\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9818 - mae: 1.9818 - val_loss: 2.4320 - val_mae: 2.4320\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9720 - mae: 1.9720 - val_loss: 2.4352 - val_mae: 2.4352\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9744 - mae: 1.9744 - val_loss: 2.3964 - val_mae: 2.3964\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9582 - mae: 1.9582 - val_loss: 2.4089 - val_mae: 2.4089\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9727 - mae: 1.9727 - val_loss: 2.3861 - val_mae: 2.3861\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9543 - mae: 1.9543 - val_loss: 2.4211 - val_mae: 2.4211\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9641 - mae: 1.9641 - val_loss: 2.3703 - val_mae: 2.3703\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9474 - mae: 1.9474 - val_loss: 2.3843 - val_mae: 2.3843\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9400 - mae: 1.9400 - val_loss: 2.3766 - val_mae: 2.3766\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9404 - mae: 1.9404 - val_loss: 2.3785 - val_mae: 2.3785\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9412 - mae: 1.9412 - val_loss: 2.4715 - val_mae: 2.4715\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9399 - mae: 1.9399 - val_loss: 2.4281 - val_mae: 2.4281\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9168 - mae: 1.9168 - val_loss: 2.3791 - val_mae: 2.3791\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9179 - mae: 1.9179 - val_loss: 2.3766 - val_mae: 2.3766\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9032 - mae: 1.9032 - val_loss: 2.4167 - val_mae: 2.4167\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9142 - mae: 1.9142 - val_loss: 2.3875 - val_mae: 2.3875\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8925 - mae: 1.8925 - val_loss: 2.4023 - val_mae: 2.4023\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8981 - mae: 1.8981 - val_loss: 2.3883 - val_mae: 2.3883\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9268 - mae: 1.9268 - val_loss: 2.3963 - val_mae: 2.3963\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8918 - mae: 1.8918 - val_loss: 2.3632 - val_mae: 2.3632\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8844 - mae: 1.8844 - val_loss: 2.3866 - val_mae: 2.3866\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6388 - mae: 3.6388\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 288.1837 - mae: 14.3001 - val_loss: 173.3641 - val_mae: 9.8645\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 138.6415 - mae: 8.7821 - val_loss: 127.0003 - val_mae: 7.9908\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 108.8208 - mae: 7.4638 - val_loss: 108.0683 - val_mae: 7.2828\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.4593 - mae: 6.7872 - val_loss: 97.9892 - val_mae: 6.8960\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.5698 - mae: 6.4270 - val_loss: 91.3684 - val_mae: 6.6550\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.7573 - mae: 6.2087 - val_loss: 87.1664 - val_mae: 6.5523\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.4307 - mae: 6.0959 - val_loss: 84.1115 - val_mae: 6.5044\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.0062 - mae: 6.0028 - val_loss: 81.5729 - val_mae: 6.4514\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.8717 - mae: 5.9289 - val_loss: 79.2337 - val_mae: 6.3788\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.9057 - mae: 5.8499 - val_loss: 77.0341 - val_mae: 6.2832\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.0045 - mae: 5.7545 - val_loss: 74.9001 - val_mae: 6.1809\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.1675 - mae: 5.6777 - val_loss: 72.7685 - val_mae: 6.0783\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.3380 - mae: 5.5787 - val_loss: 70.8125 - val_mae: 5.9483\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6151 - mae: 5.4672 - val_loss: 68.9996 - val_mae: 5.8265\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.0924 - mae: 5.3974 - val_loss: 67.3197 - val_mae: 5.7311\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.6201 - mae: 5.2777 - val_loss: 65.8123 - val_mae: 5.6129\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.2464 - mae: 5.2210 - val_loss: 64.4666 - val_mae: 5.5415\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.9996 - mae: 5.1390 - val_loss: 63.2800 - val_mae: 5.4685\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9309 - mae: 5.0785 - val_loss: 62.0748 - val_mae: 5.3976\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.9208 - mae: 5.0666 - val_loss: 61.0287 - val_mae: 5.3629\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.9129 - mae: 4.9930 - val_loss: 60.0924 - val_mae: 5.2655\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.0611 - mae: 4.9303 - val_loss: 59.2031 - val_mae: 5.1934\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.2211 - mae: 4.9176 - val_loss: 58.3701 - val_mae: 5.2093\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.5090 - mae: 4.8990 - val_loss: 57.5456 - val_mae: 5.1712\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.7129 - mae: 4.8850 - val_loss: 56.8295 - val_mae: 5.1251\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0433 - mae: 4.8568 - val_loss: 56.1255 - val_mae: 5.0505\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3530 - mae: 4.8230 - val_loss: 55.4863 - val_mae: 5.0310\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.7465 - mae: 4.8006 - val_loss: 54.8280 - val_mae: 5.0105\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.1298 - mae: 4.7221 - val_loss: 54.3179 - val_mae: 4.9171\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4967 - mae: 4.7342 - val_loss: 53.6960 - val_mae: 4.9676\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9381 - mae: 4.7353 - val_loss: 53.1230 - val_mae: 4.9032\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4735 - mae: 4.6440 - val_loss: 52.6375 - val_mae: 4.8648\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.8355 - mae: 4.6369 - val_loss: 52.0796 - val_mae: 4.8544\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.2821 - mae: 4.6281 - val_loss: 51.5803 - val_mae: 4.8392\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8186 - mae: 4.6375 - val_loss: 51.0440 - val_mae: 4.7564\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.2835 - mae: 4.5827 - val_loss: 50.5751 - val_mae: 4.6891\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.6446 - mae: 4.5416 - val_loss: 50.0384 - val_mae: 4.7111\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.1892 - mae: 4.4738 - val_loss: 49.5025 - val_mae: 4.6986\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.5921 - mae: 4.4437 - val_loss: 49.0556 - val_mae: 4.6125\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0636 - mae: 4.4524 - val_loss: 48.5192 - val_mae: 4.6015\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.5088 - mae: 4.4277 - val_loss: 48.0468 - val_mae: 4.5832\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0071 - mae: 4.3883 - val_loss: 47.5588 - val_mae: 4.5550\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3482 - mae: 4.3254 - val_loss: 47.1114 - val_mae: 4.4765\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8361 - mae: 4.2974 - val_loss: 46.5832 - val_mae: 4.4511\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.2624 - mae: 4.2806 - val_loss: 46.0655 - val_mae: 4.4048\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7190 - mae: 4.2453 - val_loss: 45.6030 - val_mae: 4.3607\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.1365 - mae: 4.1633 - val_loss: 45.0295 - val_mae: 4.3948\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.6129 - mae: 4.1843 - val_loss: 44.5420 - val_mae: 4.4112\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.9763 - mae: 4.1515 - val_loss: 44.0295 - val_mae: 4.3048\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.5590 - mae: 4.0650 - val_loss: 43.5461 - val_mae: 4.2693\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.8874 - mae: 4.1033 - val_loss: 43.0176 - val_mae: 4.2836\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.4241 - mae: 4.0323 - val_loss: 42.5432 - val_mae: 4.2389\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7872 - mae: 4.0047 - val_loss: 42.1266 - val_mae: 4.1963\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.3234 - mae: 3.9899 - val_loss: 41.6382 - val_mae: 4.1719\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.8065 - mae: 3.9455 - val_loss: 41.1898 - val_mae: 4.1261\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.2423 - mae: 3.9203 - val_loss: 40.7250 - val_mae: 4.0932\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.8489 - mae: 3.8803 - val_loss: 40.3415 - val_mae: 4.0369\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.2988 - mae: 3.8206 - val_loss: 39.9365 - val_mae: 4.0612\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.9161 - mae: 3.8560 - val_loss: 39.4915 - val_mae: 4.0415\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4710 - mae: 3.8210 - val_loss: 39.0969 - val_mae: 4.0514\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.1587 - mae: 3.8028 - val_loss: 38.7554 - val_mae: 4.0168\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.8672 - mae: 3.8360 - val_loss: 38.5333 - val_mae: 3.9596\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.2589 - mae: 3.7355 - val_loss: 38.0424 - val_mae: 3.9990\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.9481 - mae: 3.7548 - val_loss: 37.7452 - val_mae: 3.9991\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.6433 - mae: 3.7379 - val_loss: 37.4486 - val_mae: 3.9733\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3108 - mae: 3.7261 - val_loss: 37.1960 - val_mae: 3.9441\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.1428 - mae: 3.7096 - val_loss: 37.0442 - val_mae: 3.9105\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.8017 - mae: 3.6704 - val_loss: 36.6386 - val_mae: 3.9446\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4945 - mae: 3.6654 - val_loss: 36.3154 - val_mae: 3.9883\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.2544 - mae: 3.6832 - val_loss: 36.1088 - val_mae: 3.9140\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9597 - mae: 3.6427 - val_loss: 35.8007 - val_mae: 3.9379\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.7143 - mae: 3.6331 - val_loss: 35.7400 - val_mae: 3.8805\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.4752 - mae: 3.6012 - val_loss: 35.3678 - val_mae: 3.9263\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.3187 - mae: 3.6305 - val_loss: 35.2065 - val_mae: 3.8926\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.0487 - mae: 3.6344 - val_loss: 34.9825 - val_mae: 3.8812\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9317 - mae: 3.5811 - val_loss: 34.7514 - val_mae: 3.8773\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.6358 - mae: 3.5938 - val_loss: 34.4937 - val_mae: 3.8943\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5661 - mae: 3.5617 - val_loss: 34.2851 - val_mae: 3.9209\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4056 - mae: 3.5748 - val_loss: 34.1618 - val_mae: 3.8545\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.1732 - mae: 3.6035 - val_loss: 33.9424 - val_mae: 3.8602\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9142 - mae: 3.5073 - val_loss: 33.7145 - val_mae: 3.8700\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.7715 - mae: 3.5451 - val_loss: 33.5265 - val_mae: 3.8520\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5839 - mae: 3.5388 - val_loss: 33.3787 - val_mae: 3.8386\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4454 - mae: 3.5416 - val_loss: 33.3181 - val_mae: 3.8048\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.3226 - mae: 3.4957 - val_loss: 32.9743 - val_mae: 3.8242\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0624 - mae: 3.5158 - val_loss: 32.8418 - val_mae: 3.8177\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.9551 - mae: 3.5117 - val_loss: 32.7600 - val_mae: 3.7815\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.8486 - mae: 3.4913 - val_loss: 32.5976 - val_mae: 3.7741\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7591 - mae: 3.4623 - val_loss: 32.2967 - val_mae: 3.8559\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.4824 - mae: 3.5013 - val_loss: 32.5029 - val_mae: 3.7361\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.3109 - mae: 3.4250 - val_loss: 31.9627 - val_mae: 3.7923\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.2358 - mae: 3.4806 - val_loss: 31.7658 - val_mae: 3.8086\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.0457 - mae: 3.4409 - val_loss: 31.8310 - val_mae: 3.7186\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.9692 - mae: 3.4234 - val_loss: 31.4592 - val_mae: 3.7706\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.8216 - mae: 3.4229 - val_loss: 31.2603 - val_mae: 3.7745\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 25.7049 - mae: 3.4303 - val_loss: 31.2149 - val_mae: 3.7067\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.5722 - mae: 3.4239 - val_loss: 31.0029 - val_mae: 3.7164\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.3800 - mae: 3.3773 - val_loss: 30.8619 - val_mae: 3.6982\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.2725 - mae: 3.3999 - val_loss: 30.6617 - val_mae: 3.7069\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.1867 - mae: 3.3946 - val_loss: 30.5171 - val_mae: 3.7329\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37.7688 - mae: 4.1786\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 15.8939 - mae: 15.8939 - val_loss: 11.3596 - val_mae: 11.3596\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0196 - mae: 10.0196 - val_loss: 8.9619 - val_mae: 8.9619\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3582 - mae: 8.3582 - val_loss: 7.9336 - val_mae: 7.9336\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4356 - mae: 7.4356 - val_loss: 7.3522 - val_mae: 7.3522\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8602 - mae: 6.8602 - val_loss: 6.9911 - val_mae: 6.9911\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5278 - mae: 6.5278 - val_loss: 6.7667 - val_mae: 6.7667\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3216 - mae: 6.3216 - val_loss: 6.6296 - val_mae: 6.6296\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1738 - mae: 6.1738 - val_loss: 6.5063 - val_mae: 6.5063\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0443 - mae: 6.0443 - val_loss: 6.3542 - val_mae: 6.3542\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9067 - mae: 5.9067 - val_loss: 6.1699 - val_mae: 6.1699\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7523 - mae: 5.7523 - val_loss: 5.9833 - val_mae: 5.9833\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6002 - mae: 5.6002 - val_loss: 5.7765 - val_mae: 5.7765\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4459 - mae: 5.4459 - val_loss: 5.6158 - val_mae: 5.6158\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3099 - mae: 5.3099 - val_loss: 5.4613 - val_mae: 5.4613\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1968 - mae: 5.1968 - val_loss: 5.3156 - val_mae: 5.3156\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1002 - mae: 5.1002 - val_loss: 5.1916 - val_mae: 5.1916\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0146 - mae: 5.0146 - val_loss: 5.0871 - val_mae: 5.0871\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9415 - mae: 4.9415 - val_loss: 4.9762 - val_mae: 4.9762\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8660 - mae: 4.8660 - val_loss: 4.8806 - val_mae: 4.8806\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7968 - mae: 4.7968 - val_loss: 4.7951 - val_mae: 4.7951\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7459 - mae: 4.7459 - val_loss: 4.7354 - val_mae: 4.7354\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7018 - mae: 4.7018 - val_loss: 4.7067 - val_mae: 4.7067\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6599 - mae: 4.6599 - val_loss: 4.6453 - val_mae: 4.6453\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6171 - mae: 4.6171 - val_loss: 4.6163 - val_mae: 4.6163\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5810 - mae: 4.5810 - val_loss: 4.6055 - val_mae: 4.6055\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5459 - mae: 4.5459 - val_loss: 4.5601 - val_mae: 4.5601\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5173 - mae: 4.5173 - val_loss: 4.5366 - val_mae: 4.5366\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4927 - mae: 4.4927 - val_loss: 4.5174 - val_mae: 4.5174\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4700 - mae: 4.4700 - val_loss: 4.5016 - val_mae: 4.5016\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4446 - mae: 4.4446 - val_loss: 4.4927 - val_mae: 4.4927\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4213 - mae: 4.4213 - val_loss: 4.4707 - val_mae: 4.4707\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3950 - mae: 4.3950 - val_loss: 4.4568 - val_mae: 4.4568\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3715 - mae: 4.3715 - val_loss: 4.4459 - val_mae: 4.4459\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3553 - mae: 4.3553 - val_loss: 4.4254 - val_mae: 4.4254\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3339 - mae: 4.3339 - val_loss: 4.4273 - val_mae: 4.4273\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3213 - mae: 4.3213 - val_loss: 4.4043 - val_mae: 4.4043\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2880 - mae: 4.2880 - val_loss: 4.3899 - val_mae: 4.3899\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2600 - mae: 4.2600 - val_loss: 4.3769 - val_mae: 4.3769\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2429 - mae: 4.2429 - val_loss: 4.3641 - val_mae: 4.3641\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2156 - mae: 4.2156 - val_loss: 4.3583 - val_mae: 4.3583\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1915 - mae: 4.1915 - val_loss: 4.3458 - val_mae: 4.3458\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1727 - mae: 4.1727 - val_loss: 4.3596 - val_mae: 4.3596\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1507 - mae: 4.1507 - val_loss: 4.3378 - val_mae: 4.3378\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1318 - mae: 4.1318 - val_loss: 4.3246 - val_mae: 4.3246\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1066 - mae: 4.1066 - val_loss: 4.3141 - val_mae: 4.3141\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0777 - mae: 4.0777 - val_loss: 4.3236 - val_mae: 4.3236\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0606 - mae: 4.0606 - val_loss: 4.3004 - val_mae: 4.3004\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0361 - mae: 4.0361 - val_loss: 4.2955 - val_mae: 4.2955\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0173 - mae: 4.0173 - val_loss: 4.2794 - val_mae: 4.2794\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0033 - mae: 4.0033 - val_loss: 4.2671 - val_mae: 4.2671\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9873 - mae: 3.9873 - val_loss: 4.2573 - val_mae: 4.2573\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9663 - mae: 3.9663 - val_loss: 4.2467 - val_mae: 4.2467\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9545 - mae: 3.9545 - val_loss: 4.2428 - val_mae: 4.2428\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9367 - mae: 3.9367 - val_loss: 4.2329 - val_mae: 4.2329\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9251 - mae: 3.9251 - val_loss: 4.2119 - val_mae: 4.2119\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9095 - mae: 3.9095 - val_loss: 4.2142 - val_mae: 4.2142\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8918 - mae: 3.8918 - val_loss: 4.2116 - val_mae: 4.2116\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9047 - mae: 3.9047 - val_loss: 4.2021 - val_mae: 4.2021\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8650 - mae: 3.8650 - val_loss: 4.1825 - val_mae: 4.1825\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8505 - mae: 3.8505 - val_loss: 4.1698 - val_mae: 4.1698\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8416 - mae: 3.8416 - val_loss: 4.1562 - val_mae: 4.1562\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8269 - mae: 3.8269 - val_loss: 4.1516 - val_mae: 4.1516\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8258 - mae: 3.8258 - val_loss: 4.1623 - val_mae: 4.1623\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8039 - mae: 3.8039 - val_loss: 4.1532 - val_mae: 4.1532\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7903 - mae: 3.7903 - val_loss: 4.1421 - val_mae: 4.1421\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7843 - mae: 3.7843 - val_loss: 4.1248 - val_mae: 4.1248\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7694 - mae: 3.7694 - val_loss: 4.1238 - val_mae: 4.1238\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7580 - mae: 3.7580 - val_loss: 4.1177 - val_mae: 4.1177\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7533 - mae: 3.7533 - val_loss: 4.1057 - val_mae: 4.1057\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7418 - mae: 3.7418 - val_loss: 4.1133 - val_mae: 4.1133\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7297 - mae: 3.7297 - val_loss: 4.0979 - val_mae: 4.0979\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7442 - mae: 3.7442 - val_loss: 4.1075 - val_mae: 4.1075\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7126 - mae: 3.7126 - val_loss: 4.0920 - val_mae: 4.0920\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7182 - mae: 3.7182 - val_loss: 4.0988 - val_mae: 4.0988\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6949 - mae: 3.6949 - val_loss: 4.0868 - val_mae: 4.0868\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6872 - mae: 3.6872 - val_loss: 4.0660 - val_mae: 4.0660\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6817 - mae: 3.6817 - val_loss: 4.0673 - val_mae: 4.0673\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6774 - mae: 3.6774 - val_loss: 4.0650 - val_mae: 4.0650\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6590 - mae: 3.6590 - val_loss: 4.0684 - val_mae: 4.0684\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6639 - mae: 3.6639 - val_loss: 4.0907 - val_mae: 4.0907\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6510 - mae: 3.6510 - val_loss: 4.0731 - val_mae: 4.0731\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6342 - mae: 3.6342 - val_loss: 4.0815 - val_mae: 4.0815\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6332 - mae: 3.6332 - val_loss: 4.0953 - val_mae: 4.0953\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6244 - mae: 3.6244 - val_loss: 4.0277 - val_mae: 4.0277\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6169 - mae: 3.6169 - val_loss: 4.0462 - val_mae: 4.0462\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6076 - mae: 3.6076 - val_loss: 4.0248 - val_mae: 4.0248\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6051 - mae: 3.6051 - val_loss: 4.0134 - val_mae: 4.0134\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5962 - mae: 3.5962 - val_loss: 4.0475 - val_mae: 4.0475\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5983 - mae: 3.5983 - val_loss: 4.0330 - val_mae: 4.0330\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5874 - mae: 3.5874 - val_loss: 3.9839 - val_mae: 3.9839\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5782 - mae: 3.5782 - val_loss: 4.0006 - val_mae: 4.0006\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5777 - mae: 3.5777 - val_loss: 3.9926 - val_mae: 3.9926\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5665 - mae: 3.5665 - val_loss: 4.0280 - val_mae: 4.0280\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5591 - mae: 3.5591 - val_loss: 3.9696 - val_mae: 3.9696\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5587 - mae: 3.5587 - val_loss: 3.9554 - val_mae: 3.9554\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5565 - mae: 3.5565 - val_loss: 3.9708 - val_mae: 3.9708\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5531 - mae: 3.5531 - val_loss: 3.9161 - val_mae: 3.9161\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5451 - mae: 3.5451 - val_loss: 3.9345 - val_mae: 3.9345\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5374 - mae: 3.5374 - val_loss: 3.9705 - val_mae: 3.9705\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5397 - mae: 3.5397 - val_loss: 3.9381 - val_mae: 3.9381\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.8815 - mae: 4.8815\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 334.7275 - mae: 15.6284 - val_loss: 210.7013 - val_mae: 11.3909\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.9412 - mae: 10.1948 - val_loss: 156.7458 - val_mae: 9.1842\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 134.8319 - mae: 8.6211 - val_loss: 130.9352 - val_mae: 8.1370\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 114.4154 - mae: 7.7257 - val_loss: 114.8655 - val_mae: 7.5244\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.4169 - mae: 7.1164 - val_loss: 104.6785 - val_mae: 7.1486\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.1482 - mae: 6.7287 - val_loss: 97.6778 - val_mae: 6.8725\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.5091 - mae: 6.4567 - val_loss: 92.7808 - val_mae: 6.6737\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.3965 - mae: 6.2610 - val_loss: 89.0815 - val_mae: 6.5651\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.2337 - mae: 6.1339 - val_loss: 85.8487 - val_mae: 6.4781\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.6179 - mae: 6.0310 - val_loss: 83.3396 - val_mae: 6.4153\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.3978 - mae: 5.9552 - val_loss: 80.8360 - val_mae: 6.3490\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.3343 - mae: 5.8601 - val_loss: 78.5274 - val_mae: 6.2799\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.3198 - mae: 5.7749 - val_loss: 76.1357 - val_mae: 6.1555\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.3535 - mae: 5.6691 - val_loss: 74.0943 - val_mae: 6.0520\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.5511 - mae: 5.5746 - val_loss: 72.1018 - val_mae: 5.9312\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.7880 - mae: 5.4962 - val_loss: 70.1212 - val_mae: 5.8450\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.1273 - mae: 5.4013 - val_loss: 68.5856 - val_mae: 5.7421\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 62.6913 - mae: 5.3180 - val_loss: 66.9321 - val_mae: 5.6445\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.3110 - mae: 5.2342 - val_loss: 65.6235 - val_mae: 5.5513\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.1039 - mae: 5.1749 - val_loss: 64.3810 - val_mae: 5.4831\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.0153 - mae: 5.1117 - val_loss: 63.2625 - val_mae: 5.4134\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9733 - mae: 5.0854 - val_loss: 62.1960 - val_mae: 5.3611\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.0636 - mae: 5.0051 - val_loss: 61.2699 - val_mae: 5.2831\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.1563 - mae: 4.9958 - val_loss: 60.3738 - val_mae: 5.2588\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.4243 - mae: 4.9816 - val_loss: 59.5822 - val_mae: 5.2213\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.6197 - mae: 4.9213 - val_loss: 58.8210 - val_mae: 5.1384\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.9680 - mae: 4.9082 - val_loss: 58.1685 - val_mae: 5.1290\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2796 - mae: 4.8550 - val_loss: 57.5241 - val_mae: 5.0861\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.6596 - mae: 4.8458 - val_loss: 56.8348 - val_mae: 5.0694\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0755 - mae: 4.8253 - val_loss: 56.2755 - val_mae: 5.0431\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.6264 - mae: 4.7666 - val_loss: 55.7247 - val_mae: 5.0073\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.0107 - mae: 4.8020 - val_loss: 55.2265 - val_mae: 4.9712\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.4831 - mae: 4.7289 - val_loss: 54.7329 - val_mae: 4.9505\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.0616 - mae: 4.7716 - val_loss: 54.2104 - val_mae: 4.9121\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4682 - mae: 4.6915 - val_loss: 53.7177 - val_mae: 4.8797\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9991 - mae: 4.7024 - val_loss: 53.2420 - val_mae: 4.9111\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4416 - mae: 4.6958 - val_loss: 52.7691 - val_mae: 4.8358\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.9907 - mae: 4.6124 - val_loss: 52.2895 - val_mae: 4.7997\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.5271 - mae: 4.6418 - val_loss: 51.8357 - val_mae: 4.8222\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.0934 - mae: 4.6055 - val_loss: 51.3908 - val_mae: 4.7990\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.5761 - mae: 4.5944 - val_loss: 50.9497 - val_mae: 4.7484\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0991 - mae: 4.5119 - val_loss: 50.5115 - val_mae: 4.6867\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5916 - mae: 4.4737 - val_loss: 50.0514 - val_mae: 4.6829\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.0575 - mae: 4.5010 - val_loss: 49.6245 - val_mae: 4.6703\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6235 - mae: 4.4794 - val_loss: 49.1652 - val_mae: 4.6219\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.0905 - mae: 4.3965 - val_loss: 48.7022 - val_mae: 4.6045\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.5767 - mae: 4.3899 - val_loss: 48.2701 - val_mae: 4.5951\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.0778 - mae: 4.3577 - val_loss: 47.7491 - val_mae: 4.5551\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.5052 - mae: 4.3617 - val_loss: 47.2855 - val_mae: 4.5261\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0113 - mae: 4.3200 - val_loss: 46.8498 - val_mae: 4.4387\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.5043 - mae: 4.2956 - val_loss: 46.3350 - val_mae: 4.4624\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.9361 - mae: 4.2249 - val_loss: 45.8889 - val_mae: 4.4255\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.3883 - mae: 4.2081 - val_loss: 45.4279 - val_mae: 4.3783\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.8831 - mae: 4.1610 - val_loss: 44.9038 - val_mae: 4.3913\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.4031 - mae: 4.1978 - val_loss: 44.4914 - val_mae: 4.2902\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.8789 - mae: 4.0679 - val_loss: 43.9840 - val_mae: 4.3573\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.3607 - mae: 4.1185 - val_loss: 43.5066 - val_mae: 4.3426\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.9899 - mae: 4.1189 - val_loss: 43.0583 - val_mae: 4.2489\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.3702 - mae: 3.9951 - val_loss: 42.7358 - val_mae: 4.1535\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.9363 - mae: 4.0415 - val_loss: 42.2247 - val_mae: 4.1690\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.3087 - mae: 3.9346 - val_loss: 41.8226 - val_mae: 4.1435\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.8397 - mae: 3.9485 - val_loss: 41.3794 - val_mae: 4.1418\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.4185 - mae: 3.9343 - val_loss: 41.0296 - val_mae: 4.1074\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.9660 - mae: 3.8999 - val_loss: 40.5563 - val_mae: 4.1640\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.5844 - mae: 3.9184 - val_loss: 40.3160 - val_mae: 4.0187\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3126 - mae: 3.8645 - val_loss: 39.9773 - val_mae: 4.0094\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.7638 - mae: 3.8191 - val_loss: 39.5589 - val_mae: 4.0311\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.4595 - mae: 3.8187 - val_loss: 39.1943 - val_mae: 4.0255\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.0513 - mae: 3.8132 - val_loss: 38.8393 - val_mae: 4.0393\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.7480 - mae: 3.7621 - val_loss: 38.5446 - val_mae: 4.0258\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.4343 - mae: 3.8106 - val_loss: 38.2112 - val_mae: 4.0444\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.1258 - mae: 3.7266 - val_loss: 37.9434 - val_mae: 4.0390\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.7562 - mae: 3.7675 - val_loss: 37.6966 - val_mae: 3.9817\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.4994 - mae: 3.7319 - val_loss: 37.3674 - val_mae: 4.0170\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.2024 - mae: 3.7242 - val_loss: 37.1508 - val_mae: 3.9800\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.0037 - mae: 3.6904 - val_loss: 36.8592 - val_mae: 4.0085\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.7948 - mae: 3.6754 - val_loss: 36.6352 - val_mae: 4.0030\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4814 - mae: 3.7513 - val_loss: 36.4877 - val_mae: 3.9345\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 30.2909 - mae: 3.6630 - val_loss: 36.2406 - val_mae: 3.9235\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.1133 - mae: 3.6298 - val_loss: 35.9882 - val_mae: 4.0290\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8483 - mae: 3.7290 - val_loss: 35.9092 - val_mae: 3.8975\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.6591 - mae: 3.6309 - val_loss: 35.6114 - val_mae: 3.8971\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.3748 - mae: 3.6341 - val_loss: 35.2989 - val_mae: 3.9229\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1558 - mae: 3.6154 - val_loss: 35.1464 - val_mae: 3.9230\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.9618 - mae: 3.6299 - val_loss: 34.9806 - val_mae: 3.8936\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.8951 - mae: 3.6326 - val_loss: 34.6798 - val_mae: 3.9198\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.6922 - mae: 3.5887 - val_loss: 34.6177 - val_mae: 3.8648\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.4718 - mae: 3.5621 - val_loss: 34.3511 - val_mae: 3.8857\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.3203 - mae: 3.5936 - val_loss: 34.2299 - val_mae: 3.8611\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.0624 - mae: 3.5469 - val_loss: 33.9384 - val_mae: 3.8946\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9439 - mae: 3.5885 - val_loss: 33.8494 - val_mae: 3.8445\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.7558 - mae: 3.5536 - val_loss: 33.6403 - val_mae: 3.8528\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5851 - mae: 3.5461 - val_loss: 33.4822 - val_mae: 3.8208\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.4419 - mae: 3.5109 - val_loss: 33.1874 - val_mae: 3.8518\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.2654 - mae: 3.5149 - val_loss: 33.0646 - val_mae: 3.8371\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.1262 - mae: 3.5174 - val_loss: 32.8671 - val_mae: 3.8366\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.9811 - mae: 3.4975 - val_loss: 32.6740 - val_mae: 3.8108\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.8729 - mae: 3.4901 - val_loss: 32.5373 - val_mae: 3.8648\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.7703 - mae: 3.4898 - val_loss: 32.3642 - val_mae: 3.8250\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 26.5351 - mae: 3.5062 - val_loss: 32.3153 - val_mae: 3.7613\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 42.2381 - mae: 4.4039\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 15.3299 - mae: 15.3299 - val_loss: 10.7173 - val_mae: 10.7173\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4961 - mae: 9.4961 - val_loss: 8.5318 - val_mae: 8.5318\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9884 - mae: 7.9884 - val_loss: 7.6762 - val_mae: 7.6762\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1945 - mae: 7.1945 - val_loss: 7.1819 - val_mae: 7.1819\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6790 - mae: 6.6790 - val_loss: 6.8646 - val_mae: 6.8646\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.6685 - val_mae: 6.6685\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2033 - mae: 6.2033 - val_loss: 6.5435 - val_mae: 6.5435\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0744 - mae: 6.0744 - val_loss: 6.4131 - val_mae: 6.4131\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9449 - mae: 5.9449 - val_loss: 6.2457 - val_mae: 6.2457\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8003 - mae: 5.8003 - val_loss: 6.0748 - val_mae: 6.0748\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6450 - mae: 5.6450 - val_loss: 5.8573 - val_mae: 5.8573\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4924 - mae: 5.4924 - val_loss: 5.6954 - val_mae: 5.6954\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3589 - mae: 5.3589 - val_loss: 5.5190 - val_mae: 5.5190\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2334 - mae: 5.2334 - val_loss: 5.3621 - val_mae: 5.3621\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1282 - mae: 5.1282 - val_loss: 5.2463 - val_mae: 5.2463\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0301 - mae: 5.0301 - val_loss: 5.1597 - val_mae: 5.1597\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9453 - mae: 4.9453 - val_loss: 5.0103 - val_mae: 5.0103\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8656 - mae: 4.8656 - val_loss: 4.9265 - val_mae: 4.9265\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7918 - mae: 4.7918 - val_loss: 4.8128 - val_mae: 4.8128\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7330 - mae: 4.7330 - val_loss: 4.7498 - val_mae: 4.7498\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6775 - mae: 4.6775 - val_loss: 4.6962 - val_mae: 4.6962\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6307 - mae: 4.6307 - val_loss: 4.6332 - val_mae: 4.6332\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5914 - mae: 4.5914 - val_loss: 4.6121 - val_mae: 4.6121\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5533 - mae: 4.5533 - val_loss: 4.5722 - val_mae: 4.5722\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5252 - mae: 4.5252 - val_loss: 4.5457 - val_mae: 4.5457\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4952 - mae: 4.4952 - val_loss: 4.5280 - val_mae: 4.5280\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4710 - mae: 4.4710 - val_loss: 4.5233 - val_mae: 4.5233\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4489 - mae: 4.4489 - val_loss: 4.4939 - val_mae: 4.4939\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4219 - mae: 4.4219 - val_loss: 4.4752 - val_mae: 4.4752\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3997 - mae: 4.3997 - val_loss: 4.4603 - val_mae: 4.4603\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3794 - mae: 4.3794 - val_loss: 4.4465 - val_mae: 4.4465\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3540 - mae: 4.3540 - val_loss: 4.4348 - val_mae: 4.4348\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3290 - mae: 4.3290 - val_loss: 4.4190 - val_mae: 4.4190\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3158 - mae: 4.3158 - val_loss: 4.4098 - val_mae: 4.4098\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2955 - mae: 4.2955 - val_loss: 4.4109 - val_mae: 4.4109\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2665 - mae: 4.2665 - val_loss: 4.3827 - val_mae: 4.3827\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2409 - mae: 4.2409 - val_loss: 4.3851 - val_mae: 4.3851\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2255 - mae: 4.2255 - val_loss: 4.3625 - val_mae: 4.3625\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2063 - mae: 4.2063 - val_loss: 4.3549 - val_mae: 4.3549\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1765 - mae: 4.1765 - val_loss: 4.3448 - val_mae: 4.3448\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1532 - mae: 4.1532 - val_loss: 4.3448 - val_mae: 4.3448\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1327 - mae: 4.1327 - val_loss: 4.3316 - val_mae: 4.3316\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1030 - mae: 4.1030 - val_loss: 4.3172 - val_mae: 4.3172\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0850 - mae: 4.0850 - val_loss: 4.3258 - val_mae: 4.3258\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0528 - mae: 4.0528 - val_loss: 4.2922 - val_mae: 4.2922\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0436 - mae: 4.0436 - val_loss: 4.2833 - val_mae: 4.2833\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0311 - mae: 4.0311 - val_loss: 4.2976 - val_mae: 4.2976\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9967 - mae: 3.9967 - val_loss: 4.2703 - val_mae: 4.2703\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9787 - mae: 3.9787 - val_loss: 4.2565 - val_mae: 4.2565\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9774 - mae: 3.9774 - val_loss: 4.2517 - val_mae: 4.2517\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9485 - mae: 3.9485 - val_loss: 4.2382 - val_mae: 4.2382\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9372 - mae: 3.9372 - val_loss: 4.2275 - val_mae: 4.2275\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9287 - mae: 3.9287 - val_loss: 4.2039 - val_mae: 4.2039\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8991 - mae: 3.8991 - val_loss: 4.2030 - val_mae: 4.2030\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8862 - mae: 3.8862 - val_loss: 4.1794 - val_mae: 4.1794\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8713 - mae: 3.8713 - val_loss: 4.1950 - val_mae: 4.1950\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8733 - mae: 3.8733 - val_loss: 4.1925 - val_mae: 4.1925\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8337 - mae: 3.8337 - val_loss: 4.1570 - val_mae: 4.1570\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8312 - mae: 3.8312 - val_loss: 4.1529 - val_mae: 4.1529\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8078 - mae: 3.8078 - val_loss: 4.1398 - val_mae: 4.1398\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7943 - mae: 3.7943 - val_loss: 4.1328 - val_mae: 4.1328\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7810 - mae: 3.7810 - val_loss: 4.1320 - val_mae: 4.1320\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7728 - mae: 3.7728 - val_loss: 4.1269 - val_mae: 4.1269\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7601 - mae: 3.7601 - val_loss: 4.1322 - val_mae: 4.1322\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7433 - mae: 3.7433 - val_loss: 4.1019 - val_mae: 4.1019\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7414 - mae: 3.7414 - val_loss: 4.1020 - val_mae: 4.1020\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7245 - mae: 3.7245 - val_loss: 4.0942 - val_mae: 4.0942\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7117 - mae: 3.7117 - val_loss: 4.0932 - val_mae: 4.0932\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7106 - mae: 3.7106 - val_loss: 4.0737 - val_mae: 4.0737\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 3.7925 - mae: 3.792 - 0s 2ms/step - loss: 3.6985 - mae: 3.6985 - val_loss: 4.1128 - val_mae: 4.1128\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6942 - mae: 3.6942 - val_loss: 4.0763 - val_mae: 4.0763\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6822 - mae: 3.6822 - val_loss: 4.0604 - val_mae: 4.0604\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6672 - mae: 3.6672 - val_loss: 4.0816 - val_mae: 4.0816\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6471 - mae: 3.6471 - val_loss: 4.0436 - val_mae: 4.0436\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6433 - mae: 3.6433 - val_loss: 4.0939 - val_mae: 4.0939\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6505 - mae: 3.6505 - val_loss: 4.0363 - val_mae: 4.0363\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6310 - mae: 3.6310 - val_loss: 4.0508 - val_mae: 4.0508\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6233 - mae: 3.6233 - val_loss: 4.0612 - val_mae: 4.0612\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6145 - mae: 3.6145 - val_loss: 4.0100 - val_mae: 4.0100\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6221 - mae: 3.6221 - val_loss: 4.0347 - val_mae: 4.0347\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6051 - mae: 3.6051 - val_loss: 4.0745 - val_mae: 4.0745\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5935 - mae: 3.5935 - val_loss: 4.0110 - val_mae: 4.0110\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5905 - mae: 3.5905 - val_loss: 3.9994 - val_mae: 3.9994\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5946 - mae: 3.5946 - val_loss: 4.0353 - val_mae: 4.0353\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5924 - mae: 3.5924 - val_loss: 4.0252 - val_mae: 4.0252\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5818 - mae: 3.5818 - val_loss: 4.0300 - val_mae: 4.0300\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5690 - mae: 3.5690 - val_loss: 3.9728 - val_mae: 3.9728\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5628 - mae: 3.5628 - val_loss: 3.9868 - val_mae: 3.9868\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5552 - mae: 3.5552 - val_loss: 3.9918 - val_mae: 3.9918\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5556 - mae: 3.5556 - val_loss: 3.9359 - val_mae: 3.9359\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5474 - mae: 3.5474 - val_loss: 3.9735 - val_mae: 3.9735\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5383 - mae: 3.5383 - val_loss: 3.9610 - val_mae: 3.9610\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5424 - mae: 3.5424 - val_loss: 3.9063 - val_mae: 3.9063\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5483 - mae: 3.5483 - val_loss: 3.9537 - val_mae: 3.9537\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5447 - mae: 3.5447 - val_loss: 3.9454 - val_mae: 3.9454\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5273 - mae: 3.5273 - val_loss: 3.8928 - val_mae: 3.8928\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5130 - mae: 3.5130 - val_loss: 3.9371 - val_mae: 3.9371\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5086 - mae: 3.5086 - val_loss: 3.9421 - val_mae: 3.9421\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5157 - mae: 3.5157 - val_loss: 3.9283 - val_mae: 3.9283\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5058 - mae: 3.5058 - val_loss: 3.9294 - val_mae: 3.9294\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9923 - mae: 4.9923\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 5ms/step - loss: 371.6446 - mae: 16.7340 - val_loss: 234.5535 - val_mae: 12.2810\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 192.3521 - mae: 11.0316 - val_loss: 175.9952 - val_mae: 9.9742\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 151.9110 - mae: 9.3772 - val_loss: 146.5234 - val_mae: 8.7592\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 128.9649 - mae: 8.3746 - val_loss: 128.5616 - val_mae: 8.0431\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 113.9647 - mae: 7.6986 - val_loss: 115.7974 - val_mae: 7.5626\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 103.3887 - mae: 7.2055 - val_loss: 107.3297 - val_mae: 7.2505\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.0309 - mae: 6.8628 - val_loss: 100.8865 - val_mae: 7.0000\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.5192 - mae: 6.5808 - val_loss: 96.0573 - val_mae: 6.8096\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.3752 - mae: 6.4031 - val_loss: 91.9465 - val_mae: 6.6523\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.0287 - mae: 6.2552 - val_loss: 89.0100 - val_mae: 6.5655\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4443 - mae: 6.1432 - val_loss: 86.2897 - val_mae: 6.4820\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.1907 - mae: 6.0508 - val_loss: 83.9204 - val_mae: 6.4180\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.1759 - mae: 5.9804 - val_loss: 81.5540 - val_mae: 6.3552\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.2472 - mae: 5.8880 - val_loss: 79.4736 - val_mae: 6.2800\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.4010 - mae: 5.8101 - val_loss: 77.3920 - val_mae: 6.1917\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.5742 - mae: 5.7223 - val_loss: 75.3680 - val_mae: 6.0987\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.8628 - mae: 5.6243 - val_loss: 73.4807 - val_mae: 5.9828\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.2034 - mae: 5.5504 - val_loss: 71.6354 - val_mae: 5.8901\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.5446 - mae: 5.4495 - val_loss: 70.0379 - val_mae: 5.7787\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.1712 - mae: 5.3615 - val_loss: 68.4989 - val_mae: 5.6911\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.8115 - mae: 5.3064 - val_loss: 67.0961 - val_mae: 5.6192\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.5075 - mae: 5.2349 - val_loss: 65.8656 - val_mae: 5.5432\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.3939 - mae: 5.1629 - val_loss: 64.7130 - val_mae: 5.4499\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.3205 - mae: 5.1142 - val_loss: 63.6196 - val_mae: 5.4075\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.3765 - mae: 5.0774 - val_loss: 62.6985 - val_mae: 5.3372\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.5015 - mae: 5.0405 - val_loss: 61.7652 - val_mae: 5.3225\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.6638 - mae: 5.0069 - val_loss: 60.9783 - val_mae: 5.2415\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.9788 - mae: 4.9852 - val_loss: 60.2126 - val_mae: 5.2037\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.1942 - mae: 4.9258 - val_loss: 59.4831 - val_mae: 5.1480\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.5587 - mae: 4.9107 - val_loss: 58.8541 - val_mae: 5.1353\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.9155 - mae: 4.8932 - val_loss: 58.2601 - val_mae: 5.1172\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.3581 - mae: 4.8671 - val_loss: 57.6237 - val_mae: 5.0679\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.7833 - mae: 4.8383 - val_loss: 57.0844 - val_mae: 5.0436\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.2163 - mae: 4.7958 - val_loss: 56.5487 - val_mae: 5.0057\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.7553 - mae: 4.8143 - val_loss: 56.0424 - val_mae: 4.9858\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.1466 - mae: 4.7742 - val_loss: 55.4967 - val_mae: 4.9752\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6813 - mae: 4.7753 - val_loss: 54.9920 - val_mae: 4.9745\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.2504 - mae: 4.6922 - val_loss: 54.5854 - val_mae: 4.8870\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.7974 - mae: 4.7273 - val_loss: 54.1478 - val_mae: 4.8804\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.2671 - mae: 4.6824 - val_loss: 53.6615 - val_mae: 4.8935\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8092 - mae: 4.6605 - val_loss: 53.2296 - val_mae: 4.8637\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.3423 - mae: 4.6678 - val_loss: 52.7971 - val_mae: 4.8357\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.8786 - mae: 4.6151 - val_loss: 52.3637 - val_mae: 4.8329\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.4357 - mae: 4.6117 - val_loss: 51.9334 - val_mae: 4.7873\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.0072 - mae: 4.5834 - val_loss: 51.5358 - val_mae: 4.7325\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.4849 - mae: 4.5480 - val_loss: 51.1015 - val_mae: 4.7454\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0246 - mae: 4.5425 - val_loss: 50.6207 - val_mae: 4.7348\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5295 - mae: 4.4848 - val_loss: 50.2527 - val_mae: 4.6562\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.0737 - mae: 4.4696 - val_loss: 49.8044 - val_mae: 4.6729\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.6161 - mae: 4.4608 - val_loss: 49.3478 - val_mae: 4.6408\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.1057 - mae: 4.3900 - val_loss: 48.9870 - val_mae: 4.5627\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6215 - mae: 4.3741 - val_loss: 48.4881 - val_mae: 4.5877\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.2581 - mae: 4.3548 - val_loss: 48.0919 - val_mae: 4.5138\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6135 - mae: 4.3717 - val_loss: 47.5922 - val_mae: 4.5859\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0952 - mae: 4.3087 - val_loss: 47.1648 - val_mae: 4.4824\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6216 - mae: 4.2549 - val_loss: 46.6952 - val_mae: 4.4917\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.1455 - mae: 4.2334 - val_loss: 46.2568 - val_mae: 4.4725\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.6795 - mae: 4.2631 - val_loss: 45.8492 - val_mae: 4.3814\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.0946 - mae: 4.1473 - val_loss: 45.4473 - val_mae: 4.3638\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.5950 - mae: 4.1794 - val_loss: 44.9465 - val_mae: 4.3630\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0822 - mae: 4.1125 - val_loss: 44.5318 - val_mae: 4.3182\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 38.5811 - mae: 4.1200 - val_loss: 44.0834 - val_mae: 4.3070\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.1555 - mae: 4.0239 - val_loss: 43.6982 - val_mae: 4.3072\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.7174 - mae: 4.0944 - val_loss: 43.2421 - val_mae: 4.2983\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.1525 - mae: 4.0211 - val_loss: 42.8812 - val_mae: 4.2182\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.7379 - mae: 3.9675 - val_loss: 42.4956 - val_mae: 4.2266\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 36.4358 - mae: 3.9915 - val_loss: 42.1565 - val_mae: 4.1448\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.8848 - mae: 3.9202 - val_loss: 41.7783 - val_mae: 4.1625\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.5124 - mae: 3.9772 - val_loss: 41.3849 - val_mae: 4.1394\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 35.1394 - mae: 3.8885 - val_loss: 40.9862 - val_mae: 4.1741\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.7418 - mae: 3.8885 - val_loss: 40.6651 - val_mae: 4.1190\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 34.3275 - mae: 3.8502 - val_loss: 40.3249 - val_mae: 4.1254\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.9413 - mae: 3.8531 - val_loss: 40.0538 - val_mae: 4.1077\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.6067 - mae: 3.8677 - val_loss: 39.6965 - val_mae: 4.0761\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 33.3331 - mae: 3.8137 - val_loss: 39.4164 - val_mae: 4.0615\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.9726 - mae: 3.7894 - val_loss: 39.1360 - val_mae: 4.0520\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.7062 - mae: 3.8002 - val_loss: 38.8664 - val_mae: 4.0441\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.3931 - mae: 3.7934 - val_loss: 38.5428 - val_mae: 4.0534\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.0929 - mae: 3.7584 - val_loss: 38.2743 - val_mae: 4.0448\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.8140 - mae: 3.7411 - val_loss: 38.0206 - val_mae: 4.0566\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.5754 - mae: 3.7314 - val_loss: 37.7581 - val_mae: 4.0580\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.3745 - mae: 3.7657 - val_loss: 37.5324 - val_mae: 4.0346\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.1131 - mae: 3.7162 - val_loss: 37.2756 - val_mae: 4.0361\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.8827 - mae: 3.7356 - val_loss: 37.0404 - val_mae: 4.0191\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.6349 - mae: 3.7143 - val_loss: 36.9109 - val_mae: 3.9702\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.4642 - mae: 3.6575 - val_loss: 36.5545 - val_mae: 4.0056\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 30.3943 - mae: 3.7665 - val_loss: 36.3824 - val_mae: 4.0078\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.9524 - mae: 3.7076 - val_loss: 36.2830 - val_mae: 3.9465\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.8169 - mae: 3.6449 - val_loss: 35.9380 - val_mae: 3.9822\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.5965 - mae: 3.6568 - val_loss: 35.8488 - val_mae: 3.9266\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.3920 - mae: 3.6614 - val_loss: 35.5774 - val_mae: 3.9458\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.1674 - mae: 3.6515 - val_loss: 35.3786 - val_mae: 3.9311\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 29.1318 - mae: 3.6375 - val_loss: 35.2279 - val_mae: 3.9024\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.9023 - mae: 3.6281 - val_loss: 35.1189 - val_mae: 3.8939\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.7234 - mae: 3.6006 - val_loss: 34.7775 - val_mae: 3.9031\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.5252 - mae: 3.6082 - val_loss: 34.5667 - val_mae: 3.9252\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.3211 - mae: 3.5709 - val_loss: 34.4557 - val_mae: 3.8851\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 28.2628 - mae: 3.6084 - val_loss: 34.1969 - val_mae: 3.9061\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9579 - mae: 3.5653 - val_loss: 34.0548 - val_mae: 3.8717\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.9610 - mae: 3.5668 - val_loss: 33.9704 - val_mae: 3.8369\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 44.8918 - mae: 4.4674\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 15.4822 - mae: 15.4822 - val_loss: 10.6938 - val_mae: 10.6938\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3806 - mae: 9.3806 - val_loss: 8.4401 - val_mae: 8.4401\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8532 - mae: 7.8532 - val_loss: 7.5870 - val_mae: 7.5870\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0569 - mae: 7.0569 - val_loss: 7.1037 - val_mae: 7.1037\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6081 - mae: 6.6081 - val_loss: 6.8188 - val_mae: 6.8188\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3588 - mae: 6.3588 - val_loss: 6.6720 - val_mae: 6.6720\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2047 - mae: 6.2047 - val_loss: 6.5568 - val_mae: 6.5568\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0833 - mae: 6.0833 - val_loss: 6.4211 - val_mae: 6.4211\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9583 - mae: 5.9583 - val_loss: 6.2639 - val_mae: 6.2639\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8174 - mae: 5.8174 - val_loss: 6.0783 - val_mae: 6.0783\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6648 - mae: 5.6648 - val_loss: 5.9122 - val_mae: 5.9122\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5209 - mae: 5.5209 - val_loss: 5.7126 - val_mae: 5.7126\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3784 - mae: 5.3784 - val_loss: 5.5521 - val_mae: 5.5521\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2564 - mae: 5.2564 - val_loss: 5.4404 - val_mae: 5.4404\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1456 - mae: 5.1456 - val_loss: 5.2905 - val_mae: 5.2905\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0507 - mae: 5.0507 - val_loss: 5.1675 - val_mae: 5.1675\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9642 - mae: 4.9642 - val_loss: 5.0560 - val_mae: 5.0560\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8870 - mae: 4.8870 - val_loss: 4.9429 - val_mae: 4.9429\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8183 - mae: 4.8183 - val_loss: 4.8677 - val_mae: 4.8677\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7596 - mae: 4.7596 - val_loss: 4.7816 - val_mae: 4.7816\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7016 - mae: 4.7016 - val_loss: 4.7302 - val_mae: 4.7302\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6597 - mae: 4.6597 - val_loss: 4.6822 - val_mae: 4.6822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6280 - mae: 4.6280 - val_loss: 4.6247 - val_mae: 4.6247\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5776 - mae: 4.5776 - val_loss: 4.6024 - val_mae: 4.6024\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5468 - mae: 4.5468 - val_loss: 4.5646 - val_mae: 4.5646\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5112 - mae: 4.5112 - val_loss: 4.5609 - val_mae: 4.5609\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4888 - mae: 4.4888 - val_loss: 4.5213 - val_mae: 4.5213\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4629 - mae: 4.4629 - val_loss: 4.5187 - val_mae: 4.5187\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4399 - mae: 4.4399 - val_loss: 4.4857 - val_mae: 4.4857\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4183 - mae: 4.4183 - val_loss: 4.4679 - val_mae: 4.4679\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3911 - mae: 4.3911 - val_loss: 4.4527 - val_mae: 4.4527\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3685 - mae: 4.3685 - val_loss: 4.4444 - val_mae: 4.4444\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3454 - mae: 4.3454 - val_loss: 4.4272 - val_mae: 4.4272\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3346 - mae: 4.3346 - val_loss: 4.4272 - val_mae: 4.4272\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3071 - mae: 4.3071 - val_loss: 4.4009 - val_mae: 4.4009\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2929 - mae: 4.2929 - val_loss: 4.4126 - val_mae: 4.4126\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2603 - mae: 4.2603 - val_loss: 4.3751 - val_mae: 4.3751\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2462 - mae: 4.2462 - val_loss: 4.3653 - val_mae: 4.3653\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2172 - mae: 4.2172 - val_loss: 4.3555 - val_mae: 4.3555\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1945 - mae: 4.1945 - val_loss: 4.3552 - val_mae: 4.3552\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1785 - mae: 4.1785 - val_loss: 4.3557 - val_mae: 4.3557\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1509 - mae: 4.1509 - val_loss: 4.3336 - val_mae: 4.3336\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1288 - mae: 4.1288 - val_loss: 4.3271 - val_mae: 4.3271\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1179 - mae: 4.1179 - val_loss: 4.3229 - val_mae: 4.3229\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0957 - mae: 4.0957 - val_loss: 4.3226 - val_mae: 4.3226\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0632 - mae: 4.0632 - val_loss: 4.3033 - val_mae: 4.3033\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0482 - mae: 4.0482 - val_loss: 4.2936 - val_mae: 4.2936\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0215 - mae: 4.0215 - val_loss: 4.2853 - val_mae: 4.2853\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0009 - mae: 4.0009 - val_loss: 4.2722 - val_mae: 4.2722\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9905 - mae: 3.9905 - val_loss: 4.2616 - val_mae: 4.2616\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9639 - mae: 3.9639 - val_loss: 4.2652 - val_mae: 4.2652\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9534 - mae: 3.9534 - val_loss: 4.2595 - val_mae: 4.2595\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9483 - mae: 3.9483 - val_loss: 4.2329 - val_mae: 4.2329\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9209 - mae: 3.9209 - val_loss: 4.2226 - val_mae: 4.2226\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9060 - mae: 3.9060 - val_loss: 4.2256 - val_mae: 4.2256\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8944 - mae: 3.8944 - val_loss: 4.1993 - val_mae: 4.1993\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8767 - mae: 3.8767 - val_loss: 4.1871 - val_mae: 4.1871\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8816 - mae: 3.8816 - val_loss: 4.1772 - val_mae: 4.1772\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8507 - mae: 3.8507 - val_loss: 4.1800 - val_mae: 4.1800\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8320 - mae: 3.8320 - val_loss: 4.1614 - val_mae: 4.1614\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8254 - mae: 3.8254 - val_loss: 4.1619 - val_mae: 4.1619\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8044 - mae: 3.8044 - val_loss: 4.1493 - val_mae: 4.1493\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7904 - mae: 3.7904 - val_loss: 4.1468 - val_mae: 4.1468\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7779 - mae: 3.7779 - val_loss: 4.1380 - val_mae: 4.1380\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7767 - mae: 3.7767 - val_loss: 4.1343 - val_mae: 4.1343\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7611 - mae: 3.7611 - val_loss: 4.1472 - val_mae: 4.1472\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7399 - mae: 3.7399 - val_loss: 4.1211 - val_mae: 4.1211\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7465 - mae: 3.7465 - val_loss: 4.1170 - val_mae: 4.1170\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7286 - mae: 3.7286 - val_loss: 4.1253 - val_mae: 4.1253\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7101 - mae: 3.7101 - val_loss: 4.0931 - val_mae: 4.0931\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7070 - mae: 3.7070 - val_loss: 4.1290 - val_mae: 4.1290\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7210 - mae: 3.7210 - val_loss: 4.0969 - val_mae: 4.0969\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6853 - mae: 3.6853 - val_loss: 4.0888 - val_mae: 4.0888\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6706 - mae: 3.6706 - val_loss: 4.0714 - val_mae: 4.0714\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6734 - mae: 3.6734 - val_loss: 4.0595 - val_mae: 4.0595\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6616 - mae: 3.6616 - val_loss: 4.0684 - val_mae: 4.0684\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6581 - mae: 3.6581 - val_loss: 4.0538 - val_mae: 4.0538\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6461 - mae: 3.6461 - val_loss: 4.0558 - val_mae: 4.0558\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6308 - mae: 3.6308 - val_loss: 4.0912 - val_mae: 4.0912\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6209 - mae: 3.6209 - val_loss: 4.0496 - val_mae: 4.0496\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6204 - mae: 3.6204 - val_loss: 4.0351 - val_mae: 4.0351\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6145 - mae: 3.6145 - val_loss: 4.0455 - val_mae: 4.0455\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6063 - mae: 3.6063 - val_loss: 4.0506 - val_mae: 4.0506\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5968 - mae: 3.5968 - val_loss: 4.0171 - val_mae: 4.0171\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5892 - mae: 3.5892 - val_loss: 4.0392 - val_mae: 4.0392\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5967 - mae: 3.5967 - val_loss: 4.0118 - val_mae: 4.0118\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5763 - mae: 3.5763 - val_loss: 3.9897 - val_mae: 3.9897\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5824 - mae: 3.5824 - val_loss: 3.9937 - val_mae: 3.9937\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5761 - mae: 3.5761 - val_loss: 4.0352 - val_mae: 4.0352\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5610 - mae: 3.5610 - val_loss: 3.9997 - val_mae: 3.9997\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5907 - mae: 3.5907 - val_loss: 3.9683 - val_mae: 3.9683\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5690 - mae: 3.5690 - val_loss: 4.0087 - val_mae: 4.0087\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5519 - mae: 3.5519 - val_loss: 3.9578 - val_mae: 3.9578\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5379 - mae: 3.5379 - val_loss: 3.9342 - val_mae: 3.9342\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5415 - mae: 3.5415 - val_loss: 3.9721 - val_mae: 3.9721\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5343 - mae: 3.5343 - val_loss: 3.9865 - val_mae: 3.9865\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5331 - mae: 3.5331 - val_loss: 3.9795 - val_mae: 3.9795\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5199 - mae: 3.5199 - val_loss: 3.9181 - val_mae: 3.9181\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5226 - mae: 3.5226 - val_loss: 3.9645 - val_mae: 3.9645\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5125 - mae: 3.5125 - val_loss: 3.9378 - val_mae: 3.9378\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9272 - mae: 4.9272\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 257.2763 - mae: 13.1304 - val_loss: 63.9491 - val_mae: 5.9048\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.2594 - mae: 4.4463 - val_loss: 30.4039 - val_mae: 3.8988\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.3084 - mae: 3.6198 - val_loss: 25.0186 - val_mae: 3.4011\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.1781 - mae: 3.2213 - val_loss: 22.1855 - val_mae: 3.2338\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.0033 - mae: 3.0068 - val_loss: 20.8049 - val_mae: 3.2771\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.7583 - mae: 2.9048 - val_loss: 19.9697 - val_mae: 3.1499\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.7681 - mae: 2.7893 - val_loss: 18.9964 - val_mae: 3.1128\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0286 - mae: 2.7007 - val_loss: 18.6461 - val_mae: 3.1197\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3515 - mae: 2.6664 - val_loss: 18.0046 - val_mae: 3.0388\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3970 - mae: 2.7150 - val_loss: 17.8426 - val_mae: 3.0009\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.5510 - mae: 2.5907 - val_loss: 17.4238 - val_mae: 2.9423\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.1594 - mae: 2.5396 - val_loss: 17.0060 - val_mae: 2.9177\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.7142 - mae: 2.5153 - val_loss: 17.1048 - val_mae: 2.9309\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.7488 - mae: 2.4968 - val_loss: 16.9696 - val_mae: 2.8693\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.3266 - mae: 2.4897 - val_loss: 16.5582 - val_mae: 2.8874\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0216 - mae: 2.4646 - val_loss: 16.5127 - val_mae: 2.8620\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.7620 - mae: 2.4291 - val_loss: 16.2092 - val_mae: 2.8167\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5987 - mae: 2.4015 - val_loss: 16.2942 - val_mae: 2.8161\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.4802 - mae: 2.3824 - val_loss: 15.8514 - val_mae: 2.7803\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.3078 - mae: 2.3870 - val_loss: 15.7774 - val_mae: 2.7913\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.2299 - mae: 2.3592 - val_loss: 15.6676 - val_mae: 2.7426\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.2050 - mae: 2.3448 - val_loss: 15.4946 - val_mae: 2.7338\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.8581 - mae: 2.3627 - val_loss: 15.2997 - val_mae: 2.7164\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6782 - mae: 2.3162 - val_loss: 15.4515 - val_mae: 2.7204\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5594 - mae: 2.2873 - val_loss: 15.4416 - val_mae: 2.7364\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.3743 - mae: 2.2906 - val_loss: 15.1281 - val_mae: 2.6921\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.3690 - mae: 2.3051 - val_loss: 15.0084 - val_mae: 2.6871\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.1647 - mae: 2.2515 - val_loss: 15.2183 - val_mae: 2.6906\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0987 - mae: 2.2534 - val_loss: 15.1091 - val_mae: 2.6894\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9448 - mae: 2.2464 - val_loss: 14.9073 - val_mae: 2.6738\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8192 - mae: 2.2344 - val_loss: 14.9209 - val_mae: 2.6634\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.7592 - mae: 2.2190 - val_loss: 14.8556 - val_mae: 2.6684\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6689 - mae: 2.2110 - val_loss: 14.8346 - val_mae: 2.6778\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5231 - mae: 2.1925 - val_loss: 14.6223 - val_mae: 2.6576\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5210 - mae: 2.1997 - val_loss: 14.6404 - val_mae: 2.6527\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4893 - mae: 2.1971 - val_loss: 14.4360 - val_mae: 2.6372\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2149 - mae: 2.1660 - val_loss: 14.5355 - val_mae: 2.6198\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0798 - mae: 2.1432 - val_loss: 14.4688 - val_mae: 2.6269\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0442 - mae: 2.1650 - val_loss: 14.3815 - val_mae: 2.6085\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1664 - mae: 2.1785 - val_loss: 14.4702 - val_mae: 2.5825\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.9758 - mae: 2.1402 - val_loss: 14.2523 - val_mae: 2.6227\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7687 - mae: 2.1126 - val_loss: 14.3064 - val_mae: 2.5865\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6562 - mae: 2.0962 - val_loss: 14.2298 - val_mae: 2.5979\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6106 - mae: 2.1021 - val_loss: 14.2677 - val_mae: 2.5983\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4522 - mae: 2.0814 - val_loss: 14.3039 - val_mae: 2.5724\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4466 - mae: 2.0868 - val_loss: 14.1950 - val_mae: 2.5947\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3515 - mae: 2.0708 - val_loss: 14.0715 - val_mae: 2.5954\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2897 - mae: 2.0632 - val_loss: 14.3000 - val_mae: 2.5686\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1806 - mae: 2.0481 - val_loss: 14.1715 - val_mae: 2.5893\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1130 - mae: 2.0448 - val_loss: 13.9524 - val_mae: 2.5568\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0521 - mae: 2.0318 - val_loss: 14.0898 - val_mae: 2.5781\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2166 - mae: 2.0746 - val_loss: 14.3071 - val_mae: 2.5429\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9418 - mae: 2.0388 - val_loss: 14.2308 - val_mae: 2.5603\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7982 - mae: 2.0150 - val_loss: 13.9833 - val_mae: 2.5560\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7012 - mae: 1.9875 - val_loss: 13.9594 - val_mae: 2.5420\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.7249 - mae: 2.0168 - val_loss: 13.8736 - val_mae: 2.5499\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6300 - mae: 1.9817 - val_loss: 13.8868 - val_mae: 2.5274\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5695 - mae: 1.9802 - val_loss: 13.9634 - val_mae: 2.5600\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.4712 - mae: 1.9763 - val_loss: 13.9324 - val_mae: 2.5346\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3697 - mae: 1.9593 - val_loss: 13.9810 - val_mae: 2.5488\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3259 - mae: 1.9583 - val_loss: 13.9813 - val_mae: 2.5508\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3036 - mae: 1.9583 - val_loss: 13.8550 - val_mae: 2.5461\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3204 - mae: 1.9660 - val_loss: 13.8175 - val_mae: 2.5231\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1818 - mae: 1.9406 - val_loss: 14.0899 - val_mae: 2.5276\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0593 - mae: 1.9413 - val_loss: 13.8249 - val_mae: 2.5315\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0430 - mae: 1.9292 - val_loss: 13.9148 - val_mae: 2.5284\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0675 - mae: 1.9322 - val_loss: 14.1357 - val_mae: 2.5289\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8879 - mae: 1.9026 - val_loss: 13.7354 - val_mae: 2.5149\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8884 - mae: 1.9092 - val_loss: 13.7691 - val_mae: 2.5169\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7730 - mae: 1.8962 - val_loss: 13.9090 - val_mae: 2.5422\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7605 - mae: 1.9026 - val_loss: 13.7925 - val_mae: 2.5588\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6719 - mae: 1.8848 - val_loss: 13.8583 - val_mae: 2.5203\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6038 - mae: 1.8822 - val_loss: 13.6776 - val_mae: 2.5266\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7088 - mae: 1.8964 - val_loss: 13.7628 - val_mae: 2.5247\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5361 - mae: 1.8816 - val_loss: 13.9272 - val_mae: 2.5243\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4036 - mae: 1.8444 - val_loss: 13.7752 - val_mae: 2.5250\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4496 - mae: 1.8571 - val_loss: 13.9713 - val_mae: 2.5407\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3889 - mae: 1.8578 - val_loss: 13.6662 - val_mae: 2.4991\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3740 - mae: 1.8363 - val_loss: 13.8169 - val_mae: 2.5039\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3393 - mae: 1.8474 - val_loss: 13.8328 - val_mae: 2.5165\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2512 - mae: 1.8272 - val_loss: 13.9027 - val_mae: 2.5138\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1320 - mae: 1.8206 - val_loss: 13.9390 - val_mae: 2.5170\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1436 - mae: 1.8264 - val_loss: 13.6596 - val_mae: 2.5302\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0634 - mae: 1.8260 - val_loss: 13.9897 - val_mae: 2.5468\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0188 - mae: 1.8094 - val_loss: 13.7081 - val_mae: 2.5334\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0102 - mae: 1.8135 - val_loss: 13.6532 - val_mae: 2.5358\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0124 - mae: 1.7953 - val_loss: 13.6781 - val_mae: 2.5035\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8445 - mae: 1.7847 - val_loss: 13.8191 - val_mae: 2.5152\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8618 - mae: 1.7958 - val_loss: 13.7781 - val_mae: 2.5156\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8549 - mae: 1.7942 - val_loss: 13.8152 - val_mae: 2.5319\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8027 - mae: 1.7799 - val_loss: 13.8001 - val_mae: 2.5247\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7271 - mae: 1.7835 - val_loss: 13.5443 - val_mae: 2.5152\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7180 - mae: 1.7743 - val_loss: 13.3895 - val_mae: 2.4913\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6550 - mae: 1.7531 - val_loss: 13.6128 - val_mae: 2.5121\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6034 - mae: 1.7729 - val_loss: 13.9837 - val_mae: 2.5125\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5319 - mae: 1.7425 - val_loss: 13.8470 - val_mae: 2.5152\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4997 - mae: 1.7439 - val_loss: 13.7544 - val_mae: 2.5285\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4400 - mae: 1.7241 - val_loss: 13.3985 - val_mae: 2.4913\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3480 - mae: 1.7199 - val_loss: 13.7273 - val_mae: 2.5357\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4188 - mae: 1.7171 - val_loss: 13.7808 - val_mae: 2.5224\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.9230 - mae: 3.4901\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 13.4393 - mae: 13.4393 - val_loss: 6.0738 - val_mae: 6.0738\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4137 - mae: 4.4137 - val_loss: 3.2962 - val_mae: 3.2962\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2396 - mae: 3.2396 - val_loss: 3.0658 - val_mae: 3.0658\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8894 - mae: 2.8894 - val_loss: 2.8552 - val_mae: 2.8552\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7886 - mae: 2.7886 - val_loss: 2.8881 - val_mae: 2.8881\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6909 - mae: 2.6909 - val_loss: 2.8606 - val_mae: 2.8606\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6194 - mae: 2.6194 - val_loss: 2.7057 - val_mae: 2.7057\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5656 - mae: 2.5656 - val_loss: 2.7364 - val_mae: 2.7364\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5008 - mae: 2.5008 - val_loss: 2.7028 - val_mae: 2.7028\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5118 - mae: 2.5118 - val_loss: 2.5779 - val_mae: 2.5779\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4198 - mae: 2.4198 - val_loss: 2.7402 - val_mae: 2.7402\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4230 - mae: 2.4230 - val_loss: 2.6361 - val_mae: 2.6361\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3629 - mae: 2.3629 - val_loss: 2.6215 - val_mae: 2.6215\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3370 - mae: 2.3370 - val_loss: 2.5775 - val_mae: 2.5775\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3133 - mae: 2.3133 - val_loss: 2.4987 - val_mae: 2.4987\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2978 - mae: 2.2978 - val_loss: 2.5249 - val_mae: 2.5249\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2767 - mae: 2.2767 - val_loss: 2.4837 - val_mae: 2.4837\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2825 - mae: 2.2825 - val_loss: 2.5259 - val_mae: 2.5259\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2376 - mae: 2.2376 - val_loss: 2.4724 - val_mae: 2.4724\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2582 - mae: 2.2582 - val_loss: 2.4861 - val_mae: 2.4861\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1939 - mae: 2.1939 - val_loss: 2.4451 - val_mae: 2.4451\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2416 - mae: 2.2416 - val_loss: 2.5076 - val_mae: 2.5076\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1939 - mae: 2.1939 - val_loss: 2.4785 - val_mae: 2.4785\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1701 - mae: 2.1701 - val_loss: 2.4823 - val_mae: 2.4823\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1588 - mae: 2.1588 - val_loss: 2.4817 - val_mae: 2.4817\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1500 - mae: 2.1500 - val_loss: 2.4422 - val_mae: 2.4422\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1170 - mae: 2.1170 - val_loss: 2.4447 - val_mae: 2.4447\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1488 - mae: 2.1488 - val_loss: 2.4233 - val_mae: 2.4233\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1077 - mae: 2.1077 - val_loss: 2.4479 - val_mae: 2.4479\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1138 - mae: 2.1138 - val_loss: 2.4280 - val_mae: 2.4280\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0876 - mae: 2.0876 - val_loss: 2.4261 - val_mae: 2.4261\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0765 - mae: 2.0765 - val_loss: 2.4100 - val_mae: 2.4100\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0424 - mae: 2.0424 - val_loss: 2.4769 - val_mae: 2.4769\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0662 - mae: 2.0662 - val_loss: 2.4347 - val_mae: 2.4347\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0660 - mae: 2.0660 - val_loss: 2.4061 - val_mae: 2.4061\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0565 - mae: 2.0565 - val_loss: 2.3753 - val_mae: 2.3753\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0385 - mae: 2.0385 - val_loss: 2.4267 - val_mae: 2.4267\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0317 - mae: 2.0317 - val_loss: 2.4330 - val_mae: 2.4330\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0334 - mae: 2.0334 - val_loss: 2.3839 - val_mae: 2.3839\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0077 - mae: 2.0077 - val_loss: 2.3558 - val_mae: 2.3558\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0043 - mae: 2.0043 - val_loss: 2.4030 - val_mae: 2.4030\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0012 - mae: 2.0012 - val_loss: 2.4095 - val_mae: 2.4095\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9927 - mae: 1.9927 - val_loss: 2.3816 - val_mae: 2.3816\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9808 - mae: 1.9808 - val_loss: 2.3891 - val_mae: 2.3891\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9761 - mae: 1.9761 - val_loss: 2.3893 - val_mae: 2.3893\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9678 - mae: 1.9678 - val_loss: 2.3967 - val_mae: 2.3967\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9662 - mae: 1.9662 - val_loss: 2.3930 - val_mae: 2.3930\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9466 - mae: 1.9466 - val_loss: 2.4143 - val_mae: 2.4143\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9460 - mae: 1.9460 - val_loss: 2.3497 - val_mae: 2.3497\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9335 - mae: 1.9335 - val_loss: 2.3997 - val_mae: 2.3997\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9178 - mae: 1.9178 - val_loss: 2.3964 - val_mae: 2.3964\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9053 - mae: 1.9053 - val_loss: 2.3742 - val_mae: 2.3742\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9127 - mae: 1.9127 - val_loss: 2.3719 - val_mae: 2.3719\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9000 - mae: 1.9000 - val_loss: 2.3882 - val_mae: 2.3882\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8945 - mae: 1.8945 - val_loss: 2.3527 - val_mae: 2.3527\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8920 - mae: 1.8920 - val_loss: 2.3570 - val_mae: 2.3570\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8870 - mae: 1.8870 - val_loss: 2.3400 - val_mae: 2.3400\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8821 - mae: 1.8821 - val_loss: 2.3683 - val_mae: 2.3683\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8941 - mae: 1.8941 - val_loss: 2.4053 - val_mae: 2.4053\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8837 - mae: 1.8837 - val_loss: 2.3397 - val_mae: 2.3397\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8673 - mae: 1.8673 - val_loss: 2.4076 - val_mae: 2.4076\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8613 - mae: 1.8613 - val_loss: 2.3586 - val_mae: 2.3586\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8589 - mae: 1.8589 - val_loss: 2.3557 - val_mae: 2.3557\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8479 - mae: 1.8479 - val_loss: 2.3667 - val_mae: 2.3667\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8429 - mae: 1.8429 - val_loss: 2.3912 - val_mae: 2.3912\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8304 - mae: 1.8304 - val_loss: 2.3572 - val_mae: 2.3572\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8207 - mae: 1.8207 - val_loss: 2.3795 - val_mae: 2.3795\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8166 - mae: 1.8166 - val_loss: 2.3689 - val_mae: 2.3689\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8204 - mae: 1.8204 - val_loss: 2.3701 - val_mae: 2.3701\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8094 - mae: 1.8094 - val_loss: 2.3580 - val_mae: 2.3580\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8041 - mae: 1.8041 - val_loss: 2.3743 - val_mae: 2.3743\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8061 - mae: 1.8061 - val_loss: 2.3680 - val_mae: 2.3680\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7916 - mae: 1.7916 - val_loss: 2.3669 - val_mae: 2.3669\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7925 - mae: 1.7925 - val_loss: 2.3632 - val_mae: 2.3632\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7916 - mae: 1.7916 - val_loss: 2.3884 - val_mae: 2.3884\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8137 - mae: 1.8137 - val_loss: 2.3939 - val_mae: 2.3939\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8102 - mae: 1.8102 - val_loss: 2.3400 - val_mae: 2.3400\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7832 - mae: 1.7832 - val_loss: 2.3320 - val_mae: 2.3320\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7770 - mae: 1.7770 - val_loss: 2.3349 - val_mae: 2.3349\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7555 - mae: 1.7555 - val_loss: 2.3367 - val_mae: 2.3367\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7515 - mae: 1.7515 - val_loss: 2.3938 - val_mae: 2.3938\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7755 - mae: 1.7755 - val_loss: 2.3607 - val_mae: 2.3607\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7446 - mae: 1.7446 - val_loss: 2.3701 - val_mae: 2.3701\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7556 - mae: 1.7556 - val_loss: 2.3267 - val_mae: 2.3267\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7304 - mae: 1.7304 - val_loss: 2.3621 - val_mae: 2.3621\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7383 - mae: 1.7383 - val_loss: 2.3644 - val_mae: 2.3644\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7243 - mae: 1.7243 - val_loss: 2.3252 - val_mae: 2.3252\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7162 - mae: 1.7162 - val_loss: 2.3353 - val_mae: 2.3353\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7267 - mae: 1.7267 - val_loss: 2.3839 - val_mae: 2.3839\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7334 - mae: 1.7334 - val_loss: 2.3410 - val_mae: 2.3410\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7037 - mae: 1.7037 - val_loss: 2.3743 - val_mae: 2.3743\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7192 - mae: 1.7192 - val_loss: 2.3619 - val_mae: 2.3619\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7099 - mae: 1.7099 - val_loss: 2.3808 - val_mae: 2.3808\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7204 - mae: 1.7204 - val_loss: 2.3541 - val_mae: 2.3541\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6910 - mae: 1.6910 - val_loss: 2.3283 - val_mae: 2.3283\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6662 - mae: 1.6662 - val_loss: 2.3793 - val_mae: 2.3793\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6727 - mae: 1.6727 - val_loss: 2.3464 - val_mae: 2.3464\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6580 - mae: 1.6580 - val_loss: 2.3561 - val_mae: 2.3561\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6633 - mae: 1.6633 - val_loss: 2.3857 - val_mae: 2.3857\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6461 - mae: 1.6461 - val_loss: 2.3711 - val_mae: 2.3711\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.8135 - mae: 3.8135\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 255.8967 - mae: 13.0957 - val_loss: 74.4557 - val_mae: 6.5601\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.4947 - mae: 4.6845 - val_loss: 29.2903 - val_mae: 3.6624\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.5346 - mae: 3.4562 - val_loss: 23.7253 - val_mae: 3.4504\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.4745 - mae: 3.1762 - val_loss: 21.9745 - val_mae: 3.3121\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.2972 - mae: 3.0255 - val_loss: 20.5713 - val_mae: 3.1712\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.1181 - mae: 2.8949 - val_loss: 19.5720 - val_mae: 3.1314\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.2533 - mae: 2.8337 - val_loss: 19.1933 - val_mae: 3.0774\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.4778 - mae: 2.7773 - val_loss: 18.7139 - val_mae: 2.9625\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6925 - mae: 2.6723 - val_loss: 18.0386 - val_mae: 2.9838\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.2415 - mae: 2.6625 - val_loss: 18.0460 - val_mae: 2.9612\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.8432 - mae: 2.6030 - val_loss: 17.2962 - val_mae: 2.9012\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.5395 - mae: 2.5912 - val_loss: 17.2703 - val_mae: 2.8688\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.0392 - mae: 2.5462 - val_loss: 17.1345 - val_mae: 2.9246\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7295 - mae: 2.5184 - val_loss: 16.6441 - val_mae: 2.8476\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.5581 - mae: 2.5116 - val_loss: 16.6282 - val_mae: 2.7994\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4723 - mae: 2.4797 - val_loss: 16.4359 - val_mae: 2.8033\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0405 - mae: 2.4456 - val_loss: 16.3555 - val_mae: 2.8009\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.8547 - mae: 2.4314 - val_loss: 16.0558 - val_mae: 2.7577\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.7469 - mae: 2.4073 - val_loss: 15.9011 - val_mae: 2.7759\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.5971 - mae: 2.4383 - val_loss: 15.9711 - val_mae: 2.7414\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.2861 - mae: 2.3751 - val_loss: 15.9558 - val_mae: 2.7635\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.3061 - mae: 2.3601 - val_loss: 15.5876 - val_mae: 2.7228\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1075 - mae: 2.3616 - val_loss: 15.6804 - val_mae: 2.7207\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0890 - mae: 2.3913 - val_loss: 15.5023 - val_mae: 2.6989\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.8326 - mae: 2.3197 - val_loss: 15.3053 - val_mae: 2.6951\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5903 - mae: 2.3231 - val_loss: 15.2611 - val_mae: 2.6676\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5111 - mae: 2.2970 - val_loss: 15.3124 - val_mae: 2.6669\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4304 - mae: 2.3041 - val_loss: 15.0254 - val_mae: 2.6325\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.2412 - mae: 2.2767 - val_loss: 15.1422 - val_mae: 2.6559\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0944 - mae: 2.2604 - val_loss: 14.8841 - val_mae: 2.6227\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9741 - mae: 2.2408 - val_loss: 14.9465 - val_mae: 2.6329\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9470 - mae: 2.2611 - val_loss: 14.8410 - val_mae: 2.6168\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.7865 - mae: 2.2156 - val_loss: 14.7688 - val_mae: 2.6274\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7392 - mae: 2.2558 - val_loss: 14.9966 - val_mae: 2.6396\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6104 - mae: 2.2379 - val_loss: 14.6005 - val_mae: 2.6090\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5238 - mae: 2.2143 - val_loss: 14.7595 - val_mae: 2.6051\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3842 - mae: 2.1671 - val_loss: 14.5673 - val_mae: 2.5977\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3911 - mae: 2.1999 - val_loss: 14.6628 - val_mae: 2.5989\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3101 - mae: 2.1604 - val_loss: 14.2423 - val_mae: 2.5864\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1773 - mae: 2.1854 - val_loss: 14.3867 - val_mae: 2.5820\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.1588 - mae: 2.1618 - val_loss: 14.4719 - val_mae: 2.5682\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0125 - mae: 2.1449 - val_loss: 14.3689 - val_mae: 2.5612\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.9034 - mae: 2.1304 - val_loss: 14.2308 - val_mae: 2.5655\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 2.1397 - val_loss: 14.3276 - val_mae: 2.5667\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6932 - mae: 2.1205 - val_loss: 14.3634 - val_mae: 2.5482\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6961 - mae: 2.1138 - val_loss: 14.3818 - val_mae: 2.5681\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.6994 - mae: 2.1244 - val_loss: 14.3764 - val_mae: 2.5354\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5203 - mae: 2.0932 - val_loss: 14.0526 - val_mae: 2.5498\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4039 - mae: 2.0696 - val_loss: 13.9910 - val_mae: 2.5418\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4147 - mae: 2.0915 - val_loss: 14.0762 - val_mae: 2.5140\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2270 - mae: 2.0522 - val_loss: 13.9745 - val_mae: 2.5217\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2136 - mae: 2.0640 - val_loss: 14.0334 - val_mae: 2.5282\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1933 - mae: 2.0689 - val_loss: 13.9615 - val_mae: 2.5372\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0316 - mae: 2.0360 - val_loss: 13.9911 - val_mae: 2.5238\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0301 - mae: 2.0310 - val_loss: 13.9088 - val_mae: 2.5087\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0018 - mae: 2.0264 - val_loss: 13.7197 - val_mae: 2.5080\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8968 - mae: 2.0394 - val_loss: 13.8495 - val_mae: 2.5016\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7941 - mae: 2.0138 - val_loss: 13.9352 - val_mae: 2.5237\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6879 - mae: 2.0009 - val_loss: 13.8248 - val_mae: 2.5230\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6868 - mae: 2.0130 - val_loss: 14.1419 - val_mae: 2.5205\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8089 - mae: 2.0215 - val_loss: 13.8668 - val_mae: 2.5284\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5204 - mae: 1.9789 - val_loss: 13.7111 - val_mae: 2.5078\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.4502 - mae: 1.9618 - val_loss: 13.8428 - val_mae: 2.4986\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.4419 - mae: 1.9735 - val_loss: 13.7282 - val_mae: 2.4896\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5044 - mae: 1.9733 - val_loss: 13.6939 - val_mae: 2.4894\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3911 - mae: 1.9707 - val_loss: 13.8077 - val_mae: 2.4706\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3671 - mae: 1.9738 - val_loss: 13.7117 - val_mae: 2.4780\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1837 - mae: 1.9569 - val_loss: 13.6177 - val_mae: 2.4734\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1803 - mae: 1.9419 - val_loss: 13.7813 - val_mae: 2.4678\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0476 - mae: 1.9448 - val_loss: 13.5683 - val_mae: 2.4882\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0199 - mae: 1.9148 - val_loss: 13.6781 - val_mae: 2.4555\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9870 - mae: 1.9271 - val_loss: 13.5712 - val_mae: 2.4660\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9082 - mae: 1.9076 - val_loss: 13.6703 - val_mae: 2.4726\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9005 - mae: 1.9191 - val_loss: 13.5918 - val_mae: 2.4447\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8120 - mae: 1.9069 - val_loss: 13.5017 - val_mae: 2.4767\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8175 - mae: 1.8985 - val_loss: 13.6909 - val_mae: 2.4708\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7977 - mae: 1.8891 - val_loss: 13.5813 - val_mae: 2.4838\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7470 - mae: 1.8748 - val_loss: 13.6216 - val_mae: 2.4765\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7228 - mae: 1.8907 - val_loss: 13.5775 - val_mae: 2.4902\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5757 - mae: 1.8706 - val_loss: 13.6292 - val_mae: 2.4637\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4433 - mae: 1.8545 - val_loss: 13.6763 - val_mae: 2.4772\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4469 - mae: 1.8730 - val_loss: 13.5230 - val_mae: 2.4737\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3825 - mae: 1.8479 - val_loss: 13.5328 - val_mae: 2.4553\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2949 - mae: 1.8424 - val_loss: 13.5816 - val_mae: 2.4635\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3103 - mae: 1.8390 - val_loss: 13.5950 - val_mae: 2.4591\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1844 - mae: 1.8175 - val_loss: 13.5362 - val_mae: 2.4547\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1598 - mae: 1.8120 - val_loss: 13.5923 - val_mae: 2.4790\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1577 - mae: 1.8179 - val_loss: 13.7463 - val_mae: 2.4401\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2050 - mae: 1.8540 - val_loss: 13.7342 - val_mae: 2.4487\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0447 - mae: 1.8109 - val_loss: 13.7334 - val_mae: 2.4605\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9852 - mae: 1.8005 - val_loss: 13.5949 - val_mae: 2.4569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9223 - mae: 1.7913 - val_loss: 14.0001 - val_mae: 2.5017\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9192 - mae: 1.7849 - val_loss: 13.8883 - val_mae: 2.4727\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8830 - mae: 1.7930 - val_loss: 13.8462 - val_mae: 2.4962\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8101 - mae: 1.7758 - val_loss: 13.7988 - val_mae: 2.5025\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8213 - mae: 1.7696 - val_loss: 13.7025 - val_mae: 2.4602\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8037 - mae: 1.8018 - val_loss: 13.5470 - val_mae: 2.4450\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7620 - mae: 1.7898 - val_loss: 13.7490 - val_mae: 2.4609\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6498 - mae: 1.7551 - val_loss: 13.5939 - val_mae: 2.4624\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5960 - mae: 1.7460 - val_loss: 13.6148 - val_mae: 2.4526\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.1625 - mae: 3.5711\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 13.1132 - mae: 13.1132 - val_loss: 5.9476 - val_mae: 5.9476\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5484 - mae: 4.5484 - val_loss: 3.4262 - val_mae: 3.4262\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3332 - mae: 3.3332 - val_loss: 3.1341 - val_mae: 3.1341\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9881 - mae: 2.9881 - val_loss: 2.9390 - val_mae: 2.9390\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8142 - mae: 2.8142 - val_loss: 2.9106 - val_mae: 2.9106\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6954 - mae: 2.6954 - val_loss: 2.8383 - val_mae: 2.8383\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6443 - mae: 2.6443 - val_loss: 2.7838 - val_mae: 2.7838\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5764 - mae: 2.5764 - val_loss: 2.7739 - val_mae: 2.7739\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5095 - mae: 2.5095 - val_loss: 2.7421 - val_mae: 2.7421\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4479 - mae: 2.4479 - val_loss: 2.7885 - val_mae: 2.7885\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4334 - mae: 2.4334 - val_loss: 2.7380 - val_mae: 2.7380\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4199 - mae: 2.4199 - val_loss: 2.6727 - val_mae: 2.6727\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3657 - mae: 2.3657 - val_loss: 2.6422 - val_mae: 2.6422\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3372 - mae: 2.3372 - val_loss: 2.6589 - val_mae: 2.6589\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3101 - mae: 2.3101 - val_loss: 2.6395 - val_mae: 2.6395\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2894 - mae: 2.2894 - val_loss: 2.5935 - val_mae: 2.5935\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2547 - mae: 2.2547 - val_loss: 2.5982 - val_mae: 2.5982\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2417 - mae: 2.2417 - val_loss: 2.5576 - val_mae: 2.5576\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2248 - mae: 2.2248 - val_loss: 2.6019 - val_mae: 2.6019\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2261 - mae: 2.2261 - val_loss: 2.5442 - val_mae: 2.5442\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1991 - mae: 2.1991 - val_loss: 2.5435 - val_mae: 2.5435\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1729 - mae: 2.1729 - val_loss: 2.5763 - val_mae: 2.5763\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1751 - mae: 2.1751 - val_loss: 2.5450 - val_mae: 2.5450\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1664 - mae: 2.1664 - val_loss: 2.5466 - val_mae: 2.5466\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1696 - mae: 2.1696 - val_loss: 2.5267 - val_mae: 2.5267\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1524 - mae: 2.1524 - val_loss: 2.5171 - val_mae: 2.5171\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1354 - mae: 2.1354 - val_loss: 2.4932 - val_mae: 2.4932\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1297 - mae: 2.1297 - val_loss: 2.5065 - val_mae: 2.5065\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1155 - mae: 2.1155 - val_loss: 2.5066 - val_mae: 2.5066\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1122 - mae: 2.1122 - val_loss: 2.4925 - val_mae: 2.4925\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1110 - mae: 2.1110 - val_loss: 2.4947 - val_mae: 2.4947\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0809 - mae: 2.0809 - val_loss: 2.4942 - val_mae: 2.4942\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0785 - mae: 2.0785 - val_loss: 2.4660 - val_mae: 2.4660\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0772 - mae: 2.0772 - val_loss: 2.5145 - val_mae: 2.5145\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0701 - mae: 2.0701 - val_loss: 2.4939 - val_mae: 2.4939\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0663 - mae: 2.0663 - val_loss: 2.4672 - val_mae: 2.4672\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0348 - mae: 2.0348 - val_loss: 2.4650 - val_mae: 2.4650\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0242 - mae: 2.0242 - val_loss: 2.4756 - val_mae: 2.4756\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0088 - mae: 2.0088 - val_loss: 2.4696 - val_mae: 2.4696\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0362 - mae: 2.0362 - val_loss: 2.4400 - val_mae: 2.4400\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0203 - mae: 2.0203 - val_loss: 2.4740 - val_mae: 2.4740\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0330 - mae: 2.0330 - val_loss: 2.4271 - val_mae: 2.4271\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9999 - mae: 1.9999 - val_loss: 2.4175 - val_mae: 2.4175\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9852 - mae: 1.9852 - val_loss: 2.4493 - val_mae: 2.4493\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0126 - mae: 2.0126 - val_loss: 2.4166 - val_mae: 2.4166\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9668 - mae: 1.9668 - val_loss: 2.4174 - val_mae: 2.4174\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9512 - mae: 1.9512 - val_loss: 2.4419 - val_mae: 2.4419\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9647 - mae: 1.9647 - val_loss: 2.3963 - val_mae: 2.3963\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9456 - mae: 1.9456 - val_loss: 2.4023 - val_mae: 2.4023\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9366 - mae: 1.9366 - val_loss: 2.3623 - val_mae: 2.3623\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9329 - mae: 1.9329 - val_loss: 2.4171 - val_mae: 2.4171\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9641 - mae: 1.9641 - val_loss: 2.4884 - val_mae: 2.4884\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9305 - mae: 1.9305 - val_loss: 2.4453 - val_mae: 2.4453\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9476 - mae: 1.9476 - val_loss: 2.3757 - val_mae: 2.3757\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9143 - mae: 1.9143 - val_loss: 2.3868 - val_mae: 2.3868\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8852 - mae: 1.8852 - val_loss: 2.3814 - val_mae: 2.3814\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8925 - mae: 1.8925 - val_loss: 2.3870 - val_mae: 2.3870\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8857 - mae: 1.8857 - val_loss: 2.3980 - val_mae: 2.3980\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8686 - mae: 1.8686 - val_loss: 2.4078 - val_mae: 2.4078\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8695 - mae: 1.8695 - val_loss: 2.3577 - val_mae: 2.3577\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8761 - mae: 1.8761 - val_loss: 2.3685 - val_mae: 2.3685\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8915 - mae: 1.8915 - val_loss: 2.3826 - val_mae: 2.3826\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8430 - mae: 1.8430 - val_loss: 2.3641 - val_mae: 2.3641\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8701 - mae: 1.8701 - val_loss: 2.3838 - val_mae: 2.3838\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8278 - mae: 1.8278 - val_loss: 2.3449 - val_mae: 2.3449\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8214 - mae: 1.8214 - val_loss: 2.3743 - val_mae: 2.3743\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8474 - mae: 1.8474 - val_loss: 2.3395 - val_mae: 2.3395\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8277 - mae: 1.8277 - val_loss: 2.4156 - val_mae: 2.4156\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8491 - mae: 1.8491 - val_loss: 2.3954 - val_mae: 2.3954\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8174 - mae: 1.8174 - val_loss: 2.4009 - val_mae: 2.4009\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8116 - mae: 1.8116 - val_loss: 2.3683 - val_mae: 2.3683\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8408 - mae: 1.8408 - val_loss: 2.3725 - val_mae: 2.3725\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8492 - mae: 1.8492 - val_loss: 2.3603 - val_mae: 2.3603\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7896 - mae: 1.7896 - val_loss: 2.4137 - val_mae: 2.4137\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7896 - mae: 1.7896 - val_loss: 2.3979 - val_mae: 2.3979\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7853 - mae: 1.7853 - val_loss: 2.3765 - val_mae: 2.3765\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7756 - mae: 1.7756 - val_loss: 2.3741 - val_mae: 2.3741\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7786 - mae: 1.7786 - val_loss: 2.3830 - val_mae: 2.3830\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7627 - mae: 1.7627 - val_loss: 2.3741 - val_mae: 2.3741\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7964 - mae: 1.7964 - val_loss: 2.3792 - val_mae: 2.3792\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7610 - mae: 1.7610 - val_loss: 2.3573 - val_mae: 2.3573\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7581 - mae: 1.7581 - val_loss: 2.4007 - val_mae: 2.4007\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7400 - mae: 1.7400 - val_loss: 2.3614 - val_mae: 2.3614\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7556 - mae: 1.7556 - val_loss: 2.3978 - val_mae: 2.3978\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7613 - mae: 1.7613 - val_loss: 2.3520 - val_mae: 2.3520\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7088 - mae: 1.7088 - val_loss: 2.3686 - val_mae: 2.3686\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7267 - mae: 1.7267 - val_loss: 2.3540 - val_mae: 2.3540\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7298 - mae: 1.7298 - val_loss: 2.4079 - val_mae: 2.4079\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7221 - mae: 1.7221 - val_loss: 2.3501 - val_mae: 2.3501\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7306 - mae: 1.7306 - val_loss: 2.3772 - val_mae: 2.3772\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7091 - mae: 1.7091 - val_loss: 2.3904 - val_mae: 2.3904\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7076 - mae: 1.7076 - val_loss: 2.3632 - val_mae: 2.3632\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6962 - mae: 1.6962 - val_loss: 2.3565 - val_mae: 2.3565\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7021 - mae: 1.7021 - val_loss: 2.3529 - val_mae: 2.3529\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6928 - mae: 1.6928 - val_loss: 2.3920 - val_mae: 2.3920\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6878 - mae: 1.6878 - val_loss: 2.3963 - val_mae: 2.3963\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6659 - mae: 1.6659 - val_loss: 2.3899 - val_mae: 2.3899\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6863 - mae: 1.6863 - val_loss: 2.3805 - val_mae: 2.3805\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6670 - mae: 1.6670 - val_loss: 2.3319 - val_mae: 2.3319\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6689 - mae: 1.6689 - val_loss: 2.3176 - val_mae: 2.3176\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4747 - mae: 3.4747\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 268.6217 - mae: 13.1838 - val_loss: 65.5703 - val_mae: 6.0283\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.3964 - mae: 4.6239 - val_loss: 31.7566 - val_mae: 3.8056\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.6078 - mae: 3.6038 - val_loss: 26.0664 - val_mae: 3.4510\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.0194 - mae: 3.3626 - val_loss: 23.9047 - val_mae: 3.2844\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.2782 - mae: 3.1422 - val_loss: 21.5580 - val_mae: 3.2455\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.6388 - mae: 2.9900 - val_loss: 20.5260 - val_mae: 3.1858\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.4724 - mae: 2.8593 - val_loss: 19.6503 - val_mae: 3.1152\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.8758 - mae: 2.8175 - val_loss: 19.0067 - val_mae: 3.0386\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.0673 - mae: 2.7341 - val_loss: 18.4723 - val_mae: 2.9722\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.4591 - mae: 2.6847 - val_loss: 17.9397 - val_mae: 2.9391\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.0371 - mae: 2.6448 - val_loss: 17.5549 - val_mae: 2.9364\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.3897 - mae: 2.5832 - val_loss: 17.1670 - val_mae: 2.8725\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2101 - mae: 2.5720 - val_loss: 16.9939 - val_mae: 2.8464\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2675 - mae: 2.5618 - val_loss: 16.7777 - val_mae: 2.8417\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.4223 - mae: 2.4899 - val_loss: 16.4697 - val_mae: 2.8201\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2899 - mae: 2.4874 - val_loss: 16.2175 - val_mae: 2.8177\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.0030 - mae: 2.4792 - val_loss: 16.2117 - val_mae: 2.7950\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.8698 - mae: 2.4448 - val_loss: 15.8298 - val_mae: 2.7638\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.6678 - mae: 2.4058 - val_loss: 15.6655 - val_mae: 2.7500\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 11.6262 - mae: 2.4367 - val_loss: 15.4999 - val_mae: 2.7221\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.3423 - mae: 2.3900 - val_loss: 15.4417 - val_mae: 2.6930\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.1840 - mae: 2.3790 - val_loss: 15.1286 - val_mae: 2.6975\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.0597 - mae: 2.3495 - val_loss: 15.0042 - val_mae: 2.6779\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.0588 - mae: 2.3971 - val_loss: 14.9342 - val_mae: 2.6597\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6387 - mae: 2.2952 - val_loss: 15.1819 - val_mae: 2.6754\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6762 - mae: 2.3418 - val_loss: 14.7682 - val_mae: 2.6429\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5094 - mae: 2.3123 - val_loss: 14.7443 - val_mae: 2.6506\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.2578 - mae: 2.2909 - val_loss: 14.4319 - val_mae: 2.6266\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.1734 - mae: 2.2646 - val_loss: 14.4917 - val_mae: 2.6260\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.1016 - mae: 2.2659 - val_loss: 14.3994 - val_mae: 2.6195\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9566 - mae: 2.2591 - val_loss: 14.3704 - val_mae: 2.6065\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.8366 - mae: 2.2284 - val_loss: 14.2834 - val_mae: 2.5957\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.8209 - mae: 2.2203 - val_loss: 14.1378 - val_mae: 2.5862\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6401 - mae: 2.2195 - val_loss: 14.0220 - val_mae: 2.5802\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4656 - mae: 2.1822 - val_loss: 14.1978 - val_mae: 2.5684\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.5764 - mae: 2.2209 - val_loss: 14.2695 - val_mae: 2.5749\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.3973 - mae: 2.2019 - val_loss: 14.0633 - val_mae: 2.5554\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.4334 - mae: 2.1936 - val_loss: 14.1633 - val_mae: 2.5445\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1281 - mae: 2.1578 - val_loss: 13.9093 - val_mae: 2.5651\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.0313 - mae: 2.1401 - val_loss: 13.7568 - val_mae: 2.5329\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2777 - mae: 2.1752 - val_loss: 14.0486 - val_mae: 2.5566\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8313 - mae: 2.1425 - val_loss: 13.7822 - val_mae: 2.5156\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7656 - mae: 2.1209 - val_loss: 13.7142 - val_mae: 2.5317\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8700 - mae: 2.1295 - val_loss: 13.6991 - val_mae: 2.5077\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7890 - mae: 2.1139 - val_loss: 13.5460 - val_mae: 2.5088\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5473 - mae: 2.0880 - val_loss: 13.6530 - val_mae: 2.5099\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.5485 - mae: 2.0970 - val_loss: 13.6061 - val_mae: 2.4834\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5677 - mae: 2.1175 - val_loss: 13.5607 - val_mae: 2.4799\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4842 - mae: 2.1020 - val_loss: 13.7376 - val_mae: 2.5350\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.3083 - mae: 2.0677 - val_loss: 13.5878 - val_mae: 2.4985\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2655 - mae: 2.0499 - val_loss: 13.4338 - val_mae: 2.4796\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1000 - mae: 2.0350 - val_loss: 13.6728 - val_mae: 2.4782\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.1610 - mae: 2.0629 - val_loss: 13.6553 - val_mae: 2.4770\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0098 - mae: 2.0452 - val_loss: 13.5177 - val_mae: 2.5058\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.8800 - mae: 2.0194 - val_loss: 13.3233 - val_mae: 2.5021\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0337 - mae: 2.0296 - val_loss: 13.1741 - val_mae: 2.4890\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7422 - mae: 2.0108 - val_loss: 13.4294 - val_mae: 2.4705\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7826 - mae: 2.0159 - val_loss: 13.4068 - val_mae: 2.4991\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6121 - mae: 1.9872 - val_loss: 13.3198 - val_mae: 2.4381\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6314 - mae: 1.9998 - val_loss: 13.5061 - val_mae: 2.4744\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5242 - mae: 1.9841 - val_loss: 13.1848 - val_mae: 2.4779\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6159 - mae: 1.9946 - val_loss: 13.4391 - val_mae: 2.4653\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.4488 - mae: 1.9736 - val_loss: 13.2639 - val_mae: 2.4518\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3936 - mae: 1.9632 - val_loss: 13.4393 - val_mae: 2.4529\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2406 - mae: 1.9373 - val_loss: 13.1427 - val_mae: 2.4476\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1920 - mae: 1.9559 - val_loss: 13.3772 - val_mae: 2.4453\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1588 - mae: 1.9429 - val_loss: 13.3524 - val_mae: 2.4465\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1460 - mae: 1.9376 - val_loss: 13.4035 - val_mae: 2.4356\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0417 - mae: 1.9363 - val_loss: 13.1735 - val_mae: 2.4714\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0347 - mae: 1.9310 - val_loss: 13.1347 - val_mae: 2.4698\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9703 - mae: 1.9056 - val_loss: 13.0134 - val_mae: 2.4406\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8980 - mae: 1.9253 - val_loss: 13.0961 - val_mae: 2.4339\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8365 - mae: 1.9005 - val_loss: 13.3532 - val_mae: 2.4454\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8103 - mae: 1.9065 - val_loss: 13.2327 - val_mae: 2.4467\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6791 - mae: 1.8726 - val_loss: 12.9779 - val_mae: 2.4424\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7007 - mae: 1.8765 - val_loss: 13.5529 - val_mae: 2.4563\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7258 - mae: 1.8776 - val_loss: 12.9880 - val_mae: 2.4541\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5753 - mae: 1.8679 - val_loss: 12.9941 - val_mae: 2.4292\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5395 - mae: 1.8726 - val_loss: 13.0767 - val_mae: 2.4314\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5442 - mae: 1.8737 - val_loss: 13.1524 - val_mae: 2.4202\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4949 - mae: 1.8569 - val_loss: 13.6134 - val_mae: 2.4528\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4080 - mae: 1.8539 - val_loss: 13.2960 - val_mae: 2.4216\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3881 - mae: 1.8513 - val_loss: 12.8972 - val_mae: 2.4271\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2814 - mae: 1.8513 - val_loss: 13.3733 - val_mae: 2.4705\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2335 - mae: 1.8390 - val_loss: 13.0745 - val_mae: 2.4138\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1717 - mae: 1.8529 - val_loss: 13.3028 - val_mae: 2.4349\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1489 - mae: 1.8277 - val_loss: 12.9568 - val_mae: 2.4099\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0256 - mae: 1.8096 - val_loss: 13.0806 - val_mae: 2.4167\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9886 - mae: 1.7885 - val_loss: 13.0768 - val_mae: 2.4334\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9826 - mae: 1.8236 - val_loss: 13.2499 - val_mae: 2.4333\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9104 - mae: 1.8172 - val_loss: 13.9291 - val_mae: 2.5136\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9806 - mae: 1.8406 - val_loss: 13.3671 - val_mae: 2.4401\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8897 - mae: 1.7911 - val_loss: 13.1422 - val_mae: 2.4227\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8348 - mae: 1.7874 - val_loss: 13.0776 - val_mae: 2.4492\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8343 - mae: 1.7690 - val_loss: 13.0242 - val_mae: 2.4195\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7880 - mae: 1.7941 - val_loss: 13.1752 - val_mae: 2.4261\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6308 - mae: 1.7576 - val_loss: 13.1351 - val_mae: 2.4383\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6693 - mae: 1.7692 - val_loss: 13.3807 - val_mae: 2.4106\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5390 - mae: 1.7348 - val_loss: 13.1130 - val_mae: 2.4106\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4904 - mae: 1.7348 - val_loss: 13.1408 - val_mae: 2.4187\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.6757 - mae: 3.6232\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 13.7194 - mae: 13.7194 - val_loss: 5.9951 - val_mae: 5.9951\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3971 - mae: 4.3971 - val_loss: 3.2762 - val_mae: 3.2762\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3713 - mae: 3.3713 - val_loss: 3.0235 - val_mae: 3.0235\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0157 - mae: 3.0157 - val_loss: 2.8659 - val_mae: 2.8659\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8118 - mae: 2.8118 - val_loss: 2.8551 - val_mae: 2.8551\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7250 - mae: 2.7250 - val_loss: 2.9566 - val_mae: 2.9566\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6336 - mae: 2.6336 - val_loss: 2.8250 - val_mae: 2.8250\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5964 - mae: 2.5964 - val_loss: 2.6921 - val_mae: 2.6921\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5597 - mae: 2.5597 - val_loss: 2.6311 - val_mae: 2.6311\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4808 - mae: 2.4808 - val_loss: 2.8188 - val_mae: 2.8188\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4907 - mae: 2.4907 - val_loss: 2.6653 - val_mae: 2.6653\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4299 - mae: 2.4299 - val_loss: 2.6486 - val_mae: 2.6486\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4073 - mae: 2.4073 - val_loss: 2.6114 - val_mae: 2.6114\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3973 - mae: 2.3973 - val_loss: 2.6262 - val_mae: 2.6262\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3622 - mae: 2.3622 - val_loss: 2.5426 - val_mae: 2.5426\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3703 - mae: 2.3703 - val_loss: 2.6107 - val_mae: 2.6107\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3101 - mae: 2.3101 - val_loss: 2.6000 - val_mae: 2.6000\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2981 - mae: 2.2981 - val_loss: 2.5768 - val_mae: 2.5768\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2558 - mae: 2.2558 - val_loss: 2.6367 - val_mae: 2.6367\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2845 - mae: 2.2845 - val_loss: 2.5298 - val_mae: 2.5298\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2281 - mae: 2.2281 - val_loss: 2.5922 - val_mae: 2.5922\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2485 - mae: 2.2485 - val_loss: 2.4956 - val_mae: 2.4956\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2313 - mae: 2.2313 - val_loss: 2.4924 - val_mae: 2.4924\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2197 - mae: 2.2197 - val_loss: 2.5024 - val_mae: 2.5024\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1935 - mae: 2.1935 - val_loss: 2.4816 - val_mae: 2.4816\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1926 - mae: 2.1926 - val_loss: 2.4510 - val_mae: 2.4510\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1754 - mae: 2.1754 - val_loss: 2.4428 - val_mae: 2.4428\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1696 - mae: 2.1696 - val_loss: 2.4468 - val_mae: 2.4468\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1488 - mae: 2.1488 - val_loss: 2.4485 - val_mae: 2.4485\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1304 - mae: 2.1304 - val_loss: 2.4293 - val_mae: 2.4293\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1383 - mae: 2.1383 - val_loss: 2.4591 - val_mae: 2.4591\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1281 - mae: 2.1281 - val_loss: 2.4558 - val_mae: 2.4558\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1160 - mae: 2.1160 - val_loss: 2.4490 - val_mae: 2.4490\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0846 - mae: 2.0846 - val_loss: 2.4338 - val_mae: 2.4338\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0982 - mae: 2.0982 - val_loss: 2.3970 - val_mae: 2.3970\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0782 - mae: 2.0782 - val_loss: 2.3962 - val_mae: 2.3962\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0914 - mae: 2.0914 - val_loss: 2.4245 - val_mae: 2.4245\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0985 - mae: 2.0985 - val_loss: 2.4003 - val_mae: 2.4003\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0551 - mae: 2.0551 - val_loss: 2.4621 - val_mae: 2.4621\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0588 - mae: 2.0588 - val_loss: 2.4104 - val_mae: 2.4104\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0304 - mae: 2.0304 - val_loss: 2.4064 - val_mae: 2.4064\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0396 - mae: 2.0396 - val_loss: 2.4201 - val_mae: 2.4201\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0332 - mae: 2.0332 - val_loss: 2.4142 - val_mae: 2.4142\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0337 - mae: 2.0337 - val_loss: 2.3784 - val_mae: 2.3784\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0026 - mae: 2.0026 - val_loss: 2.4122 - val_mae: 2.4122\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0013 - mae: 2.0013 - val_loss: 2.4019 - val_mae: 2.4019\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0078 - mae: 2.0078 - val_loss: 2.4464 - val_mae: 2.4464\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9827 - mae: 1.9827 - val_loss: 2.4134 - val_mae: 2.4134\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9854 - mae: 1.9854 - val_loss: 2.4203 - val_mae: 2.4203\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9797 - mae: 1.9797 - val_loss: 2.3800 - val_mae: 2.3800\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9922 - mae: 1.9922 - val_loss: 2.3881 - val_mae: 2.3881\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9526 - mae: 1.9526 - val_loss: 2.3674 - val_mae: 2.3674\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9740 - mae: 1.9740 - val_loss: 2.4032 - val_mae: 2.4032\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9836 - mae: 1.9836 - val_loss: 2.3879 - val_mae: 2.3879\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9397 - mae: 1.9397 - val_loss: 2.3940 - val_mae: 2.3940\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9350 - mae: 1.9350 - val_loss: 2.3655 - val_mae: 2.3655\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9341 - mae: 1.9341 - val_loss: 2.3259 - val_mae: 2.3259\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9243 - mae: 1.9243 - val_loss: 2.4369 - val_mae: 2.4369\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9492 - mae: 1.9492 - val_loss: 2.4066 - val_mae: 2.4066\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9237 - mae: 1.9237 - val_loss: 2.3708 - val_mae: 2.3708\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9077 - mae: 1.9077 - val_loss: 2.3892 - val_mae: 2.3892\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9000 - mae: 1.9000 - val_loss: 2.3572 - val_mae: 2.3572\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8997 - mae: 1.8997 - val_loss: 2.3595 - val_mae: 2.3595\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9101 - mae: 1.9101 - val_loss: 2.3820 - val_mae: 2.3820\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8937 - mae: 1.8937 - val_loss: 2.4465 - val_mae: 2.4465\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8959 - mae: 1.8959 - val_loss: 2.4030 - val_mae: 2.4030\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8794 - mae: 1.8794 - val_loss: 2.3583 - val_mae: 2.3583\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8935 - mae: 1.8935 - val_loss: 2.3327 - val_mae: 2.3327\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8751 - mae: 1.8751 - val_loss: 2.3531 - val_mae: 2.3531\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8615 - mae: 1.8615 - val_loss: 2.3971 - val_mae: 2.3971\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8792 - mae: 1.8792 - val_loss: 2.3662 - val_mae: 2.3662\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8855 - mae: 1.8855 - val_loss: 2.3733 - val_mae: 2.3733\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8722 - mae: 1.8722 - val_loss: 2.4057 - val_mae: 2.4057\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8776 - mae: 1.8776 - val_loss: 2.4125 - val_mae: 2.4125\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8506 - mae: 1.8506 - val_loss: 2.3393 - val_mae: 2.3393\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8471 - mae: 1.8471 - val_loss: 2.3839 - val_mae: 2.3839\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8631 - mae: 1.8631 - val_loss: 2.3562 - val_mae: 2.3562\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8248 - mae: 1.8248 - val_loss: 2.3679 - val_mae: 2.3679\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8472 - mae: 1.8472 - val_loss: 2.3543 - val_mae: 2.3543\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8224 - mae: 1.8224 - val_loss: 2.4247 - val_mae: 2.4247\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8203 - mae: 1.8203 - val_loss: 2.3516 - val_mae: 2.3516\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8160 - mae: 1.8160 - val_loss: 2.3584 - val_mae: 2.3584\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8220 - mae: 1.8220 - val_loss: 2.4199 - val_mae: 2.4199\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8026 - mae: 1.8026 - val_loss: 2.3853 - val_mae: 2.3853\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8050 - mae: 1.8050 - val_loss: 2.3622 - val_mae: 2.3622\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7871 - mae: 1.7871 - val_loss: 2.4130 - val_mae: 2.4130\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7774 - mae: 1.7774 - val_loss: 2.3905 - val_mae: 2.3905\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7861 - mae: 1.7861 - val_loss: 2.3776 - val_mae: 2.3776\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7672 - mae: 1.7672 - val_loss: 2.3315 - val_mae: 2.3315\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7724 - mae: 1.7724 - val_loss: 2.3867 - val_mae: 2.3867\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7591 - mae: 1.7591 - val_loss: 2.3954 - val_mae: 2.3954\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7813 - mae: 1.7813 - val_loss: 2.4055 - val_mae: 2.4055\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7609 - mae: 1.7609 - val_loss: 2.3729 - val_mae: 2.3729\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7520 - mae: 1.7520 - val_loss: 2.3705 - val_mae: 2.3705\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7484 - mae: 1.7484 - val_loss: 2.4166 - val_mae: 2.4166\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7391 - mae: 1.7391 - val_loss: 2.3723 - val_mae: 2.3723\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7412 - mae: 1.7412 - val_loss: 2.3567 - val_mae: 2.3567\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7394 - mae: 1.7394 - val_loss: 2.3518 - val_mae: 2.3518\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7305 - mae: 1.7305 - val_loss: 2.3808 - val_mae: 2.3808\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7250 - mae: 1.7250 - val_loss: 2.3924 - val_mae: 2.3924\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8693 - mae: 3.8693\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 198.0543 - mae: 10.4129 - val_loss: 97.7092 - val_mae: 6.9518\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.5208 - mae: 6.3511 - val_loss: 87.2187 - val_mae: 6.7877\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 77.6867 - mae: 6.2083 - val_loss: 84.1665 - val_mae: 6.8071\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 75.6070 - mae: 6.1704 - val_loss: 81.6736 - val_mae: 6.7431\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 73.4143 - mae: 6.0744 - val_loss: 78.9141 - val_mae: 6.5877\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 70.9536 - mae: 5.9257 - val_loss: 75.4408 - val_mae: 6.3676\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 68.0947 - mae: 5.7658 - val_loss: 72.2047 - val_mae: 6.1506\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 65.2517 - mae: 5.5865 - val_loss: 68.9846 - val_mae: 5.9412\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 62.7193 - mae: 5.4376 - val_loss: 66.2846 - val_mae: 5.7902\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 60.3897 - mae: 5.2418 - val_loss: 63.8316 - val_mae: 5.6001\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 58.1885 - mae: 5.1651 - val_loss: 61.6120 - val_mae: 5.4971\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.3765 - mae: 5.1051 - val_loss: 59.6275 - val_mae: 5.3721\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.8759 - mae: 5.0689 - val_loss: 57.9685 - val_mae: 5.1773\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.4229 - mae: 4.8510 - val_loss: 56.6145 - val_mae: 5.1698\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.0827 - mae: 4.9283 - val_loss: 55.2490 - val_mae: 5.0536\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.7646 - mae: 4.7827 - val_loss: 54.1200 - val_mae: 5.0476\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.7422 - mae: 4.8204 - val_loss: 53.0632 - val_mae: 5.0237\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.7412 - mae: 4.7572 - val_loss: 52.0373 - val_mae: 4.8441\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.9195 - mae: 4.6007 - val_loss: 51.3172 - val_mae: 4.8287\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.9864 - mae: 4.7508 - val_loss: 50.3777 - val_mae: 4.7862\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.2748 - mae: 4.6018 - val_loss: 49.6049 - val_mae: 4.7693\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.3835 - mae: 4.5761 - val_loss: 48.8180 - val_mae: 4.6239\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.4259 - mae: 4.5055 - val_loss: 48.1261 - val_mae: 4.5259\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.6211 - mae: 4.4709 - val_loss: 47.3513 - val_mae: 4.4965\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.7368 - mae: 4.3178 - val_loss: 46.6294 - val_mae: 4.5507\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.8842 - mae: 4.3589 - val_loss: 45.8677 - val_mae: 4.3818\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.0208 - mae: 4.2648 - val_loss: 45.0921 - val_mae: 4.4609\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.2573 - mae: 4.2756 - val_loss: 44.3070 - val_mae: 4.3831\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.3816 - mae: 4.2550 - val_loss: 43.5189 - val_mae: 4.2710\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.4963 - mae: 4.1545 - val_loss: 43.1095 - val_mae: 4.1206\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.6564 - mae: 4.0144 - val_loss: 42.0555 - val_mae: 4.3080\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.6052 - mae: 4.0077 - val_loss: 41.3154 - val_mae: 4.2594\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.8175 - mae: 3.9989 - val_loss: 40.4926 - val_mae: 4.1909\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.3242 - mae: 3.9909 - val_loss: 39.7923 - val_mae: 4.1249\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.0634 - mae: 3.8259 - val_loss: 39.3031 - val_mae: 4.2306\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.4714 - mae: 3.9074 - val_loss: 38.6235 - val_mae: 3.9850\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.7566 - mae: 3.7828 - val_loss: 37.9240 - val_mae: 4.0088\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.0318 - mae: 3.7540 - val_loss: 37.4846 - val_mae: 3.9511\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.4434 - mae: 3.7183 - val_loss: 36.9565 - val_mae: 3.9218\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.9586 - mae: 3.6656 - val_loss: 36.4577 - val_mae: 4.0382\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.3965 - mae: 3.6818 - val_loss: 36.2280 - val_mae: 3.8554\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.0807 - mae: 3.6451 - val_loss: 36.2975 - val_mae: 3.8166\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.6083 - mae: 3.5826 - val_loss: 35.1881 - val_mae: 3.9690\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.1530 - mae: 3.6516 - val_loss: 35.0598 - val_mae: 3.8241\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.7577 - mae: 3.4885 - val_loss: 34.7622 - val_mae: 4.0743\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.2897 - mae: 3.5735 - val_loss: 34.4111 - val_mae: 3.8062\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.1454 - mae: 3.5315 - val_loss: 33.8365 - val_mae: 3.8940\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.0357 - mae: 3.5157 - val_loss: 33.6038 - val_mae: 3.8356\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.4216 - mae: 3.4946 - val_loss: 33.2901 - val_mae: 3.8320\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.0627 - mae: 3.4694 - val_loss: 32.9896 - val_mae: 3.8455\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.0558 - mae: 3.5051 - val_loss: 32.7302 - val_mae: 3.8327\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.5968 - mae: 3.4483 - val_loss: 32.5725 - val_mae: 3.7854\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.3570 - mae: 3.4645 - val_loss: 32.4467 - val_mae: 3.7554\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.1796 - mae: 3.4480 - val_loss: 32.5327 - val_mae: 3.7438\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.0174 - mae: 3.4271 - val_loss: 31.8928 - val_mae: 3.7399\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.7642 - mae: 3.3888 - val_loss: 31.4408 - val_mae: 3.8153\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.6840 - mae: 3.4266 - val_loss: 31.2929 - val_mae: 3.8672\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.4806 - mae: 3.4575 - val_loss: 31.1987 - val_mae: 3.6985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.0185 - mae: 3.3698 - val_loss: 30.6468 - val_mae: 3.7303\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.8579 - mae: 3.3326 - val_loss: 30.4540 - val_mae: 3.7883\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.9452 - mae: 3.3973 - val_loss: 30.2138 - val_mae: 3.7532\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.3824 - mae: 3.3335 - val_loss: 30.0398 - val_mae: 3.6649\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.2105 - mae: 3.3263 - val_loss: 29.8032 - val_mae: 3.6393\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.1622 - mae: 3.3021 - val_loss: 29.5652 - val_mae: 3.6222\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.1481 - mae: 3.3242 - val_loss: 29.3061 - val_mae: 3.6142\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.7811 - mae: 3.2752 - val_loss: 28.9776 - val_mae: 3.6832\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.4823 - mae: 3.2595 - val_loss: 28.7339 - val_mae: 3.6650\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.3505 - mae: 3.3005 - val_loss: 28.5913 - val_mae: 3.5713\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.2764 - mae: 3.2546 - val_loss: 28.4376 - val_mae: 3.5347\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.8808 - mae: 3.2236 - val_loss: 28.1428 - val_mae: 3.6547\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.1189 - mae: 3.2713 - val_loss: 27.8492 - val_mae: 3.5412\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.5654 - mae: 3.2044 - val_loss: 27.6241 - val_mae: 3.6060\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.5482 - mae: 3.2556 - val_loss: 28.1124 - val_mae: 3.4617\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.4015 - mae: 3.1741 - val_loss: 27.1740 - val_mae: 3.5226\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.0295 - mae: 3.1638 - val_loss: 26.9307 - val_mae: 3.4841\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.9845 - mae: 3.1847 - val_loss: 26.7445 - val_mae: 3.5406\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8128 - mae: 3.1585 - val_loss: 26.4843 - val_mae: 3.4893\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.9045 - mae: 3.1704 - val_loss: 26.2908 - val_mae: 3.4422\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.4415 - mae: 3.1273 - val_loss: 26.1163 - val_mae: 3.4097\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.4277 - mae: 3.1450 - val_loss: 26.1283 - val_mae: 3.3659\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.1343 - mae: 3.0940 - val_loss: 25.7167 - val_mae: 3.3845\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.9997 - mae: 3.1182 - val_loss: 25.6649 - val_mae: 3.3400\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.0508 - mae: 3.1027 - val_loss: 25.3736 - val_mae: 3.4489\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.8154 - mae: 3.0910 - val_loss: 25.5702 - val_mae: 3.5612\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.7175 - mae: 3.1237 - val_loss: 25.1165 - val_mae: 3.3006\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.4794 - mae: 3.0775 - val_loss: 24.8416 - val_mae: 3.3000\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.2774 - mae: 3.0223 - val_loss: 24.6493 - val_mae: 3.4177\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.3826 - mae: 3.0721 - val_loss: 24.4083 - val_mae: 3.3715\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0477 - mae: 3.0482 - val_loss: 24.4057 - val_mae: 3.2388\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0032 - mae: 3.0077 - val_loss: 24.0787 - val_mae: 3.3676\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.9088 - mae: 3.0432 - val_loss: 24.0835 - val_mae: 3.2311\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.6807 - mae: 2.9718 - val_loss: 23.9137 - val_mae: 3.3762\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.6893 - mae: 2.9993 - val_loss: 23.7026 - val_mae: 3.3400\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.6672 - mae: 3.0236 - val_loss: 23.5562 - val_mae: 3.3390\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.3431 - mae: 2.9682 - val_loss: 23.2491 - val_mae: 3.2638\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.2101 - mae: 2.9777 - val_loss: 23.1506 - val_mae: 3.1953\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.1507 - mae: 2.9301 - val_loss: 23.3124 - val_mae: 3.3467\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.1885 - mae: 2.9930 - val_loss: 23.0009 - val_mae: 3.1448\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.1423 - mae: 2.9595 - val_loss: 22.7270 - val_mae: 3.1632\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.9008 - mae: 2.9663 - val_loss: 22.6005 - val_mae: 3.2347\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.3566 - mae: 3.4622\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 10.5098 - mae: 10.5098 - val_loss: 6.9414 - val_mae: 6.9414\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3256 - mae: 6.3256 - val_loss: 6.8306 - val_mae: 6.8306\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2551 - mae: 6.2551 - val_loss: 6.7407 - val_mae: 6.7407\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1284 - mae: 6.1284 - val_loss: 6.5325 - val_mae: 6.5325\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9361 - mae: 5.9361 - val_loss: 6.2381 - val_mae: 6.2381\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6758 - mae: 5.6758 - val_loss: 5.8980 - val_mae: 5.8980\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4213 - mae: 5.4213 - val_loss: 5.6067 - val_mae: 5.6067\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1731 - mae: 5.1731 - val_loss: 5.2610 - val_mae: 5.2610\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0035 - mae: 5.0035 - val_loss: 5.0594 - val_mae: 5.0594\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8287 - mae: 4.8287 - val_loss: 4.8222 - val_mae: 4.8222\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7240 - mae: 4.7240 - val_loss: 4.6636 - val_mae: 4.6636\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6030 - mae: 4.6030 - val_loss: 4.6446 - val_mae: 4.6446\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5411 - mae: 4.5411 - val_loss: 4.5323 - val_mae: 4.5323\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4886 - mae: 4.4886 - val_loss: 4.4711 - val_mae: 4.4711\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4235 - mae: 4.4235 - val_loss: 4.5011 - val_mae: 4.5011\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4128 - mae: 4.4128 - val_loss: 4.4440 - val_mae: 4.4440\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3702 - mae: 4.3702 - val_loss: 4.4173 - val_mae: 4.4173\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3217 - mae: 4.3217 - val_loss: 4.4658 - val_mae: 4.4658\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2785 - mae: 4.2785 - val_loss: 4.4339 - val_mae: 4.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2702 - mae: 4.2702 - val_loss: 4.3698 - val_mae: 4.3698\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2463 - mae: 4.2463 - val_loss: 4.4488 - val_mae: 4.4488\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1887 - mae: 4.1887 - val_loss: 4.3365 - val_mae: 4.3365\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1705 - mae: 4.1705 - val_loss: 4.3186 - val_mae: 4.3186\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1331 - mae: 4.1331 - val_loss: 4.3101 - val_mae: 4.3101\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1228 - mae: 4.1228 - val_loss: 4.2861 - val_mae: 4.2861\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0545 - mae: 4.0545 - val_loss: 4.2662 - val_mae: 4.2662\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0189 - mae: 4.0189 - val_loss: 4.2729 - val_mae: 4.2729\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9692 - mae: 3.9692 - val_loss: 4.2305 - val_mae: 4.2305\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9597 - mae: 3.9597 - val_loss: 4.2415 - val_mae: 4.2415\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9171 - mae: 3.9171 - val_loss: 4.2057 - val_mae: 4.2057\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8824 - mae: 3.8824 - val_loss: 4.1885 - val_mae: 4.1885\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8537 - mae: 3.8537 - val_loss: 4.1668 - val_mae: 4.1668\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8301 - mae: 3.8301 - val_loss: 4.1738 - val_mae: 4.1738\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8249 - mae: 3.8249 - val_loss: 4.1315 - val_mae: 4.1315\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7834 - mae: 3.7834 - val_loss: 4.1443 - val_mae: 4.1443\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7899 - mae: 3.7899 - val_loss: 4.0968 - val_mae: 4.0968\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7444 - mae: 3.7444 - val_loss: 4.0829 - val_mae: 4.0829\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7178 - mae: 3.7178 - val_loss: 4.1139 - val_mae: 4.1139\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7013 - mae: 3.7013 - val_loss: 4.0724 - val_mae: 4.0724\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6617 - mae: 3.6617 - val_loss: 4.0781 - val_mae: 4.0781\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6516 - mae: 3.6516 - val_loss: 4.0449 - val_mae: 4.0449\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6358 - mae: 3.6358 - val_loss: 4.0476 - val_mae: 4.0476\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6111 - mae: 3.6111 - val_loss: 4.0287 - val_mae: 4.0287\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6023 - mae: 3.6023 - val_loss: 4.0213 - val_mae: 4.0213\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5896 - mae: 3.5896 - val_loss: 4.0110 - val_mae: 4.0110\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5756 - mae: 3.5756 - val_loss: 4.0017 - val_mae: 4.0017\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5552 - mae: 3.5552 - val_loss: 4.0638 - val_mae: 4.0638\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5644 - mae: 3.5644 - val_loss: 4.0258 - val_mae: 4.0258\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5526 - mae: 3.5526 - val_loss: 3.9775 - val_mae: 3.9775\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5439 - mae: 3.5439 - val_loss: 4.0300 - val_mae: 4.0300\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5402 - mae: 3.5402 - val_loss: 3.9597 - val_mae: 3.9597\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5169 - mae: 3.5169 - val_loss: 3.9400 - val_mae: 3.9400\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5184 - mae: 3.5184 - val_loss: 3.9771 - val_mae: 3.9771\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5226 - mae: 3.5226 - val_loss: 3.9660 - val_mae: 3.9660\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4926 - mae: 3.4926 - val_loss: 3.9171 - val_mae: 3.9171\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4883 - mae: 3.4883 - val_loss: 3.9883 - val_mae: 3.9883\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4662 - mae: 3.4662 - val_loss: 3.8886 - val_mae: 3.8886\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4805 - mae: 3.4805 - val_loss: 3.8823 - val_mae: 3.8823\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4993 - mae: 3.4993 - val_loss: 3.8791 - val_mae: 3.8791\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4563 - mae: 3.4563 - val_loss: 3.8565 - val_mae: 3.8565\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4604 - mae: 3.4604 - val_loss: 3.8663 - val_mae: 3.8663\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4681 - mae: 3.4681 - val_loss: 3.8414 - val_mae: 3.8414\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5094 - mae: 3.5094 - val_loss: 3.9070 - val_mae: 3.9070\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4463 - mae: 3.4463 - val_loss: 3.8387 - val_mae: 3.8387\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4432 - mae: 3.4432 - val_loss: 3.8412 - val_mae: 3.8412\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4303 - mae: 3.4303 - val_loss: 3.8206 - val_mae: 3.8206\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4082 - mae: 3.4082 - val_loss: 3.8601 - val_mae: 3.8601\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4250 - mae: 3.4250 - val_loss: 3.8155 - val_mae: 3.8155\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3970 - mae: 3.3970 - val_loss: 3.9013 - val_mae: 3.9013\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4017 - mae: 3.4017 - val_loss: 3.8211 - val_mae: 3.8211\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3935 - mae: 3.3935 - val_loss: 3.8057 - val_mae: 3.8057\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3751 - mae: 3.3751 - val_loss: 3.7917 - val_mae: 3.7917\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3681 - mae: 3.3681 - val_loss: 3.8574 - val_mae: 3.8574\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4056 - mae: 3.4056 - val_loss: 3.8030 - val_mae: 3.8030\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3873 - mae: 3.3873 - val_loss: 3.7370 - val_mae: 3.7370\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3529 - mae: 3.3529 - val_loss: 3.7352 - val_mae: 3.7352\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3415 - mae: 3.3415 - val_loss: 3.6883 - val_mae: 3.6883\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3557 - mae: 3.3557 - val_loss: 3.7458 - val_mae: 3.7458\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3391 - mae: 3.3391 - val_loss: 3.7251 - val_mae: 3.7251\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3202 - mae: 3.3202 - val_loss: 3.6800 - val_mae: 3.6800\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3352 - mae: 3.3352 - val_loss: 3.8020 - val_mae: 3.8020\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3120 - mae: 3.3120 - val_loss: 3.7083 - val_mae: 3.7083\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3170 - mae: 3.3170 - val_loss: 3.6499 - val_mae: 3.6499\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3222 - mae: 3.3222 - val_loss: 3.7184 - val_mae: 3.7184\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2948 - mae: 3.2948 - val_loss: 3.7697 - val_mae: 3.7697\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2892 - mae: 3.2892 - val_loss: 3.7404 - val_mae: 3.7404\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2759 - mae: 3.2759 - val_loss: 3.6001 - val_mae: 3.6001\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2629 - mae: 3.2629 - val_loss: 3.6112 - val_mae: 3.6112\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2591 - mae: 3.2591 - val_loss: 3.5776 - val_mae: 3.5776\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2622 - mae: 3.2622 - val_loss: 3.6149 - val_mae: 3.6149\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2401 - mae: 3.2401 - val_loss: 3.6583 - val_mae: 3.6583\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2470 - mae: 3.2470 - val_loss: 3.5635 - val_mae: 3.5635\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2339 - mae: 3.2339 - val_loss: 3.5437 - val_mae: 3.5437\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2330 - mae: 3.2330 - val_loss: 3.5523 - val_mae: 3.5523\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2215 - mae: 3.2215 - val_loss: 3.5914 - val_mae: 3.5914\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2362 - mae: 3.2362 - val_loss: 3.5781 - val_mae: 3.5781\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2043 - mae: 3.2043 - val_loss: 3.5321 - val_mae: 3.5321\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2102 - mae: 3.2102 - val_loss: 3.4813 - val_mae: 3.4813\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1850 - mae: 3.1850 - val_loss: 3.4876 - val_mae: 3.4876\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1744 - mae: 3.1744 - val_loss: 3.4776 - val_mae: 3.4776\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1852 - mae: 4.1852\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 190.9762 - mae: 10.5059 - val_loss: 99.2977 - val_mae: 7.0181\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.7679 - mae: 6.3603 - val_loss: 88.3472 - val_mae: 6.7928\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 78.2818 - mae: 6.2285 - val_loss: 85.0420 - val_mae: 6.8315\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 76.3252 - mae: 6.2036 - val_loss: 82.6790 - val_mae: 6.7664\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 74.4225 - mae: 6.1028 - val_loss: 80.0662 - val_mae: 6.6303\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 72.0284 - mae: 6.0297 - val_loss: 76.8251 - val_mae: 6.4814\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 65.7859 - mae: 5.66 - 0s 4ms/step - loss: 69.1170 - mae: 5.7986 - val_loss: 73.1596 - val_mae: 6.2140\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 66.0143 - mae: 5.6007 - val_loss: 69.5148 - val_mae: 5.9867\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 62.8936 - mae: 5.4567 - val_loss: 66.4673 - val_mae: 5.7891\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 60.5229 - mae: 5.2931 - val_loss: 63.7424 - val_mae: 5.6510\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 58.1285 - mae: 5.1368 - val_loss: 61.3802 - val_mae: 5.4313\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.1554 - mae: 5.0606 - val_loss: 59.3529 - val_mae: 5.3763\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.4276 - mae: 5.0005 - val_loss: 57.6731 - val_mae: 5.2009\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.9090 - mae: 4.9600 - val_loss: 56.0868 - val_mae: 5.1196\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 51.5262 - mae: 4.7888 - val_loss: 54.7627 - val_mae: 5.0761\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.4092 - mae: 4.8826 - val_loss: 53.5927 - val_mae: 4.9780\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.1919 - mae: 4.6817 - val_loss: 52.5408 - val_mae: 4.9072\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.3047 - mae: 4.7015 - val_loss: 51.6405 - val_mae: 4.9319\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.2571 - mae: 4.5902 - val_loss: 50.7102 - val_mae: 4.8687\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.5522 - mae: 4.6534 - val_loss: 49.9536 - val_mae: 4.8858\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.4989 - mae: 4.6076 - val_loss: 49.0325 - val_mae: 4.5765\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.6786 - mae: 4.3974 - val_loss: 48.2496 - val_mae: 4.5661\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.9187 - mae: 4.5249 - val_loss: 47.4872 - val_mae: 4.5063\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.8253 - mae: 4.4383 - val_loss: 46.8436 - val_mae: 4.3726\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.9331 - mae: 4.2834 - val_loss: 45.9585 - val_mae: 4.4278\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.1791 - mae: 4.2617 - val_loss: 45.1244 - val_mae: 4.3955\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.1730 - mae: 4.2504 - val_loss: 44.3356 - val_mae: 4.2976\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.2379 - mae: 4.1824 - val_loss: 43.4811 - val_mae: 4.3000\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 38.2741 - mae: 4.1108 - val_loss: 42.7617 - val_mae: 4.2056\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.2870 - mae: 4.0226 - val_loss: 41.9487 - val_mae: 4.3233\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.5230 - mae: 4.0585 - val_loss: 41.2118 - val_mae: 4.1150\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.5310 - mae: 3.9462 - val_loss: 40.4311 - val_mae: 4.0921\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.1369 - mae: 3.9510 - val_loss: 39.7232 - val_mae: 4.0605\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 34.3626 - mae: 3.8794 - val_loss: 39.1782 - val_mae: 3.9698\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.3700 - mae: 3.8395 - val_loss: 38.9380 - val_mae: 3.8935\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.5578 - mae: 3.7488 - val_loss: 37.8176 - val_mae: 4.0181\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.8282 - mae: 3.7050 - val_loss: 37.2790 - val_mae: 4.0249\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.3448 - mae: 3.7087 - val_loss: 36.9794 - val_mae: 4.1172\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.7879 - mae: 3.6801 - val_loss: 36.2830 - val_mae: 3.9834\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.1478 - mae: 3.6373 - val_loss: 35.9322 - val_mae: 4.0088\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.9218 - mae: 3.6636 - val_loss: 35.4884 - val_mae: 3.9799\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.3794 - mae: 3.6213 - val_loss: 35.1137 - val_mae: 3.9291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.9149 - mae: 3.6123 - val_loss: 35.1643 - val_mae: 3.8243\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.6481 - mae: 3.5736 - val_loss: 34.6225 - val_mae: 3.8369\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.2810 - mae: 3.4901 - val_loss: 34.1668 - val_mae: 3.9262\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.9715 - mae: 3.6174 - val_loss: 34.6605 - val_mae: 3.8079\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.8321 - mae: 3.5372 - val_loss: 34.5092 - val_mae: 3.8079\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.6074 - mae: 3.5175 - val_loss: 33.9694 - val_mae: 3.7961\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.3249 - mae: 3.5006 - val_loss: 33.3152 - val_mae: 3.7983\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 26.9167 - mae: 3.4853 - val_loss: 32.9139 - val_mae: 3.8067\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.6035 - mae: 3.4695 - val_loss: 32.5187 - val_mae: 3.8354\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.3571 - mae: 3.4335 - val_loss: 32.3026 - val_mae: 3.7934\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.0569 - mae: 3.3964 - val_loss: 32.0325 - val_mae: 3.8890\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.9005 - mae: 3.4279 - val_loss: 31.7425 - val_mae: 3.8234\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.8589 - mae: 3.4521 - val_loss: 31.5949 - val_mae: 3.7581\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.5296 - mae: 3.3871 - val_loss: 31.3332 - val_mae: 3.8579\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.2517 - mae: 3.4167 - val_loss: 31.3085 - val_mae: 3.7134\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.0907 - mae: 3.3987 - val_loss: 31.2424 - val_mae: 3.6955\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.0829 - mae: 3.3719 - val_loss: 30.6020 - val_mae: 3.7074\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 24.7326 - mae: 3.3797 - val_loss: 30.7111 - val_mae: 3.6670\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.5526 - mae: 3.3086 - val_loss: 30.0762 - val_mae: 3.6967\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.5629 - mae: 3.3470 - val_loss: 29.7638 - val_mae: 3.7093\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 24.2063 - mae: 3.3945 - val_loss: 29.7503 - val_mae: 3.6377\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.8936 - mae: 3.3155 - val_loss: 29.3869 - val_mae: 3.6438\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.8023 - mae: 3.3052 - val_loss: 29.0973 - val_mae: 3.6456\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.5546 - mae: 3.2776 - val_loss: 28.8809 - val_mae: 3.6545\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.3967 - mae: 3.2898 - val_loss: 29.2730 - val_mae: 3.5528\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.5559 - mae: 3.2510 - val_loss: 28.4699 - val_mae: 3.5841\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.2820 - mae: 3.2946 - val_loss: 28.2036 - val_mae: 3.5924\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.4088 - mae: 3.2786 - val_loss: 28.0326 - val_mae: 3.5615\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.7685 - mae: 3.2497 - val_loss: 28.0791 - val_mae: 3.5058\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.7201 - mae: 3.2334 - val_loss: 27.5759 - val_mae: 3.5422\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.4027 - mae: 3.1952 - val_loss: 27.3668 - val_mae: 3.5148\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.2472 - mae: 3.2440 - val_loss: 27.7158 - val_mae: 3.4526\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.4075 - mae: 3.2230 - val_loss: 26.9216 - val_mae: 3.5429\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.9460 - mae: 3.1123 - val_loss: 27.2362 - val_mae: 3.7081\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.0096 - mae: 3.1910 - val_loss: 26.4867 - val_mae: 3.5236\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.5942 - mae: 3.1543 - val_loss: 26.4129 - val_mae: 3.4084\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.5682 - mae: 3.1352 - val_loss: 26.1629 - val_mae: 3.5216\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.4893 - mae: 3.1178 - val_loss: 26.0857 - val_mae: 3.3818\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.2577 - mae: 3.1860 - val_loss: 26.0868 - val_mae: 3.3496\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.2064 - mae: 3.1072 - val_loss: 26.0238 - val_mae: 3.3323\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.2047 - mae: 3.1047 - val_loss: 25.5449 - val_mae: 3.3352\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.9029 - mae: 3.0908 - val_loss: 25.3860 - val_mae: 3.3236\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.7226 - mae: 3.1103 - val_loss: 25.5527 - val_mae: 3.2946\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.8276 - mae: 3.0736 - val_loss: 24.9547 - val_mae: 3.3110\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.5426 - mae: 3.0392 - val_loss: 24.7540 - val_mae: 3.4172\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.2862 - mae: 3.0395 - val_loss: 24.5357 - val_mae: 3.3094\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.4056 - mae: 3.0807 - val_loss: 24.4940 - val_mae: 3.2630\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.1023 - mae: 3.0252 - val_loss: 24.2864 - val_mae: 3.4009\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0187 - mae: 3.0338 - val_loss: 24.1124 - val_mae: 3.3557\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0701 - mae: 3.0621 - val_loss: 24.2302 - val_mae: 3.2228\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.7226 - mae: 2.9964 - val_loss: 23.7009 - val_mae: 3.2698\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.5803 - mae: 3.0016 - val_loss: 23.6087 - val_mae: 3.2454\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.4310 - mae: 2.9568 - val_loss: 23.4224 - val_mae: 3.2730\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.4039 - mae: 2.9939 - val_loss: 23.3505 - val_mae: 3.2052\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.3162 - mae: 2.9727 - val_loss: 23.1537 - val_mae: 3.2570\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.1630 - mae: 2.9487 - val_loss: 23.0246 - val_mae: 3.2517\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.1479 - mae: 2.9646 - val_loss: 22.9864 - val_mae: 3.2936\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.9886 - mae: 2.9565 - val_loss: 22.7797 - val_mae: 3.1768\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.7140 - mae: 3.6904\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 10.6821 - mae: 10.6821 - val_loss: 7.0350 - val_mae: 7.0350\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4060 - mae: 6.4060 - val_loss: 6.8229 - val_mae: 6.8229\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2561 - mae: 6.2561 - val_loss: 6.7269 - val_mae: 6.7269\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1522 - mae: 6.1522 - val_loss: 6.5685 - val_mae: 6.5685\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.9754 - mae: 5.9754 - val_loss: 6.2748 - val_mae: 6.2748\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7314 - mae: 5.7314 - val_loss: 6.0023 - val_mae: 6.0023\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4818 - mae: 5.4818 - val_loss: 5.6408 - val_mae: 5.6408\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2372 - mae: 5.2372 - val_loss: 5.3801 - val_mae: 5.3801\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0553 - mae: 5.0553 - val_loss: 5.1689 - val_mae: 5.1689\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9377 - mae: 4.9377 - val_loss: 4.9045 - val_mae: 4.9045\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7751 - mae: 4.7751 - val_loss: 4.8162 - val_mae: 4.8162\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6753 - mae: 4.6753 - val_loss: 4.7630 - val_mae: 4.7630\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5810 - mae: 4.5810 - val_loss: 4.5581 - val_mae: 4.5581\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5585 - mae: 4.5585 - val_loss: 4.4898 - val_mae: 4.4898\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4479 - mae: 4.4479 - val_loss: 4.5032 - val_mae: 4.5032\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4324 - mae: 4.4324 - val_loss: 4.5009 - val_mae: 4.5009\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3696 - mae: 4.3696 - val_loss: 4.4328 - val_mae: 4.4328\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3395 - mae: 4.3395 - val_loss: 4.4543 - val_mae: 4.4543\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3146 - mae: 4.3146 - val_loss: 4.4149 - val_mae: 4.4149\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2775 - mae: 4.2775 - val_loss: 4.3768 - val_mae: 4.3768\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2613 - mae: 4.2613 - val_loss: 4.4261 - val_mae: 4.4261\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2126 - mae: 4.2126 - val_loss: 4.3520 - val_mae: 4.3520\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1691 - mae: 4.1691 - val_loss: 4.3320 - val_mae: 4.3320\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1247 - mae: 4.1247 - val_loss: 4.2995 - val_mae: 4.2995\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0948 - mae: 4.0948 - val_loss: 4.2914 - val_mae: 4.2914\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0562 - mae: 4.0562 - val_loss: 4.3240 - val_mae: 4.3240\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0185 - mae: 4.0185 - val_loss: 4.2817 - val_mae: 4.2817\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0127 - mae: 4.0127 - val_loss: 4.2387 - val_mae: 4.2387\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9693 - mae: 3.9693 - val_loss: 4.2178 - val_mae: 4.2178\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9230 - mae: 3.9230 - val_loss: 4.2035 - val_mae: 4.2035\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8831 - mae: 3.8831 - val_loss: 4.1980 - val_mae: 4.1980\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8463 - mae: 3.8463 - val_loss: 4.1543 - val_mae: 4.1543\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8527 - mae: 3.8527 - val_loss: 4.1989 - val_mae: 4.1989\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8148 - mae: 3.8148 - val_loss: 4.1244 - val_mae: 4.1244\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7922 - mae: 3.7922 - val_loss: 4.1299 - val_mae: 4.1299\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7514 - mae: 3.7514 - val_loss: 4.1301 - val_mae: 4.1301\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7436 - mae: 3.7436 - val_loss: 4.0990 - val_mae: 4.0990\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7102 - mae: 3.7102 - val_loss: 4.0618 - val_mae: 4.0618\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7211 - mae: 3.7211 - val_loss: 4.0729 - val_mae: 4.0729\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6684 - mae: 3.6684 - val_loss: 4.0497 - val_mae: 4.0497\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6481 - mae: 3.6481 - val_loss: 4.0384 - val_mae: 4.0384\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6321 - mae: 3.6321 - val_loss: 4.0293 - val_mae: 4.0293\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6184 - mae: 3.6184 - val_loss: 4.0224 - val_mae: 4.0224\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6228 - mae: 3.6228 - val_loss: 4.0159 - val_mae: 4.0159\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5915 - mae: 3.5915 - val_loss: 4.0930 - val_mae: 4.0930\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5845 - mae: 3.5845 - val_loss: 3.9957 - val_mae: 3.9957\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6125 - mae: 3.6125 - val_loss: 3.9827 - val_mae: 3.9827\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5833 - mae: 3.5833 - val_loss: 3.9807 - val_mae: 3.9807\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5565 - mae: 3.5565 - val_loss: 3.9660 - val_mae: 3.9660\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5871 - mae: 3.5871 - val_loss: 3.9525 - val_mae: 3.9525\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5483 - mae: 3.5483 - val_loss: 3.9436 - val_mae: 3.9436\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5410 - mae: 3.5410 - val_loss: 4.0074 - val_mae: 4.0074\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5285 - mae: 3.5285 - val_loss: 4.0139 - val_mae: 4.0139\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5031 - mae: 3.5031 - val_loss: 3.9339 - val_mae: 3.9339\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4899 - mae: 3.4899 - val_loss: 3.9210 - val_mae: 3.9210\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4863 - mae: 3.4863 - val_loss: 3.9705 - val_mae: 3.9705\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4822 - mae: 3.4822 - val_loss: 3.9255 - val_mae: 3.9255\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4685 - mae: 3.4685 - val_loss: 3.8880 - val_mae: 3.8880\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4536 - mae: 3.4536 - val_loss: 3.9355 - val_mae: 3.9355\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4658 - mae: 3.4658 - val_loss: 4.0836 - val_mae: 4.0836\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5411 - mae: 3.5411 - val_loss: 3.9057 - val_mae: 3.9057\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4495 - mae: 3.4495 - val_loss: 3.9312 - val_mae: 3.9312\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4397 - mae: 3.4397 - val_loss: 3.9029 - val_mae: 3.9029\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4607 - mae: 3.4607 - val_loss: 3.8216 - val_mae: 3.8216\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4273 - mae: 3.4273 - val_loss: 3.8414 - val_mae: 3.8414\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4277 - mae: 3.4277 - val_loss: 3.8105 - val_mae: 3.8105\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3932 - mae: 3.3932 - val_loss: 4.0117 - val_mae: 4.0117\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4233 - mae: 3.4233 - val_loss: 3.8713 - val_mae: 3.8713\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4231 - mae: 3.4231 - val_loss: 3.7898 - val_mae: 3.7898\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4541 - mae: 3.4541 - val_loss: 3.7964 - val_mae: 3.7964\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3752 - mae: 3.3752 - val_loss: 3.7954 - val_mae: 3.7954\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3739 - mae: 3.3739 - val_loss: 3.8696 - val_mae: 3.8696\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3674 - mae: 3.3674 - val_loss: 3.7370 - val_mae: 3.7370\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3653 - mae: 3.3653 - val_loss: 3.8603 - val_mae: 3.8603\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3918 - mae: 3.3918 - val_loss: 3.7155 - val_mae: 3.7155\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3679 - mae: 3.3679 - val_loss: 3.7506 - val_mae: 3.7506\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3452 - mae: 3.3452 - val_loss: 3.7074 - val_mae: 3.7074\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3595 - mae: 3.3595 - val_loss: 3.7198 - val_mae: 3.7198\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3405 - mae: 3.3405 - val_loss: 3.7677 - val_mae: 3.7677\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3540 - mae: 3.3540 - val_loss: 3.7844 - val_mae: 3.7844\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3460 - mae: 3.3460 - val_loss: 3.6884 - val_mae: 3.6884\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3206 - mae: 3.3206 - val_loss: 3.6744 - val_mae: 3.6744\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3254 - mae: 3.3254 - val_loss: 3.6453 - val_mae: 3.6453\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3436 - mae: 3.3436 - val_loss: 3.6483 - val_mae: 3.6483\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3152 - mae: 3.3152 - val_loss: 3.6342 - val_mae: 3.6342\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2759 - mae: 3.2759 - val_loss: 3.6968 - val_mae: 3.6968\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3239 - mae: 3.3239 - val_loss: 3.6696 - val_mae: 3.6696\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3109 - mae: 3.3109 - val_loss: 3.5993 - val_mae: 3.5993\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2714 - mae: 3.2714 - val_loss: 3.5948 - val_mae: 3.5948\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2838 - mae: 3.2838 - val_loss: 3.6041 - val_mae: 3.6041\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2627 - mae: 3.2627 - val_loss: 3.5925 - val_mae: 3.5925\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2493 - mae: 3.2493 - val_loss: 3.5684 - val_mae: 3.5684\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2513 - mae: 3.2513 - val_loss: 3.5654 - val_mae: 3.5654\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2565 - mae: 3.2565 - val_loss: 3.6019 - val_mae: 3.6019\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2449 - mae: 3.2449 - val_loss: 3.6932 - val_mae: 3.6932\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2428 - mae: 3.2428 - val_loss: 3.5524 - val_mae: 3.5524\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2100 - mae: 3.2100 - val_loss: 3.5295 - val_mae: 3.5295\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2439 - mae: 3.2439 - val_loss: 3.5185 - val_mae: 3.5185\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2042 - mae: 3.2042 - val_loss: 3.5606 - val_mae: 3.5606\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2141 - mae: 3.2141 - val_loss: 3.5101 - val_mae: 3.5101\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.4503 - mae: 4.4503\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 171.7128 - mae: 10.1028 - val_loss: 94.6457 - val_mae: 6.8675\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.4258 - mae: 6.2815 - val_loss: 87.3567 - val_mae: 6.8694\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 77.9775 - mae: 6.2556 - val_loss: 85.0719 - val_mae: 6.8796\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 76.3908 - mae: 6.2366 - val_loss: 82.9986 - val_mae: 6.8142\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 74.7076 - mae: 6.1222 - val_loss: 80.3166 - val_mae: 6.6613\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 72.0986 - mae: 6.0226 - val_loss: 77.0934 - val_mae: 6.4792\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 69.1133 - mae: 5.8345 - val_loss: 73.3937 - val_mae: 6.2280\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 66.0797 - mae: 5.6166 - val_loss: 70.0517 - val_mae: 5.9896\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 63.2740 - mae: 5.4274 - val_loss: 66.9911 - val_mae: 5.8146\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 60.7507 - mae: 5.2876 - val_loss: 64.2037 - val_mae: 5.6223\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 58.4514 - mae: 5.1988 - val_loss: 61.9245 - val_mae: 5.4850\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 56.4742 - mae: 5.0770 - val_loss: 59.9718 - val_mae: 5.3238\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.8706 - mae: 5.0075 - val_loss: 58.3116 - val_mae: 5.1889\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.3989 - mae: 4.8507 - val_loss: 56.7933 - val_mae: 5.2792\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 51.9851 - mae: 4.9874 - val_loss: 55.5037 - val_mae: 4.9730\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.9314 - mae: 4.7440 - val_loss: 54.2073 - val_mae: 5.0849\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.7202 - mae: 4.7862 - val_loss: 53.1216 - val_mae: 4.9213\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.8183 - mae: 4.7234 - val_loss: 52.2377 - val_mae: 4.9924\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.6661 - mae: 4.6640 - val_loss: 51.2364 - val_mae: 4.7797\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.8817 - mae: 4.6393 - val_loss: 50.4017 - val_mae: 4.8160\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.9487 - mae: 4.4966 - val_loss: 49.6457 - val_mae: 4.8296\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 45.0993 - mae: 4.5851 - val_loss: 48.9045 - val_mae: 4.5096\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.2076 - mae: 4.3903 - val_loss: 47.9915 - val_mae: 4.5518\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.2090 - mae: 4.4577 - val_loss: 47.2292 - val_mae: 4.4430\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 42.3352 - mae: 4.3613 - val_loss: 46.4528 - val_mae: 4.3683\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 41.3131 - mae: 4.2097 - val_loss: 45.6020 - val_mae: 4.5079\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.4523 - mae: 4.3615 - val_loss: 44.9094 - val_mae: 4.2605\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.6367 - mae: 4.1500 - val_loss: 43.9465 - val_mae: 4.3822\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.8109 - mae: 4.1348 - val_loss: 43.1440 - val_mae: 4.2332\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.6416 - mae: 4.1283 - val_loss: 42.3592 - val_mae: 4.1508\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.7808 - mae: 4.0211 - val_loss: 41.4969 - val_mae: 4.2628\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.7495 - mae: 3.9546 - val_loss: 41.0122 - val_mae: 4.0386\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 35.2308 - mae: 3.9372 - val_loss: 40.2542 - val_mae: 4.3493\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.1230 - mae: 3.8452 - val_loss: 39.3189 - val_mae: 4.0984\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.4514 - mae: 3.8388 - val_loss: 38.7250 - val_mae: 4.0365\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.7232 - mae: 3.7531 - val_loss: 38.1795 - val_mae: 4.1414\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 32.0291 - mae: 3.7481 - val_loss: 37.5589 - val_mae: 4.0721\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 31.4016 - mae: 3.6804 - val_loss: 37.0281 - val_mae: 4.0270\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.9103 - mae: 3.7183 - val_loss: 36.5862 - val_mae: 3.9495\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.5811 - mae: 3.7223 - val_loss: 36.5035 - val_mae: 3.8700\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.0054 - mae: 3.6543 - val_loss: 36.0528 - val_mae: 3.8666\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.7352 - mae: 3.6263 - val_loss: 35.3879 - val_mae: 3.9180\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.1116 - mae: 3.5862 - val_loss: 35.0170 - val_mae: 3.9523\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.8121 - mae: 3.5548 - val_loss: 34.6815 - val_mae: 3.9298\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.8385 - mae: 3.6420 - val_loss: 34.3666 - val_mae: 3.9046\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.1634 - mae: 3.5546 - val_loss: 34.0837 - val_mae: 3.9391\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.9120 - mae: 3.5435 - val_loss: 33.8931 - val_mae: 3.8416\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.4289 - mae: 3.4853 - val_loss: 33.5688 - val_mae: 3.9630\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.2874 - mae: 3.5336 - val_loss: 33.2439 - val_mae: 3.8731\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.3587 - mae: 3.5129 - val_loss: 33.0354 - val_mae: 3.9434\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.7287 - mae: 3.4590 - val_loss: 32.8360 - val_mae: 3.8168\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.6756 - mae: 3.4674 - val_loss: 32.4919 - val_mae: 3.8113\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.5498 - mae: 3.4645 - val_loss: 33.0022 - val_mae: 4.1041\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.2635 - mae: 3.4861 - val_loss: 31.9408 - val_mae: 3.8420\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.7764 - mae: 3.4146 - val_loss: 31.9613 - val_mae: 3.7520\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.5601 - mae: 3.3979 - val_loss: 31.4347 - val_mae: 3.8136\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.4315 - mae: 3.4046 - val_loss: 31.2001 - val_mae: 3.7818\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.1074 - mae: 3.3793 - val_loss: 31.0899 - val_mae: 3.8670\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.1857 - mae: 3.4127 - val_loss: 30.7500 - val_mae: 3.8129\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.8956 - mae: 3.4111 - val_loss: 30.7501 - val_mae: 3.6889\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.6216 - mae: 3.3239 - val_loss: 30.2109 - val_mae: 3.7144\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.5835 - mae: 3.3712 - val_loss: 30.0054 - val_mae: 3.7442\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.4659 - mae: 3.3469 - val_loss: 30.1328 - val_mae: 3.6242\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.9783 - mae: 3.3093 - val_loss: 29.4928 - val_mae: 3.7102\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.9182 - mae: 3.2922 - val_loss: 29.2652 - val_mae: 3.6866\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.6462 - mae: 3.2910 - val_loss: 29.0125 - val_mae: 3.6243\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.3658 - mae: 3.2491 - val_loss: 28.8381 - val_mae: 3.6991\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.3976 - mae: 3.2880 - val_loss: 28.5476 - val_mae: 3.6091\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.1103 - mae: 3.2333 - val_loss: 28.3296 - val_mae: 3.6158\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.8737 - mae: 3.2523 - val_loss: 28.2152 - val_mae: 3.5509\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.7898 - mae: 3.2314 - val_loss: 28.1824 - val_mae: 3.4975\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.7113 - mae: 3.2312 - val_loss: 27.8118 - val_mae: 3.4858\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.3363 - mae: 3.1769 - val_loss: 27.4208 - val_mae: 3.5951\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.3557 - mae: 3.2180 - val_loss: 27.1453 - val_mae: 3.5158\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.1165 - mae: 3.1966 - val_loss: 26.9648 - val_mae: 3.5558\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.9558 - mae: 3.1619 - val_loss: 26.7110 - val_mae: 3.4896\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8108 - mae: 3.1692 - val_loss: 26.5651 - val_mae: 3.4542\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.5671 - mae: 3.1412 - val_loss: 26.3929 - val_mae: 3.4081\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.5421 - mae: 3.1588 - val_loss: 26.1347 - val_mae: 3.4958\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.3893 - mae: 3.1355 - val_loss: 25.9981 - val_mae: 3.3826\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.2223 - mae: 3.1022 - val_loss: 25.7553 - val_mae: 3.3918\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.0616 - mae: 3.0872 - val_loss: 25.6487 - val_mae: 3.4985\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.0802 - mae: 3.1259 - val_loss: 25.3131 - val_mae: 3.3758\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.7152 - mae: 3.1012 - val_loss: 25.7781 - val_mae: 3.3049\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.6874 - mae: 3.0393 - val_loss: 24.9630 - val_mae: 3.3513\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.3825 - mae: 3.0801 - val_loss: 24.9344 - val_mae: 3.3003\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 20.4270 - mae: 3.0745 - val_loss: 24.6730 - val_mae: 3.3141\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.8546 - mae: 3.1157 - val_loss: 25.2665 - val_mae: 3.2576\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.3240 - mae: 3.0120 - val_loss: 24.2632 - val_mae: 3.3318\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.9556 - mae: 3.0412 - val_loss: 24.2181 - val_mae: 3.2601\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0040 - mae: 3.0094 - val_loss: 23.9793 - val_mae: 3.2640\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 20.0259 - mae: 3.0212 - val_loss: 23.8080 - val_mae: 3.3309\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.7717 - mae: 3.0267 - val_loss: 23.6259 - val_mae: 3.2913\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.5958 - mae: 2.9779 - val_loss: 23.5997 - val_mae: 3.2183\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.3838 - mae: 2.9724 - val_loss: 23.4049 - val_mae: 3.2048\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.2161 - mae: 2.9456 - val_loss: 23.1516 - val_mae: 3.2596\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.2115 - mae: 2.9609 - val_loss: 23.1023 - val_mae: 3.2920\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.0626 - mae: 2.9508 - val_loss: 23.0883 - val_mae: 3.1632\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.9586 - mae: 2.9302 - val_loss: 22.7787 - val_mae: 3.2389\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.9461 - mae: 2.9444 - val_loss: 22.8393 - val_mae: 3.1391\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.1155 - mae: 3.8301\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 10.1766 - mae: 10.1766 - val_loss: 6.8856 - val_mae: 6.8856\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3152 - mae: 6.3152 - val_loss: 6.8303 - val_mae: 6.8303\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2237 - mae: 6.2237 - val_loss: 6.7161 - val_mae: 6.7161\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0993 - mae: 6.0993 - val_loss: 6.4728 - val_mae: 6.4728\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8869 - mae: 5.8869 - val_loss: 6.1464 - val_mae: 6.1464\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6317 - mae: 5.6317 - val_loss: 5.8384 - val_mae: 5.8384\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3790 - mae: 5.3790 - val_loss: 5.5664 - val_mae: 5.5664\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1732 - mae: 5.1732 - val_loss: 5.2950 - val_mae: 5.2950\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9943 - mae: 4.9943 - val_loss: 5.0259 - val_mae: 5.0259\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8846 - mae: 4.8846 - val_loss: 4.9162 - val_mae: 4.9162\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7415 - mae: 4.7415 - val_loss: 4.8149 - val_mae: 4.8149\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6530 - mae: 4.6530 - val_loss: 4.7096 - val_mae: 4.7096\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5496 - mae: 4.5496 - val_loss: 4.5124 - val_mae: 4.5124\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4939 - mae: 4.4939 - val_loss: 4.4828 - val_mae: 4.4828\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4335 - mae: 4.4335 - val_loss: 4.4452 - val_mae: 4.4452\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4051 - mae: 4.4051 - val_loss: 4.4236 - val_mae: 4.4236\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3799 - mae: 4.3799 - val_loss: 4.4312 - val_mae: 4.4312\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3171 - mae: 4.3171 - val_loss: 4.4002 - val_mae: 4.4002\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2776 - mae: 4.2776 - val_loss: 4.4448 - val_mae: 4.4448\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2617 - mae: 4.2617 - val_loss: 4.3677 - val_mae: 4.3677\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2326 - mae: 4.2326 - val_loss: 4.4197 - val_mae: 4.4197\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1743 - mae: 4.1743 - val_loss: 4.3339 - val_mae: 4.3339\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1308 - mae: 4.1308 - val_loss: 4.3489 - val_mae: 4.3489\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1038 - mae: 4.1038 - val_loss: 4.2965 - val_mae: 4.2965\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0742 - mae: 4.0742 - val_loss: 4.2942 - val_mae: 4.2942\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0294 - mae: 4.0294 - val_loss: 4.2714 - val_mae: 4.2714\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9639 - mae: 3.9639 - val_loss: 4.3509 - val_mae: 4.3509\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9795 - mae: 3.9795 - val_loss: 4.2504 - val_mae: 4.2504\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9343 - mae: 3.9343 - val_loss: 4.2142 - val_mae: 4.2142\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9005 - mae: 3.9005 - val_loss: 4.2136 - val_mae: 4.2136\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8687 - mae: 3.8687 - val_loss: 4.1679 - val_mae: 4.1679\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8434 - mae: 3.8434 - val_loss: 4.2279 - val_mae: 4.2279\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7905 - mae: 3.7905 - val_loss: 4.1397 - val_mae: 4.1397\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8011 - mae: 3.8011 - val_loss: 4.1913 - val_mae: 4.1913\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7813 - mae: 3.7813 - val_loss: 4.1137 - val_mae: 4.1137\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7176 - mae: 3.7176 - val_loss: 4.0909 - val_mae: 4.0909\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6981 - mae: 3.6981 - val_loss: 4.0964 - val_mae: 4.0964\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7053 - mae: 3.7053 - val_loss: 4.0787 - val_mae: 4.0787\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6674 - mae: 3.6674 - val_loss: 4.0810 - val_mae: 4.0810\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6687 - mae: 3.6687 - val_loss: 4.0615 - val_mae: 4.0615\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6415 - mae: 3.6415 - val_loss: 4.0581 - val_mae: 4.0581\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6346 - mae: 3.6346 - val_loss: 4.0419 - val_mae: 4.0419\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5940 - mae: 3.5940 - val_loss: 4.0482 - val_mae: 4.0482\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6035 - mae: 3.6035 - val_loss: 4.0310 - val_mae: 4.0310\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5915 - mae: 3.5915 - val_loss: 4.0667 - val_mae: 4.0667\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5743 - mae: 3.5743 - val_loss: 4.0433 - val_mae: 4.0433\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5623 - mae: 3.5623 - val_loss: 4.0367 - val_mae: 4.0367\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5770 - mae: 3.5770 - val_loss: 4.0118 - val_mae: 4.0118\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5613 - mae: 3.5613 - val_loss: 3.9693 - val_mae: 3.9693\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5602 - mae: 3.5602 - val_loss: 4.0650 - val_mae: 4.0650\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5130 - mae: 3.5130 - val_loss: 4.0100 - val_mae: 4.0100\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5383 - mae: 3.5383 - val_loss: 3.9959 - val_mae: 3.9959\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5083 - mae: 3.5083 - val_loss: 3.9948 - val_mae: 3.9948\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5127 - mae: 3.5127 - val_loss: 3.9568 - val_mae: 3.9568\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4859 - mae: 3.4859 - val_loss: 3.9845 - val_mae: 3.9845\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4755 - mae: 3.4755 - val_loss: 3.9457 - val_mae: 3.9457\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4801 - mae: 3.4801 - val_loss: 3.9118 - val_mae: 3.9118\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4669 - mae: 3.4669 - val_loss: 3.9801 - val_mae: 3.9801\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4612 - mae: 3.4612 - val_loss: 3.9180 - val_mae: 3.9180\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4823 - mae: 3.4823 - val_loss: 3.8577 - val_mae: 3.8577\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4962 - mae: 3.4962 - val_loss: 3.8539 - val_mae: 3.8539\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4472 - mae: 3.4472 - val_loss: 3.9075 - val_mae: 3.9075\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4413 - mae: 3.4413 - val_loss: 3.9370 - val_mae: 3.9370\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4236 - mae: 3.4236 - val_loss: 3.8665 - val_mae: 3.8665\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4151 - mae: 3.4151 - val_loss: 3.8471 - val_mae: 3.8471\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4185 - mae: 3.4185 - val_loss: 3.8706 - val_mae: 3.8706\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4215 - mae: 3.4215 - val_loss: 3.8021 - val_mae: 3.8021\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4134 - mae: 3.4134 - val_loss: 3.8400 - val_mae: 3.8400\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3834 - mae: 3.3834 - val_loss: 3.7688 - val_mae: 3.7688\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4111 - mae: 3.4111 - val_loss: 3.8780 - val_mae: 3.8780\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3780 - mae: 3.3780 - val_loss: 3.7875 - val_mae: 3.7875\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3882 - mae: 3.3882 - val_loss: 3.7440 - val_mae: 3.7440\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3727 - mae: 3.3727 - val_loss: 3.8297 - val_mae: 3.8297\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3667 - mae: 3.3667 - val_loss: 3.7282 - val_mae: 3.7282\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3944 - mae: 3.3944 - val_loss: 3.7146 - val_mae: 3.7146\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3571 - mae: 3.3571 - val_loss: 3.7154 - val_mae: 3.7154\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3716 - mae: 3.3716 - val_loss: 3.8057 - val_mae: 3.8057\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3507 - mae: 3.3507 - val_loss: 3.7582 - val_mae: 3.7582\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3068 - mae: 3.3068 - val_loss: 3.7876 - val_mae: 3.7876\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3677 - mae: 3.3677 - val_loss: 3.6780 - val_mae: 3.6780\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3246 - mae: 3.3246 - val_loss: 3.6889 - val_mae: 3.6889\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3125 - mae: 3.3125 - val_loss: 3.6505 - val_mae: 3.6505\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3458 - mae: 3.3458 - val_loss: 3.6356 - val_mae: 3.6356\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3301 - mae: 3.3301 - val_loss: 3.6288 - val_mae: 3.6288\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2943 - mae: 3.2943 - val_loss: 3.6097 - val_mae: 3.6097\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3137 - mae: 3.3137 - val_loss: 3.6117 - val_mae: 3.6117\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2948 - mae: 3.2948 - val_loss: 3.6372 - val_mae: 3.6372\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2795 - mae: 3.2795 - val_loss: 3.6988 - val_mae: 3.6988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2615 - mae: 3.2615 - val_loss: 3.6865 - val_mae: 3.6865\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2790 - mae: 3.2790 - val_loss: 3.5827 - val_mae: 3.5827\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2708 - mae: 3.2708 - val_loss: 3.5608 - val_mae: 3.5608\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2542 - mae: 3.2542 - val_loss: 3.6095 - val_mae: 3.6095\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2194 - mae: 3.2194 - val_loss: 3.5344 - val_mae: 3.5344\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2324 - mae: 3.2324 - val_loss: 3.6436 - val_mae: 3.6436\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2504 - mae: 3.2504 - val_loss: 3.5244 - val_mae: 3.5244\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2335 - mae: 3.2335 - val_loss: 3.5085 - val_mae: 3.5085\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2010 - mae: 3.2010 - val_loss: 3.5296 - val_mae: 3.5296\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2005 - mae: 3.2005 - val_loss: 3.4891 - val_mae: 3.4891\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2164 - mae: 3.2164 - val_loss: 3.4760 - val_mae: 3.4760\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1857 - mae: 3.1857 - val_loss: 3.4701 - val_mae: 3.4701\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.3915 - mae: 4.3915\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 400.5622 - mae: 17.6769 - val_loss: 166.8318 - val_mae: 10.5021\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.6448 - mae: 6.8241 - val_loss: 56.2841 - val_mae: 5.4945\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.4071 - mae: 4.6319 - val_loss: 36.2575 - val_mae: 4.2543\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.4837 - mae: 3.9334 - val_loss: 29.0248 - val_mae: 3.8681\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 25.0144 - mae: 3.5075 - val_loss: 25.1228 - val_mae: 3.4669\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.4227 - mae: 3.3016 - val_loss: 23.8572 - val_mae: 3.5223\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.9335 - mae: 3.1895 - val_loss: 22.1319 - val_mae: 3.3001\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.7838 - mae: 3.0832 - val_loss: 21.0195 - val_mae: 3.2392\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 18.7256 - mae: 2.9887 - val_loss: 20.2503 - val_mae: 3.1509\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.8175 - mae: 2.8953 - val_loss: 19.8311 - val_mae: 3.1325\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.3020 - mae: 2.8749 - val_loss: 19.3135 - val_mae: 3.1326\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7286 - mae: 2.7781 - val_loss: 18.8858 - val_mae: 3.1046\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.9581 - mae: 2.7410 - val_loss: 18.4677 - val_mae: 2.9835\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.5613 - mae: 2.7421 - val_loss: 17.9312 - val_mae: 2.9769\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9550 - mae: 2.6369 - val_loss: 17.7856 - val_mae: 2.9541\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.4975 - mae: 2.6346 - val_loss: 17.4873 - val_mae: 2.9138\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1686 - mae: 2.6138 - val_loss: 17.0673 - val_mae: 2.8890\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.6237 - mae: 2.5603 - val_loss: 16.7643 - val_mae: 2.8544\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.4266 - mae: 2.5432 - val_loss: 16.5902 - val_mae: 2.8196\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1442 - mae: 2.5227 - val_loss: 16.2903 - val_mae: 2.8354\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6644 - mae: 2.5082 - val_loss: 16.2062 - val_mae: 2.7865\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7942 - mae: 2.4792 - val_loss: 15.9736 - val_mae: 2.7720\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2791 - mae: 2.4659 - val_loss: 15.8977 - val_mae: 2.7721\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.0187 - mae: 2.4437 - val_loss: 15.8401 - val_mae: 2.7112\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8584 - mae: 2.4439 - val_loss: 15.6174 - val_mae: 2.7127\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5441 - mae: 2.3936 - val_loss: 15.5186 - val_mae: 2.6836\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3611 - mae: 2.3870 - val_loss: 15.2740 - val_mae: 2.6689\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1960 - mae: 2.3780 - val_loss: 15.3356 - val_mae: 2.6656\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.1968 - mae: 2.3523 - val_loss: 15.1264 - val_mae: 2.6641\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9427 - mae: 2.3549 - val_loss: 15.1863 - val_mae: 2.6622\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8303 - mae: 2.3147 - val_loss: 14.8913 - val_mae: 2.6140\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.9024 - mae: 2.3827 - val_loss: 14.8127 - val_mae: 2.6271\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3427 - mae: 2.2862 - val_loss: 14.7605 - val_mae: 2.6218\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2313 - mae: 2.2844 - val_loss: 14.6085 - val_mae: 2.6101\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0384 - mae: 2.2782 - val_loss: 14.8465 - val_mae: 2.6286\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9374 - mae: 2.2478 - val_loss: 14.6082 - val_mae: 2.5952\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8195 - mae: 2.2383 - val_loss: 14.3478 - val_mae: 2.5758\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7447 - mae: 2.2308 - val_loss: 14.3882 - val_mae: 2.5743\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6239 - mae: 2.2418 - val_loss: 14.3809 - val_mae: 2.5738\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4280 - mae: 2.1947 - val_loss: 14.4823 - val_mae: 2.5754\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4456 - mae: 2.2297 - val_loss: 14.3312 - val_mae: 2.5902\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1763 - mae: 2.1690 - val_loss: 14.2383 - val_mae: 2.5640\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0646 - mae: 2.1713 - val_loss: 14.4852 - val_mae: 2.5926\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0054 - mae: 2.1592 - val_loss: 14.2767 - val_mae: 2.5560\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7868 - mae: 2.1327 - val_loss: 14.0874 - val_mae: 2.5469\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9243 - mae: 2.1532 - val_loss: 14.0673 - val_mae: 2.5589\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6043 - mae: 2.1282 - val_loss: 13.9830 - val_mae: 2.5538\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5352 - mae: 2.1175 - val_loss: 13.9512 - val_mae: 2.5347\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4204 - mae: 2.1087 - val_loss: 14.2411 - val_mae: 2.5603\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4467 - mae: 2.0962 - val_loss: 13.9083 - val_mae: 2.5267\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2404 - mae: 2.0837 - val_loss: 14.3524 - val_mae: 2.5723\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2774 - mae: 2.0854 - val_loss: 14.1403 - val_mae: 2.5582\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0573 - mae: 2.0667 - val_loss: 13.7875 - val_mae: 2.5039\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9460 - mae: 2.0469 - val_loss: 13.7902 - val_mae: 2.4993\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7940 - mae: 2.0324 - val_loss: 13.8585 - val_mae: 2.5203\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7111 - mae: 2.0154 - val_loss: 13.8657 - val_mae: 2.5254\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6587 - mae: 2.0164 - val_loss: 13.7847 - val_mae: 2.4917\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4957 - mae: 1.9954 - val_loss: 14.0636 - val_mae: 2.5426\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4854 - mae: 1.9865 - val_loss: 13.7375 - val_mae: 2.4941\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3193 - mae: 1.9770 - val_loss: 13.6876 - val_mae: 2.4769\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2858 - mae: 1.9769 - val_loss: 13.8297 - val_mae: 2.5217\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2220 - mae: 1.9659 - val_loss: 13.5583 - val_mae: 2.4687\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2243 - mae: 1.9841 - val_loss: 13.7388 - val_mae: 2.5189\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 1.9577 - val_loss: 13.5600 - val_mae: 2.5043\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0087 - mae: 1.9423 - val_loss: 13.7557 - val_mae: 2.5165\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9251 - mae: 1.9334 - val_loss: 13.4801 - val_mae: 2.4921\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8791 - mae: 1.9303 - val_loss: 13.5353 - val_mae: 2.4956\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8714 - mae: 1.9194 - val_loss: 13.6112 - val_mae: 2.4997\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7136 - mae: 1.9246 - val_loss: 13.6008 - val_mae: 2.4674\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5799 - mae: 1.8986 - val_loss: 13.5944 - val_mae: 2.4996\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5464 - mae: 1.8673 - val_loss: 13.5012 - val_mae: 2.4732\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4258 - mae: 1.8581 - val_loss: 13.4674 - val_mae: 2.4659\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3785 - mae: 1.8562 - val_loss: 13.6305 - val_mae: 2.5026\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2528 - mae: 1.8382 - val_loss: 13.5142 - val_mae: 2.4812\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2022 - mae: 1.8282 - val_loss: 13.4654 - val_mae: 2.4811\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2273 - mae: 1.8399 - val_loss: 13.6262 - val_mae: 2.4798\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0853 - mae: 1.8175 - val_loss: 13.4334 - val_mae: 2.4839\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9649 - mae: 1.7945 - val_loss: 13.4442 - val_mae: 2.4544\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9756 - mae: 1.8114 - val_loss: 13.5452 - val_mae: 2.4769\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9468 - mae: 1.8036 - val_loss: 13.3541 - val_mae: 2.4620\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7846 - mae: 1.7738 - val_loss: 13.4638 - val_mae: 2.4768\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8781 - mae: 1.7927 - val_loss: 13.5483 - val_mae: 2.4763\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7563 - mae: 1.7763 - val_loss: 13.2418 - val_mae: 2.4511\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6771 - mae: 1.7631 - val_loss: 13.2765 - val_mae: 2.4598\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6143 - mae: 1.7604 - val_loss: 13.3632 - val_mae: 2.4646\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5126 - mae: 1.7399 - val_loss: 13.5350 - val_mae: 2.4857\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4434 - mae: 1.7260 - val_loss: 13.5235 - val_mae: 2.5019\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4758 - mae: 1.7375 - val_loss: 13.5138 - val_mae: 2.4812\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4903 - mae: 1.7382 - val_loss: 13.3861 - val_mae: 2.4660\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3868 - mae: 1.6924 - val_loss: 13.6870 - val_mae: 2.4801\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3238 - mae: 1.7223 - val_loss: 13.5618 - val_mae: 2.4999\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3089 - mae: 1.7085 - val_loss: 13.8300 - val_mae: 2.5169\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2152 - mae: 1.6883 - val_loss: 13.3331 - val_mae: 2.4641\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0949 - mae: 1.6711 - val_loss: 13.1844 - val_mae: 2.4515\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0588 - mae: 1.6729 - val_loss: 13.5218 - val_mae: 2.4818\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9806 - mae: 1.6484 - val_loss: 13.4717 - val_mae: 2.4681\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9054 - mae: 1.6444 - val_loss: 13.2998 - val_mae: 2.4561\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8595 - mae: 1.6441 - val_loss: 13.5923 - val_mae: 2.4794\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8633 - mae: 1.6333 - val_loss: 13.4261 - val_mae: 2.4726\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7778 - mae: 1.6496 - val_loss: 13.7953 - val_mae: 2.5091\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.8481 - mae: 4.0949\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.4322 - mae: 18.4322 - val_loss: 10.3762 - val_mae: 10.3762\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2386 - mae: 6.2386 - val_loss: 4.6785 - val_mae: 4.6785\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2909 - mae: 4.2909 - val_loss: 3.6554 - val_mae: 3.6554\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7126 - mae: 3.7126 - val_loss: 3.4008 - val_mae: 3.4008\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.3973 - mae: 3.3973 - val_loss: 3.2641 - val_mae: 3.2641\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2225 - mae: 3.2225 - val_loss: 3.2259 - val_mae: 3.2259\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0286 - mae: 3.0286 - val_loss: 2.9857 - val_mae: 2.9857\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9007 - mae: 2.9007 - val_loss: 3.0384 - val_mae: 3.0384\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8173 - mae: 2.8173 - val_loss: 2.9673 - val_mae: 2.9673\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7436 - mae: 2.7436 - val_loss: 2.8926 - val_mae: 2.8926\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6999 - mae: 2.6999 - val_loss: 2.9500 - val_mae: 2.9500\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6780 - mae: 2.6780 - val_loss: 2.9160 - val_mae: 2.9160\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5994 - mae: 2.5994 - val_loss: 2.8914 - val_mae: 2.8914\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6006 - mae: 2.6006 - val_loss: 2.8464 - val_mae: 2.8464\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5346 - mae: 2.5346 - val_loss: 2.8579 - val_mae: 2.8579\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4931 - mae: 2.4931 - val_loss: 2.8129 - val_mae: 2.8129\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5011 - mae: 2.5011 - val_loss: 2.7502 - val_mae: 2.7502\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4646 - mae: 2.4646 - val_loss: 2.7054 - val_mae: 2.7054\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4294 - mae: 2.4294 - val_loss: 2.6977 - val_mae: 2.6977\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4053 - mae: 2.4053 - val_loss: 2.6840 - val_mae: 2.6840\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4053 - mae: 2.4053 - val_loss: 2.6747 - val_mae: 2.6747\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3600 - mae: 2.3600 - val_loss: 2.6698 - val_mae: 2.6698\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3490 - mae: 2.3490 - val_loss: 2.6389 - val_mae: 2.6389\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3388 - mae: 2.3388 - val_loss: 2.6242 - val_mae: 2.6242\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2895 - mae: 2.2895 - val_loss: 2.6151 - val_mae: 2.6151\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2979 - mae: 2.2979 - val_loss: 2.5838 - val_mae: 2.5838\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2756 - mae: 2.2756 - val_loss: 2.5889 - val_mae: 2.5889\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2495 - mae: 2.2495 - val_loss: 2.5722 - val_mae: 2.5722\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2211 - mae: 2.2211 - val_loss: 2.5923 - val_mae: 2.5923\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2174 - mae: 2.2174 - val_loss: 2.6018 - val_mae: 2.6018\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1961 - mae: 2.1961 - val_loss: 2.5488 - val_mae: 2.5488\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2132 - mae: 2.2132 - val_loss: 2.5548 - val_mae: 2.5548\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1911 - mae: 2.1911 - val_loss: 2.5838 - val_mae: 2.5838\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1777 - mae: 2.1777 - val_loss: 2.5364 - val_mae: 2.5364\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1643 - mae: 2.1643 - val_loss: 2.5570 - val_mae: 2.5570\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1405 - mae: 2.1405 - val_loss: 2.5260 - val_mae: 2.5260\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1514 - mae: 2.1514 - val_loss: 2.5175 - val_mae: 2.5175\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1169 - mae: 2.1169 - val_loss: 2.5056 - val_mae: 2.5056\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1127 - mae: 2.1127 - val_loss: 2.5112 - val_mae: 2.5112\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1300 - mae: 2.1300 - val_loss: 2.5373 - val_mae: 2.5373\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1000 - mae: 2.1000 - val_loss: 2.5531 - val_mae: 2.5531\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0854 - mae: 2.0854 - val_loss: 2.4804 - val_mae: 2.4804\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0734 - mae: 2.0734 - val_loss: 2.4972 - val_mae: 2.4972\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0676 - mae: 2.0676 - val_loss: 2.5051 - val_mae: 2.5051\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0564 - mae: 2.0564 - val_loss: 2.5120 - val_mae: 2.5120\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0491 - mae: 2.0491 - val_loss: 2.5178 - val_mae: 2.5178\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0403 - mae: 2.0403 - val_loss: 2.4969 - val_mae: 2.4969\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0224 - mae: 2.0224 - val_loss: 2.4970 - val_mae: 2.4970\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0257 - mae: 2.0257 - val_loss: 2.4893 - val_mae: 2.4893\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0153 - mae: 2.0153 - val_loss: 2.5045 - val_mae: 2.5045\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0047 - mae: 2.0047 - val_loss: 2.4733 - val_mae: 2.4733\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0220 - mae: 2.0220 - val_loss: 2.4662 - val_mae: 2.4662\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9938 - mae: 1.9938 - val_loss: 2.4569 - val_mae: 2.4569\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0189 - mae: 2.0189 - val_loss: 2.4824 - val_mae: 2.4824\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9914 - mae: 1.9914 - val_loss: 2.4780 - val_mae: 2.4780\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9610 - mae: 1.9610 - val_loss: 2.4741 - val_mae: 2.4741\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9931 - mae: 1.9931 - val_loss: 2.5223 - val_mae: 2.5223\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9709 - mae: 1.9709 - val_loss: 2.5192 - val_mae: 2.5192\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9515 - mae: 1.9515 - val_loss: 2.4649 - val_mae: 2.4649\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9482 - mae: 1.9482 - val_loss: 2.4624 - val_mae: 2.4624\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9482 - mae: 1.9482 - val_loss: 2.4666 - val_mae: 2.4666\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9491 - mae: 1.9491 - val_loss: 2.5061 - val_mae: 2.5061\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9149 - mae: 1.9149 - val_loss: 2.4738 - val_mae: 2.4738\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9026 - mae: 1.9026 - val_loss: 2.4924 - val_mae: 2.4924\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9250 - mae: 1.9250 - val_loss: 2.4869 - val_mae: 2.4869\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9083 - mae: 1.9083 - val_loss: 2.4875 - val_mae: 2.4875\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8899 - mae: 1.8899 - val_loss: 2.4736 - val_mae: 2.4736\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8889 - mae: 1.8889 - val_loss: 2.4550 - val_mae: 2.4550\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8806 - mae: 1.8806 - val_loss: 2.4565 - val_mae: 2.4565\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8934 - mae: 1.8934 - val_loss: 2.4406 - val_mae: 2.4406\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8873 - mae: 1.8873 - val_loss: 2.4794 - val_mae: 2.4794\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8667 - mae: 1.8667 - val_loss: 2.4705 - val_mae: 2.4705\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8641 - mae: 1.8641 - val_loss: 2.4627 - val_mae: 2.4627\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8440 - mae: 1.8440 - val_loss: 2.4538 - val_mae: 2.4538\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8563 - mae: 1.8563 - val_loss: 2.4977 - val_mae: 2.4977\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8418 - mae: 1.8418 - val_loss: 2.4787 - val_mae: 2.4787\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8401 - mae: 1.8401 - val_loss: 2.4719 - val_mae: 2.4719\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8303 - mae: 1.8303 - val_loss: 2.4646 - val_mae: 2.4646\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8287 - mae: 1.8287 - val_loss: 2.4696 - val_mae: 2.4696\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8279 - mae: 1.8279 - val_loss: 2.4464 - val_mae: 2.4464\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8234 - mae: 1.8234 - val_loss: 2.4979 - val_mae: 2.4979\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8135 - mae: 1.8135 - val_loss: 2.4803 - val_mae: 2.4803\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8177 - mae: 1.8177 - val_loss: 2.4808 - val_mae: 2.4808\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7965 - mae: 1.7965 - val_loss: 2.4810 - val_mae: 2.4810\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7916 - mae: 1.7916 - val_loss: 2.4846 - val_mae: 2.4846\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7845 - mae: 1.7845 - val_loss: 2.4750 - val_mae: 2.4750\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7729 - mae: 1.7729 - val_loss: 2.4915 - val_mae: 2.4915\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7799 - mae: 1.7799 - val_loss: 2.4616 - val_mae: 2.4616\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7611 - mae: 1.7611 - val_loss: 2.5011 - val_mae: 2.5011\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7646 - mae: 1.7646 - val_loss: 2.4916 - val_mae: 2.4916\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7595 - mae: 1.7595 - val_loss: 2.5150 - val_mae: 2.5150\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7601 - mae: 1.7601 - val_loss: 2.4890 - val_mae: 2.4890\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7507 - mae: 1.7507 - val_loss: 2.4942 - val_mae: 2.4942\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7496 - mae: 1.7496 - val_loss: 2.4555 - val_mae: 2.4555\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7305 - mae: 1.7305 - val_loss: 2.4974 - val_mae: 2.4974\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7265 - mae: 1.7265 - val_loss: 2.4626 - val_mae: 2.4626\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7387 - mae: 1.7387 - val_loss: 2.4841 - val_mae: 2.4841\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7366 - mae: 1.7366 - val_loss: 2.4582 - val_mae: 2.4582\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7118 - mae: 1.7118 - val_loss: 2.4794 - val_mae: 2.4794\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7097 - mae: 1.7097 - val_loss: 2.4935 - val_mae: 2.4935\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6174 - mae: 3.6174\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 375.0221 - mae: 17.1158 - val_loss: 133.2939 - val_mae: 9.1107\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.6001 - mae: 6.2623 - val_loss: 50.4037 - val_mae: 5.1943\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.5050 - mae: 4.5480 - val_loss: 35.5381 - val_mae: 4.2136\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.5359 - mae: 3.8334 - val_loss: 29.2568 - val_mae: 3.7641\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 23.5141 - mae: 3.4918 - val_loss: 26.4902 - val_mae: 3.4251\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 21.2310 - mae: 3.2987 - val_loss: 24.8413 - val_mae: 3.2781\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.4765 - mae: 3.1177 - val_loss: 23.0653 - val_mae: 3.2193\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9726 - mae: 3.0103 - val_loss: 22.0230 - val_mae: 3.2000\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.1094 - mae: 2.9375 - val_loss: 21.9336 - val_mae: 3.0850\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.3692 - mae: 2.8504 - val_loss: 20.8421 - val_mae: 3.0653\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.6112 - mae: 2.7963 - val_loss: 19.8878 - val_mae: 3.1092\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.9342 - mae: 2.7534 - val_loss: 19.4221 - val_mae: 3.0154\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5917 - mae: 2.7315 - val_loss: 19.0639 - val_mae: 2.9726\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.0545 - mae: 2.6558 - val_loss: 18.8361 - val_mae: 2.9840\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.7382 - mae: 2.6549 - val_loss: 18.1421 - val_mae: 2.9422\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3549 - mae: 2.5986 - val_loss: 17.9095 - val_mae: 2.8912\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.0165 - mae: 2.5592 - val_loss: 17.6919 - val_mae: 2.8709\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6680 - mae: 2.5472 - val_loss: 17.7237 - val_mae: 2.8397\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5186 - mae: 2.5003 - val_loss: 17.0563 - val_mae: 2.8356\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1269 - mae: 2.4559 - val_loss: 17.0207 - val_mae: 2.8265\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8993 - mae: 2.4829 - val_loss: 16.9529 - val_mae: 2.7832\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.8333 - mae: 2.4306 - val_loss: 16.6085 - val_mae: 2.7503\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.4435 - mae: 2.4144 - val_loss: 16.5608 - val_mae: 2.7523\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.3297 - mae: 2.4068 - val_loss: 16.1956 - val_mae: 2.7424\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0498 - mae: 2.3837 - val_loss: 15.9964 - val_mae: 2.7315\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0129 - mae: 2.3740 - val_loss: 15.8475 - val_mae: 2.6944\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6066 - mae: 2.3329 - val_loss: 15.7427 - val_mae: 2.6804\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5007 - mae: 2.3202 - val_loss: 15.6505 - val_mae: 2.6641\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.3190 - mae: 2.2862 - val_loss: 15.3805 - val_mae: 2.6565\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1675 - mae: 2.2520 - val_loss: 15.4105 - val_mae: 2.6569\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0848 - mae: 2.2655 - val_loss: 15.1884 - val_mae: 2.6382\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8760 - mae: 2.2510 - val_loss: 15.0955 - val_mae: 2.6212\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7627 - mae: 2.2339 - val_loss: 15.0314 - val_mae: 2.6199\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6493 - mae: 2.2080 - val_loss: 14.8827 - val_mae: 2.5991\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.4613 - mae: 2.2058 - val_loss: 14.7851 - val_mae: 2.6048\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3726 - mae: 2.2045 - val_loss: 14.6815 - val_mae: 2.5760\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2377 - mae: 2.1714 - val_loss: 14.6610 - val_mae: 2.5851\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0824 - mae: 2.1514 - val_loss: 14.3405 - val_mae: 2.5637\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0487 - mae: 2.1544 - val_loss: 14.8608 - val_mae: 2.5910\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8691 - mae: 2.1353 - val_loss: 14.4338 - val_mae: 2.5443\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7229 - mae: 2.1033 - val_loss: 14.3098 - val_mae: 2.5316\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5882 - mae: 2.0870 - val_loss: 14.1687 - val_mae: 2.5286\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4977 - mae: 2.0804 - val_loss: 14.3729 - val_mae: 2.5403\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4992 - mae: 2.0728 - val_loss: 13.8687 - val_mae: 2.5099\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3474 - mae: 2.0289 - val_loss: 13.8628 - val_mae: 2.5243\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2026 - mae: 2.0284 - val_loss: 13.9342 - val_mae: 2.5089\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1163 - mae: 2.0229 - val_loss: 13.7721 - val_mae: 2.5109\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1141 - mae: 2.0370 - val_loss: 13.9780 - val_mae: 2.4991\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9701 - mae: 2.0168 - val_loss: 13.7486 - val_mae: 2.4947\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8197 - mae: 1.9962 - val_loss: 13.6499 - val_mae: 2.4909\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6998 - mae: 1.9989 - val_loss: 13.5933 - val_mae: 2.4902\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6189 - mae: 1.9706 - val_loss: 13.7936 - val_mae: 2.4852\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5406 - mae: 1.9570 - val_loss: 13.2878 - val_mae: 2.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4156 - mae: 1.9432 - val_loss: 13.4765 - val_mae: 2.4672\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5051 - mae: 1.9628 - val_loss: 13.6730 - val_mae: 2.4837\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2666 - mae: 1.9394 - val_loss: 13.4434 - val_mae: 2.4608\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2853 - mae: 1.9339 - val_loss: 13.5168 - val_mae: 2.4707\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0874 - mae: 1.8997 - val_loss: 13.3186 - val_mae: 2.4474\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1116 - mae: 1.8975 - val_loss: 13.1692 - val_mae: 2.4617\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8750 - mae: 1.8950 - val_loss: 13.4346 - val_mae: 2.4664\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9203 - mae: 1.9150 - val_loss: 13.3532 - val_mae: 2.4396\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7830 - mae: 1.8570 - val_loss: 13.2329 - val_mae: 2.4426\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7737 - mae: 1.8766 - val_loss: 13.3179 - val_mae: 2.4345\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5519 - mae: 1.8464 - val_loss: 13.4981 - val_mae: 2.4558\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5088 - mae: 1.8314 - val_loss: 13.0689 - val_mae: 2.4330\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4481 - mae: 1.8160 - val_loss: 13.2077 - val_mae: 2.4425\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4590 - mae: 1.8542 - val_loss: 13.0684 - val_mae: 2.4276\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3930 - mae: 1.8169 - val_loss: 13.2442 - val_mae: 2.4216\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2168 - mae: 1.7947 - val_loss: 12.9738 - val_mae: 2.4218\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2601 - mae: 1.7927 - val_loss: 12.9318 - val_mae: 2.4206\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0886 - mae: 1.7712 - val_loss: 12.9649 - val_mae: 2.4205\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0877 - mae: 1.7978 - val_loss: 13.1222 - val_mae: 2.4138\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9928 - mae: 1.7442 - val_loss: 13.2428 - val_mae: 2.4125\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9744 - mae: 1.7780 - val_loss: 13.1036 - val_mae: 2.4066\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8213 - mae: 1.7525 - val_loss: 12.8843 - val_mae: 2.4034\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9100 - mae: 1.7792 - val_loss: 13.2760 - val_mae: 2.4148\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6562 - mae: 1.7142 - val_loss: 12.9239 - val_mae: 2.4136\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6415 - mae: 1.7187 - val_loss: 12.8536 - val_mae: 2.4164\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6463 - mae: 1.7028 - val_loss: 13.0202 - val_mae: 2.4000\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5655 - mae: 1.7062 - val_loss: 12.8715 - val_mae: 2.3888\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4720 - mae: 1.7003 - val_loss: 13.0701 - val_mae: 2.3997\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4299 - mae: 1.6803 - val_loss: 12.9751 - val_mae: 2.3849\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3305 - mae: 1.6648 - val_loss: 12.7440 - val_mae: 2.3982\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3480 - mae: 1.6681 - val_loss: 12.8404 - val_mae: 2.3905\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2798 - mae: 1.6549 - val_loss: 13.1291 - val_mae: 2.3832\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1956 - mae: 1.6512 - val_loss: 12.9124 - val_mae: 2.3713\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1611 - mae: 1.6408 - val_loss: 12.6844 - val_mae: 2.3828\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1168 - mae: 1.6305 - val_loss: 12.9694 - val_mae: 2.3775\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0335 - mae: 1.6222 - val_loss: 12.8399 - val_mae: 2.3759\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1457 - mae: 1.6501 - val_loss: 13.0037 - val_mae: 2.3749\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9621 - mae: 1.6195 - val_loss: 12.8794 - val_mae: 2.3702\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8325 - mae: 1.6056 - val_loss: 13.8871 - val_mae: 2.4687\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9845 - mae: 1.6301 - val_loss: 12.7150 - val_mae: 2.4018\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8529 - mae: 1.6076 - val_loss: 13.0800 - val_mae: 2.3779\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7934 - mae: 1.6017 - val_loss: 12.7379 - val_mae: 2.3793\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7216 - mae: 1.5781 - val_loss: 12.8953 - val_mae: 2.3665\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7306 - mae: 1.5926 - val_loss: 12.8533 - val_mae: 2.3732\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6678 - mae: 1.5719 - val_loss: 12.8974 - val_mae: 2.3587\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6164 - mae: 1.5591 - val_loss: 12.7501 - val_mae: 2.3701\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5557 - mae: 1.5553 - val_loss: 12.6741 - val_mae: 2.3642\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3785 - mae: 3.5351\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.7835 - mae: 18.7835 - val_loss: 11.9912 - val_mae: 11.9912\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1253 - mae: 8.1253 - val_loss: 6.1190 - val_mae: 6.1190\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3251 - mae: 5.3251 - val_loss: 4.4784 - val_mae: 4.4784\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0706 - mae: 4.0706 - val_loss: 3.6211 - val_mae: 3.6211\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4170 - mae: 3.4170 - val_loss: 3.2612 - val_mae: 3.2612\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0601 - mae: 3.0601 - val_loss: 3.1141 - val_mae: 3.1141\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.9303 - mae: 2.9303 - val_loss: 3.0261 - val_mae: 3.0261\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8277 - mae: 2.8277 - val_loss: 2.9408 - val_mae: 2.9408\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7392 - mae: 2.7392 - val_loss: 2.9331 - val_mae: 2.9331\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6964 - mae: 2.6964 - val_loss: 2.9142 - val_mae: 2.9142\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6532 - mae: 2.6532 - val_loss: 2.8210 - val_mae: 2.8210\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6017 - mae: 2.6017 - val_loss: 2.8621 - val_mae: 2.8621\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5372 - mae: 2.5372 - val_loss: 2.8824 - val_mae: 2.8824\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5741 - mae: 2.5741 - val_loss: 2.7690 - val_mae: 2.7690\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5076 - mae: 2.5076 - val_loss: 2.7614 - val_mae: 2.7614\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4862 - mae: 2.4862 - val_loss: 2.7431 - val_mae: 2.7431\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4445 - mae: 2.4445 - val_loss: 2.7566 - val_mae: 2.7566\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4180 - mae: 2.4180 - val_loss: 2.7516 - val_mae: 2.7516\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3998 - mae: 2.3998 - val_loss: 2.7020 - val_mae: 2.7020\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3637 - mae: 2.3637 - val_loss: 2.7326 - val_mae: 2.7326\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3569 - mae: 2.3569 - val_loss: 2.6870 - val_mae: 2.6870\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3395 - mae: 2.3395 - val_loss: 2.7050 - val_mae: 2.7050\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3260 - mae: 2.3260 - val_loss: 2.6653 - val_mae: 2.6653\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3029 - mae: 2.3029 - val_loss: 2.6363 - val_mae: 2.6363\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2893 - mae: 2.2893 - val_loss: 2.6373 - val_mae: 2.6373\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3149 - mae: 2.3149 - val_loss: 2.6631 - val_mae: 2.6631\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2926 - mae: 2.2926 - val_loss: 2.5841 - val_mae: 2.5841\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2531 - mae: 2.2531 - val_loss: 2.5567 - val_mae: 2.5567\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2560 - mae: 2.2560 - val_loss: 2.5820 - val_mae: 2.5820\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2609 - mae: 2.2609 - val_loss: 2.5609 - val_mae: 2.5609\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2357 - mae: 2.2357 - val_loss: 2.5712 - val_mae: 2.5712\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2181 - mae: 2.2181 - val_loss: 2.5530 - val_mae: 2.5530\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1872 - mae: 2.1872 - val_loss: 2.5302 - val_mae: 2.5302\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2031 - mae: 2.2031 - val_loss: 2.5614 - val_mae: 2.5614\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1716 - mae: 2.1716 - val_loss: 2.5633 - val_mae: 2.5633\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1747 - mae: 2.1747 - val_loss: 2.5725 - val_mae: 2.5725\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1640 - mae: 2.1640 - val_loss: 2.4919 - val_mae: 2.4919\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1808 - mae: 2.1808 - val_loss: 2.5578 - val_mae: 2.5578\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1395 - mae: 2.1395 - val_loss: 2.4876 - val_mae: 2.4876\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1068 - mae: 2.1068 - val_loss: 2.4978 - val_mae: 2.4978\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1372 - mae: 2.1372 - val_loss: 2.5539 - val_mae: 2.5539\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1140 - mae: 2.1140 - val_loss: 2.4762 - val_mae: 2.4762\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1002 - mae: 2.1002 - val_loss: 2.5066 - val_mae: 2.5066\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0663 - mae: 2.0663 - val_loss: 2.4611 - val_mae: 2.4611\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0714 - mae: 2.0714 - val_loss: 2.4872 - val_mae: 2.4872\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0550 - mae: 2.0550 - val_loss: 2.4850 - val_mae: 2.4850\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0474 - mae: 2.0474 - val_loss: 2.4812 - val_mae: 2.4812\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0307 - mae: 2.0307 - val_loss: 2.4369 - val_mae: 2.4369\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0242 - mae: 2.0242 - val_loss: 2.4653 - val_mae: 2.4653\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0041 - mae: 2.0041 - val_loss: 2.4205 - val_mae: 2.4205\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0078 - mae: 2.0078 - val_loss: 2.4196 - val_mae: 2.4196\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9958 - mae: 1.9958 - val_loss: 2.4287 - val_mae: 2.4287\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0069 - mae: 2.0069 - val_loss: 2.4311 - val_mae: 2.4311\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9833 - mae: 1.9833 - val_loss: 2.4324 - val_mae: 2.4324\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9744 - mae: 1.9744 - val_loss: 2.4806 - val_mae: 2.4806\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9856 - mae: 1.9856 - val_loss: 2.4719 - val_mae: 2.4719\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9830 - mae: 1.9830 - val_loss: 2.4165 - val_mae: 2.4165\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9406 - mae: 1.9406 - val_loss: 2.4386 - val_mae: 2.4386\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9576 - mae: 1.9576 - val_loss: 2.4573 - val_mae: 2.4573\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9411 - mae: 1.9411 - val_loss: 2.4333 - val_mae: 2.4333\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9356 - mae: 1.9356 - val_loss: 2.4431 - val_mae: 2.4431\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9191 - mae: 1.9191 - val_loss: 2.4283 - val_mae: 2.4283\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9115 - mae: 1.9115 - val_loss: 2.4393 - val_mae: 2.4393\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9133 - mae: 1.9133 - val_loss: 2.4325 - val_mae: 2.4325\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8981 - mae: 1.8981 - val_loss: 2.4089 - val_mae: 2.4089\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8899 - mae: 1.8899 - val_loss: 2.4443 - val_mae: 2.4443\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8925 - mae: 1.8925 - val_loss: 2.5015 - val_mae: 2.5015\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8961 - mae: 1.8961 - val_loss: 2.4568 - val_mae: 2.4568\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8775 - mae: 1.8775 - val_loss: 2.4252 - val_mae: 2.4252\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8681 - mae: 1.8681 - val_loss: 2.4258 - val_mae: 2.4258\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8714 - mae: 1.8714 - val_loss: 2.4016 - val_mae: 2.4016\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8754 - mae: 1.8754 - val_loss: 2.4227 - val_mae: 2.4227\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8501 - mae: 1.8501 - val_loss: 2.4391 - val_mae: 2.4391\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8411 - mae: 1.8411 - val_loss: 2.4168 - val_mae: 2.4168\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8312 - mae: 1.8312 - val_loss: 2.4275 - val_mae: 2.4275\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8438 - mae: 1.8438 - val_loss: 2.3974 - val_mae: 2.3974\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8126 - mae: 1.8126 - val_loss: 2.4122 - val_mae: 2.4122\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8084 - mae: 1.8084 - val_loss: 2.4169 - val_mae: 2.4169\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8097 - mae: 1.8097 - val_loss: 2.4630 - val_mae: 2.4630\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8203 - mae: 1.8203 - val_loss: 2.4379 - val_mae: 2.4379\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7908 - mae: 1.7908 - val_loss: 2.3954 - val_mae: 2.3954\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7763 - mae: 1.7763 - val_loss: 2.3871 - val_mae: 2.3871\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7859 - mae: 1.7859 - val_loss: 2.4006 - val_mae: 2.4006\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7669 - mae: 1.7669 - val_loss: 2.4082 - val_mae: 2.4082\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7551 - mae: 1.7551 - val_loss: 2.3934 - val_mae: 2.3934\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7361 - mae: 1.7361 - val_loss: 2.4046 - val_mae: 2.4046\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7743 - mae: 1.7743 - val_loss: 2.3615 - val_mae: 2.3615\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7521 - mae: 1.7521 - val_loss: 2.3845 - val_mae: 2.3845\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7660 - mae: 1.7660 - val_loss: 2.4475 - val_mae: 2.4475\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7397 - mae: 1.7397 - val_loss: 2.4184 - val_mae: 2.4184\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7303 - mae: 1.7303 - val_loss: 2.4352 - val_mae: 2.4352\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7167 - mae: 1.7167 - val_loss: 2.4124 - val_mae: 2.4124\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7225 - mae: 1.7225 - val_loss: 2.4079 - val_mae: 2.4079\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7006 - mae: 1.7006 - val_loss: 2.3975 - val_mae: 2.3975\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6905 - mae: 1.6905 - val_loss: 2.4192 - val_mae: 2.4192\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6858 - mae: 1.6858 - val_loss: 2.3966 - val_mae: 2.3966\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6808 - mae: 1.6808 - val_loss: 2.3992 - val_mae: 2.3992\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6592 - mae: 1.6592 - val_loss: 2.4468 - val_mae: 2.4468\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7026 - mae: 1.7026 - val_loss: 2.4265 - val_mae: 2.4265\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6566 - mae: 1.6566 - val_loss: 2.4698 - val_mae: 2.4698\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1197 - mae: 3.1197\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 410.2696 - mae: 18.0675 - val_loss: 159.5366 - val_mae: 10.2658\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6010 - mae: 6.5747 - val_loss: 57.1586 - val_mae: 5.3808\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3430 - mae: 4.6929 - val_loss: 38.3327 - val_mae: 4.2108\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 31.6598 - mae: 3.9778 - val_loss: 30.9569 - val_mae: 3.7108\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 27.0499 - mae: 3.6495 - val_loss: 27.1351 - val_mae: 3.4761\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 24.1683 - mae: 3.4261 - val_loss: 24.5420 - val_mae: 3.3055\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 22.2552 - mae: 3.2341 - val_loss: 22.4651 - val_mae: 3.2321\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 20.8360 - mae: 3.1449 - val_loss: 21.4297 - val_mae: 3.1053\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 19.8877 - mae: 3.0638 - val_loss: 20.4333 - val_mae: 3.1018\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.8648 - mae: 2.9887 - val_loss: 19.9311 - val_mae: 3.2187\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.9285 - mae: 2.9136 - val_loss: 19.2018 - val_mae: 3.0111\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 17.2708 - mae: 2.8534 - val_loss: 18.5904 - val_mae: 3.0091\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.7583 - mae: 2.8194 - val_loss: 17.9965 - val_mae: 2.9588\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.1741 - mae: 2.7784 - val_loss: 17.6852 - val_mae: 2.9531\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.7375 - mae: 2.7044 - val_loss: 17.4735 - val_mae: 2.9623\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.3760 - mae: 2.7007 - val_loss: 17.2244 - val_mae: 2.9511\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.0555 - mae: 2.6705 - val_loss: 16.7940 - val_mae: 2.8796\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.5527 - mae: 2.6280 - val_loss: 16.5935 - val_mae: 2.8908\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.2775 - mae: 2.5975 - val_loss: 16.3727 - val_mae: 2.8521\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1423 - mae: 2.5923 - val_loss: 16.1719 - val_mae: 2.8300\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8160 - mae: 2.5685 - val_loss: 15.9047 - val_mae: 2.7941\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.5395 - mae: 2.5287 - val_loss: 15.8460 - val_mae: 2.7932\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2161 - mae: 2.4970 - val_loss: 15.6011 - val_mae: 2.7632\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.1149 - mae: 2.5098 - val_loss: 15.7271 - val_mae: 2.7591\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.8085 - mae: 2.4635 - val_loss: 15.3243 - val_mae: 2.7490\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.7791 - mae: 2.4674 - val_loss: 15.2838 - val_mae: 2.7147\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5068 - mae: 2.4342 - val_loss: 15.2241 - val_mae: 2.7332\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.6484 - mae: 2.4656 - val_loss: 15.1452 - val_mae: 2.7042\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.2689 - mae: 2.4254 - val_loss: 15.0236 - val_mae: 2.6942\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1688 - mae: 2.3927 - val_loss: 15.0065 - val_mae: 2.6883\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.9327 - mae: 2.3947 - val_loss: 14.9337 - val_mae: 2.6662\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7269 - mae: 2.3557 - val_loss: 14.6356 - val_mae: 2.6410\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6293 - mae: 2.3580 - val_loss: 14.5840 - val_mae: 2.6327\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2289 - mae: 2.3138 - val_loss: 14.6516 - val_mae: 2.6582\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.2197 - mae: 2.3221 - val_loss: 14.6978 - val_mae: 2.6408\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3442 - mae: 2.3371 - val_loss: 14.5401 - val_mae: 2.6383\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0657 - mae: 2.3087 - val_loss: 14.2622 - val_mae: 2.6047\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8926 - mae: 2.2893 - val_loss: 14.1569 - val_mae: 2.5896\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.0066 - mae: 2.2858 - val_loss: 14.1622 - val_mae: 2.5741\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5939 - mae: 2.2448 - val_loss: 14.1817 - val_mae: 2.5576\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5597 - mae: 2.2370 - val_loss: 14.0937 - val_mae: 2.5519\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.5508 - mae: 2.2684 - val_loss: 14.0851 - val_mae: 2.5776\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2703 - mae: 2.2313 - val_loss: 13.9719 - val_mae: 2.5248\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1292 - mae: 2.1876 - val_loss: 13.9449 - val_mae: 2.5456\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2295 - mae: 2.2089 - val_loss: 13.8745 - val_mae: 2.5511\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0268 - mae: 2.2029 - val_loss: 13.7619 - val_mae: 2.5444\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8845 - mae: 2.2041 - val_loss: 13.7940 - val_mae: 2.5137\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.8697 - mae: 2.1790 - val_loss: 13.7408 - val_mae: 2.5007\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6952 - mae: 2.1623 - val_loss: 13.6653 - val_mae: 2.4909\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5667 - mae: 2.1679 - val_loss: 13.5845 - val_mae: 2.4985\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5640 - mae: 2.1467 - val_loss: 13.6779 - val_mae: 2.4873\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.5729 - mae: 2.1759 - val_loss: 13.5686 - val_mae: 2.5072\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2350 - mae: 2.1123 - val_loss: 13.5921 - val_mae: 2.4766\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2590 - mae: 2.1447 - val_loss: 13.8010 - val_mae: 2.5202\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2273 - mae: 2.1188 - val_loss: 13.4077 - val_mae: 2.4618\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0897 - mae: 2.1044 - val_loss: 13.4587 - val_mae: 2.4490\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.9442 - mae: 2.0929 - val_loss: 13.3363 - val_mae: 2.4890\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.0163 - mae: 2.1268 - val_loss: 13.3179 - val_mae: 2.4607\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8163 - mae: 2.0924 - val_loss: 13.4483 - val_mae: 2.4450\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.6648 - mae: 2.0587 - val_loss: 13.4003 - val_mae: 2.4751\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.7519 - mae: 2.0985 - val_loss: 13.3880 - val_mae: 2.4526\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5814 - mae: 2.0690 - val_loss: 13.2958 - val_mae: 2.4532\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4225 - mae: 2.0409 - val_loss: 13.4210 - val_mae: 2.4587\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4906 - mae: 2.0612 - val_loss: 13.3615 - val_mae: 2.4433\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2325 - mae: 2.0174 - val_loss: 13.4860 - val_mae: 2.4865\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2525 - mae: 2.0349 - val_loss: 13.1941 - val_mae: 2.4725\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0668 - mae: 1.9969 - val_loss: 13.3576 - val_mae: 2.4464\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9719 - mae: 1.9898 - val_loss: 13.2078 - val_mae: 2.4504\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9662 - mae: 1.9933 - val_loss: 13.1333 - val_mae: 2.4558\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9752 - mae: 2.0166 - val_loss: 13.4083 - val_mae: 2.4550\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9012 - mae: 2.0057 - val_loss: 13.0995 - val_mae: 2.4503\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8983 - mae: 2.0095 - val_loss: 13.2099 - val_mae: 2.4502\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7029 - mae: 1.9654 - val_loss: 13.1810 - val_mae: 2.4340\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6617 - mae: 1.9690 - val_loss: 13.0225 - val_mae: 2.4076\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5437 - mae: 1.9525 - val_loss: 13.0284 - val_mae: 2.4335\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4572 - mae: 1.9363 - val_loss: 13.0136 - val_mae: 2.4174\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5118 - mae: 1.9489 - val_loss: 13.0908 - val_mae: 2.4324\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3624 - mae: 1.9392 - val_loss: 13.1023 - val_mae: 2.4406\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3709 - mae: 1.9389 - val_loss: 13.0479 - val_mae: 2.4214\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3046 - mae: 1.9316 - val_loss: 13.2189 - val_mae: 2.4310\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1659 - mae: 1.9047 - val_loss: 12.9423 - val_mae: 2.4179\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0316 - mae: 1.9021 - val_loss: 13.0236 - val_mae: 2.4228\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0167 - mae: 1.8789 - val_loss: 12.9573 - val_mae: 2.4190\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9746 - mae: 1.8828 - val_loss: 12.8997 - val_mae: 2.4179\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9934 - mae: 1.8999 - val_loss: 13.0846 - val_mae: 2.4276\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8565 - mae: 1.8759 - val_loss: 13.0121 - val_mae: 2.4151\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8723 - mae: 1.8682 - val_loss: 13.0376 - val_mae: 2.4255\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7533 - mae: 1.8789 - val_loss: 12.8284 - val_mae: 2.4120\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6211 - mae: 1.8510 - val_loss: 12.8875 - val_mae: 2.4046\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6107 - mae: 1.8450 - val_loss: 12.8246 - val_mae: 2.3944\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4861 - mae: 1.8360 - val_loss: 12.8738 - val_mae: 2.4077\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4351 - mae: 1.8347 - val_loss: 12.9063 - val_mae: 2.4146\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4626 - mae: 1.8438 - val_loss: 13.1713 - val_mae: 2.4471\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4103 - mae: 1.8346 - val_loss: 13.1510 - val_mae: 2.4243\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3680 - mae: 1.8339 - val_loss: 13.1094 - val_mae: 2.3995\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2830 - mae: 1.8288 - val_loss: 12.8132 - val_mae: 2.4019\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1427 - mae: 1.7905 - val_loss: 13.0957 - val_mae: 2.3771\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2653 - mae: 1.8212 - val_loss: 12.9574 - val_mae: 2.3919\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1253 - mae: 1.8123 - val_loss: 12.8914 - val_mae: 2.4128\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0759 - mae: 1.7725 - val_loss: 13.1139 - val_mae: 2.4388\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.9823 - mae: 3.6511\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.3702 - mae: 18.3702 - val_loss: 11.2535 - val_mae: 11.2535\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0367 - mae: 8.0367 - val_loss: 6.4431 - val_mae: 6.4431\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3471 - mae: 5.3471 - val_loss: 4.4576 - val_mae: 4.4576\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2260 - mae: 4.2260 - val_loss: 3.6815 - val_mae: 3.6815\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6661 - mae: 3.6661 - val_loss: 3.2869 - val_mae: 3.2869\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.4088 - mae: 3.4088 - val_loss: 3.1400 - val_mae: 3.1400\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1668 - mae: 3.1668 - val_loss: 3.0365 - val_mae: 3.0365\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.0017 - mae: 3.0017 - val_loss: 2.9258 - val_mae: 2.9258\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.8927 - mae: 2.8927 - val_loss: 2.8578 - val_mae: 2.8578\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7833 - mae: 2.7833 - val_loss: 2.7909 - val_mae: 2.7909\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6985 - mae: 2.6985 - val_loss: 2.7586 - val_mae: 2.7586\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.6239 - mae: 2.6239 - val_loss: 2.7514 - val_mae: 2.7514\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.5445 - mae: 2.5445 - val_loss: 2.7234 - val_mae: 2.7234\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4975 - mae: 2.4975 - val_loss: 2.7195 - val_mae: 2.7195\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4628 - mae: 2.4628 - val_loss: 2.6955 - val_mae: 2.6955\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4297 - mae: 2.4297 - val_loss: 2.6519 - val_mae: 2.6519\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4305 - mae: 2.4305 - val_loss: 2.7078 - val_mae: 2.7078\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.4319 - mae: 2.4319 - val_loss: 2.6705 - val_mae: 2.6705\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3855 - mae: 2.3855 - val_loss: 2.6296 - val_mae: 2.6296\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3365 - mae: 2.3365 - val_loss: 2.5954 - val_mae: 2.5954\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3086 - mae: 2.3086 - val_loss: 2.6080 - val_mae: 2.6080\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2948 - mae: 2.2948 - val_loss: 2.5586 - val_mae: 2.5586\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2849 - mae: 2.2849 - val_loss: 2.5568 - val_mae: 2.5568\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2806 - mae: 2.2806 - val_loss: 2.5438 - val_mae: 2.5438\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2383 - mae: 2.2383 - val_loss: 2.5458 - val_mae: 2.5458\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2174 - mae: 2.2174 - val_loss: 2.5553 - val_mae: 2.5553\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2196 - mae: 2.2196 - val_loss: 2.5180 - val_mae: 2.5180\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1925 - mae: 2.1925 - val_loss: 2.5207 - val_mae: 2.5207\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1994 - mae: 2.1994 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1656 - mae: 2.1656 - val_loss: 2.5171 - val_mae: 2.5171\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1728 - mae: 2.1728 - val_loss: 2.4998 - val_mae: 2.4998\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1483 - mae: 2.1483 - val_loss: 2.4990 - val_mae: 2.4990\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1575 - mae: 2.1575 - val_loss: 2.4747 - val_mae: 2.4747\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1213 - mae: 2.1213 - val_loss: 2.4635 - val_mae: 2.4635\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1136 - mae: 2.1136 - val_loss: 2.4488 - val_mae: 2.4488\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1179 - mae: 2.1179 - val_loss: 2.4701 - val_mae: 2.4701\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0832 - mae: 2.0832 - val_loss: 2.4510 - val_mae: 2.4510\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1024 - mae: 2.1024 - val_loss: 2.4582 - val_mae: 2.4582\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1044 - mae: 2.1044 - val_loss: 2.5390 - val_mae: 2.5390\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0881 - mae: 2.0881 - val_loss: 2.4356 - val_mae: 2.4356\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0847 - mae: 2.0847 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0766 - mae: 2.0766 - val_loss: 2.4206 - val_mae: 2.4206\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0461 - mae: 2.0461 - val_loss: 2.3857 - val_mae: 2.3857\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0499 - mae: 2.0499 - val_loss: 2.3691 - val_mae: 2.3691\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0562 - mae: 2.0562 - val_loss: 2.4277 - val_mae: 2.4277\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0203 - mae: 2.0203 - val_loss: 2.3807 - val_mae: 2.3807\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0347 - mae: 2.0347 - val_loss: 2.3876 - val_mae: 2.3876\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0179 - mae: 2.0179 - val_loss: 2.3708 - val_mae: 2.3708\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.0081 - mae: 2.0081 - val_loss: 2.3778 - val_mae: 2.3778\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.9050 - mae: 1.905 - 0s 2ms/step - loss: 1.9785 - mae: 1.9785 - val_loss: 2.3693 - val_mae: 2.3693\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9906 - mae: 1.9906 - val_loss: 2.3967 - val_mae: 2.3967\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.1109 - mae: 2.110 - 0s 2ms/step - loss: 1.9936 - mae: 1.9936 - val_loss: 2.3525 - val_mae: 2.3525\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9802 - mae: 1.9802 - val_loss: 2.3435 - val_mae: 2.3435\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9447 - mae: 1.9447 - val_loss: 2.3504 - val_mae: 2.3504\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9764 - mae: 1.9764 - val_loss: 2.3752 - val_mae: 2.3752\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9483 - mae: 1.9483 - val_loss: 2.3231 - val_mae: 2.3231\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9552 - mae: 1.9552 - val_loss: 2.3685 - val_mae: 2.3685\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9262 - mae: 1.9262 - val_loss: 2.3327 - val_mae: 2.3327\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9291 - mae: 1.9291 - val_loss: 2.3368 - val_mae: 2.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9139 - mae: 1.9139 - val_loss: 2.3207 - val_mae: 2.3207\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.9003 - mae: 1.9003 - val_loss: 2.3179 - val_mae: 2.3179\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8901 - mae: 1.8901 - val_loss: 2.3270 - val_mae: 2.3270\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8879 - mae: 1.8879 - val_loss: 2.3413 - val_mae: 2.3413\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8817 - mae: 1.8817 - val_loss: 2.3418 - val_mae: 2.3418\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8673 - mae: 1.8673 - val_loss: 2.3326 - val_mae: 2.3326\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8695 - mae: 1.8695 - val_loss: 2.3031 - val_mae: 2.3031\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8549 - mae: 1.8549 - val_loss: 2.3138 - val_mae: 2.3138\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8443 - mae: 1.8443 - val_loss: 2.2984 - val_mae: 2.2984\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8517 - mae: 1.8517 - val_loss: 2.2980 - val_mae: 2.2980\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8394 - mae: 1.8394 - val_loss: 2.3204 - val_mae: 2.3204\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8194 - mae: 1.8194 - val_loss: 2.3052 - val_mae: 2.3052\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8214 - mae: 1.8214 - val_loss: 2.2848 - val_mae: 2.2848\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8241 - mae: 1.8241 - val_loss: 2.2800 - val_mae: 2.2800\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8019 - mae: 1.8019 - val_loss: 2.2646 - val_mae: 2.2646\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8032 - mae: 1.8032 - val_loss: 2.2794 - val_mae: 2.2794\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8055 - mae: 1.8055 - val_loss: 2.2869 - val_mae: 2.2869\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8291 - mae: 1.8291 - val_loss: 2.3132 - val_mae: 2.3132\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.8030 - mae: 1.8030 - val_loss: 2.3128 - val_mae: 2.3128\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7982 - mae: 1.7982 - val_loss: 2.3192 - val_mae: 2.3192\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7817 - mae: 1.7817 - val_loss: 2.3095 - val_mae: 2.3095\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7654 - mae: 1.7654 - val_loss: 2.2949 - val_mae: 2.2949\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7685 - mae: 1.7685 - val_loss: 2.2885 - val_mae: 2.2885\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7571 - mae: 1.7571 - val_loss: 2.2888 - val_mae: 2.2888\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7394 - mae: 1.7394 - val_loss: 2.2916 - val_mae: 2.2916\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7451 - mae: 1.7451 - val_loss: 2.2821 - val_mae: 2.2821\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7476 - mae: 1.7476 - val_loss: 2.2863 - val_mae: 2.2863\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7252 - mae: 1.7252 - val_loss: 2.3073 - val_mae: 2.3073\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7430 - mae: 1.7430 - val_loss: 2.3382 - val_mae: 2.3382\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7419 - mae: 1.7419 - val_loss: 2.2822 - val_mae: 2.2822\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7302 - mae: 1.7302 - val_loss: 2.3135 - val_mae: 2.3135\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7101 - mae: 1.7101 - val_loss: 2.3075 - val_mae: 2.3075\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7139 - mae: 1.7139 - val_loss: 2.3088 - val_mae: 2.3088\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6918 - mae: 1.6918 - val_loss: 2.2944 - val_mae: 2.2944\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7032 - mae: 1.7032 - val_loss: 2.2847 - val_mae: 2.2847\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6937 - mae: 1.6937 - val_loss: 2.2555 - val_mae: 2.2555\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6877 - mae: 1.6877 - val_loss: 2.2866 - val_mae: 2.2866\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6811 - mae: 1.6811 - val_loss: 2.3119 - val_mae: 2.3119\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6728 - mae: 1.6728 - val_loss: 2.2753 - val_mae: 2.2753\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6578 - mae: 1.6578 - val_loss: 2.2850 - val_mae: 2.2850\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6602 - mae: 1.6602 - val_loss: 2.2810 - val_mae: 2.2810\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6937 - mae: 3.6937\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 389.0442 - mae: 17.5243 - val_loss: 290.2773 - val_mae: 14.2179\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 247.4709 - mae: 13.0982 - val_loss: 231.7334 - val_mae: 12.1455\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 207.8820 - mae: 11.6520 - val_loss: 203.9023 - val_mae: 11.0763\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 184.9732 - mae: 10.7331 - val_loss: 184.7514 - val_mae: 10.3161\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 168.1539 - mae: 10.0476 - val_loss: 169.9465 - val_mae: 9.7132\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 154.8264 - mae: 9.4716 - val_loss: 157.9674 - val_mae: 9.2302\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 144.0746 - mae: 9.0252 - val_loss: 148.1355 - val_mae: 8.8433\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 135.1421 - mae: 8.6412 - val_loss: 139.9341 - val_mae: 8.5218\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 127.5557 - mae: 8.3191 - val_loss: 133.1774 - val_mae: 8.2679\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 121.2973 - mae: 8.0516 - val_loss: 127.3168 - val_mae: 8.0624\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.9500 - mae: 7.8080 - val_loss: 122.2983 - val_mae: 7.8855\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.3082 - mae: 7.5980 - val_loss: 118.1777 - val_mae: 7.7372\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.3539 - mae: 7.4199 - val_loss: 114.2895 - val_mae: 7.5974\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 103.7582 - mae: 7.2479 - val_loss: 110.9521 - val_mae: 7.4831\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 100.5856 - mae: 7.1037 - val_loss: 108.1587 - val_mae: 7.3848\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.8857 - mae: 6.9750 - val_loss: 105.5601 - val_mae: 7.2868\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.5696 - mae: 6.8617 - val_loss: 103.4355 - val_mae: 7.2007\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.5030 - mae: 6.7726 - val_loss: 101.5078 - val_mae: 7.1266\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.7806 - mae: 6.6902 - val_loss: 99.6815 - val_mae: 7.0588\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.1886 - mae: 6.6206 - val_loss: 98.3175 - val_mae: 7.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.8776 - mae: 6.5646 - val_loss: 97.0925 - val_mae: 6.9616\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.7194 - mae: 6.5174 - val_loss: 96.0008 - val_mae: 6.9403\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.7041 - mae: 6.4803 - val_loss: 95.0384 - val_mae: 6.9253\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.7950 - mae: 6.4479 - val_loss: 94.1997 - val_mae: 6.9111\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.9970 - mae: 6.4199 - val_loss: 93.4185 - val_mae: 6.9013\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.3217 - mae: 6.4048 - val_loss: 92.7108 - val_mae: 6.8983\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.6993 - mae: 6.3944 - val_loss: 92.1489 - val_mae: 6.8999\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.1535 - mae: 6.3799 - val_loss: 91.6203 - val_mae: 6.9058\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.6780 - mae: 6.3731 - val_loss: 91.1898 - val_mae: 6.9126\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.2600 - mae: 6.3687 - val_loss: 90.7633 - val_mae: 6.9222\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.8877 - mae: 6.3632 - val_loss: 90.3482 - val_mae: 6.9319\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.5437 - mae: 6.3583 - val_loss: 90.0347 - val_mae: 6.9375\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.2243 - mae: 6.3568 - val_loss: 89.6843 - val_mae: 6.9464\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.9400 - mae: 6.3562 - val_loss: 89.3813 - val_mae: 6.9538\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.6816 - mae: 6.3532 - val_loss: 89.1226 - val_mae: 6.9548\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4225 - mae: 6.3492 - val_loss: 88.8447 - val_mae: 6.9560\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.1770 - mae: 6.3499 - val_loss: 88.5376 - val_mae: 6.9590\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.9130 - mae: 6.3437 - val_loss: 88.2224 - val_mae: 6.9572\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6353 - mae: 6.3370 - val_loss: 87.9278 - val_mae: 6.9508\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.3279 - mae: 6.3279 - val_loss: 87.5339 - val_mae: 6.9438\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.9908 - mae: 6.3153 - val_loss: 87.0988 - val_mae: 6.9269\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.5843 - mae: 6.2962 - val_loss: 86.5706 - val_mae: 6.8980\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.0592 - mae: 6.2684 - val_loss: 85.9413 - val_mae: 6.8637\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.4474 - mae: 6.2313 - val_loss: 85.1636 - val_mae: 6.8143\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.7093 - mae: 6.1773 - val_loss: 84.2843 - val_mae: 6.7451\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.9580 - mae: 6.1264 - val_loss: 83.4770 - val_mae: 6.6837\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.1981 - mae: 6.0731 - val_loss: 82.5503 - val_mae: 6.6254\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.3404 - mae: 6.0065 - val_loss: 81.6123 - val_mae: 6.5427\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.5448 - mae: 5.9371 - val_loss: 80.6984 - val_mae: 6.4699\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.7332 - mae: 5.8902 - val_loss: 79.8153 - val_mae: 6.4208\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.8808 - mae: 5.8498 - val_loss: 78.9052 - val_mae: 6.3733\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.0449 - mae: 5.7960 - val_loss: 77.9448 - val_mae: 6.3124\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.1575 - mae: 5.7162 - val_loss: 76.9866 - val_mae: 6.2393\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.3208 - mae: 5.6519 - val_loss: 75.9701 - val_mae: 6.1650\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.2978 - mae: 5.6121 - val_loss: 74.9164 - val_mae: 6.1265\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.3058 - mae: 5.5656 - val_loss: 73.9145 - val_mae: 6.0709\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.2810 - mae: 5.5078 - val_loss: 72.7897 - val_mae: 5.9859\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.3189 - mae: 5.4128 - val_loss: 71.6144 - val_mae: 5.8722\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.2630 - mae: 5.3947 - val_loss: 70.5117 - val_mae: 5.8239\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.1692 - mae: 5.3084 - val_loss: 69.3582 - val_mae: 5.7462\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.0469 - mae: 5.2472 - val_loss: 68.1656 - val_mae: 5.6459\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.0386 - mae: 5.1804 - val_loss: 67.0522 - val_mae: 5.5628\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.9131 - mae: 5.1357 - val_loss: 65.9444 - val_mae: 5.4901\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.8833 - mae: 5.0928 - val_loss: 64.8773 - val_mae: 5.4362\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.9707 - mae: 5.0418 - val_loss: 63.7837 - val_mae: 5.3333\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.9470 - mae: 4.9539 - val_loss: 62.7678 - val_mae: 5.2498\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.0047 - mae: 4.9338 - val_loss: 61.8555 - val_mae: 5.1961\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.2278 - mae: 4.8793 - val_loss: 60.9226 - val_mae: 5.1523\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.3970 - mae: 4.8756 - val_loss: 60.0873 - val_mae: 5.0419\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.5593 - mae: 4.8250 - val_loss: 59.2753 - val_mae: 5.0288\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.7272 - mae: 4.7828 - val_loss: 58.5185 - val_mae: 4.9958\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.0789 - mae: 4.7587 - val_loss: 57.7776 - val_mae: 4.9480\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.4289 - mae: 4.7370 - val_loss: 57.0190 - val_mae: 4.9194\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6964 - mae: 4.6702 - val_loss: 56.3784 - val_mae: 4.8631\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0419 - mae: 4.6537 - val_loss: 55.7279 - val_mae: 4.8636\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.3791 - mae: 4.6453 - val_loss: 55.1081 - val_mae: 4.8320\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.7968 - mae: 4.6338 - val_loss: 54.4534 - val_mae: 4.8220\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.1608 - mae: 4.5970 - val_loss: 53.9080 - val_mae: 4.7633\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.5836 - mae: 4.5547 - val_loss: 53.3142 - val_mae: 4.7668\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.9995 - mae: 4.5396 - val_loss: 52.7694 - val_mae: 4.7509\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.3998 - mae: 4.5157 - val_loss: 52.2518 - val_mae: 4.7108\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 45.8733 - mae: 4.4673 - val_loss: 51.7420 - val_mae: 4.6786\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.3044 - mae: 4.5077 - val_loss: 51.1462 - val_mae: 4.6998\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7276 - mae: 4.4356 - val_loss: 50.6840 - val_mae: 4.6191\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.1591 - mae: 4.3627 - val_loss: 50.2306 - val_mae: 4.5834\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.6713 - mae: 4.3549 - val_loss: 49.7071 - val_mae: 4.5863\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.1472 - mae: 4.3014 - val_loss: 49.2178 - val_mae: 4.5768\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.6476 - mae: 4.3136 - val_loss: 48.7937 - val_mae: 4.5569\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.0980 - mae: 4.2876 - val_loss: 48.2700 - val_mae: 4.5535\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.6184 - mae: 4.2609 - val_loss: 47.9314 - val_mae: 4.4890\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.1532 - mae: 4.2026 - val_loss: 47.4559 - val_mae: 4.4901\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.7603 - mae: 4.2103 - val_loss: 47.0661 - val_mae: 4.4692\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.2955 - mae: 4.2090 - val_loss: 46.6765 - val_mae: 4.4408\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.8755 - mae: 4.1478 - val_loss: 46.2978 - val_mae: 4.4340\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.3896 - mae: 4.1459 - val_loss: 45.8996 - val_mae: 4.4074\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.0577 - mae: 4.0902 - val_loss: 45.4418 - val_mae: 4.4483\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.5255 - mae: 4.1131 - val_loss: 45.0332 - val_mae: 4.4179\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.1861 - mae: 4.0742 - val_loss: 44.6737 - val_mae: 4.3900\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.7417 - mae: 4.0796 - val_loss: 44.3586 - val_mae: 4.3740\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 37.4307 - mae: 4.0817 - val_loss: 44.0356 - val_mae: 4.3669\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 61.3486 - mae: 5.0860\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 17.9875 - mae: 17.9875 - val_loss: 14.5259 - val_mae: 14.5259\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.2418 - mae: 13.2418 - val_loss: 12.2189 - val_mae: 12.2189\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.6534 - mae: 11.6534 - val_loss: 11.0410 - val_mae: 11.0410\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.6810 - mae: 10.6810 - val_loss: 10.2289 - val_mae: 10.2289\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.9309 - mae: 9.9309 - val_loss: 9.5915 - val_mae: 9.5915\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.3340 - mae: 9.3340 - val_loss: 9.0844 - val_mae: 9.0844\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8669 - mae: 8.8669 - val_loss: 8.7039 - val_mae: 8.7039\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4990 - mae: 8.4990 - val_loss: 8.3965 - val_mae: 8.3965\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.1896 - mae: 8.1896 - val_loss: 8.1648 - val_mae: 8.1648\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9179 - mae: 7.9179 - val_loss: 7.9590 - val_mae: 7.9590\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6754 - mae: 7.6754 - val_loss: 7.7871 - val_mae: 7.7871\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4695 - mae: 7.4695 - val_loss: 7.6353 - val_mae: 7.6353\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2887 - mae: 7.2887 - val_loss: 7.5044 - val_mae: 7.5044\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1294 - mae: 7.1294 - val_loss: 7.3996 - val_mae: 7.3996\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0004 - mae: 7.0004 - val_loss: 7.3040 - val_mae: 7.3040\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8857 - mae: 6.8857 - val_loss: 7.2121 - val_mae: 7.2121\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7841 - mae: 6.7841 - val_loss: 7.1377 - val_mae: 7.1377\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7036 - mae: 6.7036 - val_loss: 7.0778 - val_mae: 7.0778\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6365 - mae: 6.6365 - val_loss: 7.0170 - val_mae: 7.0170\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5793 - mae: 6.5793 - val_loss: 6.9772 - val_mae: 6.9772\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5352 - mae: 6.5352 - val_loss: 6.9548 - val_mae: 6.9548\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5008 - mae: 6.5008 - val_loss: 6.9388 - val_mae: 6.9388\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4712 - mae: 6.4712 - val_loss: 6.9283 - val_mae: 6.9283\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4489 - mae: 6.4489 - val_loss: 6.9180 - val_mae: 6.9180\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4324 - mae: 6.4324 - val_loss: 6.9091 - val_mae: 6.9091\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4201 - mae: 6.4201 - val_loss: 6.9058 - val_mae: 6.9058\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4101 - mae: 6.4101 - val_loss: 6.9028 - val_mae: 6.9028\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4000 - mae: 6.4000 - val_loss: 6.9000 - val_mae: 6.9000\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3927 - mae: 6.3927 - val_loss: 6.8979 - val_mae: 6.8979\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.8978 - val_mae: 6.8978\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3792 - mae: 6.3792 - val_loss: 6.8951 - val_mae: 6.8951\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3719 - mae: 6.3719 - val_loss: 6.8900 - val_mae: 6.8900\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3655 - mae: 6.3655 - val_loss: 6.8808 - val_mae: 6.8808\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3547 - mae: 6.3547 - val_loss: 6.8724 - val_mae: 6.8724\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3424 - mae: 6.3424 - val_loss: 6.8575 - val_mae: 6.8575\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3252 - mae: 6.3252 - val_loss: 6.8347 - val_mae: 6.8347\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3011 - mae: 6.3011 - val_loss: 6.8015 - val_mae: 6.8015\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2626 - mae: 6.2626 - val_loss: 6.7373 - val_mae: 6.7373\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2157 - mae: 6.2157 - val_loss: 6.6520 - val_mae: 6.6520\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1542 - mae: 6.1542 - val_loss: 6.5763 - val_mae: 6.5763\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0879 - mae: 6.0879 - val_loss: 6.4868 - val_mae: 6.4868\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0235 - mae: 6.0235 - val_loss: 6.3993 - val_mae: 6.3993\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9609 - mae: 5.9609 - val_loss: 6.3128 - val_mae: 6.3128\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8919 - mae: 5.8919 - val_loss: 6.2241 - val_mae: 6.2241\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8318 - mae: 5.8318 - val_loss: 6.1106 - val_mae: 6.1106\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7405 - mae: 5.7405 - val_loss: 6.0527 - val_mae: 6.0527\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6623 - mae: 5.6623 - val_loss: 5.9267 - val_mae: 5.9267\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5857 - mae: 5.5857 - val_loss: 5.8046 - val_mae: 5.8046\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5009 - mae: 5.5009 - val_loss: 5.7067 - val_mae: 5.7067\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4088 - mae: 5.4088 - val_loss: 5.5830 - val_mae: 5.5830\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3284 - mae: 5.3284 - val_loss: 5.5027 - val_mae: 5.5027\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2456 - mae: 5.2456 - val_loss: 5.3735 - val_mae: 5.3735\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1639 - mae: 5.1639 - val_loss: 5.3020 - val_mae: 5.3020\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0847 - mae: 5.0847 - val_loss: 5.2087 - val_mae: 5.2087\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0192 - mae: 5.0192 - val_loss: 5.1263 - val_mae: 5.1263\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9563 - mae: 4.9563 - val_loss: 5.0324 - val_mae: 5.0324\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9101 - mae: 4.9101 - val_loss: 4.9605 - val_mae: 4.9605\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8530 - mae: 4.8530 - val_loss: 4.9329 - val_mae: 4.9329\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8195 - mae: 4.8195 - val_loss: 4.8853 - val_mae: 4.8853\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7677 - mae: 4.7677 - val_loss: 4.8318 - val_mae: 4.8318\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7287 - mae: 4.7287 - val_loss: 4.7960 - val_mae: 4.7960\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7012 - mae: 4.7012 - val_loss: 4.7702 - val_mae: 4.7702\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6695 - mae: 4.6695 - val_loss: 4.7478 - val_mae: 4.7478\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6404 - mae: 4.6404 - val_loss: 4.7184 - val_mae: 4.7184\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6120 - mae: 4.6120 - val_loss: 4.6994 - val_mae: 4.6994\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5902 - mae: 4.5902 - val_loss: 4.6704 - val_mae: 4.6704\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5677 - mae: 4.5677 - val_loss: 4.6553 - val_mae: 4.6553\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5332 - mae: 4.5332 - val_loss: 4.6335 - val_mae: 4.6335\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5081 - mae: 4.5081 - val_loss: 4.6085 - val_mae: 4.6085\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4822 - mae: 4.4822 - val_loss: 4.5925 - val_mae: 4.5925\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4611 - mae: 4.4611 - val_loss: 4.5732 - val_mae: 4.5732\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4325 - mae: 4.4325 - val_loss: 4.5353 - val_mae: 4.5353\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4132 - mae: 4.4132 - val_loss: 4.5431 - val_mae: 4.5431\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3783 - mae: 4.3783 - val_loss: 4.5106 - val_mae: 4.5106\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3530 - mae: 4.3530 - val_loss: 4.4916 - val_mae: 4.4916\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3285 - mae: 4.3285 - val_loss: 4.4804 - val_mae: 4.4804\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3125 - mae: 4.3125 - val_loss: 4.4617 - val_mae: 4.4617\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2926 - mae: 4.2926 - val_loss: 4.4584 - val_mae: 4.4584\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2713 - mae: 4.2713 - val_loss: 4.4386 - val_mae: 4.4386\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2546 - mae: 4.2546 - val_loss: 4.4257 - val_mae: 4.4257\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2428 - mae: 4.2428 - val_loss: 4.4136 - val_mae: 4.4136\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2230 - mae: 4.2230 - val_loss: 4.4025 - val_mae: 4.4025\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2132 - mae: 4.2132 - val_loss: 4.4059 - val_mae: 4.4059\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1895 - mae: 4.1895 - val_loss: 4.3784 - val_mae: 4.3784\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1740 - mae: 4.1740 - val_loss: 4.3756 - val_mae: 4.3756\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1509 - mae: 4.1509 - val_loss: 4.3542 - val_mae: 4.3542\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1468 - mae: 4.1468 - val_loss: 4.3444 - val_mae: 4.3444\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1302 - mae: 4.1302 - val_loss: 4.3403 - val_mae: 4.3403\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1128 - mae: 4.1128 - val_loss: 4.3220 - val_mae: 4.3220\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1023 - mae: 4.1023 - val_loss: 4.3213 - val_mae: 4.3213\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0908 - mae: 4.0908 - val_loss: 4.2939 - val_mae: 4.2939\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0759 - mae: 4.0759 - val_loss: 4.2991 - val_mae: 4.2991\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0813 - mae: 4.0813 - val_loss: 4.2788 - val_mae: 4.2788\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0474 - mae: 4.0474 - val_loss: 4.2946 - val_mae: 4.2946\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0528 - mae: 4.0528 - val_loss: 4.2569 - val_mae: 4.2569\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0340 - mae: 4.0340 - val_loss: 4.2514 - val_mae: 4.2514\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0254 - mae: 4.0254 - val_loss: 4.2351 - val_mae: 4.2351\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0155 - mae: 4.0155 - val_loss: 4.2344 - val_mae: 4.2344\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0099 - mae: 4.0099 - val_loss: 4.2241 - val_mae: 4.2241\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.9911 - mae: 3.9911 - val_loss: 4.2117 - val_mae: 4.2117\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.5229 - mae: 5.5229\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 452.3780 - mae: 19.2229 - val_loss: 348.5760 - val_mae: 16.1184\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 301.3220 - mae: 14.9378 - val_loss: 283.5248 - val_mae: 13.9812\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 258.1562 - mae: 13.4703 - val_loss: 252.4539 - val_mae: 12.8935\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 231.9373 - mae: 12.5395 - val_loss: 230.0812 - val_mae: 12.0820\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 211.7929 - mae: 11.7906 - val_loss: 212.0913 - val_mae: 11.4005\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 195.6503 - mae: 11.1699 - val_loss: 197.7061 - val_mae: 10.8300\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 182.6051 - mae: 10.6379 - val_loss: 185.5236 - val_mae: 10.3472\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.3375 - mae: 10.1834 - val_loss: 175.4272 - val_mae: 9.9371\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 161.6741 - mae: 9.7680 - val_loss: 166.0826 - val_mae: 9.5573\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 153.2187 - mae: 9.4129 - val_loss: 158.3125 - val_mae: 9.2441\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 145.8600 - mae: 9.0924 - val_loss: 151.2905 - val_mae: 8.9671\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 139.2069 - mae: 8.8190 - val_loss: 145.0119 - val_mae: 8.7195\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 133.1919 - mae: 8.5603 - val_loss: 139.3655 - val_mae: 8.5012\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 127.8843 - mae: 8.3367 - val_loss: 134.2910 - val_mae: 8.3110\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 123.1586 - mae: 8.1417 - val_loss: 129.8704 - val_mae: 8.1553\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 118.9626 - mae: 7.9471 - val_loss: 125.8903 - val_mae: 8.0135\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.1765 - mae: 7.7762 - val_loss: 122.3265 - val_mae: 7.8884\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.7686 - mae: 7.6173 - val_loss: 119.0071 - val_mae: 7.7684\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 108.6444 - mae: 7.4788 - val_loss: 116.1884 - val_mae: 7.6670\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 105.8899 - mae: 7.3502 - val_loss: 113.5111 - val_mae: 7.5713\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 103.3594 - mae: 7.2299 - val_loss: 111.1059 - val_mae: 7.4902\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.1261 - mae: 7.1297 - val_loss: 108.9180 - val_mae: 7.4140\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.0726 - mae: 7.0298 - val_loss: 106.9356 - val_mae: 7.3413\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 97.1569 - mae: 6.9431 - val_loss: 105.2274 - val_mae: 7.2752\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 95.4542 - mae: 6.8602 - val_loss: 103.5395 - val_mae: 7.2065\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 93.8970 - mae: 6.7896 - val_loss: 102.0568 - val_mae: 7.1482\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.4712 - mae: 6.7237 - val_loss: 100.6919 - val_mae: 7.0984\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.1905 - mae: 6.6670 - val_loss: 99.4388 - val_mae: 7.0507\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.0273 - mae: 6.6134 - val_loss: 98.3582 - val_mae: 7.0075\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.9683 - mae: 6.5722 - val_loss: 97.3336 - val_mae: 6.9696\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.0162 - mae: 6.5326 - val_loss: 96.4090 - val_mae: 6.9500\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.1392 - mae: 6.4974 - val_loss: 95.6259 - val_mae: 6.9372\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.4122 - mae: 6.4696 - val_loss: 94.7897 - val_mae: 6.9239\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.6700 - mae: 6.4480 - val_loss: 94.1480 - val_mae: 6.9128\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.0638 - mae: 6.4261 - val_loss: 93.5394 - val_mae: 6.9055\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.4988 - mae: 6.4110 - val_loss: 93.0041 - val_mae: 6.9030\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.9832 - mae: 6.4010 - val_loss: 92.5503 - val_mae: 6.9019\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.5444 - mae: 6.3925 - val_loss: 92.0358 - val_mae: 6.9059\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.0888 - mae: 6.3819 - val_loss: 91.6521 - val_mae: 6.9098\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.7122 - mae: 6.3753 - val_loss: 91.2446 - val_mae: 6.9168\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.3667 - mae: 6.3730 - val_loss: 90.9029 - val_mae: 6.9241\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.0446 - mae: 6.3677 - val_loss: 90.6049 - val_mae: 6.9298\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.7511 - mae: 6.3628 - val_loss: 90.3297 - val_mae: 6.9338\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.4828 - mae: 6.3587 - val_loss: 90.0094 - val_mae: 6.9395\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.2201 - mae: 6.3586 - val_loss: 89.7208 - val_mae: 6.9461\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.9758 - mae: 6.3561 - val_loss: 89.4508 - val_mae: 6.9485\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.7451 - mae: 6.3502 - val_loss: 89.2184 - val_mae: 6.9479\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4860 - mae: 6.3465 - val_loss: 88.9230 - val_mae: 6.9481\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.2224 - mae: 6.3413 - val_loss: 88.6099 - val_mae: 6.9453\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.9564 - mae: 6.3340 - val_loss: 88.2609 - val_mae: 6.9391\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6226 - mae: 6.3226 - val_loss: 87.8653 - val_mae: 6.9248\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.2398 - mae: 6.3087 - val_loss: 87.3619 - val_mae: 6.9050\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.7271 - mae: 6.2804 - val_loss: 86.7495 - val_mae: 6.8684\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.1305 - mae: 6.2410 - val_loss: 85.9187 - val_mae: 6.8135\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.4247 - mae: 6.1908 - val_loss: 85.0685 - val_mae: 6.7549\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.6074 - mae: 6.1434 - val_loss: 84.1813 - val_mae: 6.6937\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.7461 - mae: 6.0821 - val_loss: 83.2300 - val_mae: 6.6221\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.0379 - mae: 6.0026 - val_loss: 82.1729 - val_mae: 6.5308\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.0322 - mae: 5.9612 - val_loss: 81.2262 - val_mae: 6.4725\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.0988 - mae: 5.8739 - val_loss: 80.1137 - val_mae: 6.3896\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.1004 - mae: 5.8081 - val_loss: 79.0415 - val_mae: 6.3140\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.1757 - mae: 5.7665 - val_loss: 77.8885 - val_mae: 6.2578\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.0829 - mae: 5.6871 - val_loss: 76.7817 - val_mae: 6.1568\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.1118 - mae: 5.6108 - val_loss: 75.6424 - val_mae: 6.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.0722 - mae: 5.5597 - val_loss: 74.4799 - val_mae: 6.0205\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 66.9437 - mae: 5.4883 - val_loss: 73.2740 - val_mae: 5.9291\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.8507 - mae: 5.4188 - val_loss: 72.0719 - val_mae: 5.8259\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.7831 - mae: 5.3430 - val_loss: 70.8098 - val_mae: 5.7628\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.6620 - mae: 5.3021 - val_loss: 69.6577 - val_mae: 5.6883\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.5181 - mae: 5.2330 - val_loss: 68.4783 - val_mae: 5.6071\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 61.4761 - mae: 5.1728 - val_loss: 67.1934 - val_mae: 5.5019\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.4583 - mae: 5.0960 - val_loss: 66.1184 - val_mae: 5.3969\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.4075 - mae: 5.0717 - val_loss: 65.0161 - val_mae: 5.3511\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.3166 - mae: 4.9934 - val_loss: 63.9900 - val_mae: 5.2616\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.4129 - mae: 4.9471 - val_loss: 62.9549 - val_mae: 5.1877\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.5005 - mae: 4.8788 - val_loss: 62.0282 - val_mae: 5.0994\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.6653 - mae: 4.8615 - val_loss: 61.1011 - val_mae: 5.0499\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.8397 - mae: 4.8163 - val_loss: 60.2615 - val_mae: 4.9920\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.0886 - mae: 4.7463 - val_loss: 59.4996 - val_mae: 4.9380\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.4436 - mae: 4.7651 - val_loss: 58.7077 - val_mae: 4.9360\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.6438 - mae: 4.6940 - val_loss: 58.0372 - val_mae: 4.8277\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.9035 - mae: 4.6835 - val_loss: 57.3393 - val_mae: 4.8850\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3548 - mae: 4.6728 - val_loss: 56.6658 - val_mae: 4.8042\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.7630 - mae: 4.6568 - val_loss: 56.0521 - val_mae: 4.8011\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.1325 - mae: 4.6276 - val_loss: 55.4330 - val_mae: 4.7482\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.5382 - mae: 4.5701 - val_loss: 54.8410 - val_mae: 4.7062\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.9176 - mae: 4.5564 - val_loss: 54.2613 - val_mae: 4.7263\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.4494 - mae: 4.5537 - val_loss: 53.7231 - val_mae: 4.7341\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.9138 - mae: 4.5538 - val_loss: 53.2155 - val_mae: 4.7205\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.3190 - mae: 4.5202 - val_loss: 52.6830 - val_mae: 4.6652\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.8470 - mae: 4.4840 - val_loss: 52.1847 - val_mae: 4.6374\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.4720 - mae: 4.4699 - val_loss: 51.7639 - val_mae: 4.5998\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.8255 - mae: 4.4099 - val_loss: 51.2999 - val_mae: 4.5763\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.3468 - mae: 4.4313 - val_loss: 50.7786 - val_mae: 4.6054\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.7963 - mae: 4.3760 - val_loss: 50.3995 - val_mae: 4.5435\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.3449 - mae: 4.3469 - val_loss: 49.9213 - val_mae: 4.5452\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8433 - mae: 4.3254 - val_loss: 49.5322 - val_mae: 4.5128\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.4041 - mae: 4.3219 - val_loss: 49.0259 - val_mae: 4.5139\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.9417 - mae: 4.2881 - val_loss: 48.6456 - val_mae: 4.4874\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.4880 - mae: 4.2587 - val_loss: 48.3099 - val_mae: 4.4588\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 69.5055 - mae: 5.4450\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 4ms/step - loss: 18.7186 - mae: 18.7186 - val_loss: 15.4271 - val_mae: 15.4271\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.1475 - mae: 14.1475 - val_loss: 13.1015 - val_mae: 13.1015\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.5647 - mae: 12.5647 - val_loss: 11.9507 - val_mae: 11.9507\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5683 - mae: 11.5683 - val_loss: 11.0999 - val_mae: 11.0999\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8132 - mae: 10.8132 - val_loss: 10.4295 - val_mae: 10.4295\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.1798 - mae: 10.1798 - val_loss: 9.8592 - val_mae: 9.8592\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.6276 - mae: 9.6276 - val_loss: 9.3755 - val_mae: 9.3755\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.1739 - mae: 9.1739 - val_loss: 8.9941 - val_mae: 8.9941\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8042 - mae: 8.8042 - val_loss: 8.6743 - val_mae: 8.6743\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.4846 - mae: 8.4846 - val_loss: 8.4119 - val_mae: 8.4119\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2144 - mae: 8.2144 - val_loss: 8.1949 - val_mae: 8.1949\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9668 - mae: 7.9668 - val_loss: 8.0112 - val_mae: 8.0112\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.7447 - mae: 7.7447 - val_loss: 7.8457 - val_mae: 7.8457\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.5466 - mae: 7.5466 - val_loss: 7.7045 - val_mae: 7.7045\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3699 - mae: 7.3699 - val_loss: 7.5679 - val_mae: 7.5679\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.2086 - mae: 7.2086 - val_loss: 7.4615 - val_mae: 7.4615\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0677 - mae: 7.0677 - val_loss: 7.3582 - val_mae: 7.3582\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9508 - mae: 6.9508 - val_loss: 7.2679 - val_mae: 7.2679\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8483 - mae: 6.8483 - val_loss: 7.1879 - val_mae: 7.1879\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7613 - mae: 6.7613 - val_loss: 7.1214 - val_mae: 7.1214\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6862 - mae: 6.6862 - val_loss: 7.0630 - val_mae: 7.0630\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6247 - mae: 6.6247 - val_loss: 7.0188 - val_mae: 7.0188\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5768 - mae: 6.5768 - val_loss: 6.9752 - val_mae: 6.9752\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5359 - mae: 6.5359 - val_loss: 6.9549 - val_mae: 6.9549\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5012 - mae: 6.5012 - val_loss: 6.9434 - val_mae: 6.9434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4749 - mae: 6.4749 - val_loss: 6.9327 - val_mae: 6.9327\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4535 - mae: 6.4535 - val_loss: 6.9220 - val_mae: 6.9220\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4368 - mae: 6.4368 - val_loss: 6.9142 - val_mae: 6.9142\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4238 - mae: 6.4238 - val_loss: 6.9110 - val_mae: 6.9110\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4152 - mae: 6.4152 - val_loss: 6.9087 - val_mae: 6.9087\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4064 - mae: 6.4064 - val_loss: 6.9072 - val_mae: 6.9072\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3994 - mae: 6.3994 - val_loss: 6.9061 - val_mae: 6.9061\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3938 - mae: 6.3938 - val_loss: 6.9051 - val_mae: 6.9051\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9068 - val_mae: 6.9068\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3839 - mae: 6.3839 - val_loss: 6.9047 - val_mae: 6.9047\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3790 - mae: 6.3790 - val_loss: 6.9026 - val_mae: 6.9026\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3738 - mae: 6.3738 - val_loss: 6.8968 - val_mae: 6.8968\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3674 - mae: 6.3674 - val_loss: 6.8922 - val_mae: 6.8922\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3588 - mae: 6.3588 - val_loss: 6.8830 - val_mae: 6.8830\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3487 - mae: 6.3487 - val_loss: 6.8668 - val_mae: 6.8668\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3332 - mae: 6.3332 - val_loss: 6.8486 - val_mae: 6.8486\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3092 - mae: 6.3092 - val_loss: 6.8080 - val_mae: 6.8080\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2704 - mae: 6.2704 - val_loss: 6.7410 - val_mae: 6.7410\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2168 - mae: 6.2168 - val_loss: 6.6540 - val_mae: 6.6540\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1627 - mae: 6.1627 - val_loss: 6.5861 - val_mae: 6.5861\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1057 - mae: 6.1057 - val_loss: 6.5154 - val_mae: 6.5154\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0535 - mae: 6.0535 - val_loss: 6.4642 - val_mae: 6.4642\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9986 - mae: 5.9986 - val_loss: 6.3831 - val_mae: 6.3831\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9529 - mae: 5.9529 - val_loss: 6.3373 - val_mae: 6.3373\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9033 - mae: 5.9033 - val_loss: 6.2645 - val_mae: 6.2645\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8518 - mae: 5.8518 - val_loss: 6.2201 - val_mae: 6.2201\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8042 - mae: 5.8042 - val_loss: 6.1711 - val_mae: 6.1711\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7356 - mae: 5.7356 - val_loss: 6.0580 - val_mae: 6.0580\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6725 - mae: 5.6725 - val_loss: 5.9977 - val_mae: 5.9977\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6037 - mae: 5.6037 - val_loss: 5.9129 - val_mae: 5.9129\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5327 - mae: 5.5327 - val_loss: 5.7811 - val_mae: 5.7811\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4523 - mae: 5.4523 - val_loss: 5.7279 - val_mae: 5.7279\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3768 - mae: 5.3768 - val_loss: 5.6146 - val_mae: 5.6146\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2967 - mae: 5.2967 - val_loss: 5.4850 - val_mae: 5.4850\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2155 - mae: 5.2155 - val_loss: 5.3857 - val_mae: 5.3857\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1346 - mae: 5.1346 - val_loss: 5.2817 - val_mae: 5.2817\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0504 - mae: 5.0504 - val_loss: 5.1898 - val_mae: 5.1898\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9830 - mae: 4.9830 - val_loss: 5.1187 - val_mae: 5.1187\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9187 - mae: 4.9187 - val_loss: 5.0539 - val_mae: 5.0539\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8648 - mae: 4.8648 - val_loss: 4.9761 - val_mae: 4.9761\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8155 - mae: 4.8155 - val_loss: 4.9226 - val_mae: 4.9226\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7670 - mae: 4.7670 - val_loss: 4.8748 - val_mae: 4.8748\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7234 - mae: 4.7234 - val_loss: 4.8377 - val_mae: 4.8377\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6813 - mae: 4.6813 - val_loss: 4.7804 - val_mae: 4.7804\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6440 - mae: 4.6440 - val_loss: 4.7498 - val_mae: 4.7498\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6111 - mae: 4.6111 - val_loss: 4.7145 - val_mae: 4.7145\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5778 - mae: 4.5778 - val_loss: 4.7111 - val_mae: 4.7111\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5585 - mae: 4.5585 - val_loss: 4.6921 - val_mae: 4.6921\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5222 - mae: 4.5222 - val_loss: 4.6469 - val_mae: 4.6469\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4935 - mae: 4.4935 - val_loss: 4.6198 - val_mae: 4.6198\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4651 - mae: 4.4651 - val_loss: 4.6027 - val_mae: 4.6027\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4354 - mae: 4.4354 - val_loss: 4.5704 - val_mae: 4.5704\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4129 - mae: 4.4129 - val_loss: 4.5588 - val_mae: 4.5588\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3820 - mae: 4.3820 - val_loss: 4.5411 - val_mae: 4.5411\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3738 - mae: 4.3738 - val_loss: 4.5322 - val_mae: 4.5322\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3316 - mae: 4.3316 - val_loss: 4.5041 - val_mae: 4.5041\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3240 - mae: 4.3240 - val_loss: 4.4975 - val_mae: 4.4975\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3000 - mae: 4.3000 - val_loss: 4.4943 - val_mae: 4.4943\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2800 - mae: 4.2800 - val_loss: 4.4737 - val_mae: 4.4737\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2675 - mae: 4.2675 - val_loss: 4.4652 - val_mae: 4.4652\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2446 - mae: 4.2446 - val_loss: 4.4449 - val_mae: 4.4449\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2345 - mae: 4.2345 - val_loss: 4.4378 - val_mae: 4.4378\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2030 - mae: 4.2030 - val_loss: 4.4368 - val_mae: 4.4368\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2009 - mae: 4.2009 - val_loss: 4.4209 - val_mae: 4.4209\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1858 - mae: 4.1858 - val_loss: 4.4078 - val_mae: 4.4078\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1832 - mae: 4.1832 - val_loss: 4.4044 - val_mae: 4.4044\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1579 - mae: 4.1579 - val_loss: 4.3994 - val_mae: 4.3994\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1437 - mae: 4.1437 - val_loss: 4.3758 - val_mae: 4.3758\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1315 - mae: 4.1315 - val_loss: 4.3751 - val_mae: 4.3751\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1156 - mae: 4.1156 - val_loss: 4.3594 - val_mae: 4.3594\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1035 - mae: 4.1035 - val_loss: 4.3441 - val_mae: 4.3441\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0906 - mae: 4.0906 - val_loss: 4.3326 - val_mae: 4.3326\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0794 - mae: 4.0794 - val_loss: 4.3273 - val_mae: 4.3273\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0687 - mae: 4.0687 - val_loss: 4.3168 - val_mae: 4.3168\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0646 - mae: 4.0646 - val_loss: 4.2953 - val_mae: 4.2953\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6308 - mae: 5.6308\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 389.2519 - mae: 17.5192 - val_loss: 294.0572 - val_mae: 14.3419\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 251.5182 - mae: 13.2486 - val_loss: 237.0055 - val_mae: 12.3376\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 212.9350 - mae: 11.8306 - val_loss: 209.0475 - val_mae: 11.2801\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 190.0322 - mae: 10.9441 - val_loss: 189.6809 - val_mae: 10.5148\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 173.4006 - mae: 10.2607 - val_loss: 175.4914 - val_mae: 9.9393\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.5867 - mae: 9.7041 - val_loss: 163.5397 - val_mae: 9.4536\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 149.7344 - mae: 9.2577 - val_loss: 153.8471 - val_mae: 9.0673\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 140.6982 - mae: 8.8756 - val_loss: 145.3056 - val_mae: 8.7312\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 132.9201 - mae: 8.5460 - val_loss: 138.2734 - val_mae: 8.4602\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 126.1832 - mae: 8.2733 - val_loss: 131.8315 - val_mae: 8.2231\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 120.3336 - mae: 8.0071 - val_loss: 126.5318 - val_mae: 8.0355\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 115.3683 - mae: 7.7827 - val_loss: 122.0502 - val_mae: 7.8780\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 111.1304 - mae: 7.5905 - val_loss: 117.9799 - val_mae: 7.7314\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 107.3176 - mae: 7.4181 - val_loss: 114.5471 - val_mae: 7.6078\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 104.0744 - mae: 7.2598 - val_loss: 111.3609 - val_mae: 7.4983\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 101.1933 - mae: 7.1293 - val_loss: 108.7623 - val_mae: 7.4079\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 98.6929 - mae: 7.0165 - val_loss: 106.4085 - val_mae: 7.3208\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 96.4998 - mae: 6.9089 - val_loss: 104.3669 - val_mae: 7.2403\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 94.5207 - mae: 6.8172 - val_loss: 102.4581 - val_mae: 7.1630\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 92.7803 - mae: 6.7432 - val_loss: 100.8584 - val_mae: 7.1042\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.2843 - mae: 6.6751 - val_loss: 99.2689 - val_mae: 7.0437\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 89.8663 - mae: 6.6065 - val_loss: 98.0762 - val_mae: 6.9965\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 88.6979 - mae: 6.5560 - val_loss: 96.9835 - val_mae: 6.9611\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.6367 - mae: 6.5117 - val_loss: 95.9425 - val_mae: 6.9417\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 86.6621 - mae: 6.4790 - val_loss: 95.1220 - val_mae: 6.9289\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.8570 - mae: 6.4523 - val_loss: 94.2432 - val_mae: 6.9143\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 85.1161 - mae: 6.4284 - val_loss: 93.5549 - val_mae: 6.9054\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 84.4654 - mae: 6.4109 - val_loss: 92.9121 - val_mae: 6.9028\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.8774 - mae: 6.3968 - val_loss: 92.3546 - val_mae: 6.9030\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 83.3537 - mae: 6.3852 - val_loss: 91.8881 - val_mae: 6.9083\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.9218 - mae: 6.3804 - val_loss: 91.4123 - val_mae: 6.9159\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.5163 - mae: 6.3748 - val_loss: 91.0167 - val_mae: 6.9251\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 82.1553 - mae: 6.3697 - val_loss: 90.7411 - val_mae: 6.9307\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.8317 - mae: 6.3681 - val_loss: 90.3585 - val_mae: 6.9405\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.5334 - mae: 6.3648 - val_loss: 90.0838 - val_mae: 6.9465\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.2623 - mae: 6.3617 - val_loss: 89.8223 - val_mae: 6.9523\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.0113 - mae: 6.3618 - val_loss: 89.5148 - val_mae: 6.9611\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.7745 - mae: 6.3623 - val_loss: 89.2450 - val_mae: 6.9667\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.5390 - mae: 6.3576 - val_loss: 89.0296 - val_mae: 6.9672\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.3364 - mae: 6.3595 - val_loss: 88.7490 - val_mae: 6.9706\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.1028 - mae: 6.3535 - val_loss: 88.4938 - val_mae: 6.9690\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.8703 - mae: 6.3455 - val_loss: 88.1998 - val_mae: 6.9643\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.6158 - mae: 6.3404 - val_loss: 87.8635 - val_mae: 6.9585\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 79.2906 - mae: 6.3324 - val_loss: 87.5011 - val_mae: 6.9465\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.9125 - mae: 6.3130 - val_loss: 87.0343 - val_mae: 6.9231\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 78.4557 - mae: 6.2884 - val_loss: 86.4235 - val_mae: 6.8884\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 77.8619 - mae: 6.2529 - val_loss: 85.6652 - val_mae: 6.8384\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 77.1517 - mae: 6.2058 - val_loss: 84.7687 - val_mae: 6.7787\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 76.3766 - mae: 6.1456 - val_loss: 83.8904 - val_mae: 6.7122\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 75.5419 - mae: 6.0912 - val_loss: 82.9599 - val_mae: 6.6494\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 74.7111 - mae: 6.0363 - val_loss: 82.0022 - val_mae: 6.5769\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.8596 - mae: 5.9634 - val_loss: 81.0170 - val_mae: 6.4844\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 73.0561 - mae: 5.9250 - val_loss: 80.1264 - val_mae: 6.4489\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 72.1659 - mae: 5.8579 - val_loss: 79.1444 - val_mae: 6.3735\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 71.3172 - mae: 5.7691 - val_loss: 78.1128 - val_mae: 6.3038\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 70.2984 - mae: 5.7351 - val_loss: 77.0549 - val_mae: 6.2425\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 69.3727 - mae: 5.6462 - val_loss: 75.8959 - val_mae: 6.1583\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 68.2486 - mae: 5.6088 - val_loss: 74.7326 - val_mae: 6.1015\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 67.2571 - mae: 5.5123 - val_loss: 73.4313 - val_mae: 5.9937\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 65.9212 - mae: 5.4665 - val_loss: 72.1618 - val_mae: 5.9255\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 64.6963 - mae: 5.3977 - val_loss: 70.8365 - val_mae: 5.8309\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 63.4484 - mae: 5.3189 - val_loss: 69.4687 - val_mae: 5.7158\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 62.1793 - mae: 5.2364 - val_loss: 68.0942 - val_mae: 5.6039\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 60.9811 - mae: 5.1739 - val_loss: 66.8027 - val_mae: 5.5094\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 59.8242 - mae: 5.0985 - val_loss: 65.4896 - val_mae: 5.3879\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 58.6789 - mae: 5.0546 - val_loss: 64.4178 - val_mae: 5.3600\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 57.6371 - mae: 4.9913 - val_loss: 63.2655 - val_mae: 5.2577\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 56.6136 - mae: 4.9396 - val_loss: 62.2594 - val_mae: 5.1914\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 55.8317 - mae: 4.8788 - val_loss: 61.3189 - val_mae: 5.1383\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.8921 - mae: 4.8409 - val_loss: 60.3963 - val_mae: 5.0849\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 54.0701 - mae: 4.8378 - val_loss: 59.5497 - val_mae: 5.0565\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 53.2534 - mae: 4.7914 - val_loss: 58.7461 - val_mae: 4.9667\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 52.6261 - mae: 4.7477 - val_loss: 57.9781 - val_mae: 4.9397\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.9046 - mae: 4.7125 - val_loss: 57.2951 - val_mae: 4.8754\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 51.3180 - mae: 4.6674 - val_loss: 56.6507 - val_mae: 4.8762\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.6593 - mae: 4.6795 - val_loss: 56.0038 - val_mae: 4.8854\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 50.0378 - mae: 4.6434 - val_loss: 55.3821 - val_mae: 4.8488\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 49.4637 - mae: 4.6559 - val_loss: 54.7436 - val_mae: 4.8207\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.8480 - mae: 4.6128 - val_loss: 54.1646 - val_mae: 4.7509\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 48.2733 - mae: 4.5671 - val_loss: 53.6135 - val_mae: 4.7451\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.7415 - mae: 4.5803 - val_loss: 52.9937 - val_mae: 4.7313\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 47.1264 - mae: 4.5412 - val_loss: 52.4625 - val_mae: 4.7167\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.6305 - mae: 4.5054 - val_loss: 51.9344 - val_mae: 4.6966\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 46.0576 - mae: 4.4997 - val_loss: 51.3766 - val_mae: 4.6681\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 45.5381 - mae: 4.4400 - val_loss: 50.8697 - val_mae: 4.6448\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.9340 - mae: 4.4327 - val_loss: 50.3623 - val_mae: 4.6278\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 44.4758 - mae: 4.4078 - val_loss: 49.8429 - val_mae: 4.6007\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.8950 - mae: 4.3611 - val_loss: 49.3960 - val_mae: 4.5358\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 43.4243 - mae: 4.3240 - val_loss: 48.9664 - val_mae: 4.5162\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.8722 - mae: 4.3180 - val_loss: 48.4100 - val_mae: 4.5133\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 42.3662 - mae: 4.2701 - val_loss: 48.0273 - val_mae: 4.4747\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.8649 - mae: 4.2452 - val_loss: 47.5557 - val_mae: 4.4784\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 41.4012 - mae: 4.2363 - val_loss: 47.0910 - val_mae: 4.4984\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.9786 - mae: 4.2202 - val_loss: 46.6588 - val_mae: 4.4872\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.5395 - mae: 4.1983 - val_loss: 46.2351 - val_mae: 4.4499\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 40.0410 - mae: 4.2001 - val_loss: 45.8751 - val_mae: 4.4027\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.5962 - mae: 4.1514 - val_loss: 45.4691 - val_mae: 4.4024\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 39.1926 - mae: 4.1337 - val_loss: 45.1063 - val_mae: 4.3800\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.7869 - mae: 4.0938 - val_loss: 44.7261 - val_mae: 4.3642\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 38.4007 - mae: 4.1269 - val_loss: 44.2979 - val_mae: 4.3725\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 62.8016 - mae: 5.1480\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 18.4369 - mae: 18.4369 - val_loss: 15.0551 - val_mae: 15.0551\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.8861 - mae: 13.8861 - val_loss: 12.9566 - val_mae: 12.9566\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4709 - mae: 12.4709 - val_loss: 11.9239 - val_mae: 11.9239\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 11.5779 - mae: 11.5779 - val_loss: 11.1308 - val_mae: 11.1308\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.8673 - mae: 10.8673 - val_loss: 10.4991 - val_mae: 10.4991\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.2638 - mae: 10.2638 - val_loss: 9.9533 - val_mae: 9.9533\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 9.7287 - mae: 9.7287 - val_loss: 9.4680 - val_mae: 9.4680\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 9.2618 - mae: 9.2618 - val_loss: 9.0719 - val_mae: 9.0719\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8878 - mae: 8.8878 - val_loss: 8.7543 - val_mae: 8.7543\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.5759 - mae: 8.5759 - val_loss: 8.5034 - val_mae: 8.5034\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3122 - mae: 8.3122 - val_loss: 8.2685 - val_mae: 8.2685\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.0739 - mae: 8.0739 - val_loss: 8.1002 - val_mae: 8.1002\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.8573 - mae: 7.8573 - val_loss: 7.9399 - val_mae: 7.9399\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6611 - mae: 7.6611 - val_loss: 7.7872 - val_mae: 7.7872\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.4883 - mae: 7.4883 - val_loss: 7.6588 - val_mae: 7.6588\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3264 - mae: 7.3264 - val_loss: 7.5407 - val_mae: 7.5407\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.1722 - mae: 7.1722 - val_loss: 7.4341 - val_mae: 7.4341\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.0391 - mae: 7.0391 - val_loss: 7.3334 - val_mae: 7.3334\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.9215 - mae: 6.9215 - val_loss: 7.2437 - val_mae: 7.2437\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.8195 - mae: 6.8195 - val_loss: 7.1656 - val_mae: 7.1656\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.7382 - mae: 6.7382 - val_loss: 7.1061 - val_mae: 7.1061\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6687 - mae: 6.6687 - val_loss: 7.0494 - val_mae: 7.0494\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6090 - mae: 6.6090 - val_loss: 7.0002 - val_mae: 7.0002\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5642 - mae: 6.5642 - val_loss: 6.9660 - val_mae: 6.9660\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5232 - mae: 6.5232 - val_loss: 6.9503 - val_mae: 6.9503\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4929 - mae: 6.4929 - val_loss: 6.9386 - val_mae: 6.9386\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4687 - mae: 6.4687 - val_loss: 6.9287 - val_mae: 6.9287\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4482 - mae: 6.4482 - val_loss: 6.9177 - val_mae: 6.9177\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4328 - mae: 6.4328 - val_loss: 6.9113 - val_mae: 6.9113\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4213 - mae: 6.4213 - val_loss: 6.9082 - val_mae: 6.9082\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4120 - mae: 6.4120 - val_loss: 6.9056 - val_mae: 6.9056\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4046 - mae: 6.4046 - val_loss: 6.9032 - val_mae: 6.9032\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3980 - mae: 6.3980 - val_loss: 6.9015 - val_mae: 6.9015\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3908 - mae: 6.3908 - val_loss: 6.8992 - val_mae: 6.8992\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3853 - mae: 6.3853 - val_loss: 6.8977 - val_mae: 6.8977\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3780 - mae: 6.3780 - val_loss: 6.8962 - val_mae: 6.8962\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3729 - mae: 6.3729 - val_loss: 6.8904 - val_mae: 6.8904\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3648 - mae: 6.3648 - val_loss: 6.8838 - val_mae: 6.8838\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3556 - mae: 6.3556 - val_loss: 6.8752 - val_mae: 6.8752\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3435 - mae: 6.3435 - val_loss: 6.8618 - val_mae: 6.8618\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3274 - mae: 6.3274 - val_loss: 6.8382 - val_mae: 6.8382\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3047 - mae: 6.3047 - val_loss: 6.8001 - val_mae: 6.8001\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2676 - mae: 6.2676 - val_loss: 6.7425 - val_mae: 6.7425\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2170 - mae: 6.2170 - val_loss: 6.6612 - val_mae: 6.6612\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1642 - mae: 6.1642 - val_loss: 6.5930 - val_mae: 6.5930\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.1147 - mae: 6.1147 - val_loss: 6.5211 - val_mae: 6.5211\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0630 - mae: 6.0630 - val_loss: 6.4568 - val_mae: 6.4568\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0165 - mae: 6.0165 - val_loss: 6.4157 - val_mae: 6.4157\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9739 - mae: 5.9739 - val_loss: 6.3555 - val_mae: 6.3555\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9293 - mae: 5.9293 - val_loss: 6.2848 - val_mae: 6.2848\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8847 - mae: 5.8847 - val_loss: 6.2488 - val_mae: 6.2488\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.8289 - mae: 5.8289 - val_loss: 6.1697 - val_mae: 6.1697\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7762 - mae: 5.7762 - val_loss: 6.1189 - val_mae: 6.1189\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7224 - mae: 5.7224 - val_loss: 6.0475 - val_mae: 6.0475\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.6643 - mae: 5.6643 - val_loss: 5.9653 - val_mae: 5.9653\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5987 - mae: 5.5987 - val_loss: 5.8718 - val_mae: 5.8718\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5383 - mae: 5.5383 - val_loss: 5.8109 - val_mae: 5.8109\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4686 - mae: 5.4686 - val_loss: 5.7120 - val_mae: 5.7120\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.4013 - mae: 5.4013 - val_loss: 5.6276 - val_mae: 5.6276\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3305 - mae: 5.3305 - val_loss: 5.5523 - val_mae: 5.5523\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2591 - mae: 5.2591 - val_loss: 5.4420 - val_mae: 5.4420\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1941 - mae: 5.1941 - val_loss: 5.3648 - val_mae: 5.3648\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.1238 - mae: 5.1238 - val_loss: 5.2717 - val_mae: 5.2717\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0546 - mae: 5.0546 - val_loss: 5.1851 - val_mae: 5.1851\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9930 - mae: 4.9930 - val_loss: 5.0785 - val_mae: 5.0785\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9383 - mae: 4.9383 - val_loss: 5.0055 - val_mae: 5.0055\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8938 - mae: 4.8938 - val_loss: 4.9556 - val_mae: 4.9556\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.8430 - mae: 4.8430 - val_loss: 4.8967 - val_mae: 4.8967\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7972 - mae: 4.7972 - val_loss: 4.8513 - val_mae: 4.8513\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7631 - mae: 4.7631 - val_loss: 4.8118 - val_mae: 4.8118\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7239 - mae: 4.7239 - val_loss: 4.7795 - val_mae: 4.7795\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6859 - mae: 4.6859 - val_loss: 4.7491 - val_mae: 4.7491\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6532 - mae: 4.6532 - val_loss: 4.7189 - val_mae: 4.7189\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.6266 - mae: 4.6266 - val_loss: 4.6987 - val_mae: 4.6987\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5877 - mae: 4.5877 - val_loss: 4.6679 - val_mae: 4.6679\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5631 - mae: 4.5631 - val_loss: 4.6521 - val_mae: 4.6521\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5343 - mae: 4.5343 - val_loss: 4.6262 - val_mae: 4.6262\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.5086 - mae: 4.5086 - val_loss: 4.6086 - val_mae: 4.6086\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4770 - mae: 4.4770 - val_loss: 4.5696 - val_mae: 4.5696\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4493 - mae: 4.4493 - val_loss: 4.5593 - val_mae: 4.5593\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.4183 - mae: 4.4183 - val_loss: 4.5363 - val_mae: 4.5363\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3882 - mae: 4.3882 - val_loss: 4.5164 - val_mae: 4.5164\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3608 - mae: 4.3608 - val_loss: 4.4952 - val_mae: 4.4952\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3305 - mae: 4.3305 - val_loss: 4.4794 - val_mae: 4.4794\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.3151 - mae: 4.3151 - val_loss: 4.4657 - val_mae: 4.4657\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2909 - mae: 4.2909 - val_loss: 4.4551 - val_mae: 4.4551\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2644 - mae: 4.2644 - val_loss: 4.4418 - val_mae: 4.4418\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2436 - mae: 4.2436 - val_loss: 4.4304 - val_mae: 4.4304\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2223 - mae: 4.2223 - val_loss: 4.4071 - val_mae: 4.4071\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.2072 - mae: 4.2072 - val_loss: 4.3890 - val_mae: 4.3890\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1883 - mae: 4.1883 - val_loss: 4.3806 - val_mae: 4.3806\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1741 - mae: 4.1741 - val_loss: 4.3772 - val_mae: 4.3772\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1604 - mae: 4.1604 - val_loss: 4.3642 - val_mae: 4.3642\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1439 - mae: 4.1439 - val_loss: 4.3457 - val_mae: 4.3457\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1286 - mae: 4.1286 - val_loss: 4.3332 - val_mae: 4.3332\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1184 - mae: 4.1184 - val_loss: 4.3388 - val_mae: 4.3388\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.1023 - mae: 4.1023 - val_loss: 4.3172 - val_mae: 4.3172\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0906 - mae: 4.0906 - val_loss: 4.3110 - val_mae: 4.3110\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0827 - mae: 4.0827 - val_loss: 4.3048 - val_mae: 4.3048\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.0717 - mae: 4.0717 - val_loss: 4.2931 - val_mae: 4.2931\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.5748 - mae: 5.5748\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 269.3442 - mae: 13.4016 - val_loss: 59.8217 - val_mae: 5.8256\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.3587 - mae: 4.4916 - val_loss: 28.3310 - val_mae: 3.5969\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.6229 - mae: 3.5005 - val_loss: 24.2644 - val_mae: 3.5728\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.0839 - mae: 3.2083 - val_loss: 20.8077 - val_mae: 3.0710\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.7758 - mae: 2.9460 - val_loss: 19.5912 - val_mae: 3.1241\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.2260 - mae: 2.8285 - val_loss: 18.6675 - val_mae: 3.0529\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.8690 - mae: 2.7368 - val_loss: 18.2648 - val_mae: 2.9795\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3049 - mae: 2.6493 - val_loss: 17.4414 - val_mae: 2.9002\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.4370 - mae: 2.5947 - val_loss: 17.4851 - val_mae: 2.8905\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2666 - mae: 2.5455 - val_loss: 16.6135 - val_mae: 2.8172\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.0193 - mae: 2.5802 - val_loss: 16.3281 - val_mae: 2.8512\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3921 - mae: 2.4642 - val_loss: 16.0942 - val_mae: 2.7961\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0897 - mae: 2.4674 - val_loss: 16.0357 - val_mae: 2.7982\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4797 - mae: 2.3624 - val_loss: 15.6019 - val_mae: 2.7688\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4122 - mae: 2.4173 - val_loss: 15.9093 - val_mae: 2.7118\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2203 - mae: 2.3596 - val_loss: 15.8148 - val_mae: 2.7693\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0354 - mae: 2.3420 - val_loss: 15.5711 - val_mae: 2.7388\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4974 - mae: 2.2921 - val_loss: 15.0313 - val_mae: 2.6767\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1687 - mae: 2.2712 - val_loss: 15.1020 - val_mae: 2.6990\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9662 - mae: 2.2575 - val_loss: 14.6084 - val_mae: 2.6586\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8914 - mae: 2.2341 - val_loss: 14.3381 - val_mae: 2.6393\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6375 - mae: 2.1943 - val_loss: 14.2649 - val_mae: 2.6076\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4294 - mae: 2.2002 - val_loss: 14.3238 - val_mae: 2.6248\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3899 - mae: 2.1793 - val_loss: 14.6905 - val_mae: 2.6321\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0678 - mae: 2.1543 - val_loss: 13.9754 - val_mae: 2.5631\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8723 - mae: 2.1293 - val_loss: 14.2753 - val_mae: 2.5999\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6220 - mae: 2.1093 - val_loss: 13.8643 - val_mae: 2.5580\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5527 - mae: 2.1103 - val_loss: 13.7336 - val_mae: 2.5574\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5960 - mae: 2.1099 - val_loss: 13.9361 - val_mae: 2.5522\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2158 - mae: 2.0576 - val_loss: 13.9196 - val_mae: 2.5539\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0257 - mae: 2.0411 - val_loss: 13.9503 - val_mae: 2.6071\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8508 - mae: 2.0181 - val_loss: 13.7990 - val_mae: 2.5082\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8288 - mae: 2.0161 - val_loss: 13.5729 - val_mae: 2.5086\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6254 - mae: 1.9942 - val_loss: 13.8817 - val_mae: 2.4945\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6558 - mae: 1.9730 - val_loss: 13.7901 - val_mae: 2.5104\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3349 - mae: 1.9728 - val_loss: 13.4887 - val_mae: 2.5327\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2510 - mae: 1.9479 - val_loss: 13.4669 - val_mae: 2.5165\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9549 - mae: 1.9132 - val_loss: 13.3665 - val_mae: 2.4802\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9214 - mae: 1.9060 - val_loss: 13.6420 - val_mae: 2.5080\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8184 - mae: 1.9017 - val_loss: 13.2942 - val_mae: 2.4735\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5709 - mae: 1.8586 - val_loss: 13.5130 - val_mae: 2.5454\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5620 - mae: 1.8647 - val_loss: 13.4861 - val_mae: 2.5289\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4553 - mae: 1.8662 - val_loss: 13.4221 - val_mae: 2.4679\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1478 - mae: 1.8125 - val_loss: 13.3650 - val_mae: 2.4780\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2190 - mae: 1.8396 - val_loss: 13.5168 - val_mae: 2.4608\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3806 - mae: 1.8599 - val_loss: 13.3020 - val_mae: 2.4830\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1584 - mae: 1.8210 - val_loss: 13.1928 - val_mae: 2.4607\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9692 - mae: 1.8095 - val_loss: 13.8110 - val_mae: 2.4688\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8421 - mae: 1.7995 - val_loss: 13.2540 - val_mae: 2.5054\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4078 - mae: 1.7087 - val_loss: 13.8231 - val_mae: 2.4494\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6349 - mae: 1.7144 - val_loss: 13.5451 - val_mae: 2.4815\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4472 - mae: 1.7098 - val_loss: 13.4799 - val_mae: 2.5004\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3840 - mae: 1.7130 - val_loss: 13.2321 - val_mae: 2.4684\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3558 - mae: 1.7002 - val_loss: 13.4540 - val_mae: 2.5259\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1902 - mae: 1.6986 - val_loss: 13.4770 - val_mae: 2.4289\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2133 - mae: 1.6772 - val_loss: 13.2603 - val_mae: 2.4415\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9624 - mae: 1.6400 - val_loss: 13.5186 - val_mae: 2.4458\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8779 - mae: 1.6324 - val_loss: 13.4075 - val_mae: 2.4820\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8713 - mae: 1.6314 - val_loss: 13.6088 - val_mae: 2.4417\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7803 - mae: 1.6079 - val_loss: 13.6070 - val_mae: 2.4540\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.6575 - mae: 1.6075 - val_loss: 13.1250 - val_mae: 2.4239\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5645 - mae: 1.5810 - val_loss: 13.2948 - val_mae: 2.4615\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5874 - mae: 1.5976 - val_loss: 13.6330 - val_mae: 2.4288\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6428 - mae: 1.5574 - val_loss: 13.6537 - val_mae: 2.4599\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4478 - mae: 1.5607 - val_loss: 13.1416 - val_mae: 2.4236\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3662 - mae: 1.5564 - val_loss: 13.5869 - val_mae: 2.4513\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3450 - mae: 1.5311 - val_loss: 13.5633 - val_mae: 2.4389\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3037 - mae: 1.5285 - val_loss: 13.4069 - val_mae: 2.4194\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0981 - mae: 1.5071 - val_loss: 13.3065 - val_mae: 2.4657\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3108 - mae: 1.5091 - val_loss: 13.8371 - val_mae: 2.4399\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0320 - mae: 1.4765 - val_loss: 13.6922 - val_mae: 2.4187\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0991 - mae: 1.4707 - val_loss: 13.2665 - val_mae: 2.4133\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0321 - mae: 1.4739 - val_loss: 13.2251 - val_mae: 2.4413\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9226 - mae: 1.4495 - val_loss: 13.6770 - val_mae: 2.4202\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9399 - mae: 1.4634 - val_loss: 13.9610 - val_mae: 2.5211\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7584 - mae: 1.4361 - val_loss: 13.8749 - val_mae: 2.4232\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7326 - mae: 1.4202 - val_loss: 13.7509 - val_mae: 2.4133\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7118 - mae: 1.4450 - val_loss: 13.6248 - val_mae: 2.4362\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6594 - mae: 1.3985 - val_loss: 13.3204 - val_mae: 2.4049\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6537 - mae: 1.4059 - val_loss: 13.9732 - val_mae: 2.4627\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6374 - mae: 1.4389 - val_loss: 14.0627 - val_mae: 2.4591\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6094 - mae: 1.3774 - val_loss: 13.6749 - val_mae: 2.4937\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4334 - mae: 1.3553 - val_loss: 13.8629 - val_mae: 2.4329\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4214 - mae: 1.3489 - val_loss: 13.4842 - val_mae: 2.3966\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3410 - mae: 1.3209 - val_loss: 13.3721 - val_mae: 2.3802\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3423 - mae: 1.3641 - val_loss: 13.6177 - val_mae: 2.3550\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2597 - mae: 1.3129 - val_loss: 13.7707 - val_mae: 2.4650\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2838 - mae: 1.3071 - val_loss: 13.7984 - val_mae: 2.4103\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1773 - mae: 1.3090 - val_loss: 13.7136 - val_mae: 2.4044\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2321 - mae: 1.3009 - val_loss: 13.3394 - val_mae: 2.3961\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0940 - mae: 1.3055 - val_loss: 13.4907 - val_mae: 2.3770\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0619 - mae: 1.2517 - val_loss: 13.5110 - val_mae: 2.4218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3765 - mae: 1.3587 - val_loss: 14.1308 - val_mae: 2.4056\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2327 - mae: 1.3228 - val_loss: 13.6792 - val_mae: 2.3993\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0071 - mae: 1.2580 - val_loss: 13.9117 - val_mae: 2.3863\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9955 - mae: 1.2656 - val_loss: 13.6950 - val_mae: 2.4522\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8883 - mae: 1.2348 - val_loss: 13.6090 - val_mae: 2.3726\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8561 - mae: 1.2338 - val_loss: 13.7427 - val_mae: 2.4183\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8776 - mae: 1.2086 - val_loss: 13.6091 - val_mae: 2.4104\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7829 - mae: 1.2157 - val_loss: 13.6882 - val_mae: 2.4458\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.2681 - mae: 3.3991\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 12.7723 - mae: 12.7723 - val_loss: 5.3253 - val_mae: 5.3253\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4272 - mae: 4.4272 - val_loss: 3.4820 - val_mae: 3.4820\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3590 - mae: 3.3590 - val_loss: 3.0735 - val_mae: 3.0735\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0324 - mae: 3.0324 - val_loss: 2.9718 - val_mae: 2.9718\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7959 - mae: 2.7959 - val_loss: 2.9172 - val_mae: 2.9172\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7625 - mae: 2.7625 - val_loss: 2.7547 - val_mae: 2.7547\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6749 - mae: 2.6749 - val_loss: 2.7593 - val_mae: 2.7593\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5680 - mae: 2.5680 - val_loss: 2.6441 - val_mae: 2.6441\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4585 - mae: 2.4585 - val_loss: 2.5183 - val_mae: 2.5183\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4448 - mae: 2.4448 - val_loss: 2.5836 - val_mae: 2.5836\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3845 - mae: 2.3845 - val_loss: 2.5664 - val_mae: 2.5664\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3490 - mae: 2.3490 - val_loss: 2.4806 - val_mae: 2.4806\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3120 - mae: 2.3120 - val_loss: 2.5640 - val_mae: 2.5640\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2871 - mae: 2.2871 - val_loss: 2.5487 - val_mae: 2.5487\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2407 - mae: 2.2407 - val_loss: 2.4881 - val_mae: 2.4881\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2147 - mae: 2.2147 - val_loss: 2.4811 - val_mae: 2.4811\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1665 - mae: 2.1665 - val_loss: 2.5233 - val_mae: 2.5233\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1548 - mae: 2.1548 - val_loss: 2.4237 - val_mae: 2.4237\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1383 - mae: 2.1383 - val_loss: 2.4613 - val_mae: 2.4613\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1095 - mae: 2.1095 - val_loss: 2.4835 - val_mae: 2.4835\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1566 - mae: 2.1566 - val_loss: 2.5013 - val_mae: 2.5013\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0922 - mae: 2.0922 - val_loss: 2.4821 - val_mae: 2.4821\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0649 - mae: 2.0649 - val_loss: 2.4268 - val_mae: 2.4268\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0650 - mae: 2.0650 - val_loss: 2.4694 - val_mae: 2.4694\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0659 - mae: 2.0659 - val_loss: 2.4148 - val_mae: 2.4148\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9955 - mae: 1.9955 - val_loss: 2.4130 - val_mae: 2.4130\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0122 - mae: 2.0122 - val_loss: 2.4475 - val_mae: 2.4475\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0150 - mae: 2.0150 - val_loss: 2.4144 - val_mae: 2.4144\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9572 - mae: 1.9572 - val_loss: 2.4348 - val_mae: 2.4348\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9540 - mae: 1.9540 - val_loss: 2.4120 - val_mae: 2.4120\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9253 - mae: 1.9253 - val_loss: 2.4371 - val_mae: 2.4371\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9213 - mae: 1.9213 - val_loss: 2.4198 - val_mae: 2.4198\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9026 - mae: 1.9026 - val_loss: 2.4133 - val_mae: 2.4133\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8642 - mae: 1.8642 - val_loss: 2.4707 - val_mae: 2.4707\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8779 - mae: 1.8779 - val_loss: 2.4498 - val_mae: 2.4498\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8554 - mae: 1.8554 - val_loss: 2.3893 - val_mae: 2.3893\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8657 - mae: 1.8657 - val_loss: 2.4273 - val_mae: 2.4273\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8735 - mae: 1.8735 - val_loss: 2.4605 - val_mae: 2.4605\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8410 - mae: 1.8410 - val_loss: 2.4428 - val_mae: 2.4428\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8199 - mae: 1.8199 - val_loss: 2.4851 - val_mae: 2.4851\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8346 - mae: 1.8346 - val_loss: 2.4443 - val_mae: 2.4443\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8020 - mae: 1.8020 - val_loss: 2.4658 - val_mae: 2.4658\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7845 - mae: 1.7845 - val_loss: 2.4107 - val_mae: 2.4107\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7543 - mae: 1.7543 - val_loss: 2.4072 - val_mae: 2.4072\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7231 - mae: 1.7231 - val_loss: 2.4636 - val_mae: 2.4636\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7230 - mae: 1.7230 - val_loss: 2.5269 - val_mae: 2.5269\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7326 - mae: 1.7326 - val_loss: 2.4455 - val_mae: 2.4455\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7148 - mae: 1.7148 - val_loss: 2.4549 - val_mae: 2.4549\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7412 - mae: 1.7412 - val_loss: 2.4286 - val_mae: 2.4286\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6931 - mae: 1.6931 - val_loss: 2.5203 - val_mae: 2.5203\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7276 - mae: 1.7276 - val_loss: 2.4370 - val_mae: 2.4370\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6798 - mae: 1.6798 - val_loss: 2.4417 - val_mae: 2.4417\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6583 - mae: 1.6583 - val_loss: 2.5074 - val_mae: 2.5074\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7169 - mae: 1.7169 - val_loss: 2.4571 - val_mae: 2.4571\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6321 - mae: 1.6321 - val_loss: 2.4164 - val_mae: 2.4164\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6319 - mae: 1.6319 - val_loss: 2.4022 - val_mae: 2.4022\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5960 - mae: 1.5960 - val_loss: 2.4013 - val_mae: 2.4013\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5952 - mae: 1.5952 - val_loss: 2.4088 - val_mae: 2.4088\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5779 - mae: 1.5779 - val_loss: 2.4421 - val_mae: 2.4421\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5794 - mae: 1.5794 - val_loss: 2.4710 - val_mae: 2.4710\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5621 - mae: 1.5621 - val_loss: 2.4971 - val_mae: 2.4971\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5926 - mae: 1.5926 - val_loss: 2.4015 - val_mae: 2.4015\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5663 - mae: 1.5663 - val_loss: 2.4710 - val_mae: 2.4710\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5471 - mae: 1.5471 - val_loss: 2.4729 - val_mae: 2.4729\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5636 - mae: 1.5636 - val_loss: 2.4724 - val_mae: 2.4724\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5507 - mae: 1.5507 - val_loss: 2.4340 - val_mae: 2.4340\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5225 - mae: 1.5225 - val_loss: 2.4673 - val_mae: 2.4673\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5042 - mae: 1.5042 - val_loss: 2.4503 - val_mae: 2.4503\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5228 - mae: 1.5228 - val_loss: 2.4731 - val_mae: 2.4731\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4801 - mae: 1.4801 - val_loss: 2.4637 - val_mae: 2.4637\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4881 - mae: 1.4881 - val_loss: 2.4423 - val_mae: 2.4423\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4716 - mae: 1.4716 - val_loss: 2.4464 - val_mae: 2.4464\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4770 - mae: 1.4770 - val_loss: 2.4335 - val_mae: 2.4335\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4489 - mae: 1.4489 - val_loss: 2.4248 - val_mae: 2.4248\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4462 - mae: 1.4462 - val_loss: 2.4386 - val_mae: 2.4386\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4719 - mae: 1.4719 - val_loss: 2.4410 - val_mae: 2.4410\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4359 - mae: 1.4359 - val_loss: 2.4508 - val_mae: 2.4508\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4389 - mae: 1.4389 - val_loss: 2.3876 - val_mae: 2.3876\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4470 - mae: 1.4470 - val_loss: 2.4774 - val_mae: 2.4774\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4503 - mae: 1.4503 - val_loss: 2.4501 - val_mae: 2.4501\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4399 - mae: 1.4399 - val_loss: 2.4298 - val_mae: 2.4298\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4212 - mae: 1.4212 - val_loss: 2.4511 - val_mae: 2.4511\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4013 - mae: 1.4013 - val_loss: 2.4629 - val_mae: 2.4629\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3789 - mae: 1.3789 - val_loss: 2.5020 - val_mae: 2.5020\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3710 - mae: 1.3710 - val_loss: 2.4285 - val_mae: 2.4285\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3465 - mae: 1.3465 - val_loss: 2.4561 - val_mae: 2.4561\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3846 - mae: 1.3846 - val_loss: 2.4568 - val_mae: 2.4568\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3606 - mae: 1.3606 - val_loss: 2.4615 - val_mae: 2.4615\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3286 - mae: 1.3286 - val_loss: 2.4607 - val_mae: 2.4607\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3595 - mae: 1.3595 - val_loss: 2.4662 - val_mae: 2.4662\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3448 - mae: 1.3448 - val_loss: 2.4587 - val_mae: 2.4587\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3083 - mae: 1.3083 - val_loss: 2.4301 - val_mae: 2.4301\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3282 - mae: 1.3282 - val_loss: 2.4153 - val_mae: 2.4153\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2849 - mae: 1.2849 - val_loss: 2.4483 - val_mae: 2.4483\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2975 - mae: 1.2975 - val_loss: 2.4839 - val_mae: 2.4839\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2935 - mae: 1.2935 - val_loss: 2.4343 - val_mae: 2.4343\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3154 - mae: 1.3154 - val_loss: 2.4889 - val_mae: 2.4889\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2898 - mae: 1.2898 - val_loss: 2.4536 - val_mae: 2.4536\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2505 - mae: 1.2505 - val_loss: 2.4738 - val_mae: 2.4738\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2611 - mae: 1.2611 - val_loss: 2.4297 - val_mae: 2.4297\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6329 - mae: 3.6329\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 256.4485 - mae: 13.0526 - val_loss: 52.8176 - val_mae: 5.3757\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.0494 - mae: 4.0489 - val_loss: 26.9286 - val_mae: 3.5435\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.2411 - mae: 3.2983 - val_loss: 22.5277 - val_mae: 3.3046\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.3452 - mae: 3.0713 - val_loss: 20.9613 - val_mae: 3.1301\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.1404 - mae: 2.8895 - val_loss: 19.7014 - val_mae: 3.1041\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.0162 - mae: 2.7928 - val_loss: 18.7023 - val_mae: 2.9786\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.1033 - mae: 2.6721 - val_loss: 18.4192 - val_mae: 2.9523\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2207 - mae: 2.6150 - val_loss: 17.7776 - val_mae: 2.9658\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6341 - mae: 2.5993 - val_loss: 17.4233 - val_mae: 2.8517\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.3297 - mae: 2.5617 - val_loss: 16.8506 - val_mae: 2.7954\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.9297 - mae: 2.5443 - val_loss: 16.4147 - val_mae: 2.7489\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.5380 - mae: 2.4739 - val_loss: 16.8166 - val_mae: 2.8659\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3331 - mae: 2.4805 - val_loss: 16.2327 - val_mae: 2.7658\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.2579 - mae: 2.4763 - val_loss: 15.8062 - val_mae: 2.7346\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4939 - mae: 2.3973 - val_loss: 15.9422 - val_mae: 2.6956\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3079 - mae: 2.3678 - val_loss: 15.4167 - val_mae: 2.6715\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.8869 - mae: 2.3180 - val_loss: 15.0105 - val_mae: 2.6296\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.6844 - mae: 2.3102 - val_loss: 15.1885 - val_mae: 2.6421\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.5117 - mae: 2.2901 - val_loss: 15.3313 - val_mae: 2.6511\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1493 - mae: 2.2420 - val_loss: 15.3093 - val_mae: 2.6665\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8510 - mae: 2.2318 - val_loss: 15.0493 - val_mae: 2.6455\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9056 - mae: 2.2340 - val_loss: 14.4971 - val_mae: 2.5763\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6094 - mae: 2.1714 - val_loss: 14.6102 - val_mae: 2.6149\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5175 - mae: 2.1957 - val_loss: 14.7440 - val_mae: 2.5382\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3468 - mae: 2.2017 - val_loss: 14.6268 - val_mae: 2.5666\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0875 - mae: 2.1846 - val_loss: 14.2072 - val_mae: 2.5609\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8449 - mae: 2.1401 - val_loss: 14.0405 - val_mae: 2.5235\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5374 - mae: 2.0863 - val_loss: 13.7759 - val_mae: 2.5184\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4280 - mae: 2.0850 - val_loss: 13.6479 - val_mae: 2.5360\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1722 - mae: 2.0586 - val_loss: 13.7787 - val_mae: 2.5247\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0413 - mae: 2.0524 - val_loss: 13.4892 - val_mae: 2.4993\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8667 - mae: 2.0165 - val_loss: 13.5091 - val_mae: 2.4531\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9848 - mae: 2.0707 - val_loss: 13.2945 - val_mae: 2.4634\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5433 - mae: 2.0163 - val_loss: 13.7937 - val_mae: 2.5358\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3998 - mae: 1.9790 - val_loss: 13.7540 - val_mae: 2.5254\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4301 - mae: 1.9983 - val_loss: 13.5411 - val_mae: 2.4242\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6811 - mae: 2.0342 - val_loss: 13.6474 - val_mae: 2.4531\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2024 - mae: 1.9693 - val_loss: 13.3442 - val_mae: 2.4456\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7850 - mae: 1.8721 - val_loss: 13.2414 - val_mae: 2.4410\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7134 - mae: 1.8907 - val_loss: 13.3412 - val_mae: 2.4490\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6332 - mae: 1.8813 - val_loss: 13.3136 - val_mae: 2.4381\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5511 - mae: 1.8916 - val_loss: 13.1546 - val_mae: 2.4965\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7588 - mae: 1.9153 - val_loss: 12.7285 - val_mae: 2.4337\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5534 - mae: 1.8597 - val_loss: 12.7821 - val_mae: 2.3860\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2387 - mae: 1.8456 - val_loss: 13.2053 - val_mae: 2.4544\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9623 - mae: 1.8068 - val_loss: 13.2163 - val_mae: 2.4170\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9427 - mae: 1.8046 - val_loss: 12.8472 - val_mae: 2.4145\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8097 - mae: 1.7886 - val_loss: 13.4210 - val_mae: 2.4170\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9381 - mae: 1.7987 - val_loss: 12.7732 - val_mae: 2.4087\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6867 - mae: 1.7863 - val_loss: 13.0832 - val_mae: 2.4089\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7043 - mae: 1.7640 - val_loss: 12.9164 - val_mae: 2.4634\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4743 - mae: 1.7386 - val_loss: 13.2709 - val_mae: 2.4255\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4368 - mae: 1.7127 - val_loss: 12.8196 - val_mae: 2.4364\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2239 - mae: 1.6877 - val_loss: 12.8772 - val_mae: 2.4549\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3621 - mae: 1.7149 - val_loss: 13.3504 - val_mae: 2.4560\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1148 - mae: 1.6860 - val_loss: 13.2301 - val_mae: 2.3988\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8883 - mae: 1.6495 - val_loss: 12.9822 - val_mae: 2.4338\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8012 - mae: 1.6363 - val_loss: 12.8035 - val_mae: 2.3930\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8958 - mae: 1.6334 - val_loss: 12.7276 - val_mae: 2.3649\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6819 - mae: 1.6103 - val_loss: 12.8353 - val_mae: 2.4108\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5284 - mae: 1.5936 - val_loss: 13.2928 - val_mae: 2.3840\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5265 - mae: 1.5925 - val_loss: 13.1149 - val_mae: 2.4142\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4806 - mae: 1.5885 - val_loss: 12.9161 - val_mae: 2.4015\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3337 - mae: 1.5520 - val_loss: 12.8299 - val_mae: 2.3848\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3609 - mae: 1.5488 - val_loss: 13.0032 - val_mae: 2.3980\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4017 - mae: 1.5568 - val_loss: 12.8994 - val_mae: 2.4066\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2015 - mae: 1.5470 - val_loss: 13.7023 - val_mae: 2.5037\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3423 - mae: 1.5768 - val_loss: 13.1165 - val_mae: 2.3940\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0385 - mae: 1.5046 - val_loss: 13.1778 - val_mae: 2.3743\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9510 - mae: 1.4914 - val_loss: 13.1218 - val_mae: 2.3981\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9455 - mae: 1.4977 - val_loss: 13.1415 - val_mae: 2.4781\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8646 - mae: 1.4427 - val_loss: 13.0488 - val_mae: 2.4432\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6739 - mae: 1.4199 - val_loss: 12.8003 - val_mae: 2.4005\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7831 - mae: 1.4492 - val_loss: 12.9411 - val_mae: 2.4017\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6353 - mae: 1.4138 - val_loss: 12.9047 - val_mae: 2.3729\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5454 - mae: 1.3945 - val_loss: 13.1864 - val_mae: 2.4198\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7412 - mae: 1.4332 - val_loss: 13.0814 - val_mae: 2.4185\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4497 - mae: 1.3720 - val_loss: 13.0574 - val_mae: 2.4237\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4459 - mae: 1.3646 - val_loss: 12.9980 - val_mae: 2.3788\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3512 - mae: 1.3535 - val_loss: 12.9491 - val_mae: 2.3738\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4243 - mae: 1.3531 - val_loss: 12.9582 - val_mae: 2.4077\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3653 - mae: 1.3594 - val_loss: 13.0460 - val_mae: 2.3649\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2154 - mae: 1.3453 - val_loss: 13.1104 - val_mae: 2.3805\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2485 - mae: 1.3268 - val_loss: 13.0549 - val_mae: 2.4040\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1902 - mae: 1.3303 - val_loss: 13.2249 - val_mae: 2.4368\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1815 - mae: 1.3215 - val_loss: 12.8182 - val_mae: 2.3739\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0206 - mae: 1.2699 - val_loss: 13.1943 - val_mae: 2.4313\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0831 - mae: 1.3279 - val_loss: 13.0960 - val_mae: 2.3689\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1233 - mae: 1.3006 - val_loss: 12.9659 - val_mae: 2.3752\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0532 - mae: 1.2922 - val_loss: 13.1218 - val_mae: 2.3902\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9264 - mae: 1.2501 - val_loss: 13.1825 - val_mae: 2.4239\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9162 - mae: 1.2781 - val_loss: 13.2823 - val_mae: 2.3698\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8828 - mae: 1.2529 - val_loss: 13.9240 - val_mae: 2.4428\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8499 - mae: 1.2622 - val_loss: 13.2701 - val_mae: 2.4107\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8102 - mae: 1.2357 - val_loss: 13.2873 - val_mae: 2.4570\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6881 - mae: 1.2193 - val_loss: 13.2968 - val_mae: 2.3857\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6265 - mae: 1.1920 - val_loss: 13.1391 - val_mae: 2.3862\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7749 - mae: 1.2317 - val_loss: 13.3208 - val_mae: 2.3708\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7462 - mae: 1.2263 - val_loss: 13.6069 - val_mae: 2.4920\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6413 - mae: 1.2207 - val_loss: 13.3648 - val_mae: 2.4061\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.7610 - mae: 3.8474\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 13.8723 - mae: 13.8723 - val_loss: 6.2327 - val_mae: 6.2327\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4483 - mae: 4.4483 - val_loss: 3.3716 - val_mae: 3.3716\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4353 - mae: 3.4353 - val_loss: 3.0258 - val_mae: 3.0258\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1023 - mae: 3.1023 - val_loss: 2.8999 - val_mae: 2.8999\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8191 - mae: 2.8191 - val_loss: 2.7351 - val_mae: 2.7351\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7599 - mae: 2.7599 - val_loss: 2.6932 - val_mae: 2.6932\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6265 - mae: 2.6265 - val_loss: 2.6950 - val_mae: 2.6950\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5071 - mae: 2.5071 - val_loss: 2.6152 - val_mae: 2.6152\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5363 - mae: 2.5363 - val_loss: 2.5690 - val_mae: 2.5690\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4228 - mae: 2.4228 - val_loss: 2.6821 - val_mae: 2.6821\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4183 - mae: 2.4183 - val_loss: 2.6128 - val_mae: 2.6128\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3676 - mae: 2.3676 - val_loss: 2.5555 - val_mae: 2.5555\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2910 - mae: 2.2910 - val_loss: 2.5113 - val_mae: 2.5113\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2549 - mae: 2.2549 - val_loss: 2.5023 - val_mae: 2.5023\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2256 - mae: 2.2256 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1997 - mae: 2.1997 - val_loss: 2.5306 - val_mae: 2.5306\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1578 - mae: 2.1578 - val_loss: 2.4962 - val_mae: 2.4962\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1346 - mae: 2.1346 - val_loss: 2.4940 - val_mae: 2.4940\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1627 - mae: 2.1627 - val_loss: 2.5317 - val_mae: 2.5317\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0994 - mae: 2.0994 - val_loss: 2.4687 - val_mae: 2.4687\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0993 - mae: 2.0993 - val_loss: 2.5182 - val_mae: 2.5182\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0624 - mae: 2.0624 - val_loss: 2.4860 - val_mae: 2.4860\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0846 - mae: 2.0846 - val_loss: 2.5084 - val_mae: 2.5084\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0764 - mae: 2.0764 - val_loss: 2.4608 - val_mae: 2.4608\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9908 - mae: 1.9908 - val_loss: 2.4986 - val_mae: 2.4986\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9879 - mae: 1.9879 - val_loss: 2.4817 - val_mae: 2.4817\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9916 - mae: 1.9916 - val_loss: 2.4467 - val_mae: 2.4467\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9586 - mae: 1.9586 - val_loss: 2.5427 - val_mae: 2.5427\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9709 - mae: 1.9709 - val_loss: 2.5170 - val_mae: 2.5170\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9652 - mae: 1.9652 - val_loss: 2.4420 - val_mae: 2.4420\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9503 - mae: 1.9503 - val_loss: 2.5395 - val_mae: 2.5395\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9284 - mae: 1.9284 - val_loss: 2.4287 - val_mae: 2.4287\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8732 - mae: 1.8732 - val_loss: 2.4251 - val_mae: 2.4251\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8663 - mae: 1.8663 - val_loss: 2.5532 - val_mae: 2.5532\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9261 - mae: 1.9261 - val_loss: 2.4966 - val_mae: 2.4966\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8598 - mae: 1.8598 - val_loss: 2.4912 - val_mae: 2.4912\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8204 - mae: 1.8204 - val_loss: 2.4586 - val_mae: 2.4586\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8096 - mae: 1.8096 - val_loss: 2.4367 - val_mae: 2.4367\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8439 - mae: 1.8439 - val_loss: 2.4536 - val_mae: 2.4536\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7887 - mae: 1.7887 - val_loss: 2.5548 - val_mae: 2.5548\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7857 - mae: 1.7857 - val_loss: 2.4421 - val_mae: 2.4421\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7727 - mae: 1.7727 - val_loss: 2.4981 - val_mae: 2.4981\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7451 - mae: 1.7451 - val_loss: 2.4918 - val_mae: 2.4918\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7868 - mae: 1.7868 - val_loss: 2.5428 - val_mae: 2.5428\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7448 - mae: 1.7448 - val_loss: 2.4924 - val_mae: 2.4924\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7091 - mae: 1.7091 - val_loss: 2.4610 - val_mae: 2.4610\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7214 - mae: 1.7214 - val_loss: 2.4920 - val_mae: 2.4920\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7121 - mae: 1.7121 - val_loss: 2.4866 - val_mae: 2.4866\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7153 - mae: 1.7153 - val_loss: 2.5829 - val_mae: 2.5829\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6946 - mae: 1.6946 - val_loss: 2.4171 - val_mae: 2.4171\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6731 - mae: 1.6731 - val_loss: 2.5066 - val_mae: 2.5066\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6467 - mae: 1.6467 - val_loss: 2.4764 - val_mae: 2.4764\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6494 - mae: 1.6494 - val_loss: 2.5304 - val_mae: 2.5304\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6457 - mae: 1.6457 - val_loss: 2.5594 - val_mae: 2.5594\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6183 - mae: 1.6183 - val_loss: 2.5003 - val_mae: 2.5003\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6022 - mae: 1.6022 - val_loss: 2.4407 - val_mae: 2.4407\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6010 - mae: 1.6010 - val_loss: 2.4775 - val_mae: 2.4775\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6009 - mae: 1.6009 - val_loss: 2.5789 - val_mae: 2.5789\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5777 - mae: 1.5777 - val_loss: 2.5220 - val_mae: 2.5220\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5702 - mae: 1.5702 - val_loss: 2.5291 - val_mae: 2.5291\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5918 - mae: 1.5918 - val_loss: 2.5140 - val_mae: 2.5140\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5641 - mae: 1.5641 - val_loss: 2.5000 - val_mae: 2.5000\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5386 - mae: 1.5386 - val_loss: 2.5127 - val_mae: 2.5127\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5134 - mae: 1.5134 - val_loss: 2.5613 - val_mae: 2.5613\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5025 - mae: 1.5025 - val_loss: 2.5865 - val_mae: 2.5865\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5034 - mae: 1.5034 - val_loss: 2.5263 - val_mae: 2.5263\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4921 - mae: 1.4921 - val_loss: 2.5446 - val_mae: 2.5446\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4949 - mae: 1.4949 - val_loss: 2.4812 - val_mae: 2.4812\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5274 - mae: 1.5274 - val_loss: 2.5502 - val_mae: 2.5502\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4740 - mae: 1.4740 - val_loss: 2.5599 - val_mae: 2.5599\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4483 - mae: 1.4483 - val_loss: 2.4899 - val_mae: 2.4899\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4331 - mae: 1.4331 - val_loss: 2.4736 - val_mae: 2.4736\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4641 - mae: 1.4641 - val_loss: 2.4685 - val_mae: 2.4685\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4506 - mae: 1.4506 - val_loss: 2.4819 - val_mae: 2.4819\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4034 - mae: 1.4034 - val_loss: 2.5791 - val_mae: 2.5791\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4014 - mae: 1.4014 - val_loss: 2.4542 - val_mae: 2.4542\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4150 - mae: 1.4150 - val_loss: 2.5276 - val_mae: 2.5276\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3875 - mae: 1.3875 - val_loss: 2.5340 - val_mae: 2.5340\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3881 - mae: 1.3881 - val_loss: 2.5096 - val_mae: 2.5096\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3645 - mae: 1.3645 - val_loss: 2.4776 - val_mae: 2.4776\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3528 - mae: 1.3528 - val_loss: 2.5492 - val_mae: 2.5492\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3768 - mae: 1.3768 - val_loss: 2.5067 - val_mae: 2.5067\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3648 - mae: 1.3648 - val_loss: 2.5233 - val_mae: 2.5233\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3162 - mae: 1.3162 - val_loss: 2.4755 - val_mae: 2.4755\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3199 - mae: 1.3199 - val_loss: 2.5414 - val_mae: 2.5414\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3222 - mae: 1.3222 - val_loss: 2.4947 - val_mae: 2.4947\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2908 - mae: 1.2908 - val_loss: 2.4922 - val_mae: 2.4922\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3071 - mae: 1.3071 - val_loss: 2.5578 - val_mae: 2.5578\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3091 - mae: 1.3091 - val_loss: 2.5285 - val_mae: 2.5285\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3364 - mae: 1.3364 - val_loss: 2.5614 - val_mae: 2.5614\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2969 - mae: 1.2969 - val_loss: 2.5806 - val_mae: 2.5806\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2655 - mae: 1.2655 - val_loss: 2.5623 - val_mae: 2.5623\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2688 - mae: 1.2688 - val_loss: 2.5243 - val_mae: 2.5243\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2627 - mae: 1.2627 - val_loss: 2.5049 - val_mae: 2.5049\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2640 - mae: 1.2640 - val_loss: 2.4876 - val_mae: 2.4876\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2402 - mae: 1.2402 - val_loss: 2.5622 - val_mae: 2.5622\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2447 - mae: 1.2447 - val_loss: 2.5469 - val_mae: 2.5469\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2391 - mae: 1.2391 - val_loss: 2.5788 - val_mae: 2.5788\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2483 - mae: 1.2483 - val_loss: 2.4873 - val_mae: 2.4873\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2859 - mae: 1.2859 - val_loss: 2.5258 - val_mae: 2.5258\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6001 - mae: 3.6001\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 273.9631 - mae: 13.7304 - val_loss: 61.6831 - val_mae: 5.7877\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.4901 - mae: 4.4041 - val_loss: 29.4902 - val_mae: 3.6200\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.0637 - mae: 3.4066 - val_loss: 23.5770 - val_mae: 3.2825\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.5298 - mae: 3.0953 - val_loss: 21.1431 - val_mae: 3.2684\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.0574 - mae: 2.9138 - val_loss: 19.8528 - val_mae: 3.0925\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.7434 - mae: 2.7702 - val_loss: 18.8542 - val_mae: 3.1334\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.9591 - mae: 2.7380 - val_loss: 18.9564 - val_mae: 2.9340\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.2707 - mae: 2.6288 - val_loss: 17.7311 - val_mae: 2.9652\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5988 - mae: 2.6014 - val_loss: 17.6103 - val_mae: 2.9730\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5128 - mae: 2.6116 - val_loss: 17.6476 - val_mae: 2.8481\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.7432 - mae: 2.5354 - val_loss: 16.8594 - val_mae: 2.8494\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1459 - mae: 2.4704 - val_loss: 17.7125 - val_mae: 3.0175\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.0188 - mae: 2.4896 - val_loss: 16.4516 - val_mae: 2.8005\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7892 - mae: 2.4634 - val_loss: 16.4902 - val_mae: 2.7877\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4418 - mae: 2.4217 - val_loss: 16.3044 - val_mae: 2.7583\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2684 - mae: 2.4254 - val_loss: 15.5121 - val_mae: 2.7355\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0564 - mae: 2.4039 - val_loss: 15.7516 - val_mae: 2.7060\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.6626 - mae: 2.3503 - val_loss: 15.6629 - val_mae: 2.6925\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3663 - mae: 2.3340 - val_loss: 15.5624 - val_mae: 2.6996\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.2981 - mae: 2.3407 - val_loss: 15.5043 - val_mae: 2.7034\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0228 - mae: 2.2820 - val_loss: 15.2872 - val_mae: 2.6436\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.8720 - mae: 2.2720 - val_loss: 15.3221 - val_mae: 2.6659\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0221 - mae: 2.2816 - val_loss: 15.2234 - val_mae: 2.6734\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5966 - mae: 2.2194 - val_loss: 15.0102 - val_mae: 2.6273\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2008 - mae: 2.2081 - val_loss: 14.8032 - val_mae: 2.6000\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0050 - mae: 2.1875 - val_loss: 14.8427 - val_mae: 2.6177\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0554 - mae: 2.1721 - val_loss: 14.7272 - val_mae: 2.6173\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7990 - mae: 2.1592 - val_loss: 14.8156 - val_mae: 2.6092\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6992 - mae: 2.1592 - val_loss: 15.1054 - val_mae: 2.6058\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6477 - mae: 2.1500 - val_loss: 14.4027 - val_mae: 2.5840\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2550 - mae: 2.1249 - val_loss: 14.4721 - val_mae: 2.5706\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0378 - mae: 2.1042 - val_loss: 15.1483 - val_mae: 2.6435\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0311 - mae: 2.0759 - val_loss: 14.2718 - val_mae: 2.5423\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8456 - mae: 2.0451 - val_loss: 13.9790 - val_mae: 2.5486\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8041 - mae: 2.0473 - val_loss: 14.4375 - val_mae: 2.5800\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6959 - mae: 2.0666 - val_loss: 14.6344 - val_mae: 2.5784\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4902 - mae: 2.0302 - val_loss: 14.0242 - val_mae: 2.4906\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2384 - mae: 2.0058 - val_loss: 13.8624 - val_mae: 2.5319\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2898 - mae: 2.0116 - val_loss: 14.0443 - val_mae: 2.5217\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2069 - mae: 1.9847 - val_loss: 14.1039 - val_mae: 2.5239\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8304 - mae: 1.9379 - val_loss: 13.6694 - val_mae: 2.4680\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8007 - mae: 1.9455 - val_loss: 13.9634 - val_mae: 2.4878\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6421 - mae: 1.9012 - val_loss: 13.9308 - val_mae: 2.4819\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4538 - mae: 1.8886 - val_loss: 13.9652 - val_mae: 2.4719\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3115 - mae: 1.8655 - val_loss: 13.7732 - val_mae: 2.4577\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1857 - mae: 1.8518 - val_loss: 13.7569 - val_mae: 2.5140\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1005 - mae: 1.8386 - val_loss: 13.5349 - val_mae: 2.4401\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0524 - mae: 1.8200 - val_loss: 13.8333 - val_mae: 2.4483\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1775 - mae: 1.8563 - val_loss: 13.6302 - val_mae: 2.4931\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7354 - mae: 1.7836 - val_loss: 13.8299 - val_mae: 2.4689\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6565 - mae: 1.7604 - val_loss: 13.7320 - val_mae: 2.4705\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4730 - mae: 1.7465 - val_loss: 13.4470 - val_mae: 2.4743\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4588 - mae: 1.7461 - val_loss: 13.4837 - val_mae: 2.4756\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3428 - mae: 1.7130 - val_loss: 13.7811 - val_mae: 2.4637\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6116 - mae: 1.8028 - val_loss: 13.8483 - val_mae: 2.4731\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2047 - mae: 1.6994 - val_loss: 13.5827 - val_mae: 2.4947\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3625 - mae: 1.7428 - val_loss: 13.7934 - val_mae: 2.4546\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1593 - mae: 1.7107 - val_loss: 13.6269 - val_mae: 2.4313\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0514 - mae: 1.6739 - val_loss: 13.7038 - val_mae: 2.4673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7557 - mae: 1.6165 - val_loss: 13.8554 - val_mae: 2.4371\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8113 - mae: 1.6374 - val_loss: 13.7521 - val_mae: 2.4675\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6346 - mae: 1.5898 - val_loss: 13.6105 - val_mae: 2.5128\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5279 - mae: 1.5604 - val_loss: 13.7275 - val_mae: 2.4673\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5867 - mae: 1.5900 - val_loss: 13.5049 - val_mae: 2.4543\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5348 - mae: 1.5705 - val_loss: 13.7536 - val_mae: 2.4370\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6272 - mae: 1.6023 - val_loss: 13.8818 - val_mae: 2.4906\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4948 - mae: 1.5861 - val_loss: 13.6522 - val_mae: 2.4832\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3477 - mae: 1.5304 - val_loss: 13.9744 - val_mae: 2.4679\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3145 - mae: 1.5296 - val_loss: 13.4458 - val_mae: 2.4132\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0865 - mae: 1.4930 - val_loss: 13.6361 - val_mae: 2.5051\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1213 - mae: 1.5153 - val_loss: 13.4361 - val_mae: 2.4247\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0778 - mae: 1.4819 - val_loss: 13.9210 - val_mae: 2.4515\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9904 - mae: 1.4766 - val_loss: 13.5423 - val_mae: 2.4732\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8129 - mae: 1.4386 - val_loss: 13.7097 - val_mae: 2.4233\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8669 - mae: 1.4515 - val_loss: 13.6555 - val_mae: 2.4746\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7382 - mae: 1.4329 - val_loss: 13.9859 - val_mae: 2.4279\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8407 - mae: 1.4597 - val_loss: 13.8302 - val_mae: 2.4333\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6419 - mae: 1.4048 - val_loss: 13.8273 - val_mae: 2.4556\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6220 - mae: 1.3819 - val_loss: 13.5712 - val_mae: 2.4137\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5207 - mae: 1.3924 - val_loss: 13.9737 - val_mae: 2.4225\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4915 - mae: 1.3654 - val_loss: 13.8878 - val_mae: 2.4512\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5569 - mae: 1.3809 - val_loss: 13.4526 - val_mae: 2.4099\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5335 - mae: 1.3887 - val_loss: 13.8201 - val_mae: 2.3802\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4129 - mae: 1.3552 - val_loss: 13.6820 - val_mae: 2.3942\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2524 - mae: 1.3232 - val_loss: 13.4516 - val_mae: 2.4011\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4035 - mae: 1.3670 - val_loss: 13.9955 - val_mae: 2.5135\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2759 - mae: 1.3309 - val_loss: 13.6904 - val_mae: 2.4016\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2528 - mae: 1.3336 - val_loss: 13.8162 - val_mae: 2.3853\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1915 - mae: 1.3092 - val_loss: 13.6524 - val_mae: 2.4323\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1504 - mae: 1.2957 - val_loss: 14.0263 - val_mae: 2.4825\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0789 - mae: 1.2757 - val_loss: 13.6422 - val_mae: 2.4137\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0558 - mae: 1.2798 - val_loss: 13.7219 - val_mae: 2.4449\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9750 - mae: 1.2682 - val_loss: 13.9123 - val_mae: 2.3913\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9992 - mae: 1.2700 - val_loss: 13.8274 - val_mae: 2.4193\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9548 - mae: 1.2552 - val_loss: 13.7476 - val_mae: 2.4581\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9313 - mae: 1.2571 - val_loss: 13.7577 - val_mae: 2.4449\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8432 - mae: 1.2359 - val_loss: 13.6726 - val_mae: 2.4157\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8124 - mae: 1.2250 - val_loss: 13.9258 - val_mae: 2.4715\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8161 - mae: 1.2241 - val_loss: 14.0715 - val_mae: 2.4240\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8033 - mae: 1.2385 - val_loss: 13.8986 - val_mae: 2.4044\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.0836 - mae: 3.6877\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 13.7634 - mae: 13.7634 - val_loss: 5.5870 - val_mae: 5.5870\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3801 - mae: 4.3801 - val_loss: 3.2810 - val_mae: 3.2810\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2280 - mae: 3.2280 - val_loss: 3.4250 - val_mae: 3.4250\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9301 - mae: 2.9301 - val_loss: 2.9524 - val_mae: 2.9524\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7857 - mae: 2.7857 - val_loss: 2.8687 - val_mae: 2.8687\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6862 - mae: 2.6862 - val_loss: 2.8516 - val_mae: 2.8516\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5750 - mae: 2.5750 - val_loss: 2.8471 - val_mae: 2.8471\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5478 - mae: 2.5478 - val_loss: 2.8199 - val_mae: 2.8199\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4620 - mae: 2.4620 - val_loss: 2.6685 - val_mae: 2.6685\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4270 - mae: 2.4270 - val_loss: 2.7171 - val_mae: 2.7171\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4004 - mae: 2.4004 - val_loss: 2.7655 - val_mae: 2.7655\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3663 - mae: 2.3663 - val_loss: 2.5786 - val_mae: 2.5786\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3513 - mae: 2.3513 - val_loss: 2.5265 - val_mae: 2.5265\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2588 - mae: 2.2588 - val_loss: 2.5665 - val_mae: 2.5665\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2508 - mae: 2.2508 - val_loss: 2.5268 - val_mae: 2.5268\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2249 - mae: 2.2249 - val_loss: 2.5773 - val_mae: 2.5773\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2259 - mae: 2.2259 - val_loss: 2.6355 - val_mae: 2.6355\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2612 - mae: 2.2612 - val_loss: 2.5384 - val_mae: 2.5384\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1475 - mae: 2.1475 - val_loss: 2.4780 - val_mae: 2.4780\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1540 - mae: 2.1540 - val_loss: 2.5019 - val_mae: 2.5019\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1083 - mae: 2.1083 - val_loss: 2.5099 - val_mae: 2.5099\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0914 - mae: 2.0914 - val_loss: 2.4746 - val_mae: 2.4746\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0713 - mae: 2.0713 - val_loss: 2.4801 - val_mae: 2.4801\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0542 - mae: 2.0542 - val_loss: 2.4943 - val_mae: 2.4943\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0531 - mae: 2.0531 - val_loss: 2.4327 - val_mae: 2.4327\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0213 - mae: 2.0213 - val_loss: 2.4167 - val_mae: 2.4167\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9742 - mae: 1.9742 - val_loss: 2.4370 - val_mae: 2.4370\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0540 - mae: 2.0540 - val_loss: 2.4334 - val_mae: 2.4334\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9493 - mae: 1.9493 - val_loss: 2.4261 - val_mae: 2.4261\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9802 - mae: 1.9802 - val_loss: 2.4484 - val_mae: 2.4484\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9551 - mae: 1.9551 - val_loss: 2.3882 - val_mae: 2.3882\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8921 - mae: 1.8921 - val_loss: 2.4601 - val_mae: 2.4601\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9228 - mae: 1.9228 - val_loss: 2.3758 - val_mae: 2.3758\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8858 - mae: 1.8858 - val_loss: 2.3784 - val_mae: 2.3784\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8949 - mae: 1.8949 - val_loss: 2.3204 - val_mae: 2.3204\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8954 - mae: 1.8954 - val_loss: 2.4183 - val_mae: 2.4183\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8585 - mae: 1.8585 - val_loss: 2.3760 - val_mae: 2.3760\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8479 - mae: 1.8479 - val_loss: 2.3564 - val_mae: 2.3564\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8222 - mae: 1.8222 - val_loss: 2.3749 - val_mae: 2.3749\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8344 - mae: 1.8344 - val_loss: 2.4126 - val_mae: 2.4126\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7873 - mae: 1.7873 - val_loss: 2.3816 - val_mae: 2.3816\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8131 - mae: 1.8131 - val_loss: 2.3950 - val_mae: 2.3950\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7603 - mae: 1.7603 - val_loss: 2.4419 - val_mae: 2.4419\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7653 - mae: 1.7653 - val_loss: 2.3635 - val_mae: 2.3635\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7397 - mae: 1.7397 - val_loss: 2.3660 - val_mae: 2.3660\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7470 - mae: 1.7470 - val_loss: 2.4179 - val_mae: 2.4179\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7248 - mae: 1.7248 - val_loss: 2.4112 - val_mae: 2.4112\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6879 - mae: 1.6879 - val_loss: 2.4508 - val_mae: 2.4508\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6844 - mae: 1.6844 - val_loss: 2.3549 - val_mae: 2.3549\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6773 - mae: 1.6773 - val_loss: 2.3889 - val_mae: 2.3889\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6699 - mae: 1.6699 - val_loss: 2.3245 - val_mae: 2.3245\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6715 - mae: 1.6715 - val_loss: 2.4352 - val_mae: 2.4352\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6698 - mae: 1.6698 - val_loss: 2.3252 - val_mae: 2.3252\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6306 - mae: 1.6306 - val_loss: 2.4455 - val_mae: 2.4455\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6467 - mae: 1.6467 - val_loss: 2.3542 - val_mae: 2.3542\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6422 - mae: 1.6422 - val_loss: 2.3607 - val_mae: 2.3607\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5875 - mae: 1.5875 - val_loss: 2.3242 - val_mae: 2.3242\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5689 - mae: 1.5689 - val_loss: 2.3861 - val_mae: 2.3861\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5350 - mae: 1.5350 - val_loss: 2.3234 - val_mae: 2.3234\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5176 - mae: 1.5176 - val_loss: 2.3160 - val_mae: 2.3160\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5346 - mae: 1.5346 - val_loss: 2.3422 - val_mae: 2.3422\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5148 - mae: 1.5148 - val_loss: 2.3766 - val_mae: 2.3766\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4877 - mae: 1.4877 - val_loss: 2.3475 - val_mae: 2.3475\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4941 - mae: 1.4941 - val_loss: 2.4017 - val_mae: 2.4017\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4898 - mae: 1.4898 - val_loss: 2.2951 - val_mae: 2.2951\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4923 - mae: 1.4923 - val_loss: 2.3580 - val_mae: 2.3580\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4533 - mae: 1.4533 - val_loss: 2.3583 - val_mae: 2.3583\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4873 - mae: 1.4873 - val_loss: 2.3319 - val_mae: 2.3319\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4223 - mae: 1.4223 - val_loss: 2.3479 - val_mae: 2.3479\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4039 - mae: 1.4039 - val_loss: 2.3139 - val_mae: 2.3139\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3935 - mae: 1.3935 - val_loss: 2.3209 - val_mae: 2.3209\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3976 - mae: 1.3976 - val_loss: 2.4177 - val_mae: 2.4177\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4122 - mae: 1.4122 - val_loss: 2.3248 - val_mae: 2.3248\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3855 - mae: 1.3855 - val_loss: 2.3009 - val_mae: 2.3009\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3657 - mae: 1.3657 - val_loss: 2.3096 - val_mae: 2.3096\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3570 - mae: 1.3570 - val_loss: 2.2998 - val_mae: 2.2998\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3554 - mae: 1.3554 - val_loss: 2.2805 - val_mae: 2.2805\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3467 - mae: 1.3467 - val_loss: 2.3143 - val_mae: 2.3143\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3298 - mae: 1.3298 - val_loss: 2.3544 - val_mae: 2.3544\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3459 - mae: 1.3459 - val_loss: 2.3471 - val_mae: 2.3471\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3577 - mae: 1.3577 - val_loss: 2.3308 - val_mae: 2.3308\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3149 - mae: 1.3149 - val_loss: 2.3193 - val_mae: 2.3193\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3368 - mae: 1.3368 - val_loss: 2.3173 - val_mae: 2.3173\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3011 - mae: 1.3011 - val_loss: 2.3183 - val_mae: 2.3183\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2557 - mae: 1.2557 - val_loss: 2.3144 - val_mae: 2.3144\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2678 - mae: 1.2678 - val_loss: 2.3595 - val_mae: 2.3595\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2597 - mae: 1.2597 - val_loss: 2.2757 - val_mae: 2.2757\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2753 - mae: 1.2753 - val_loss: 2.3053 - val_mae: 2.3053\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3190 - mae: 1.3190 - val_loss: 2.3136 - val_mae: 2.3136\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2507 - mae: 1.2507 - val_loss: 2.3286 - val_mae: 2.3286\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2424 - mae: 1.2424 - val_loss: 2.3116 - val_mae: 2.3116\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2295 - mae: 1.2295 - val_loss: 2.2744 - val_mae: 2.2744\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1994 - mae: 1.1994 - val_loss: 2.3463 - val_mae: 2.3463\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1740 - mae: 1.1740 - val_loss: 2.3617 - val_mae: 2.3617\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1873 - mae: 1.1873 - val_loss: 2.3300 - val_mae: 2.3300\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1618 - mae: 1.1618 - val_loss: 2.3437 - val_mae: 2.3437\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1903 - mae: 1.1903 - val_loss: 2.3029 - val_mae: 2.3029\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2076 - mae: 1.2076 - val_loss: 2.3688 - val_mae: 2.3688\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1599 - mae: 1.1599 - val_loss: 2.3339 - val_mae: 2.3339\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1574 - mae: 1.1574 - val_loss: 2.3333 - val_mae: 2.3333\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4630 - mae: 3.4630\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 310.5580 - mae: 14.7480 - val_loss: 186.7728 - val_mae: 10.3971\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 154.6065 - mae: 9.4180 - val_loss: 144.8975 - val_mae: 8.7158\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 125.6149 - mae: 8.2368 - val_loss: 124.6131 - val_mae: 7.9692\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 109.7074 - mae: 7.5316 - val_loss: 112.5581 - val_mae: 7.5402\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 99.7389 - mae: 7.0717 - val_loss: 104.9516 - val_mae: 7.2656\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.3829 - mae: 6.7658 - val_loss: 99.5310 - val_mae: 7.0558\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 89.0291 - mae: 6.5807 - val_loss: 96.1062 - val_mae: 6.9486\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.2334 - mae: 6.4695 - val_loss: 93.7453 - val_mae: 6.9134\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.1993 - mae: 6.4045 - val_loss: 92.3613 - val_mae: 6.9149\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.9193 - mae: 6.3840 - val_loss: 91.1930 - val_mae: 6.9407\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.9769 - mae: 6.3768 - val_loss: 90.4993 - val_mae: 6.9646\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.4036 - mae: 6.3746 - val_loss: 90.0242 - val_mae: 6.9870\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.9865 - mae: 6.3808 - val_loss: 89.5460 - val_mae: 7.0187\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6822 - mae: 6.3965 - val_loss: 89.3201 - val_mae: 7.0372\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5020 - mae: 6.3996 - val_loss: 89.1744 - val_mae: 7.0496\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.3785 - mae: 6.4063 - val_loss: 89.0439 - val_mae: 7.0615\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.2624 - mae: 6.4108 - val_loss: 88.9149 - val_mae: 7.0741\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.1888 - mae: 6.4200 - val_loss: 88.8099 - val_mae: 7.0790\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.0843 - mae: 6.4163 - val_loss: 88.6986 - val_mae: 7.0846\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.9855 - mae: 6.4268 - val_loss: 88.5569 - val_mae: 7.0933\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.9128 - mae: 6.4194 - val_loss: 88.4069 - val_mae: 7.0833\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.7381 - mae: 6.4198 - val_loss: 88.2023 - val_mae: 7.0821\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.5513 - mae: 6.4146 - val_loss: 87.9363 - val_mae: 7.0713\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.2983 - mae: 6.3962 - val_loss: 87.5127 - val_mae: 7.0413\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.8966 - mae: 6.3742 - val_loss: 86.9667 - val_mae: 7.0147\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.3456 - mae: 6.3360 - val_loss: 86.1380 - val_mae: 6.9624\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.4722 - mae: 6.2665 - val_loss: 84.6797 - val_mae: 6.8514\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.9590 - mae: 6.1778 - val_loss: 82.7400 - val_mae: 6.7088\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.1330 - mae: 6.0111 - val_loss: 80.1604 - val_mae: 6.5050\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.6713 - mae: 5.8695 - val_loss: 77.2540 - val_mae: 6.2964\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.9124 - mae: 5.6446 - val_loss: 73.9798 - val_mae: 6.0459\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.0165 - mae: 5.4424 - val_loss: 70.5853 - val_mae: 5.8190\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 62.9377 - mae: 5.3139 - val_loss: 67.2149 - val_mae: 5.5567\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 60.0797 - mae: 5.1146 - val_loss: 64.2759 - val_mae: 5.3320\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.6931 - mae: 4.9499 - val_loss: 61.9393 - val_mae: 5.2414\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.6659 - mae: 4.9111 - val_loss: 60.0383 - val_mae: 4.9504\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.1977 - mae: 4.8176 - val_loss: 58.3649 - val_mae: 4.8571\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.6993 - mae: 4.7063 - val_loss: 57.0938 - val_mae: 4.8684\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.4538 - mae: 4.6964 - val_loss: 55.9584 - val_mae: 4.8201\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.3169 - mae: 4.6134 - val_loss: 54.9508 - val_mae: 4.7642\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.3164 - mae: 4.6543 - val_loss: 53.8290 - val_mae: 4.6565\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.3289 - mae: 4.5420 - val_loss: 52.8145 - val_mae: 4.6428\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.1019 - mae: 4.5162 - val_loss: 51.7954 - val_mae: 4.6478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.2023 - mae: 4.4771 - val_loss: 50.8169 - val_mae: 4.5962\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.0795 - mae: 4.3835 - val_loss: 49.9173 - val_mae: 4.5411\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 43.9269 - mae: 4.3754 - val_loss: 48.8808 - val_mae: 4.5454\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 42.8960 - mae: 4.3249 - val_loss: 47.9950 - val_mae: 4.3722\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 42.0008 - mae: 4.2025 - val_loss: 47.2913 - val_mae: 4.3139\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.9074 - mae: 4.1750 - val_loss: 46.1211 - val_mae: 4.3871\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 39.9112 - mae: 4.1015 - val_loss: 45.3353 - val_mae: 4.3056\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.3153 - mae: 4.1000 - val_loss: 44.4753 - val_mae: 4.2945\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.3118 - mae: 3.9917 - val_loss: 43.8473 - val_mae: 4.3165\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.5369 - mae: 3.9971 - val_loss: 43.0092 - val_mae: 4.2149\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.7083 - mae: 3.9377 - val_loss: 42.2918 - val_mae: 4.1778\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.1103 - mae: 3.9066 - val_loss: 42.0039 - val_mae: 4.0797\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.4557 - mae: 3.8907 - val_loss: 41.0291 - val_mae: 4.1202\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.8058 - mae: 3.8793 - val_loss: 40.6022 - val_mae: 4.0676\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.3569 - mae: 3.8078 - val_loss: 39.9265 - val_mae: 4.0540\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.6548 - mae: 3.7958 - val_loss: 39.3163 - val_mae: 4.0372\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 33.0848 - mae: 3.8142 - val_loss: 38.9561 - val_mae: 3.9745\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.6576 - mae: 3.7470 - val_loss: 38.1710 - val_mae: 4.0953\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.1506 - mae: 3.7445 - val_loss: 37.6207 - val_mae: 3.9573\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.8369 - mae: 3.7572 - val_loss: 37.2447 - val_mae: 3.9289\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 31.2882 - mae: 3.6620 - val_loss: 36.4967 - val_mae: 3.9469\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.9608 - mae: 3.6700 - val_loss: 36.3553 - val_mae: 3.8527\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.4510 - mae: 3.6589 - val_loss: 35.5632 - val_mae: 3.9254\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 30.1080 - mae: 3.6347 - val_loss: 35.1344 - val_mae: 3.8972\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.8114 - mae: 3.6243 - val_loss: 34.8942 - val_mae: 3.8036\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.4327 - mae: 3.5926 - val_loss: 34.3467 - val_mae: 3.8605\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.1772 - mae: 3.5768 - val_loss: 33.9014 - val_mae: 3.8294\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 28.6824 - mae: 3.5631 - val_loss: 33.5018 - val_mae: 3.7503\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.3396 - mae: 3.5357 - val_loss: 33.1956 - val_mae: 3.7229\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.0823 - mae: 3.5006 - val_loss: 32.7697 - val_mae: 3.7219\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.7741 - mae: 3.4885 - val_loss: 32.5240 - val_mae: 3.7979\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.5835 - mae: 3.5368 - val_loss: 32.0737 - val_mae: 3.7299\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 27.0897 - mae: 3.4460 - val_loss: 31.8345 - val_mae: 3.7480\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.9754 - mae: 3.4650 - val_loss: 31.4484 - val_mae: 3.7148\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.5640 - mae: 3.4580 - val_loss: 31.1826 - val_mae: 3.5789\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 26.2659 - mae: 3.3965 - val_loss: 30.8784 - val_mae: 3.5454\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.0064 - mae: 3.4172 - val_loss: 30.5206 - val_mae: 3.5365\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.6452 - mae: 3.3590 - val_loss: 30.0791 - val_mae: 3.5582\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.3732 - mae: 3.3547 - val_loss: 29.9052 - val_mae: 3.5033\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 25.2211 - mae: 3.3562 - val_loss: 29.7858 - val_mae: 3.4638\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 24.8986 - mae: 3.3084 - val_loss: 29.3598 - val_mae: 3.5891\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.2799 - mae: 3.4452 - val_loss: 29.0066 - val_mae: 3.5318\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 24.7437 - mae: 3.3640 - val_loss: 28.7879 - val_mae: 3.4197\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.1349 - mae: 3.2909 - val_loss: 28.4794 - val_mae: 3.4456\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.0212 - mae: 3.2730 - val_loss: 28.2411 - val_mae: 3.4097\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.9453 - mae: 3.2685 - val_loss: 28.0364 - val_mae: 3.5037\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.7789 - mae: 3.2603 - val_loss: 27.8400 - val_mae: 3.5085\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 23.1111 - mae: 3.2163 - val_loss: 27.8712 - val_mae: 3.3190\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 23.1663 - mae: 3.2114 - val_loss: 27.2556 - val_mae: 3.3565\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 23.1263 - mae: 3.2154 - val_loss: 27.0674 - val_mae: 3.3818\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 22.7558 - mae: 3.2089 - val_loss: 26.8914 - val_mae: 3.3057\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 22.4587 - mae: 3.1528 - val_loss: 26.6138 - val_mae: 3.3520\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.3837 - mae: 3.1682 - val_loss: 26.7153 - val_mae: 3.2561\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.1475 - mae: 3.1415 - val_loss: 26.2602 - val_mae: 3.3041\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.9163 - mae: 3.1343 - val_loss: 26.0812 - val_mae: 3.2768\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.8945 - mae: 3.1524 - val_loss: 25.8540 - val_mae: 3.3110\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.7753 - mae: 3.1445 - val_loss: 25.8219 - val_mae: 3.2074\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 33.9202 - mae: 4.0876\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 14.4656 - mae: 14.4656 - val_loss: 10.4113 - val_mae: 10.4113\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4892 - mae: 9.4892 - val_loss: 8.7418 - val_mae: 8.7418\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2398 - mae: 8.2398 - val_loss: 7.9862 - val_mae: 7.9862\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5127 - mae: 7.5127 - val_loss: 7.5202 - val_mae: 7.5202\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0206 - mae: 7.0206 - val_loss: 7.2072 - val_mae: 7.2072\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7014 - mae: 6.7014 - val_loss: 7.0109 - val_mae: 7.0109\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5357 - mae: 6.5357 - val_loss: 6.9406 - val_mae: 6.9406\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4556 - mae: 6.4556 - val_loss: 6.9163 - val_mae: 6.9163\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4192 - mae: 6.4192 - val_loss: 6.9131 - val_mae: 6.9131\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4036 - mae: 6.4036 - val_loss: 6.9154 - val_mae: 6.9154\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3953 - mae: 6.3953 - val_loss: 6.9222 - val_mae: 6.9222\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9232 - val_mae: 6.9232\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3828 - mae: 6.3828 - val_loss: 6.9272 - val_mae: 6.9272\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3799 - mae: 6.3799 - val_loss: 6.9280 - val_mae: 6.9280\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3789 - mae: 6.3789 - val_loss: 6.9395 - val_mae: 6.9395\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3727 - mae: 6.3727 - val_loss: 6.9284 - val_mae: 6.9284\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3695 - mae: 6.3695 - val_loss: 6.9300 - val_mae: 6.9300\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3635 - mae: 6.3635 - val_loss: 6.9117 - val_mae: 6.9117\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3481 - mae: 6.3481 - val_loss: 6.8980 - val_mae: 6.8980\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3285 - mae: 6.3285 - val_loss: 6.8640 - val_mae: 6.8640\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.2914 - mae: 6.2914 - val_loss: 6.7950 - val_mae: 6.7950\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2222 - mae: 6.2222 - val_loss: 6.6541 - val_mae: 6.6541\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1215 - mae: 6.1215 - val_loss: 6.5005 - val_mae: 6.5005\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9919 - mae: 5.9919 - val_loss: 6.3066 - val_mae: 6.3066\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8617 - mae: 5.8617 - val_loss: 6.1061 - val_mae: 6.1061\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6991 - mae: 5.6991 - val_loss: 5.9506 - val_mae: 5.9506\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5105 - mae: 5.5105 - val_loss: 5.6034 - val_mae: 5.6034\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2788 - mae: 5.2788 - val_loss: 5.2758 - val_mae: 5.2758\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0806 - mae: 5.0806 - val_loss: 5.1697 - val_mae: 5.1697\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9504 - mae: 4.9504 - val_loss: 4.9966 - val_mae: 4.9966\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8165 - mae: 4.8165 - val_loss: 4.8400 - val_mae: 4.8400\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7308 - mae: 4.7308 - val_loss: 4.8419 - val_mae: 4.8419\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6733 - mae: 4.6733 - val_loss: 4.7866 - val_mae: 4.7866\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6400 - mae: 4.6400 - val_loss: 4.6736 - val_mae: 4.6736\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6027 - mae: 4.6027 - val_loss: 4.6771 - val_mae: 4.6771\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5593 - mae: 4.5593 - val_loss: 4.6729 - val_mae: 4.6729\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5162 - mae: 4.5162 - val_loss: 4.5826 - val_mae: 4.5826\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4913 - mae: 4.4913 - val_loss: 4.6305 - val_mae: 4.6305\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4946 - mae: 4.4946 - val_loss: 4.5404 - val_mae: 4.5404\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4309 - mae: 4.4309 - val_loss: 4.5466 - val_mae: 4.5466\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3848 - mae: 4.3848 - val_loss: 4.5209 - val_mae: 4.5209\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3550 - mae: 4.3550 - val_loss: 4.4815 - val_mae: 4.4815\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3145 - mae: 4.3145 - val_loss: 4.4703 - val_mae: 4.4703\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2812 - mae: 4.2812 - val_loss: 4.4151 - val_mae: 4.4151\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2363 - mae: 4.2363 - val_loss: 4.4028 - val_mae: 4.4028\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2164 - mae: 4.2164 - val_loss: 4.3731 - val_mae: 4.3731\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2006 - mae: 4.2006 - val_loss: 4.4061 - val_mae: 4.4061\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1504 - mae: 4.1504 - val_loss: 4.3359 - val_mae: 4.3359\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1622 - mae: 4.1622 - val_loss: 4.3133 - val_mae: 4.3133\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1235 - mae: 4.1235 - val_loss: 4.2976 - val_mae: 4.2976\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0861 - mae: 4.0861 - val_loss: 4.2779 - val_mae: 4.2779\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0598 - mae: 4.0598 - val_loss: 4.2921 - val_mae: 4.2921\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0711 - mae: 4.0711 - val_loss: 4.2787 - val_mae: 4.2787\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0282 - mae: 4.0282 - val_loss: 4.2522 - val_mae: 4.2522\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0123 - mae: 4.0123 - val_loss: 4.2191 - val_mae: 4.2191\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0044 - mae: 4.0044 - val_loss: 4.2219 - val_mae: 4.2219\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9802 - mae: 3.9802 - val_loss: 4.2059 - val_mae: 4.2059\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9514 - mae: 3.9514 - val_loss: 4.1986 - val_mae: 4.1986\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9526 - mae: 3.9526 - val_loss: 4.1889 - val_mae: 4.1889\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9289 - mae: 3.9289 - val_loss: 4.1764 - val_mae: 4.1764\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9242 - mae: 3.9242 - val_loss: 4.1621 - val_mae: 4.1621\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9096 - mae: 3.9096 - val_loss: 4.1457 - val_mae: 4.1457\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8973 - mae: 3.8973 - val_loss: 4.1350 - val_mae: 4.1350\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8727 - mae: 3.8727 - val_loss: 4.1248 - val_mae: 4.1248\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8585 - mae: 3.8585 - val_loss: 4.1185 - val_mae: 4.1185\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8469 - mae: 3.8469 - val_loss: 4.1066 - val_mae: 4.1066\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8250 - mae: 3.8250 - val_loss: 4.0904 - val_mae: 4.0904\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8218 - mae: 3.8218 - val_loss: 4.0993 - val_mae: 4.0993\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8140 - mae: 3.8140 - val_loss: 4.0684 - val_mae: 4.0684\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7861 - mae: 3.7861 - val_loss: 4.0514 - val_mae: 4.0514\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7796 - mae: 3.7796 - val_loss: 4.0394 - val_mae: 4.0394\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7618 - mae: 3.7618 - val_loss: 4.0470 - val_mae: 4.0470\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7291 - mae: 3.7291 - val_loss: 4.0095 - val_mae: 4.0095\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7200 - mae: 3.7200 - val_loss: 4.0230 - val_mae: 4.0230\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7085 - mae: 3.7085 - val_loss: 4.0153 - val_mae: 4.0153\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7075 - mae: 3.7075 - val_loss: 3.9820 - val_mae: 3.9820\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6936 - mae: 3.6936 - val_loss: 3.9687 - val_mae: 3.9687\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6782 - mae: 3.6782 - val_loss: 3.9509 - val_mae: 3.9509\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6671 - mae: 3.6671 - val_loss: 3.9701 - val_mae: 3.9701\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6495 - mae: 3.6495 - val_loss: 3.9347 - val_mae: 3.9347\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6510 - mae: 3.6510 - val_loss: 3.9345 - val_mae: 3.9345\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6380 - mae: 3.6380 - val_loss: 3.9502 - val_mae: 3.9502\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6505 - mae: 3.6505 - val_loss: 3.9087 - val_mae: 3.9087\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6125 - mae: 3.6125 - val_loss: 3.8890 - val_mae: 3.8890\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6417 - mae: 3.6417 - val_loss: 3.9119 - val_mae: 3.9119\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6124 - mae: 3.6124 - val_loss: 3.8650 - val_mae: 3.8650\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6148 - mae: 3.6148 - val_loss: 3.9101 - val_mae: 3.9101\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5773 - mae: 3.5773 - val_loss: 3.9043 - val_mae: 3.9043\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5774 - mae: 3.5774 - val_loss: 3.8870 - val_mae: 3.8870\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5690 - mae: 3.5690 - val_loss: 3.8544 - val_mae: 3.8544\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5460 - mae: 3.5460 - val_loss: 4.0217 - val_mae: 4.0217\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5851 - mae: 3.5851 - val_loss: 3.7992 - val_mae: 3.7992\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5605 - mae: 3.5605 - val_loss: 3.7887 - val_mae: 3.7887\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5279 - mae: 3.5279 - val_loss: 3.8390 - val_mae: 3.8390\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5376 - mae: 3.5376 - val_loss: 3.7924 - val_mae: 3.7924\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5315 - mae: 3.5315 - val_loss: 3.8189 - val_mae: 3.8189\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5088 - mae: 3.5088 - val_loss: 3.7653 - val_mae: 3.7653\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5032 - mae: 3.5032 - val_loss: 3.7380 - val_mae: 3.7380\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5277 - mae: 3.5277 - val_loss: 3.7945 - val_mae: 3.7945\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4964 - mae: 3.4964 - val_loss: 3.7999 - val_mae: 3.7999\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.1317 - mae: 5.1317\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 327.5628 - mae: 15.3534 - val_loss: 203.6158 - val_mae: 11.0622\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 171.2946 - mae: 10.1497 - val_loss: 161.7232 - val_mae: 9.3809\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 140.1669 - mae: 8.8561 - val_loss: 138.6494 - val_mae: 8.4759\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 122.0543 - mae: 8.0942 - val_loss: 124.0450 - val_mae: 7.9501\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.1045 - mae: 7.5453 - val_loss: 114.0471 - val_mae: 7.5921\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.7700 - mae: 7.1663 - val_loss: 107.5123 - val_mae: 7.3646\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 96.0438 - mae: 6.8820 - val_loss: 102.2683 - val_mae: 7.1581\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 91.7533 - mae: 6.6905 - val_loss: 98.8844 - val_mae: 7.0304\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.7397 - mae: 6.5627 - val_loss: 96.3194 - val_mae: 6.9523\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.4450 - mae: 6.4752 - val_loss: 94.3303 - val_mae: 6.9211\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.7266 - mae: 6.4170 - val_loss: 92.9185 - val_mae: 6.9118\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.5685 - mae: 6.3987 - val_loss: 91.8274 - val_mae: 6.9240\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.5700 - mae: 6.3747 - val_loss: 91.0641 - val_mae: 6.9454\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.8998 - mae: 6.3815 - val_loss: 90.4317 - val_mae: 6.9681\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.4770 - mae: 6.3838 - val_loss: 90.0356 - val_mae: 6.9878\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.1040 - mae: 6.3916 - val_loss: 89.6650 - val_mae: 7.0105\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.8117 - mae: 6.3920 - val_loss: 89.4694 - val_mae: 7.0247\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6703 - mae: 6.3966 - val_loss: 89.3283 - val_mae: 7.0344\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4964 - mae: 6.4012 - val_loss: 89.1487 - val_mae: 7.0523\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.3704 - mae: 6.4058 - val_loss: 89.0425 - val_mae: 7.0593\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.2742 - mae: 6.4101 - val_loss: 88.9229 - val_mae: 7.0697\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.1888 - mae: 6.4117 - val_loss: 88.8182 - val_mae: 7.0733\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.1054 - mae: 6.4134 - val_loss: 88.7048 - val_mae: 7.0731\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.9962 - mae: 6.4187 - val_loss: 88.5602 - val_mae: 7.0799\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.8695 - mae: 6.4183 - val_loss: 88.3876 - val_mae: 7.0806\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.7766 - mae: 6.4218 - val_loss: 88.1698 - val_mae: 7.0727\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 79.5198 - mae: 6.4012 - val_loss: 87.8754 - val_mae: 7.0490\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.2444 - mae: 6.3825 - val_loss: 87.4584 - val_mae: 7.0316\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.8681 - mae: 6.3591 - val_loss: 86.8233 - val_mae: 6.9883\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.2795 - mae: 6.3201 - val_loss: 85.8573 - val_mae: 6.9150\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.3623 - mae: 6.2659 - val_loss: 84.8206 - val_mae: 6.8483\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 76.2695 - mae: 6.1712 - val_loss: 83.4067 - val_mae: 6.7297\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.9751 - mae: 6.0971 - val_loss: 81.7916 - val_mae: 6.6314\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 73.5253 - mae: 5.9616 - val_loss: 79.8290 - val_mae: 6.4800\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 71.6066 - mae: 5.8496 - val_loss: 77.6507 - val_mae: 6.3203\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 69.4258 - mae: 5.6793 - val_loss: 74.9483 - val_mae: 6.0947\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.9009 - mae: 5.5071 - val_loss: 72.0833 - val_mae: 5.9226\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 64.3431 - mae: 5.3855 - val_loss: 68.9586 - val_mae: 5.6558\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 61.7067 - mae: 5.2111 - val_loss: 66.4112 - val_mae: 5.5030\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 59.4827 - mae: 5.0338 - val_loss: 63.9849 - val_mae: 5.2995\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 57.5430 - mae: 5.0258 - val_loss: 61.8821 - val_mae: 5.0819\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 55.6389 - mae: 4.8006 - val_loss: 60.2431 - val_mae: 5.0641\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.4371 - mae: 4.8949 - val_loss: 59.0112 - val_mae: 5.0475\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.0369 - mae: 4.7476 - val_loss: 57.8154 - val_mae: 4.9337\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.0045 - mae: 4.7242 - val_loss: 56.7009 - val_mae: 4.8394\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.0422 - mae: 4.6458 - val_loss: 55.8003 - val_mae: 4.7624\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.0385 - mae: 4.6327 - val_loss: 54.8384 - val_mae: 4.8110\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.1163 - mae: 4.5982 - val_loss: 53.9097 - val_mae: 4.6984\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.3176 - mae: 4.5975 - val_loss: 53.1502 - val_mae: 4.5992\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.4186 - mae: 4.4886 - val_loss: 52.2306 - val_mae: 4.6198\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.3149 - mae: 4.4407 - val_loss: 51.3843 - val_mae: 4.7096\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 45.4094 - mae: 4.4744 - val_loss: 50.7686 - val_mae: 4.4186\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7559 - mae: 4.3297 - val_loss: 49.6312 - val_mae: 4.5057\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5658 - mae: 4.2419 - val_loss: 48.8326 - val_mae: 4.5754\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.7133 - mae: 4.2705 - val_loss: 47.9740 - val_mae: 4.4389\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8754 - mae: 4.2515 - val_loss: 47.2757 - val_mae: 4.3435\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.0419 - mae: 4.1407 - val_loss: 46.4787 - val_mae: 4.4772\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.2356 - mae: 4.0975 - val_loss: 45.7667 - val_mae: 4.4302\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.5724 - mae: 4.1087 - val_loss: 45.0669 - val_mae: 4.3388\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.6184 - mae: 4.0886 - val_loss: 44.5723 - val_mae: 4.1888\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.9944 - mae: 3.9667 - val_loss: 43.7005 - val_mae: 4.2638\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.4091 - mae: 3.9864 - val_loss: 43.1408 - val_mae: 4.2935\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.6845 - mae: 3.9413 - val_loss: 42.4886 - val_mae: 4.2377\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.2922 - mae: 3.9216 - val_loss: 41.9563 - val_mae: 4.1747\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.5147 - mae: 3.8748 - val_loss: 41.4232 - val_mae: 4.2651\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.4039 - mae: 3.9310 - val_loss: 40.7924 - val_mae: 4.2048\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.5754 - mae: 3.8740 - val_loss: 40.2864 - val_mae: 4.1580\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.0299 - mae: 3.7968 - val_loss: 39.8012 - val_mae: 4.1202\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.6824 - mae: 3.7911 - val_loss: 39.3212 - val_mae: 4.1506\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.2432 - mae: 3.7897 - val_loss: 39.1581 - val_mae: 4.2234\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.0846 - mae: 3.8031 - val_loss: 38.3598 - val_mae: 4.0426\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.3558 - mae: 3.7640 - val_loss: 37.8907 - val_mae: 4.0226\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.9620 - mae: 3.7071 - val_loss: 37.7100 - val_mae: 3.9648\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.5679 - mae: 3.7001 - val_loss: 37.0038 - val_mae: 3.9994\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.1832 - mae: 3.7046 - val_loss: 36.6871 - val_mae: 3.9379\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.9343 - mae: 3.6803 - val_loss: 36.2669 - val_mae: 3.9213\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.7433 - mae: 3.6583 - val_loss: 35.7722 - val_mae: 3.9360\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.4172 - mae: 3.6840 - val_loss: 35.4540 - val_mae: 3.8997\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.8443 - mae: 3.6037 - val_loss: 35.1065 - val_mae: 3.8547\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.7497 - mae: 3.6181 - val_loss: 34.6435 - val_mae: 3.8563\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.2560 - mae: 3.5911 - val_loss: 34.4156 - val_mae: 3.8174\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.9452 - mae: 3.5835 - val_loss: 34.0622 - val_mae: 3.7829\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 26.4654 - mae: 3.28 - 0s 3ms/step - loss: 28.6408 - mae: 3.5354 - val_loss: 33.6226 - val_mae: 3.8431\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.6073 - mae: 3.5805 - val_loss: 33.5148 - val_mae: 3.7156\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.0688 - mae: 3.5105 - val_loss: 32.9807 - val_mae: 3.7881\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.7453 - mae: 3.5002 - val_loss: 32.8371 - val_mae: 3.6841\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.6409 - mae: 3.4942 - val_loss: 32.4481 - val_mae: 3.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.2436 - mae: 3.4829 - val_loss: 32.0043 - val_mae: 3.6825\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.9583 - mae: 3.4415 - val_loss: 31.6823 - val_mae: 3.6943\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.0094 - mae: 3.5061 - val_loss: 31.4721 - val_mae: 3.6122\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.4665 - mae: 3.4454 - val_loss: 31.8058 - val_mae: 3.5605\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.6192 - mae: 3.4217 - val_loss: 31.4912 - val_mae: 3.5333\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.1397 - mae: 3.4063 - val_loss: 30.5791 - val_mae: 3.5506\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.7703 - mae: 3.3847 - val_loss: 30.2874 - val_mae: 3.5785\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.5058 - mae: 3.3626 - val_loss: 29.9301 - val_mae: 3.6008\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.4167 - mae: 3.3861 - val_loss: 29.9905 - val_mae: 3.4664\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.2463 - mae: 3.3727 - val_loss: 29.8843 - val_mae: 3.4478\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.1592 - mae: 3.3720 - val_loss: 29.5150 - val_mae: 3.4293\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.6904 - mae: 3.3128 - val_loss: 29.0104 - val_mae: 3.4724\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.5399 - mae: 3.3150 - val_loss: 28.7149 - val_mae: 3.4520\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.5316 - mae: 4.2590\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 14.9217 - mae: 14.9217 - val_loss: 10.7176 - val_mae: 10.7176\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.6981 - mae: 9.6981 - val_loss: 8.8646 - val_mae: 8.8646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3465 - mae: 8.3465 - val_loss: 8.0366 - val_mae: 8.0366\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5622 - mae: 7.5622 - val_loss: 7.5444 - val_mae: 7.5444\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0522 - mae: 7.0522 - val_loss: 7.2665 - val_mae: 7.2665\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7560 - mae: 6.7560 - val_loss: 7.0408 - val_mae: 7.0408\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5666 - mae: 6.5666 - val_loss: 6.9554 - val_mae: 6.9554\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4744 - mae: 6.4744 - val_loss: 6.9223 - val_mae: 6.9223\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4298 - mae: 6.4298 - val_loss: 6.9156 - val_mae: 6.9156\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4085 - mae: 6.4085 - val_loss: 6.9154 - val_mae: 6.9154\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3986 - mae: 6.3986 - val_loss: 6.9208 - val_mae: 6.9208\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3917 - mae: 6.3917 - val_loss: 6.9239 - val_mae: 6.9239\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9279 - val_mae: 6.9279\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9337 - val_mae: 6.9337\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3833 - mae: 6.3833 - val_loss: 6.9308 - val_mae: 6.9308\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3835 - mae: 6.3835 - val_loss: 6.9385 - val_mae: 6.9385\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3767 - mae: 6.3767 - val_loss: 6.9326 - val_mae: 6.9326\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3738 - mae: 6.3738 - val_loss: 6.9323 - val_mae: 6.9323\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3689 - mae: 6.3689 - val_loss: 6.9305 - val_mae: 6.9305\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3609 - mae: 6.3609 - val_loss: 6.9174 - val_mae: 6.9174\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3473 - mae: 6.3473 - val_loss: 6.8962 - val_mae: 6.8962\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3268 - mae: 6.3268 - val_loss: 6.8577 - val_mae: 6.8577\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2858 - mae: 6.2858 - val_loss: 6.7709 - val_mae: 6.7709\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2067 - mae: 6.2067 - val_loss: 6.6125 - val_mae: 6.6125\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1082 - mae: 6.1082 - val_loss: 6.4921 - val_mae: 6.4921\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9968 - mae: 5.9968 - val_loss: 6.3514 - val_mae: 6.3514\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8720 - mae: 5.8720 - val_loss: 6.1787 - val_mae: 6.1787\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.7233 - mae: 5.7233 - val_loss: 5.9826 - val_mae: 5.9826\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5258 - mae: 5.5258 - val_loss: 5.6053 - val_mae: 5.6053\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3468 - mae: 5.3468 - val_loss: 5.3287 - val_mae: 5.3287\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.1108 - mae: 5.1108 - val_loss: 5.2564 - val_mae: 5.2564\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9631 - mae: 4.9631 - val_loss: 5.0208 - val_mae: 5.0208\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8340 - mae: 4.8340 - val_loss: 4.8827 - val_mae: 4.8827\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7580 - mae: 4.7580 - val_loss: 4.8959 - val_mae: 4.8959\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6986 - mae: 4.6986 - val_loss: 4.7680 - val_mae: 4.7680\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.6511 - mae: 4.6511 - val_loss: 4.7330 - val_mae: 4.7330\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6205 - mae: 4.6205 - val_loss: 4.7070 - val_mae: 4.7070\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.5830 - mae: 4.5830 - val_loss: 4.6458 - val_mae: 4.6458\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5487 - mae: 4.5487 - val_loss: 4.6255 - val_mae: 4.6255\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5471 - mae: 4.5471 - val_loss: 4.6982 - val_mae: 4.6982\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4793 - mae: 4.4793 - val_loss: 4.5750 - val_mae: 4.5750\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.4579 - mae: 4.4579 - val_loss: 4.5995 - val_mae: 4.5995\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.4191 - mae: 4.4191 - val_loss: 4.5105 - val_mae: 4.5105\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4036 - mae: 4.4036 - val_loss: 4.4829 - val_mae: 4.4829\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3534 - mae: 4.3534 - val_loss: 4.5091 - val_mae: 4.5091\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3280 - mae: 4.3280 - val_loss: 4.4636 - val_mae: 4.4636\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.2982 - mae: 4.2982 - val_loss: 4.4549 - val_mae: 4.4549\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2521 - mae: 4.2521 - val_loss: 4.4081 - val_mae: 4.4081\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2154 - mae: 4.2154 - val_loss: 4.3982 - val_mae: 4.3982\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2093 - mae: 4.2093 - val_loss: 4.3807 - val_mae: 4.3807\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1553 - mae: 4.1553 - val_loss: 4.3747 - val_mae: 4.3747\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1497 - mae: 4.1497 - val_loss: 4.3890 - val_mae: 4.3890\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.1281 - mae: 4.1281 - val_loss: 4.3375 - val_mae: 4.3375\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1092 - mae: 4.1092 - val_loss: 4.3580 - val_mae: 4.3580\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0843 - mae: 4.0843 - val_loss: 4.3082 - val_mae: 4.3082\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0693 - mae: 4.0693 - val_loss: 4.3009 - val_mae: 4.3009\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0579 - mae: 4.0579 - val_loss: 4.2936 - val_mae: 4.2936\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0483 - mae: 4.0483 - val_loss: 4.2622 - val_mae: 4.2622\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0064 - mae: 4.0064 - val_loss: 4.2443 - val_mae: 4.2443\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9870 - mae: 3.9870 - val_loss: 4.2482 - val_mae: 4.2482\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9690 - mae: 3.9690 - val_loss: 4.2094 - val_mae: 4.2094\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9561 - mae: 3.9561 - val_loss: 4.1967 - val_mae: 4.1967\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9558 - mae: 3.9558 - val_loss: 4.1852 - val_mae: 4.1852\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9290 - mae: 3.9290 - val_loss: 4.1693 - val_mae: 4.1693\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9148 - mae: 3.9148 - val_loss: 4.1506 - val_mae: 4.1506\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9165 - mae: 3.9165 - val_loss: 4.1417 - val_mae: 4.1417\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8913 - mae: 3.8913 - val_loss: 4.1402 - val_mae: 4.1402\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8663 - mae: 3.8663 - val_loss: 4.1276 - val_mae: 4.1276\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8542 - mae: 3.8542 - val_loss: 4.1149 - val_mae: 4.1149\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8421 - mae: 3.8421 - val_loss: 4.1093 - val_mae: 4.1093\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8359 - mae: 3.8359 - val_loss: 4.0937 - val_mae: 4.0937\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8181 - mae: 3.8181 - val_loss: 4.0748 - val_mae: 4.0748\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8048 - mae: 3.8048 - val_loss: 4.0665 - val_mae: 4.0665\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7843 - mae: 3.7843 - val_loss: 4.0650 - val_mae: 4.0650\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7909 - mae: 3.7909 - val_loss: 4.0376 - val_mae: 4.0376\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7625 - mae: 3.7625 - val_loss: 4.0435 - val_mae: 4.0435\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7361 - mae: 3.7361 - val_loss: 4.0226 - val_mae: 4.0226\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7362 - mae: 3.7362 - val_loss: 3.9985 - val_mae: 3.9985\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7359 - mae: 3.7359 - val_loss: 4.0044 - val_mae: 4.0044\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7290 - mae: 3.7290 - val_loss: 3.9913 - val_mae: 3.9913\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6848 - mae: 3.6848 - val_loss: 3.9871 - val_mae: 3.9871\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6865 - mae: 3.6865 - val_loss: 3.9740 - val_mae: 3.9740\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6764 - mae: 3.6764 - val_loss: 3.9431 - val_mae: 3.9431\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6534 - mae: 3.6534 - val_loss: 3.9472 - val_mae: 3.9472\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6415 - mae: 3.6415 - val_loss: 3.9502 - val_mae: 3.9502\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6447 - mae: 3.6447 - val_loss: 3.9269 - val_mae: 3.9269\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6193 - mae: 3.6193 - val_loss: 3.9708 - val_mae: 3.9708\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6465 - mae: 3.6465 - val_loss: 3.9818 - val_mae: 3.9818\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6187 - mae: 3.6187 - val_loss: 3.9358 - val_mae: 3.9358\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6038 - mae: 3.6038 - val_loss: 3.9099 - val_mae: 3.9099\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5833 - mae: 3.5833 - val_loss: 3.9143 - val_mae: 3.9143\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5713 - mae: 3.5713 - val_loss: 3.8616 - val_mae: 3.8616\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5739 - mae: 3.5739 - val_loss: 3.8694 - val_mae: 3.8694\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5580 - mae: 3.5580 - val_loss: 3.8422 - val_mae: 3.8422\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5669 - mae: 3.5669 - val_loss: 3.8379 - val_mae: 3.8379\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5533 - mae: 3.5533 - val_loss: 3.8211 - val_mae: 3.8211\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5322 - mae: 3.5322 - val_loss: 3.8018 - val_mae: 3.8018\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5201 - mae: 3.5201 - val_loss: 3.8381 - val_mae: 3.8381\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5190 - mae: 3.5190 - val_loss: 3.7940 - val_mae: 3.7940\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4962 - mae: 3.4962 - val_loss: 3.7696 - val_mae: 3.7696\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.6567 - mae: 4.6567\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 294.3257 - mae: 14.1578 - val_loss: 178.5065 - val_mae: 10.0613\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 147.4786 - mae: 9.1238 - val_loss: 137.7950 - val_mae: 8.4436\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 119.2033 - mae: 7.9660 - val_loss: 119.2225 - val_mae: 7.7770\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 104.4968 - mae: 7.2967 - val_loss: 108.2755 - val_mae: 7.3916\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.7399 - mae: 6.8796 - val_loss: 101.5136 - val_mae: 7.1294\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 90.3778 - mae: 6.6285 - val_loss: 97.0311 - val_mae: 6.9647\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.7998 - mae: 6.4859 - val_loss: 94.3555 - val_mae: 6.9199\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.6464 - mae: 6.4241 - val_loss: 92.2532 - val_mae: 6.9146\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.0890 - mae: 6.3860 - val_loss: 91.3195 - val_mae: 6.9335\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 82.1395 - mae: 6.3790 - val_loss: 90.5502 - val_mae: 6.9589\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.4792 - mae: 6.3722 - val_loss: 89.9974 - val_mae: 6.9836\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.0845 - mae: 6.3954 - val_loss: 89.5527 - val_mae: 7.0104\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.7204 - mae: 6.3922 - val_loss: 89.3395 - val_mae: 7.0245\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5245 - mae: 6.3976 - val_loss: 89.1144 - val_mae: 7.0433\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.3576 - mae: 6.4065 - val_loss: 88.9380 - val_mae: 7.0602\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.2179 - mae: 6.4110 - val_loss: 88.8051 - val_mae: 7.0682\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.1260 - mae: 6.4187 - val_loss: 88.6723 - val_mae: 7.0700\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.9652 - mae: 6.4110 - val_loss: 88.5201 - val_mae: 7.0705\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.8542 - mae: 6.4104 - val_loss: 88.3239 - val_mae: 7.0700\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.6862 - mae: 6.4127 - val_loss: 88.0883 - val_mae: 7.0632\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.4345 - mae: 6.3943 - val_loss: 87.7709 - val_mae: 7.0430\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 79.1208 - mae: 6.3717 - val_loss: 87.3044 - val_mae: 7.0130\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.6669 - mae: 6.3463 - val_loss: 86.6443 - val_mae: 6.9725\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 78.0462 - mae: 6.2977 - val_loss: 85.6975 - val_mae: 6.8947\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 77.1233 - mae: 6.2484 - val_loss: 84.5916 - val_mae: 6.8458\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 75.9460 - mae: 6.1666 - val_loss: 83.0785 - val_mae: 6.7275\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 74.5153 - mae: 6.0676 - val_loss: 81.3257 - val_mae: 6.5888\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 72.8996 - mae: 5.9420 - val_loss: 79.2866 - val_mae: 6.4479\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 70.9620 - mae: 5.7849 - val_loss: 76.7811 - val_mae: 6.2853\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 68.7224 - mae: 5.7215 - val_loss: 74.0315 - val_mae: 6.0873\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 66.2203 - mae: 5.4827 - val_loss: 70.9734 - val_mae: 5.8509\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 63.4007 - mae: 5.3404 - val_loss: 67.9706 - val_mae: 5.6507\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 60.7865 - mae: 5.1435 - val_loss: 65.1270 - val_mae: 5.4525\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 58.3796 - mae: 5.0622 - val_loss: 62.9101 - val_mae: 5.2875\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 56.4217 - mae: 4.9626 - val_loss: 60.9566 - val_mae: 4.9688\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 54.6683 - mae: 4.8149 - val_loss: 59.1635 - val_mae: 5.0189\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 53.3091 - mae: 4.7636 - val_loss: 57.8710 - val_mae: 4.8783\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 52.1915 - mae: 4.8231 - val_loss: 56.6621 - val_mae: 4.8491\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 51.0385 - mae: 4.6834 - val_loss: 55.6865 - val_mae: 4.8598\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 49.9650 - mae: 4.6750 - val_loss: 54.6513 - val_mae: 4.7194\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 48.8942 - mae: 4.6236 - val_loss: 53.6948 - val_mae: 4.7471\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 47.9650 - mae: 4.6117 - val_loss: 52.8597 - val_mae: 4.5860\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.9935 - mae: 4.4911 - val_loss: 51.8213 - val_mae: 4.7175\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 46.1471 - mae: 4.4926 - val_loss: 51.1009 - val_mae: 4.8196\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 44.7228 - mae: 4.4710 - val_loss: 49.9989 - val_mae: 4.5082\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.8338 - mae: 4.3055 - val_loss: 48.9863 - val_mae: 4.5225\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 42.7296 - mae: 4.3437 - val_loss: 48.1787 - val_mae: 4.4830\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 41.8495 - mae: 4.2583 - val_loss: 47.2368 - val_mae: 4.4154\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.7795 - mae: 4.1189 - val_loss: 46.4047 - val_mae: 4.4226\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 40.1377 - mae: 4.1942 - val_loss: 45.5188 - val_mae: 4.3865\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 39.3320 - mae: 4.1279 - val_loss: 44.7662 - val_mae: 4.3070\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 38.4006 - mae: 4.0016 - val_loss: 44.0822 - val_mae: 4.2768\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 37.6469 - mae: 4.0523 - val_loss: 43.6902 - val_mae: 4.1405\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.9521 - mae: 3.9562 - val_loss: 42.6733 - val_mae: 4.1728\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 36.0413 - mae: 3.9584 - val_loss: 42.0229 - val_mae: 4.1597\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 35.5906 - mae: 3.8830 - val_loss: 41.3992 - val_mae: 4.2438\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.8569 - mae: 3.8740 - val_loss: 40.8321 - val_mae: 4.1020\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 34.5026 - mae: 3.8475 - val_loss: 40.0466 - val_mae: 4.1415\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.6765 - mae: 3.8269 - val_loss: 39.5848 - val_mae: 4.0850\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 33.0944 - mae: 3.7846 - val_loss: 38.9511 - val_mae: 4.1027\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.6585 - mae: 3.7667 - val_loss: 38.3815 - val_mae: 4.0666\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 32.2647 - mae: 3.7473 - val_loss: 37.9388 - val_mae: 4.0161\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.7824 - mae: 3.7352 - val_loss: 37.4150 - val_mae: 4.0020\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.4499 - mae: 3.6845 - val_loss: 36.9427 - val_mae: 4.0279\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 31.0971 - mae: 3.7293 - val_loss: 36.8673 - val_mae: 3.9035\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.6423 - mae: 3.6696 - val_loss: 36.0361 - val_mae: 3.9513\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.3392 - mae: 3.6661 - val_loss: 35.9669 - val_mae: 3.8463\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 30.0930 - mae: 3.6633 - val_loss: 35.4893 - val_mae: 3.8293\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.5761 - mae: 3.6268 - val_loss: 35.1065 - val_mae: 3.8213\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 29.1833 - mae: 3.5851 - val_loss: 34.4315 - val_mae: 3.8318\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 28.9623 - mae: 3.5700 - val_loss: 34.0433 - val_mae: 3.8425\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.8303 - mae: 3.5824 - val_loss: 33.6831 - val_mae: 3.8825\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 28.5718 - mae: 3.5737 - val_loss: 33.5240 - val_mae: 3.9162\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.9632 - mae: 3.5364 - val_loss: 33.1787 - val_mae: 3.6981\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.8557 - mae: 3.5102 - val_loss: 32.6733 - val_mae: 3.7038\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.4442 - mae: 3.5068 - val_loss: 32.7822 - val_mae: 3.6393\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 27.1979 - mae: 3.4792 - val_loss: 32.0575 - val_mae: 3.6485\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.9727 - mae: 3.4781 - val_loss: 31.5983 - val_mae: 3.7177\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.6599 - mae: 3.4626 - val_loss: 31.4345 - val_mae: 3.6269\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.4235 - mae: 3.4383 - val_loss: 31.0094 - val_mae: 3.6251\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.0587 - mae: 3.4203 - val_loss: 30.7509 - val_mae: 3.6030\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.9454 - mae: 3.4372 - val_loss: 30.5433 - val_mae: 3.5595\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.6441 - mae: 3.3969 - val_loss: 30.0765 - val_mae: 3.5905\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.3964 - mae: 3.4040 - val_loss: 29.8897 - val_mae: 3.5414\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.0974 - mae: 3.3445 - val_loss: 29.6735 - val_mae: 3.6478\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 25.1113 - mae: 3.4015 - val_loss: 29.3585 - val_mae: 3.5098\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.8773 - mae: 3.3765 - val_loss: 29.2089 - val_mae: 3.4849\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.5525 - mae: 3.3500 - val_loss: 28.9852 - val_mae: 3.4507\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.4266 - mae: 3.3277 - val_loss: 28.6766 - val_mae: 3.4755\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.1434 - mae: 3.3107 - val_loss: 28.4149 - val_mae: 3.5473\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.9995 - mae: 3.3143 - val_loss: 28.1384 - val_mae: 3.4924\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.7139 - mae: 3.2730 - val_loss: 27.9446 - val_mae: 3.4292\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.8666 - mae: 3.3368 - val_loss: 27.6442 - val_mae: 3.4410\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.4816 - mae: 3.2772 - val_loss: 27.8183 - val_mae: 3.3532\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 23.1633 - mae: 3.2492 - val_loss: 27.2320 - val_mae: 3.3930\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.9282 - mae: 3.2366 - val_loss: 27.6717 - val_mae: 3.3206\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 22.9792 - mae: 3.2282 - val_loss: 26.8922 - val_mae: 3.3554\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.6528 - mae: 3.2272 - val_loss: 26.7329 - val_mae: 3.4131\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.6282 - mae: 3.2561 - val_loss: 26.8848 - val_mae: 3.2918\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 22.3039 - mae: 3.1751 - val_loss: 26.3001 - val_mae: 3.3451\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.5834 - mae: 4.0476\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 14.3146 - mae: 14.3146 - val_loss: 9.9966 - val_mae: 9.9966\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1447 - mae: 9.1447 - val_loss: 8.4721 - val_mae: 8.4721\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.0169 - mae: 8.0169 - val_loss: 7.8294 - val_mae: 7.8294\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3362 - mae: 7.3362 - val_loss: 7.4101 - val_mae: 7.4101\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8999 - mae: 6.8999 - val_loss: 7.1422 - val_mae: 7.1422\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6459 - mae: 6.6459 - val_loss: 6.9827 - val_mae: 6.9827\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5087 - mae: 6.5087 - val_loss: 6.9350 - val_mae: 6.9350\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4430 - mae: 6.4430 - val_loss: 6.9143 - val_mae: 6.9143\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4120 - mae: 6.4120 - val_loss: 6.9130 - val_mae: 6.9130\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3996 - mae: 6.3996 - val_loss: 6.9161 - val_mae: 6.9161\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9181 - val_mae: 6.9181\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3852 - mae: 6.3852 - val_loss: 6.9240 - val_mae: 6.9240\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3835 - mae: 6.3835 - val_loss: 6.9283 - val_mae: 6.9283\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3781 - mae: 6.3781 - val_loss: 6.9279 - val_mae: 6.9279\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3753 - mae: 6.3753 - val_loss: 6.9246 - val_mae: 6.9246\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3686 - mae: 6.3686 - val_loss: 6.9257 - val_mae: 6.9257\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3628 - mae: 6.3628 - val_loss: 6.9200 - val_mae: 6.9200\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3522 - mae: 6.3522 - val_loss: 6.9037 - val_mae: 6.9037\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3386 - mae: 6.3386 - val_loss: 6.8799 - val_mae: 6.8799\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3104 - mae: 6.3104 - val_loss: 6.8214 - val_mae: 6.8214\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2685 - mae: 6.2685 - val_loss: 6.7488 - val_mae: 6.7488\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1941 - mae: 6.1941 - val_loss: 6.6163 - val_mae: 6.6163\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0983 - mae: 6.0983 - val_loss: 6.4956 - val_mae: 6.4956\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.9853 - mae: 5.9853 - val_loss: 6.3376 - val_mae: 6.3376\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8673 - mae: 5.8673 - val_loss: 6.1331 - val_mae: 6.1331\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.7134 - mae: 5.7134 - val_loss: 5.9422 - val_mae: 5.9422\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5344 - mae: 5.5344 - val_loss: 5.6589 - val_mae: 5.6589\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.3277 - mae: 5.3277 - val_loss: 5.3388 - val_mae: 5.3388\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1126 - mae: 5.1126 - val_loss: 5.0779 - val_mae: 5.0779\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9533 - mae: 4.9533 - val_loss: 5.0521 - val_mae: 5.0521\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8160 - mae: 4.8160 - val_loss: 4.8252 - val_mae: 4.8252\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7243 - mae: 4.7243 - val_loss: 4.7450 - val_mae: 4.7450\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6819 - mae: 4.6819 - val_loss: 4.7205 - val_mae: 4.7205\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6429 - mae: 4.6429 - val_loss: 4.6544 - val_mae: 4.6544\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5884 - mae: 4.5884 - val_loss: 4.6297 - val_mae: 4.6297\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5478 - mae: 4.5478 - val_loss: 4.6354 - val_mae: 4.6354\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5112 - mae: 4.5112 - val_loss: 4.5689 - val_mae: 4.5689\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4667 - mae: 4.4667 - val_loss: 4.6696 - val_mae: 4.6696\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4281 - mae: 4.4281 - val_loss: 4.4938 - val_mae: 4.4938\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3921 - mae: 4.3921 - val_loss: 4.4922 - val_mae: 4.4922\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3504 - mae: 4.3504 - val_loss: 4.4473 - val_mae: 4.4473\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3024 - mae: 4.3024 - val_loss: 4.4303 - val_mae: 4.4303\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2675 - mae: 4.2675 - val_loss: 4.4216 - val_mae: 4.4216\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2431 - mae: 4.2431 - val_loss: 4.3856 - val_mae: 4.3856\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2093 - mae: 4.2093 - val_loss: 4.3550 - val_mae: 4.3550\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1781 - mae: 4.1781 - val_loss: 4.3630 - val_mae: 4.3630\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1507 - mae: 4.1507 - val_loss: 4.3517 - val_mae: 4.3517\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1181 - mae: 4.1181 - val_loss: 4.3364 - val_mae: 4.3364\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0980 - mae: 4.0980 - val_loss: 4.2973 - val_mae: 4.2973\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0605 - mae: 4.0605 - val_loss: 4.2724 - val_mae: 4.2724\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1003 - mae: 4.1003 - val_loss: 4.2711 - val_mae: 4.2711\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0424 - mae: 4.0424 - val_loss: 4.2488 - val_mae: 4.2488\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0045 - mae: 4.0045 - val_loss: 4.2188 - val_mae: 4.2188\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0160 - mae: 4.0160 - val_loss: 4.2275 - val_mae: 4.2275\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9801 - mae: 3.9801 - val_loss: 4.1848 - val_mae: 4.1848\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9761 - mae: 3.9761 - val_loss: 4.1712 - val_mae: 4.1712\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9557 - mae: 3.9557 - val_loss: 4.1924 - val_mae: 4.1924\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9328 - mae: 3.9328 - val_loss: 4.1628 - val_mae: 4.1628\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9190 - mae: 3.9190 - val_loss: 4.1261 - val_mae: 4.1261\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8980 - mae: 3.8980 - val_loss: 4.2051 - val_mae: 4.2051\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9001 - mae: 3.9001 - val_loss: 4.1145 - val_mae: 4.1145\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8712 - mae: 3.8712 - val_loss: 4.0976 - val_mae: 4.0976\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8572 - mae: 3.8572 - val_loss: 4.0873 - val_mae: 4.0873\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8412 - mae: 3.8412 - val_loss: 4.0780 - val_mae: 4.0780\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8288 - mae: 3.8288 - val_loss: 4.0903 - val_mae: 4.0903\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8233 - mae: 3.8233 - val_loss: 4.0570 - val_mae: 4.0570\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8165 - mae: 3.8165 - val_loss: 4.0451 - val_mae: 4.0451\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7740 - mae: 3.7740 - val_loss: 4.0271 - val_mae: 4.0271\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7806 - mae: 3.7806 - val_loss: 4.0163 - val_mae: 4.0163\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.7657 - mae: 3.7657 - val_loss: 3.9923 - val_mae: 3.9923\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7318 - mae: 3.7318 - val_loss: 4.0237 - val_mae: 4.0237\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7235 - mae: 3.7235 - val_loss: 3.9963 - val_mae: 3.9963\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7139 - mae: 3.7139 - val_loss: 3.9753 - val_mae: 3.9753\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.6915 - mae: 3.6915 - val_loss: 3.9532 - val_mae: 3.9532\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6778 - mae: 3.6778 - val_loss: 3.9381 - val_mae: 3.9381\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6674 - mae: 3.6674 - val_loss: 3.9194 - val_mae: 3.9194\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6826 - mae: 3.6826 - val_loss: 3.9187 - val_mae: 3.9187\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6233 - mae: 3.6233 - val_loss: 3.9075 - val_mae: 3.9075\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6800 - mae: 3.6800 - val_loss: 3.8941 - val_mae: 3.8941\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6231 - mae: 3.6231 - val_loss: 3.9050 - val_mae: 3.9050\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6402 - mae: 3.6402 - val_loss: 3.9014 - val_mae: 3.9014\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6047 - mae: 3.6047 - val_loss: 3.8637 - val_mae: 3.8637\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5874 - mae: 3.5874 - val_loss: 3.9029 - val_mae: 3.9029\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5733 - mae: 3.5733 - val_loss: 3.8202 - val_mae: 3.8202\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5856 - mae: 3.5856 - val_loss: 3.8164 - val_mae: 3.8164\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5640 - mae: 3.5640 - val_loss: 3.8488 - val_mae: 3.8488\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5609 - mae: 3.5609 - val_loss: 3.8344 - val_mae: 3.8344\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5522 - mae: 3.5522 - val_loss: 3.8465 - val_mae: 3.8465\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5509 - mae: 3.5509 - val_loss: 3.8314 - val_mae: 3.8314\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5236 - mae: 3.5236 - val_loss: 3.7514 - val_mae: 3.7514\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5184 - mae: 3.5184 - val_loss: 3.7762 - val_mae: 3.7762\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5092 - mae: 3.5092 - val_loss: 3.7518 - val_mae: 3.7518\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5083 - mae: 3.5083 - val_loss: 3.7588 - val_mae: 3.7588\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4938 - mae: 3.4938 - val_loss: 3.7306 - val_mae: 3.7306\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4981 - mae: 3.4981 - val_loss: 3.6947 - val_mae: 3.6947\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4899 - mae: 3.4899 - val_loss: 3.7358 - val_mae: 3.7358\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4501 - mae: 3.4501 - val_loss: 3.6970 - val_mae: 3.6970\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4801 - mae: 3.4801 - val_loss: 3.6933 - val_mae: 3.6933\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4495 - mae: 3.4495 - val_loss: 3.6599 - val_mae: 3.6599\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4551 - mae: 3.4551 - val_loss: 3.7089 - val_mae: 3.7089\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9363 - mae: 4.9363\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 201.1817 - mae: 10.3905 - val_loss: 38.4998 - val_mae: 4.0430\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 27.5853 - mae: 3.6890 - val_loss: 25.4965 - val_mae: 3.8058\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 19.9343 - mae: 3.1710 - val_loss: 24.1575 - val_mae: 3.2524\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.2961 - mae: 2.9115 - val_loss: 20.2606 - val_mae: 3.3140\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.8628 - mae: 2.8455 - val_loss: 18.6517 - val_mae: 3.0510\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 14.0352 - mae: 2.6385 - val_loss: 17.7489 - val_mae: 3.0063\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 13.2138 - mae: 2.5992 - val_loss: 17.7608 - val_mae: 3.0478\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 12.9234 - mae: 2.5593 - val_loss: 16.1367 - val_mae: 2.8320\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.8025 - mae: 2.4559 - val_loss: 15.8736 - val_mae: 2.7269\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.4767 - mae: 2.3972 - val_loss: 16.8870 - val_mae: 2.8506\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 10.9739 - mae: 2.3772 - val_loss: 15.7874 - val_mae: 2.6452\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.3146 - mae: 2.2793 - val_loss: 14.6940 - val_mae: 2.6275\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.8275 - mae: 2.2406 - val_loss: 15.1082 - val_mae: 2.7031\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.7759 - mae: 2.2223 - val_loss: 15.1062 - val_mae: 2.5959\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.3280 - mae: 2.1884 - val_loss: 14.0925 - val_mae: 2.6031\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.2109 - mae: 2.1625 - val_loss: 14.3673 - val_mae: 2.5736\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.4778 - mae: 2.1136 - val_loss: 14.5588 - val_mae: 2.5849\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.4575 - mae: 2.1017 - val_loss: 14.2152 - val_mae: 2.5244\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.2773 - mae: 2.0886 - val_loss: 14.7497 - val_mae: 2.5618\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.9778 - mae: 2.0915 - val_loss: 13.8251 - val_mae: 2.5363\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.6213 - mae: 2.0250 - val_loss: 13.1405 - val_mae: 2.4304\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.2046 - mae: 1.9664 - val_loss: 13.3556 - val_mae: 2.4616\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.4550 - mae: 2.0237 - val_loss: 14.3517 - val_mae: 2.5949\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.8552 - mae: 1.9127 - val_loss: 12.9331 - val_mae: 2.4322\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.3134 - mae: 2.0040 - val_loss: 13.1646 - val_mae: 2.4351\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.7793 - mae: 1.9023 - val_loss: 12.9441 - val_mae: 2.4348\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.1833 - mae: 1.8214 - val_loss: 12.9676 - val_mae: 2.4495\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.0314 - mae: 1.8149 - val_loss: 13.0335 - val_mae: 2.4127\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.9691 - mae: 1.8346 - val_loss: 13.1691 - val_mae: 2.4478\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.8658 - mae: 1.7882 - val_loss: 12.9626 - val_mae: 2.4310\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6371 - mae: 1.7566 - val_loss: 12.8511 - val_mae: 2.3876\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5062 - mae: 1.7394 - val_loss: 13.0207 - val_mae: 2.4350\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.2217 - mae: 1.6927 - val_loss: 12.8455 - val_mae: 2.4219\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.2834 - mae: 1.7590 - val_loss: 13.9355 - val_mae: 2.5060\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.1420 - mae: 1.6786 - val_loss: 12.5230 - val_mae: 2.3903\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.0476 - mae: 1.6602 - val_loss: 13.0617 - val_mae: 2.4338\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.0642 - mae: 1.6345 - val_loss: 12.6472 - val_mae: 2.4413\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.7800 - mae: 1.6020 - val_loss: 12.4262 - val_mae: 2.3768\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.5401 - mae: 1.5859 - val_loss: 12.6595 - val_mae: 2.3827\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.8103 - mae: 1.6263 - val_loss: 12.7639 - val_mae: 2.3744\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.3906 - mae: 1.5559 - val_loss: 13.1285 - val_mae: 2.4695\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3911 - mae: 1.5406 - val_loss: 12.7598 - val_mae: 2.3728\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3548 - mae: 1.5570 - val_loss: 12.5791 - val_mae: 2.3588\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.1457 - mae: 1.4969 - val_loss: 12.2859 - val_mae: 2.3431\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.9631 - mae: 1.4456 - val_loss: 12.9233 - val_mae: 2.4237\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9160 - mae: 1.4552 - val_loss: 12.8222 - val_mae: 2.3691\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9851 - mae: 1.4824 - val_loss: 12.5207 - val_mae: 2.3671\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8248 - mae: 1.4388 - val_loss: 13.0708 - val_mae: 2.4038\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.7543 - mae: 1.4048 - val_loss: 12.5805 - val_mae: 2.3754\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6632 - mae: 1.4163 - val_loss: 12.6333 - val_mae: 2.4183\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5991 - mae: 1.3947 - val_loss: 13.6848 - val_mae: 2.4064\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6337 - mae: 1.3840 - val_loss: 12.9170 - val_mae: 2.4084\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4946 - mae: 1.3710 - val_loss: 12.8449 - val_mae: 2.3696\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3146 - mae: 1.3495 - val_loss: 13.1429 - val_mae: 2.3744\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3386 - mae: 1.3478 - val_loss: 13.0189 - val_mae: 2.4587\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4827 - mae: 1.4035 - val_loss: 12.6430 - val_mae: 2.4267\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2889 - mae: 1.3166 - val_loss: 12.8901 - val_mae: 2.3535\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0966 - mae: 1.3121 - val_loss: 13.0106 - val_mae: 2.3672\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1733 - mae: 1.2848 - val_loss: 13.0013 - val_mae: 2.4538\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9558 - mae: 1.2673 - val_loss: 12.9141 - val_mae: 2.4307\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9586 - mae: 1.2600 - val_loss: 13.0521 - val_mae: 2.4083\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9977 - mae: 1.2696 - val_loss: 12.7973 - val_mae: 2.4649\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8373 - mae: 1.2413 - val_loss: 12.9259 - val_mae: 2.3304\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8252 - mae: 1.2503 - val_loss: 12.4917 - val_mae: 2.3552\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7078 - mae: 1.2312 - val_loss: 13.0055 - val_mae: 2.3768\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8571 - mae: 1.2426 - val_loss: 12.6798 - val_mae: 2.3256\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7632 - mae: 1.2213 - val_loss: 13.0605 - val_mae: 2.3995\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6779 - mae: 1.2001 - val_loss: 12.8860 - val_mae: 2.4261\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5707 - mae: 1.1561 - val_loss: 13.3143 - val_mae: 2.4443\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4933 - mae: 1.1636 - val_loss: 12.8439 - val_mae: 2.3995\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5065 - mae: 1.1593 - val_loss: 13.2953 - val_mae: 2.4574\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4284 - mae: 1.1253 - val_loss: 13.1944 - val_mae: 2.3969\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4763 - mae: 1.1877 - val_loss: 12.7984 - val_mae: 2.3390\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.5558 - mae: 1.1562 - val_loss: 13.2792 - val_mae: 2.4529\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4309 - mae: 1.1615 - val_loss: 13.5854 - val_mae: 2.4012\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8925 - mae: 1.2968 - val_loss: 13.2010 - val_mae: 2.3997\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3931 - mae: 1.1405 - val_loss: 12.6801 - val_mae: 2.3415\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2594 - mae: 1.0975 - val_loss: 12.7713 - val_mae: 2.3999\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2103 - mae: 1.0889 - val_loss: 13.2990 - val_mae: 2.4184\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1505 - mae: 1.0623 - val_loss: 12.9395 - val_mae: 2.3582\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0618 - mae: 1.0342 - val_loss: 12.9430 - val_mae: 2.4071\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0901 - mae: 1.0258 - val_loss: 13.2707 - val_mae: 2.4134\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.2713 - mae: 1.0848 - val_loss: 13.0640 - val_mae: 2.3852\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0913 - mae: 1.0714 - val_loss: 13.6362 - val_mae: 2.4351\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.3297 - mae: 1.1296 - val_loss: 13.0219 - val_mae: 2.3763\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1294 - mae: 1.0641 - val_loss: 13.5075 - val_mae: 2.4419\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0116 - mae: 1.0492 - val_loss: 12.8909 - val_mae: 2.3700\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0038 - mae: 1.0340 - val_loss: 13.1752 - val_mae: 2.4122\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8713 - mae: 0.9753 - val_loss: 13.5265 - val_mae: 2.4598\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9096 - mae: 1.0187 - val_loss: 13.0941 - val_mae: 2.3942\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9152 - mae: 1.0256 - val_loss: 13.4390 - val_mae: 2.4731\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8692 - mae: 1.0047 - val_loss: 13.3729 - val_mae: 2.4462\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6910 - mae: 0.9208 - val_loss: 12.9835 - val_mae: 2.3567\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8707 - mae: 1.0058 - val_loss: 13.8674 - val_mae: 2.4509\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9052 - mae: 1.0016 - val_loss: 13.5117 - val_mae: 2.4026\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7746 - mae: 0.9608 - val_loss: 13.0740 - val_mae: 2.3723\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6645 - mae: 0.9166 - val_loss: 13.7291 - val_mae: 2.4613\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7356 - mae: 0.9575 - val_loss: 13.1659 - val_mae: 2.4145\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7242 - mae: 0.9441 - val_loss: 13.0852 - val_mae: 2.4417\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6410 - mae: 0.9209 - val_loss: 13.5907 - val_mae: 2.4334\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0609 - mae: 3.4110\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 9.8611 - mae: 9.8611 - val_loss: 3.5143 - val_mae: 3.5143\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3791 - mae: 3.3791 - val_loss: 3.0079 - val_mae: 3.0079\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9688 - mae: 2.9688 - val_loss: 2.8167 - val_mae: 2.8167\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7459 - mae: 2.7459 - val_loss: 2.9417 - val_mae: 2.9417\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5597 - mae: 2.5597 - val_loss: 2.7250 - val_mae: 2.7250\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.5023 - mae: 2.5023 - val_loss: 2.5386 - val_mae: 2.5386\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5330 - mae: 2.5330 - val_loss: 2.6078 - val_mae: 2.6078\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.3266 - mae: 2.3266 - val_loss: 2.6810 - val_mae: 2.6810\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3990 - mae: 2.3990 - val_loss: 2.3853 - val_mae: 2.3853\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.2545 - mae: 2.2545 - val_loss: 2.4157 - val_mae: 2.4157\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1954 - mae: 2.1954 - val_loss: 2.3851 - val_mae: 2.3851\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2100 - mae: 2.2100 - val_loss: 2.5211 - val_mae: 2.5211\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1942 - mae: 2.1942 - val_loss: 2.5968 - val_mae: 2.5968\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1686 - mae: 2.1686 - val_loss: 2.4866 - val_mae: 2.4866\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0254 - mae: 2.0254 - val_loss: 2.3790 - val_mae: 2.3790\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0178 - mae: 2.0178 - val_loss: 2.3164 - val_mae: 2.3164\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0468 - mae: 2.0468 - val_loss: 2.3886 - val_mae: 2.3886\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9500 - mae: 1.9500 - val_loss: 2.3682 - val_mae: 2.3682\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9828 - mae: 1.9828 - val_loss: 2.3239 - val_mae: 2.3239\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8999 - mae: 1.8999 - val_loss: 2.3760 - val_mae: 2.3760\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8518 - mae: 1.8518 - val_loss: 2.4005 - val_mae: 2.4005\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8564 - mae: 1.8564 - val_loss: 2.3400 - val_mae: 2.3400\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8334 - mae: 1.8334 - val_loss: 2.4552 - val_mae: 2.4552\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8122 - mae: 1.8122 - val_loss: 2.4736 - val_mae: 2.4736\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9127 - mae: 1.9127 - val_loss: 2.4435 - val_mae: 2.4435\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8051 - mae: 1.8051 - val_loss: 2.4620 - val_mae: 2.4620\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7655 - mae: 1.7655 - val_loss: 2.3850 - val_mae: 2.3850\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7534 - mae: 1.7534 - val_loss: 2.4300 - val_mae: 2.4300\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.6879 - mae: 1.6879 - val_loss: 2.5381 - val_mae: 2.5381\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7436 - mae: 1.7436 - val_loss: 2.4449 - val_mae: 2.4449\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6436 - mae: 1.6436 - val_loss: 2.4159 - val_mae: 2.4159\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6376 - mae: 1.6376 - val_loss: 2.2708 - val_mae: 2.2708\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6240 - mae: 1.6240 - val_loss: 2.3466 - val_mae: 2.3466\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5833 - mae: 1.5833 - val_loss: 2.3611 - val_mae: 2.3611\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5889 - mae: 1.5889 - val_loss: 2.6048 - val_mae: 2.6048\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5426 - mae: 1.5426 - val_loss: 2.3457 - val_mae: 2.3457\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4852 - mae: 1.4852 - val_loss: 2.4088 - val_mae: 2.4088\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5784 - mae: 1.5784 - val_loss: 2.4844 - val_mae: 2.4844\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5110 - mae: 1.5110 - val_loss: 2.3923 - val_mae: 2.3923\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4789 - mae: 1.4789 - val_loss: 2.3518 - val_mae: 2.3518\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4750 - mae: 1.4750 - val_loss: 2.4109 - val_mae: 2.4109\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4456 - mae: 1.4456 - val_loss: 2.4973 - val_mae: 2.4973\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4640 - mae: 1.4640 - val_loss: 2.4308 - val_mae: 2.4308\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3978 - mae: 1.3978 - val_loss: 2.3598 - val_mae: 2.3598\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3861 - mae: 1.3861 - val_loss: 2.4257 - val_mae: 2.4257\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4039 - mae: 1.4039 - val_loss: 2.4032 - val_mae: 2.4032\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3904 - mae: 1.3904 - val_loss: 2.6231 - val_mae: 2.6231\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.3850 - mae: 1.3850 - val_loss: 2.4857 - val_mae: 2.4857\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3758 - mae: 1.3758 - val_loss: 2.3438 - val_mae: 2.3438\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2908 - mae: 1.2908 - val_loss: 2.4399 - val_mae: 2.4399\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2937 - mae: 1.2937 - val_loss: 2.4836 - val_mae: 2.4836\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.3598 - mae: 1.3598 - val_loss: 2.3737 - val_mae: 2.3737\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2990 - mae: 1.2990 - val_loss: 2.3979 - val_mae: 2.3979\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2730 - mae: 1.2730 - val_loss: 2.3449 - val_mae: 2.3449\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2473 - mae: 1.2473 - val_loss: 2.5119 - val_mae: 2.5119\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2627 - mae: 1.2627 - val_loss: 2.4821 - val_mae: 2.4821\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2509 - mae: 1.2509 - val_loss: 2.4453 - val_mae: 2.4453\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2655 - mae: 1.2655 - val_loss: 2.5003 - val_mae: 2.5003\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2779 - mae: 1.2779 - val_loss: 2.5033 - val_mae: 2.5033\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.2396 - mae: 1.2396 - val_loss: 2.3911 - val_mae: 2.3911\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2500 - mae: 1.2500 - val_loss: 2.4314 - val_mae: 2.4314\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2222 - mae: 1.2222 - val_loss: 2.4881 - val_mae: 2.4881\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2461 - mae: 1.2461 - val_loss: 2.3983 - val_mae: 2.3983\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2045 - mae: 1.2045 - val_loss: 2.4943 - val_mae: 2.4943\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1849 - mae: 1.1849 - val_loss: 2.3803 - val_mae: 2.3803\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1416 - mae: 1.1416 - val_loss: 2.4638 - val_mae: 2.4638\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1565 - mae: 1.1565 - val_loss: 2.4071 - val_mae: 2.4071\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.1606 - mae: 1.1606 - val_loss: 2.3625 - val_mae: 2.3625\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.1327 - mae: 1.1327 - val_loss: 2.4812 - val_mae: 2.4812\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.1306 - mae: 1.1306 - val_loss: 2.4368 - val_mae: 2.4368\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1143 - mae: 1.1143 - val_loss: 2.3588 - val_mae: 2.3588\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1045 - mae: 1.1045 - val_loss: 2.3974 - val_mae: 2.3974\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0800 - mae: 1.0800 - val_loss: 2.4165 - val_mae: 2.4165\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1361 - mae: 1.1361 - val_loss: 2.6116 - val_mae: 2.6116\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1825 - mae: 1.1825 - val_loss: 2.4457 - val_mae: 2.4457\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0989 - mae: 1.0989 - val_loss: 2.3703 - val_mae: 2.3703\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1130 - mae: 1.1130 - val_loss: 2.6054 - val_mae: 2.6054\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1181 - mae: 1.1181 - val_loss: 2.4357 - val_mae: 2.4357\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0319 - mae: 1.0319 - val_loss: 2.4438 - val_mae: 2.4438\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0414 - mae: 1.0414 - val_loss: 2.4216 - val_mae: 2.4216\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0668 - mae: 1.0668 - val_loss: 2.3963 - val_mae: 2.3963\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0803 - mae: 1.0803 - val_loss: 2.5117 - val_mae: 2.5117\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0286 - mae: 1.0286 - val_loss: 2.4441 - val_mae: 2.4441\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0306 - mae: 1.0306 - val_loss: 2.4475 - val_mae: 2.4475\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0282 - mae: 1.0282 - val_loss: 2.4819 - val_mae: 2.4819\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0271 - mae: 1.0271 - val_loss: 2.4436 - val_mae: 2.4436\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0353 - mae: 1.0353 - val_loss: 2.4307 - val_mae: 2.4307\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0384 - mae: 1.0384 - val_loss: 2.4351 - val_mae: 2.4351\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9953 - mae: 0.9953 - val_loss: 2.4657 - val_mae: 2.4657\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0118 - mae: 1.0118 - val_loss: 2.4303 - val_mae: 2.4303\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9919 - mae: 0.9919 - val_loss: 2.4673 - val_mae: 2.4673\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9409 - mae: 0.9409 - val_loss: 2.4831 - val_mae: 2.4831\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0016 - mae: 1.0016 - val_loss: 2.4376 - val_mae: 2.4376\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9938 - mae: 0.9938 - val_loss: 2.5445 - val_mae: 2.5445\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9677 - mae: 0.9677 - val_loss: 2.4690 - val_mae: 2.4690\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9671 - mae: 0.9671 - val_loss: 2.5291 - val_mae: 2.5291\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9316 - mae: 0.9316 - val_loss: 2.5531 - val_mae: 2.5531\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9695 - mae: 0.9695 - val_loss: 2.4307 - val_mae: 2.4307\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9303 - mae: 0.9303 - val_loss: 2.4648 - val_mae: 2.4648\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9464 - mae: 0.9464 - val_loss: 2.4287 - val_mae: 2.4287\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4727 - mae: 3.4727\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 179.8865 - mae: 10.3600 - val_loss: 41.7894 - val_mae: 4.3290\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.4743 - mae: 3.8153 - val_loss: 24.1952 - val_mae: 3.4660\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.0904 - mae: 3.0709 - val_loss: 20.7747 - val_mae: 3.3224\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.8874 - mae: 2.9627 - val_loss: 19.7964 - val_mae: 3.2553\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 15.0678 - mae: 2.7918 - val_loss: 17.9948 - val_mae: 3.0580\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 13.3781 - mae: 2.6638 - val_loss: 18.0309 - val_mae: 2.9355\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 13.0183 - mae: 2.5884 - val_loss: 16.7711 - val_mae: 2.8638\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 12.2334 - mae: 2.5156 - val_loss: 16.2713 - val_mae: 2.8405\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.5014 - mae: 2.4592 - val_loss: 16.2935 - val_mae: 2.7242\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.2828 - mae: 2.4558 - val_loss: 15.3772 - val_mae: 2.7138\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 10.4884 - mae: 2.3826 - val_loss: 14.7378 - val_mae: 2.6248\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 10.6392 - mae: 2.3483 - val_loss: 15.2508 - val_mae: 2.6193\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 10.1547 - mae: 2.3161 - val_loss: 14.1439 - val_mae: 2.5462\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.1803 - mae: 2.1766 - val_loss: 14.0909 - val_mae: 2.6576\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.3151 - mae: 2.2245 - val_loss: 13.6322 - val_mae: 2.5965\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.0076 - mae: 2.2110 - val_loss: 13.9720 - val_mae: 2.4950\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.4792 - mae: 2.1308 - val_loss: 14.5350 - val_mae: 2.4950\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.1813 - mae: 2.1138 - val_loss: 13.2902 - val_mae: 2.5281\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.9909 - mae: 2.0743 - val_loss: 13.4989 - val_mae: 2.5067\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.6510 - mae: 2.0693 - val_loss: 13.8521 - val_mae: 2.4601\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.6823 - mae: 2.0306 - val_loss: 13.2732 - val_mae: 2.4641\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.1330 - mae: 1.9689 - val_loss: 12.7479 - val_mae: 2.3722\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.0949 - mae: 1.9834 - val_loss: 13.0951 - val_mae: 2.3912\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.8161 - mae: 1.9446 - val_loss: 12.8180 - val_mae: 2.4317\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.5950 - mae: 1.8772 - val_loss: 13.1500 - val_mae: 2.3844\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3703 - mae: 1.8607 - val_loss: 12.8214 - val_mae: 2.3380\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3431 - mae: 1.8713 - val_loss: 12.8463 - val_mae: 2.3124\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.9499 - mae: 1.8252 - val_loss: 14.0169 - val_mae: 2.4334\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.2574 - mae: 1.8706 - val_loss: 13.7802 - val_mae: 2.4844\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.9314 - mae: 1.8222 - val_loss: 12.7194 - val_mae: 2.3249\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.6161 - mae: 1.7841 - val_loss: 13.8560 - val_mae: 2.4485\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6523 - mae: 1.7988 - val_loss: 13.0723 - val_mae: 2.3570\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.2588 - mae: 1.7024 - val_loss: 12.8174 - val_mae: 2.3437\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.3514 - mae: 1.7252 - val_loss: 13.1982 - val_mae: 2.3722\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.2733 - mae: 1.7347 - val_loss: 13.2618 - val_mae: 2.4162\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.0508 - mae: 1.6715 - val_loss: 13.3060 - val_mae: 2.3943\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.9611 - mae: 1.6547 - val_loss: 13.5920 - val_mae: 2.4444\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.6122 - mae: 1.6043 - val_loss: 12.8890 - val_mae: 2.3283\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 4.7362 - mae: 1.6276 - val_loss: 12.8256 - val_mae: 2.3527\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.6163 - mae: 1.5773 - val_loss: 13.1330 - val_mae: 2.3847\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.8171 - mae: 1.6543 - val_loss: 13.2513 - val_mae: 2.3740\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3841 - mae: 1.5745 - val_loss: 12.9011 - val_mae: 2.3571\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.5340 - mae: 1.6135 - val_loss: 13.4882 - val_mae: 2.4026\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3690 - mae: 1.5739 - val_loss: 12.7518 - val_mae: 2.3408\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9799 - mae: 1.4790 - val_loss: 12.7015 - val_mae: 2.2813\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0498 - mae: 1.5088 - val_loss: 13.0787 - val_mae: 2.3518\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8305 - mae: 1.4315 - val_loss: 12.8780 - val_mae: 2.3564\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7452 - mae: 1.4453 - val_loss: 12.5972 - val_mae: 2.3677\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6978 - mae: 1.4208 - val_loss: 12.7034 - val_mae: 2.3257\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8323 - mae: 1.4672 - val_loss: 13.4525 - val_mae: 2.3947\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6243 - mae: 1.4151 - val_loss: 13.0773 - val_mae: 2.2785\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8664 - mae: 1.4493 - val_loss: 13.0657 - val_mae: 2.4561\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5952 - mae: 1.4154 - val_loss: 12.7452 - val_mae: 2.3842\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3754 - mae: 1.3465 - val_loss: 13.3954 - val_mae: 2.4180\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3319 - mae: 1.3545 - val_loss: 13.3434 - val_mae: 2.4396\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3829 - mae: 1.3478 - val_loss: 13.8156 - val_mae: 2.4289\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2604 - mae: 1.3278 - val_loss: 13.9243 - val_mae: 2.4443\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1249 - mae: 1.2805 - val_loss: 12.9148 - val_mae: 2.3813\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0876 - mae: 1.3003 - val_loss: 13.7411 - val_mae: 2.3940\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0981 - mae: 1.3124 - val_loss: 13.0031 - val_mae: 2.4003\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2165 - mae: 1.3332 - val_loss: 13.8314 - val_mae: 2.4912\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8810 - mae: 1.2432 - val_loss: 12.9914 - val_mae: 2.3829\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9203 - mae: 1.2501 - val_loss: 13.3298 - val_mae: 2.4171\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8679 - mae: 1.2680 - val_loss: 14.0655 - val_mae: 2.4762\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8138 - mae: 1.2361 - val_loss: 12.5985 - val_mae: 2.3275\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7049 - mae: 1.1869 - val_loss: 13.2971 - val_mae: 2.3454\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6400 - mae: 1.1845 - val_loss: 13.2967 - val_mae: 2.3122\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6166 - mae: 1.1963 - val_loss: 12.9460 - val_mae: 2.3636\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6173 - mae: 1.1832 - val_loss: 12.9363 - val_mae: 2.2786\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5740 - mae: 1.1796 - val_loss: 13.7313 - val_mae: 2.4263\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.5525 - mae: 1.1667 - val_loss: 13.0163 - val_mae: 2.3744\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3971 - mae: 1.1491 - val_loss: 13.3499 - val_mae: 2.3600\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.5278 - mae: 1.1518 - val_loss: 13.3964 - val_mae: 2.3816\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3795 - mae: 1.1240 - val_loss: 13.5108 - val_mae: 2.3942\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4319 - mae: 1.1315 - val_loss: 13.3689 - val_mae: 2.3972\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2992 - mae: 1.0878 - val_loss: 13.2160 - val_mae: 2.4303\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4182 - mae: 1.1354 - val_loss: 13.1023 - val_mae: 2.3047\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2429 - mae: 1.0879 - val_loss: 13.4617 - val_mae: 2.3784\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2368 - mae: 1.0882 - val_loss: 13.9522 - val_mae: 2.4859\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2385 - mae: 1.0985 - val_loss: 13.4289 - val_mae: 2.3470\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1509 - mae: 1.0587 - val_loss: 14.2658 - val_mae: 2.4663\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1418 - mae: 1.0608 - val_loss: 13.3289 - val_mae: 2.3414\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0648 - mae: 1.0466 - val_loss: 13.1027 - val_mae: 2.3803\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2306 - mae: 1.1132 - val_loss: 13.8235 - val_mae: 2.5109\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1320 - mae: 1.0508 - val_loss: 14.1739 - val_mae: 2.4549\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0681 - mae: 1.0159 - val_loss: 13.2829 - val_mae: 2.3786\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0531 - mae: 1.0473 - val_loss: 13.6862 - val_mae: 2.3664\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9127 - mae: 0.9763 - val_loss: 13.3213 - val_mae: 2.3991\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8933 - mae: 0.9750 - val_loss: 14.1005 - val_mae: 2.4464\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8678 - mae: 0.9882 - val_loss: 14.3305 - val_mae: 2.4252\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9126 - mae: 0.9896 - val_loss: 13.7232 - val_mae: 2.3459\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0313 - mae: 1.0279 - val_loss: 13.4811 - val_mae: 2.3690\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8263 - mae: 0.9782 - val_loss: 13.3251 - val_mae: 2.3581\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8981 - mae: 0.9779 - val_loss: 13.6451 - val_mae: 2.4212\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9432 - mae: 1.0264 - val_loss: 13.6535 - val_mae: 2.4048\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7105 - mae: 0.9226 - val_loss: 13.4135 - val_mae: 2.3694\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8456 - mae: 0.9812 - val_loss: 13.9675 - val_mae: 2.4308\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6616 - mae: 0.9079 - val_loss: 13.9527 - val_mae: 2.4371\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6588 - mae: 0.9100 - val_loss: 13.8038 - val_mae: 2.4743\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6507 - mae: 0.8982 - val_loss: 13.5701 - val_mae: 2.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 17.1134 - mae: 3.4327\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 9.9438 - mae: 9.9438 - val_loss: 3.2070 - val_mae: 3.2070\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2102 - mae: 3.2102 - val_loss: 2.8885 - val_mae: 2.8885\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7921 - mae: 2.7921 - val_loss: 2.5642 - val_mae: 2.5642\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6810 - mae: 2.6810 - val_loss: 2.8602 - val_mae: 2.8602\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5074 - mae: 2.5074 - val_loss: 2.6867 - val_mae: 2.6867\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5457 - mae: 2.5457 - val_loss: 2.7929 - val_mae: 2.7929\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3963 - mae: 2.3963 - val_loss: 2.6788 - val_mae: 2.6788\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.3309 - mae: 2.3309 - val_loss: 2.4676 - val_mae: 2.4676\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.3059 - mae: 2.3059 - val_loss: 2.7021 - val_mae: 2.7021\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.2702 - mae: 2.2702 - val_loss: 2.3836 - val_mae: 2.3836\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.1659 - mae: 2.1659 - val_loss: 2.7794 - val_mae: 2.7794\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.1502 - mae: 2.1502 - val_loss: 2.3406 - val_mae: 2.3406\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0754 - mae: 2.0754 - val_loss: 2.4356 - val_mae: 2.4356\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1231 - mae: 2.1231 - val_loss: 2.5004 - val_mae: 2.5004\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.1218 - mae: 2.1218 - val_loss: 2.4270 - val_mae: 2.4270\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0426 - mae: 2.0426 - val_loss: 2.3897 - val_mae: 2.3897\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9972 - mae: 1.9972 - val_loss: 2.3160 - val_mae: 2.3160\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9644 - mae: 1.9644 - val_loss: 2.4539 - val_mae: 2.4539\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9475 - mae: 1.9475 - val_loss: 2.2846 - val_mae: 2.2846\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9188 - mae: 1.9188 - val_loss: 2.5693 - val_mae: 2.5693\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8406 - mae: 1.8406 - val_loss: 2.4457 - val_mae: 2.4457\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7966 - mae: 1.7966 - val_loss: 2.4332 - val_mae: 2.4332\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8132 - mae: 1.8132 - val_loss: 2.4128 - val_mae: 2.4128\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8210 - mae: 1.8210 - val_loss: 2.3676 - val_mae: 2.3676\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7407 - mae: 1.7407 - val_loss: 2.6187 - val_mae: 2.6187\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7619 - mae: 1.7619 - val_loss: 2.3405 - val_mae: 2.3405\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7066 - mae: 1.7066 - val_loss: 2.4951 - val_mae: 2.4951\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7793 - mae: 1.7793 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6605 - mae: 1.6605 - val_loss: 2.4742 - val_mae: 2.4742\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6318 - mae: 1.6318 - val_loss: 2.3828 - val_mae: 2.3828\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6126 - mae: 1.6126 - val_loss: 2.3661 - val_mae: 2.3661\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5939 - mae: 1.5939 - val_loss: 2.4679 - val_mae: 2.4679\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5608 - mae: 1.5608 - val_loss: 2.4887 - val_mae: 2.4887\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5850 - mae: 1.5850 - val_loss: 2.3553 - val_mae: 2.3553\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5403 - mae: 1.5403 - val_loss: 2.5254 - val_mae: 2.5254\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5310 - mae: 1.5310 - val_loss: 2.3487 - val_mae: 2.3487\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5163 - mae: 1.5163 - val_loss: 2.4950 - val_mae: 2.4950\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4615 - mae: 1.4615 - val_loss: 2.3998 - val_mae: 2.3998\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4752 - mae: 1.4752 - val_loss: 2.4176 - val_mae: 2.4176\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4190 - mae: 1.4190 - val_loss: 2.6208 - val_mae: 2.6208\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5013 - mae: 1.5013 - val_loss: 2.3706 - val_mae: 2.3706\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4449 - mae: 1.4449 - val_loss: 2.3480 - val_mae: 2.3480\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4013 - mae: 1.4013 - val_loss: 2.4115 - val_mae: 2.4115\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4358 - mae: 1.4358 - val_loss: 2.4531 - val_mae: 2.4531\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3832 - mae: 1.3832 - val_loss: 2.4153 - val_mae: 2.4153\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4433 - mae: 1.4433 - val_loss: 2.4664 - val_mae: 2.4664\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3350 - mae: 1.3350 - val_loss: 2.4020 - val_mae: 2.4020\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3884 - mae: 1.3884 - val_loss: 2.4198 - val_mae: 2.4198\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3941 - mae: 1.3941 - val_loss: 2.4678 - val_mae: 2.4678\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2752 - mae: 1.2752 - val_loss: 2.5193 - val_mae: 2.5193\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2705 - mae: 1.2705 - val_loss: 2.4078 - val_mae: 2.4078\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2402 - mae: 1.2402 - val_loss: 2.4465 - val_mae: 2.4465\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3785 - mae: 1.3785 - val_loss: 2.2861 - val_mae: 2.2861\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2389 - mae: 1.2389 - val_loss: 2.5030 - val_mae: 2.5030\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2177 - mae: 1.2177 - val_loss: 2.4912 - val_mae: 2.4912\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2295 - mae: 1.2295 - val_loss: 2.4091 - val_mae: 2.4091\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2059 - mae: 1.2059 - val_loss: 2.4181 - val_mae: 2.4181\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2300 - mae: 1.2300 - val_loss: 2.4825 - val_mae: 2.4825\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3130 - mae: 1.3130 - val_loss: 2.4366 - val_mae: 2.4366\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1896 - mae: 1.1896 - val_loss: 2.6072 - val_mae: 2.6072\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2436 - mae: 1.2436 - val_loss: 2.5656 - val_mae: 2.5656\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2310 - mae: 1.2310 - val_loss: 2.3877 - val_mae: 2.3877\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1496 - mae: 1.1496 - val_loss: 2.3509 - val_mae: 2.3509\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2636 - mae: 1.2636 - val_loss: 2.4012 - val_mae: 2.4012\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1314 - mae: 1.1314 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1358 - mae: 1.1358 - val_loss: 2.4496 - val_mae: 2.4496\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0771 - mae: 1.0771 - val_loss: 2.4443 - val_mae: 2.4443\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0933 - mae: 1.0933 - val_loss: 2.4646 - val_mae: 2.4646\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1092 - mae: 1.1092 - val_loss: 2.4563 - val_mae: 2.4563\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1695 - mae: 1.1695 - val_loss: 2.3623 - val_mae: 2.3623\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2035 - mae: 1.2035 - val_loss: 2.4562 - val_mae: 2.4562\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0941 - mae: 1.0941 - val_loss: 2.5091 - val_mae: 2.5091\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0554 - mae: 1.0554 - val_loss: 2.4660 - val_mae: 2.4660\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0631 - mae: 1.0631 - val_loss: 2.4552 - val_mae: 2.4552\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1073 - mae: 1.1073 - val_loss: 2.3791 - val_mae: 2.3791\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0681 - mae: 1.0681 - val_loss: 2.3665 - val_mae: 2.3665\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0757 - mae: 1.0757 - val_loss: 2.4937 - val_mae: 2.4937\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0507 - mae: 1.0507 - val_loss: 2.3921 - val_mae: 2.3921\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0482 - mae: 1.0482 - val_loss: 2.3648 - val_mae: 2.3648\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0593 - mae: 1.0593 - val_loss: 2.4304 - val_mae: 2.4304\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0277 - mae: 1.0277 - val_loss: 2.5533 - val_mae: 2.5533\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0315 - mae: 1.0315 - val_loss: 2.4313 - val_mae: 2.4313\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0450 - mae: 1.0450 - val_loss: 2.4833 - val_mae: 2.4833\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0892 - mae: 1.0892 - val_loss: 2.4542 - val_mae: 2.4542\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9949 - mae: 0.9949 - val_loss: 2.3717 - val_mae: 2.3717\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9955 - mae: 0.9955 - val_loss: 2.4421 - val_mae: 2.4421\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9566 - mae: 0.9566 - val_loss: 2.5020 - val_mae: 2.5020\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9749 - mae: 0.9749 - val_loss: 2.5295 - val_mae: 2.5295\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9866 - mae: 0.9866 - val_loss: 2.5080 - val_mae: 2.5080\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9607 - mae: 0.9607 - val_loss: 2.4811 - val_mae: 2.4811\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0156 - mae: 1.0156 - val_loss: 2.4745 - val_mae: 2.4745\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9661 - mae: 0.9661 - val_loss: 2.4715 - val_mae: 2.4715\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9555 - mae: 0.9555 - val_loss: 2.4720 - val_mae: 2.4720\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9494 - mae: 0.9494 - val_loss: 2.5672 - val_mae: 2.5672\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9791 - mae: 0.9791 - val_loss: 2.4419 - val_mae: 2.4419\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9236 - mae: 0.9236 - val_loss: 2.4815 - val_mae: 2.4815\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9866 - mae: 0.9866 - val_loss: 2.5040 - val_mae: 2.5040\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9287 - mae: 0.9287 - val_loss: 2.4588 - val_mae: 2.4588\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9301 - mae: 0.9301 - val_loss: 2.4979 - val_mae: 2.4979\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9130 - mae: 0.9130 - val_loss: 2.4259 - val_mae: 2.4259\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5119 - mae: 3.5119\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 9ms/step - loss: 182.5348 - mae: 10.0534 - val_loss: 34.2505 - val_mae: 3.8728\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 23.0873 - mae: 3.4841 - val_loss: 23.9174 - val_mae: 3.3241\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.4975 - mae: 3.0299 - val_loss: 19.1440 - val_mae: 2.9315\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.5562 - mae: 2.7785 - val_loss: 18.0844 - val_mae: 2.8982\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 14.4375 - mae: 2.7650 - val_loss: 17.4085 - val_mae: 2.8190\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 13.2439 - mae: 2.6158 - val_loss: 15.7268 - val_mae: 2.6977\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.9820 - mae: 2.4986 - val_loss: 15.5122 - val_mae: 2.7917\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 11.2535 - mae: 2.4397 - val_loss: 15.8114 - val_mae: 2.6795\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 11.1727 - mae: 2.4208 - val_loss: 15.5818 - val_mae: 2.6117\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 10.6576 - mae: 2.3441 - val_loss: 15.2889 - val_mae: 2.7558\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.8565 - mae: 2.2811 - val_loss: 14.9786 - val_mae: 2.6071\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.6729 - mae: 2.2779 - val_loss: 14.9617 - val_mae: 2.5822\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 8.9973 - mae: 2.2072 - val_loss: 13.9240 - val_mae: 2.5444\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 9.2595 - mae: 2.2713 - val_loss: 13.8574 - val_mae: 2.5308\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 8.5145 - mae: 2.1307 - val_loss: 14.1989 - val_mae: 2.5675\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.0966 - mae: 2.0819 - val_loss: 13.9705 - val_mae: 2.5293\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.9592 - mae: 2.1034 - val_loss: 14.0541 - val_mae: 2.4990\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.6208 - mae: 2.0247 - val_loss: 13.5156 - val_mae: 2.4750\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.1037 - mae: 1.9974 - val_loss: 12.9900 - val_mae: 2.4609\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 7.0932 - mae: 2.0199 - val_loss: 13.2177 - val_mae: 2.5097\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.6836 - mae: 1.9223 - val_loss: 14.0555 - val_mae: 2.5185\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.8131 - mae: 1.9797 - val_loss: 13.0690 - val_mae: 2.4352\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 6.2034 - mae: 1.8451 - val_loss: 12.8777 - val_mae: 2.4319\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 5.9444 - mae: 1.8168 - val_loss: 12.9956 - val_mae: 2.4404\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.8615 - mae: 1.7895 - val_loss: 13.4460 - val_mae: 2.5130\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6524 - mae: 1.8063 - val_loss: 12.5138 - val_mae: 2.4370\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.6505 - mae: 1.7875 - val_loss: 13.0297 - val_mae: 2.4059\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.5088 - mae: 1.7760 - val_loss: 13.1096 - val_mae: 2.4574\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.1880 - mae: 1.6895 - val_loss: 12.6842 - val_mae: 2.3581\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.0371 - mae: 1.6778 - val_loss: 13.2517 - val_mae: 2.4444\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.8094 - mae: 1.6265 - val_loss: 12.8689 - val_mae: 2.4061\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.0596 - mae: 1.6735 - val_loss: 12.4654 - val_mae: 2.3797\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.7122 - mae: 1.6112 - val_loss: 13.1563 - val_mae: 2.4538\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.4921 - mae: 1.5810 - val_loss: 13.5606 - val_mae: 2.4626\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3496 - mae: 1.5426 - val_loss: 12.7613 - val_mae: 2.3857\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.1405 - mae: 1.5102 - val_loss: 12.8429 - val_mae: 2.3763\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.1133 - mae: 1.4917 - val_loss: 13.1672 - val_mae: 2.4217\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0140 - mae: 1.4973 - val_loss: 12.9400 - val_mae: 2.4204\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8675 - mae: 1.4571 - val_loss: 12.9270 - val_mae: 2.3592\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8234 - mae: 1.4380 - val_loss: 12.4689 - val_mae: 2.3993\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9549 - mae: 1.4712 - val_loss: 13.0480 - val_mae: 2.4361\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5748 - mae: 1.4087 - val_loss: 13.3385 - val_mae: 2.3681\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5424 - mae: 1.3922 - val_loss: 12.7288 - val_mae: 2.3638\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6455 - mae: 1.4273 - val_loss: 12.8584 - val_mae: 2.3578\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5258 - mae: 1.3798 - val_loss: 13.8025 - val_mae: 2.5289\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5749 - mae: 1.4017 - val_loss: 13.6285 - val_mae: 2.3981\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3093 - mae: 1.3305 - val_loss: 13.7588 - val_mae: 2.4623\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3182 - mae: 1.3539 - val_loss: 13.2790 - val_mae: 2.3804\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2746 - mae: 1.3437 - val_loss: 14.1357 - val_mae: 2.5472\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3902 - mae: 1.3575 - val_loss: 14.0235 - val_mae: 2.4700\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1242 - mae: 1.3019 - val_loss: 13.5060 - val_mae: 2.4457\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1900 - mae: 1.3184 - val_loss: 13.7084 - val_mae: 2.4754\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0226 - mae: 1.2618 - val_loss: 13.3055 - val_mae: 2.4768\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1554 - mae: 1.3239 - val_loss: 13.6769 - val_mae: 2.4372\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0041 - mae: 1.2731 - val_loss: 13.4926 - val_mae: 2.4593\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8268 - mae: 1.2375 - val_loss: 12.8720 - val_mae: 2.3738\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7820 - mae: 1.2119 - val_loss: 13.3087 - val_mae: 2.3634\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6580 - mae: 1.1833 - val_loss: 13.7868 - val_mae: 2.4376\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6503 - mae: 1.1939 - val_loss: 13.2941 - val_mae: 2.3752\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.5215 - mae: 1.1574 - val_loss: 13.4449 - val_mae: 2.4680\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5576 - mae: 1.1646 - val_loss: 13.3292 - val_mae: 2.3954\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5671 - mae: 1.2058 - val_loss: 14.0135 - val_mae: 2.4870\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6923 - mae: 1.2197 - val_loss: 13.2107 - val_mae: 2.4042\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4354 - mae: 1.1527 - val_loss: 13.7061 - val_mae: 2.4182\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4001 - mae: 1.1196 - val_loss: 13.7277 - val_mae: 2.4412\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.4370 - mae: 1.1233 - val_loss: 13.3139 - val_mae: 2.4073\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3022 - mae: 1.1126 - val_loss: 13.8037 - val_mae: 2.4520\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3151 - mae: 1.1106 - val_loss: 13.1704 - val_mae: 2.4188\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2554 - mae: 1.0958 - val_loss: 13.4958 - val_mae: 2.3965\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3137 - mae: 1.1106 - val_loss: 14.3582 - val_mae: 2.5974\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4250 - mae: 1.1506 - val_loss: 14.3098 - val_mae: 2.5278\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2505 - mae: 1.0873 - val_loss: 13.7317 - val_mae: 2.4889\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1137 - mae: 1.0392 - val_loss: 13.8938 - val_mae: 2.4802\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1027 - mae: 1.0488 - val_loss: 14.0319 - val_mae: 2.5527\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0251 - mae: 1.0442 - val_loss: 14.5548 - val_mae: 2.6121\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0622 - mae: 1.0534 - val_loss: 13.9679 - val_mae: 2.4855\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0188 - mae: 1.0525 - val_loss: 13.8463 - val_mae: 2.4603\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0023 - mae: 1.0229 - val_loss: 13.8645 - val_mae: 2.4688\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9978 - mae: 1.0023 - val_loss: 14.2071 - val_mae: 2.5075\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9135 - mae: 1.0124 - val_loss: 13.8429 - val_mae: 2.4976\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0773 - mae: 1.0342 - val_loss: 14.4117 - val_mae: 2.5413\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.9473 - mae: 1.0034 - val_loss: 14.2575 - val_mae: 2.4732\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8067 - mae: 0.9715 - val_loss: 13.6827 - val_mae: 2.4192\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8755 - mae: 0.9773 - val_loss: 14.0709 - val_mae: 2.4763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8126 - mae: 0.9642 - val_loss: 14.1071 - val_mae: 2.4487\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7953 - mae: 0.9643 - val_loss: 14.0709 - val_mae: 2.4452\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8760 - mae: 0.9847 - val_loss: 13.7631 - val_mae: 2.4390\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9068 - mae: 1.0002 - val_loss: 14.2142 - val_mae: 2.5013\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7916 - mae: 0.9592 - val_loss: 14.7267 - val_mae: 2.5939\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7636 - mae: 0.9631 - val_loss: 14.6981 - val_mae: 2.5555\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7715 - mae: 0.9613 - val_loss: 13.8031 - val_mae: 2.4131\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7231 - mae: 0.9270 - val_loss: 13.9036 - val_mae: 2.4651\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.8510 - mae: 0.9681 - val_loss: 13.8208 - val_mae: 2.4441\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6548 - mae: 0.9255 - val_loss: 14.1493 - val_mae: 2.5081\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6333 - mae: 0.9220 - val_loss: 14.5361 - val_mae: 2.5560\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6475 - mae: 0.9371 - val_loss: 14.5166 - val_mae: 2.4980\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5146 - mae: 0.8823 - val_loss: 13.8500 - val_mae: 2.4856\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5469 - mae: 0.8701 - val_loss: 13.8626 - val_mae: 2.4410\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5885 - mae: 0.8886 - val_loss: 14.4373 - val_mae: 2.5663\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5046 - mae: 0.8543 - val_loss: 13.8992 - val_mae: 2.4910\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.5406 - mae: 3.5952\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 8ms/step - loss: 9.8064 - mae: 9.8064 - val_loss: 4.8534 - val_mae: 4.8534\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3501 - mae: 3.3501 - val_loss: 3.2420 - val_mae: 3.2420\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0638 - mae: 3.0638 - val_loss: 2.7526 - val_mae: 2.7526\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7343 - mae: 2.7343 - val_loss: 2.9445 - val_mae: 2.9445\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.5965 - mae: 2.5965 - val_loss: 2.6839 - val_mae: 2.6839\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4777 - mae: 2.4777 - val_loss: 2.6683 - val_mae: 2.6683\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3873 - mae: 2.3873 - val_loss: 2.6170 - val_mae: 2.6170\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.3896 - mae: 2.3896 - val_loss: 2.5629 - val_mae: 2.5629\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2811 - mae: 2.2811 - val_loss: 2.5808 - val_mae: 2.5808\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2302 - mae: 2.2302 - val_loss: 2.5119 - val_mae: 2.5119\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.2564 - mae: 2.2564 - val_loss: 2.5618 - val_mae: 2.5618\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.2197 - mae: 2.2197 - val_loss: 2.5217 - val_mae: 2.5217\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1060 - mae: 2.1060 - val_loss: 2.4255 - val_mae: 2.4255\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1649 - mae: 2.1649 - val_loss: 2.3820 - val_mae: 2.3820\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0872 - mae: 2.0872 - val_loss: 2.8203 - val_mae: 2.8203\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.1556 - mae: 2.1556 - val_loss: 2.4419 - val_mae: 2.4419\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0612 - mae: 2.0612 - val_loss: 2.4721 - val_mae: 2.4721\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.0214 - mae: 2.0214 - val_loss: 2.4303 - val_mae: 2.4303\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9740 - mae: 1.9740 - val_loss: 2.4401 - val_mae: 2.4401\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9791 - mae: 1.9791 - val_loss: 2.5183 - val_mae: 2.5183\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.9677 - mae: 1.9677 - val_loss: 2.6008 - val_mae: 2.6008\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.9140 - mae: 1.9140 - val_loss: 2.3667 - val_mae: 2.3667\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8978 - mae: 1.8978 - val_loss: 2.6336 - val_mae: 2.6336\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8165 - mae: 1.8165 - val_loss: 2.4590 - val_mae: 2.4590\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8147 - mae: 1.8147 - val_loss: 2.4877 - val_mae: 2.4877\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.8366 - mae: 1.8366 - val_loss: 2.4923 - val_mae: 2.4923\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7872 - mae: 1.7872 - val_loss: 2.3571 - val_mae: 2.3571\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7823 - mae: 1.7823 - val_loss: 2.4880 - val_mae: 2.4880\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.7676 - mae: 1.7676 - val_loss: 2.4600 - val_mae: 2.4600\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6904 - mae: 1.6904 - val_loss: 2.4642 - val_mae: 2.4642\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6896 - mae: 1.6896 - val_loss: 2.5014 - val_mae: 2.5014\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6849 - mae: 1.6849 - val_loss: 2.4826 - val_mae: 2.4826\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6960 - mae: 1.6960 - val_loss: 2.4894 - val_mae: 2.4894\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6191 - mae: 1.6191 - val_loss: 2.4050 - val_mae: 2.4050\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6303 - mae: 1.6303 - val_loss: 2.4221 - val_mae: 2.4221\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.6808 - mae: 1.6808 - val_loss: 2.5062 - val_mae: 2.5062\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5366 - mae: 1.5366 - val_loss: 2.4061 - val_mae: 2.4061\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5432 - mae: 1.5432 - val_loss: 2.4773 - val_mae: 2.4773\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5256 - mae: 1.5256 - val_loss: 2.3796 - val_mae: 2.3796\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.5391 - mae: 1.5391 - val_loss: 2.4665 - val_mae: 2.4665\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5126 - mae: 1.5126 - val_loss: 2.5049 - val_mae: 2.5049\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.5127 - mae: 1.5127 - val_loss: 2.5184 - val_mae: 2.5184\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4685 - mae: 1.4685 - val_loss: 2.5183 - val_mae: 2.5183\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4674 - mae: 1.4674 - val_loss: 2.4958 - val_mae: 2.4958\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4699 - mae: 1.4699 - val_loss: 2.5307 - val_mae: 2.5307\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4748 - mae: 1.4748 - val_loss: 2.4908 - val_mae: 2.4908\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3994 - mae: 1.3994 - val_loss: 2.5368 - val_mae: 2.5368\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4112 - mae: 1.4112 - val_loss: 2.4845 - val_mae: 2.4845\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3560 - mae: 1.3560 - val_loss: 2.4317 - val_mae: 2.4317\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3786 - mae: 1.3786 - val_loss: 2.4610 - val_mae: 2.4610\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3949 - mae: 1.3949 - val_loss: 2.3589 - val_mae: 2.3589\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3481 - mae: 1.3481 - val_loss: 2.3910 - val_mae: 2.3910\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.3612 - mae: 1.3612 - val_loss: 2.4272 - val_mae: 2.4272\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.4234 - mae: 1.4234 - val_loss: 2.3706 - val_mae: 2.3706\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2984 - mae: 1.2984 - val_loss: 2.4045 - val_mae: 2.4045\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2881 - mae: 1.2881 - val_loss: 2.4666 - val_mae: 2.4666\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2997 - mae: 1.2997 - val_loss: 2.5680 - val_mae: 2.5680\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2823 - mae: 1.2823 - val_loss: 2.5097 - val_mae: 2.5097\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2912 - mae: 1.2912 - val_loss: 2.5205 - val_mae: 2.5205\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2526 - mae: 1.2526 - val_loss: 2.4522 - val_mae: 2.4522\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2585 - mae: 1.2585 - val_loss: 2.4191 - val_mae: 2.4191\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2094 - mae: 1.2094 - val_loss: 2.4668 - val_mae: 2.4668\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.2569 - mae: 1.2569 - val_loss: 2.4188 - val_mae: 2.4188\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2100 - mae: 1.2100 - val_loss: 2.4691 - val_mae: 2.4691\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2110 - mae: 1.2110 - val_loss: 2.5574 - val_mae: 2.5574\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2230 - mae: 1.2230 - val_loss: 2.4373 - val_mae: 2.4373\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1992 - mae: 1.1992 - val_loss: 2.4226 - val_mae: 2.4226\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1814 - mae: 1.1814 - val_loss: 2.5569 - val_mae: 2.5569\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1722 - mae: 1.1722 - val_loss: 2.3708 - val_mae: 2.3708\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1780 - mae: 1.1780 - val_loss: 2.5480 - val_mae: 2.5480\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.2011 - mae: 1.2011 - val_loss: 2.5129 - val_mae: 2.5129\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1547 - mae: 1.1547 - val_loss: 2.5274 - val_mae: 2.5274\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1422 - mae: 1.1422 - val_loss: 2.4496 - val_mae: 2.4496\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1779 - mae: 1.1779 - val_loss: 2.4542 - val_mae: 2.4542\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1506 - mae: 1.1506 - val_loss: 2.4876 - val_mae: 2.4876\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0980 - mae: 1.0980 - val_loss: 2.5180 - val_mae: 2.5180\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1231 - mae: 1.1231 - val_loss: 2.5418 - val_mae: 2.5418\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1051 - mae: 1.1051 - val_loss: 2.4927 - val_mae: 2.4927\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1464 - mae: 1.1464 - val_loss: 2.4979 - val_mae: 2.4979\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0522 - mae: 1.0522 - val_loss: 2.5137 - val_mae: 2.5137\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0997 - mae: 1.0997 - val_loss: 2.4616 - val_mae: 2.4616\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0509 - mae: 1.0509 - val_loss: 2.5338 - val_mae: 2.5338\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.0838 - mae: 1.0838 - val_loss: 2.5262 - val_mae: 2.5262\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.1301 - mae: 1.1301 - val_loss: 2.4422 - val_mae: 2.4422\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0516 - mae: 1.0516 - val_loss: 2.4659 - val_mae: 2.4659\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0209 - mae: 1.0209 - val_loss: 2.4171 - val_mae: 2.4171\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0423 - mae: 1.0423 - val_loss: 2.5681 - val_mae: 2.5681\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.0122 - mae: 1.0122 - val_loss: 2.3709 - val_mae: 2.3709\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0190 - mae: 1.0190 - val_loss: 2.4099 - val_mae: 2.4099\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0420 - mae: 1.0420 - val_loss: 2.3902 - val_mae: 2.3902\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9779 - mae: 0.9779 - val_loss: 2.3519 - val_mae: 2.3519\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0196 - mae: 1.0196 - val_loss: 2.3977 - val_mae: 2.3977\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 1.0053 - mae: 1.0053 - val_loss: 2.5531 - val_mae: 2.5531\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9903 - mae: 0.9903 - val_loss: 2.4546 - val_mae: 2.4546\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9824 - mae: 0.9824 - val_loss: 2.4349 - val_mae: 2.4349\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9866 - mae: 0.9866 - val_loss: 2.4449 - val_mae: 2.4449\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9510 - mae: 0.9510 - val_loss: 2.4193 - val_mae: 2.4193\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9522 - mae: 0.9522 - val_loss: 2.4249 - val_mae: 2.4249\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9542 - mae: 0.9542 - val_loss: 2.3941 - val_mae: 2.3941\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9256 - mae: 0.9256 - val_loss: 2.4237 - val_mae: 2.4237\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8071 - mae: 3.8071\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 184.5276 - mae: 10.4330 - val_loss: 103.0115 - val_mae: 7.1885\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 87.2546 - mae: 6.5080 - val_loss: 91.5848 - val_mae: 6.9401\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 81.8310 - mae: 6.4021 - val_loss: 89.8072 - val_mae: 7.0242\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 81.1036 - mae: 6.4387 - val_loss: 89.3080 - val_mae: 7.0873\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.5250 - mae: 6.4259 - val_loss: 89.2692 - val_mae: 7.0933\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4313 - mae: 6.4409 - val_loss: 89.1743 - val_mae: 7.1208\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4624 - mae: 6.4813 - val_loss: 89.1300 - val_mae: 7.1448\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4600 - mae: 6.4630 - val_loss: 89.1129 - val_mae: 7.1494\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4354 - mae: 6.4661 - val_loss: 89.0959 - val_mae: 7.1448\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4473 - mae: 6.4550 - val_loss: 89.0806 - val_mae: 7.1362\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3366 - mae: 6.4712 - val_loss: 89.0502 - val_mae: 7.1421\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3314 - mae: 6.4693 - val_loss: 89.0153 - val_mae: 7.1477\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2766 - mae: 6.4709 - val_loss: 88.9742 - val_mae: 7.1454\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3252 - mae: 6.4556 - val_loss: 88.9407 - val_mae: 7.1128\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3146 - mae: 6.4877 - val_loss: 88.8404 - val_mae: 7.1453\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.1194 - mae: 6.4583 - val_loss: 88.7369 - val_mae: 7.1150\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.0647 - mae: 6.4427 - val_loss: 88.5703 - val_mae: 7.1033\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.8104 - mae: 6.4313 - val_loss: 88.2675 - val_mae: 7.0900\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.5163 - mae: 6.4204 - val_loss: 87.7395 - val_mae: 7.0583\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 78.9319 - mae: 6.3753 - val_loss: 86.7555 - val_mae: 6.9943\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 78.0327 - mae: 6.2772 - val_loss: 84.6064 - val_mae: 6.8528\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 75.2487 - mae: 6.1760 - val_loss: 80.1163 - val_mae: 6.5148\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 70.0973 - mae: 5.7345 - val_loss: 72.1757 - val_mae: 5.8279\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 62.5129 - mae: 5.2297 - val_loss: 65.3918 - val_mae: 5.5957\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 57.1180 - mae: 5.0499 - val_loss: 60.3893 - val_mae: 4.7244\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 53.8402 - mae: 4.7761 - val_loss: 57.4189 - val_mae: 5.0547\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 51.6096 - mae: 4.7111 - val_loss: 54.9957 - val_mae: 4.6644\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 49.4253 - mae: 4.6168 - val_loss: 53.1981 - val_mae: 4.6666\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 48.0932 - mae: 4.6339 - val_loss: 51.4409 - val_mae: 4.5226\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 46.4322 - mae: 4.4845 - val_loss: 50.5026 - val_mae: 4.3360\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 44.1759 - mae: 4.3738 - val_loss: 48.3310 - val_mae: 4.5309\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 42.2075 - mae: 4.2849 - val_loss: 46.6043 - val_mae: 4.3260\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 40.3587 - mae: 4.1859 - val_loss: 45.3660 - val_mae: 4.1186\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 38.7740 - mae: 4.0402 - val_loss: 43.5026 - val_mae: 4.1140\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 37.4141 - mae: 4.0019 - val_loss: 42.4854 - val_mae: 3.9730\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 35.6535 - mae: 3.8416 - val_loss: 40.6272 - val_mae: 4.0703\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 34.8261 - mae: 3.8744 - val_loss: 39.4940 - val_mae: 4.0439\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 34.0375 - mae: 3.8674 - val_loss: 38.5368 - val_mae: 3.8584\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 32.4602 - mae: 3.6834 - val_loss: 37.6958 - val_mae: 4.0587\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 31.7296 - mae: 3.6872 - val_loss: 36.5204 - val_mae: 3.7840\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 30.4713 - mae: 3.6221 - val_loss: 35.6835 - val_mae: 3.7336\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 29.9871 - mae: 3.5648 - val_loss: 34.6884 - val_mae: 3.7045\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 29.5325 - mae: 3.5787 - val_loss: 34.4952 - val_mae: 3.6547\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 28.9154 - mae: 3.5663 - val_loss: 33.1489 - val_mae: 3.6550\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.9726 - mae: 3.4732 - val_loss: 32.4699 - val_mae: 3.6410\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.5699 - mae: 3.4579 - val_loss: 31.9090 - val_mae: 3.5866\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.7206 - mae: 3.4183 - val_loss: 32.5354 - val_mae: 3.5448\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.3913 - mae: 3.4117 - val_loss: 30.8656 - val_mae: 3.4975\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.9600 - mae: 3.3563 - val_loss: 30.1286 - val_mae: 3.5020\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.5177 - mae: 3.3362 - val_loss: 29.8464 - val_mae: 3.6063\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.0620 - mae: 3.3052 - val_loss: 29.1387 - val_mae: 3.4540\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.4469 - mae: 3.2824 - val_loss: 28.7849 - val_mae: 3.4021\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.9470 - mae: 3.2330 - val_loss: 28.4571 - val_mae: 3.5138\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.0798 - mae: 3.2526 - val_loss: 27.7524 - val_mae: 3.3989\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.3053 - mae: 3.2046 - val_loss: 27.4637 - val_mae: 3.4048\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.9694 - mae: 3.1898 - val_loss: 27.0557 - val_mae: 3.3166\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.6190 - mae: 3.1535 - val_loss: 26.9042 - val_mae: 3.2399\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.2728 - mae: 3.1455 - val_loss: 26.4015 - val_mae: 3.2959\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.2246 - mae: 3.1444 - val_loss: 26.1433 - val_mae: 3.2195\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.0034 - mae: 3.1018 - val_loss: 26.2174 - val_mae: 3.1738\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.4231 - mae: 3.0882 - val_loss: 25.3504 - val_mae: 3.2063\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.1989 - mae: 3.0501 - val_loss: 25.2870 - val_mae: 3.1499\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 21.2430 - mae: 3.0690 - val_loss: 24.8435 - val_mae: 3.2197\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.6828 - mae: 3.0567 - val_loss: 24.7157 - val_mae: 3.1111\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.4713 - mae: 2.9795 - val_loss: 24.2415 - val_mae: 3.1730\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.2119 - mae: 2.9795 - val_loss: 24.0821 - val_mae: 3.1381\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.9635 - mae: 2.9692 - val_loss: 24.8165 - val_mae: 3.4386\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 20.0886 - mae: 3.0312 - val_loss: 23.6893 - val_mae: 3.0929\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.5899 - mae: 2.9182 - val_loss: 23.9094 - val_mae: 3.2985\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.7996 - mae: 2.9851 - val_loss: 23.8985 - val_mae: 3.3208\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.3476 - mae: 2.9365 - val_loss: 23.2762 - val_mae: 3.1951\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.5558 - mae: 3.0149 - val_loss: 23.5016 - val_mae: 3.2811\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.2059 - mae: 2.9575 - val_loss: 22.8613 - val_mae: 3.1370\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 18.5216 - mae: 2.8403 - val_loss: 22.6108 - val_mae: 3.1020\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.7371 - mae: 2.9260 - val_loss: 22.4615 - val_mae: 3.0695\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 18.3986 - mae: 2.8607 - val_loss: 22.2918 - val_mae: 3.0477\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 18.2210 - mae: 2.8507 - val_loss: 22.1920 - val_mae: 3.0031\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.9620 - mae: 2.8225 - val_loss: 22.0162 - val_mae: 3.0291\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.7824 - mae: 2.7972 - val_loss: 22.3685 - val_mae: 3.1700\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.0730 - mae: 2.8642 - val_loss: 21.7590 - val_mae: 2.9833\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.5010 - mae: 2.7637 - val_loss: 22.5487 - val_mae: 3.2363\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.0186 - mae: 2.8563 - val_loss: 21.6651 - val_mae: 2.9486\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.2808 - mae: 2.7771 - val_loss: 21.5414 - val_mae: 2.9368\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.4075 - mae: 2.7824 - val_loss: 21.8646 - val_mae: 2.8989\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.2335 - mae: 2.7478 - val_loss: 21.1756 - val_mae: 2.9274\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.0064 - mae: 2.7479 - val_loss: 21.1228 - val_mae: 2.9580\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.9010 - mae: 2.7420 - val_loss: 21.1035 - val_mae: 2.9116\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.8907 - mae: 2.7429 - val_loss: 21.5747 - val_mae: 3.1257\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.8743 - mae: 2.7630 - val_loss: 20.8121 - val_mae: 2.9391\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.8057 - mae: 2.7324 - val_loss: 20.8245 - val_mae: 2.8892\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.6944 - mae: 2.7136 - val_loss: 20.6489 - val_mae: 2.9136\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 16.5828 - mae: 2.7157 - val_loss: 20.5890 - val_mae: 2.9278\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.3100 - mae: 2.6796 - val_loss: 20.5693 - val_mae: 2.9449\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.4324 - mae: 2.6932 - val_loss: 20.5939 - val_mae: 2.9695\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.3481 - mae: 2.6796 - val_loss: 20.3964 - val_mae: 2.9135\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.5615 - mae: 2.7571 - val_loss: 20.2912 - val_mae: 2.9148\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.2970 - mae: 2.7340 - val_loss: 20.2223 - val_mae: 2.8983\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.1701 - mae: 2.6991 - val_loss: 20.1394 - val_mae: 2.8879\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.8349 - mae: 2.6553 - val_loss: 20.8166 - val_mae: 2.8497\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.2191 - mae: 2.6721 - val_loss: 20.3421 - val_mae: 2.8419\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.6620 - mae: 3.3803\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 8ms/step - loss: 9.1159 - mae: 9.1159 - val_loss: 6.9198 - val_mae: 6.9198\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9546 - val_mae: 6.9546\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3986 - mae: 6.3986 - val_loss: 6.9588 - val_mae: 6.9588\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3916 - mae: 6.3916 - val_loss: 6.9639 - val_mae: 6.9639\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9790 - val_mae: 6.9790\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.4111 - mae: 6.4111 - val_loss: 6.9573 - val_mae: 6.9573\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9786 - val_mae: 6.9786\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9583 - val_mae: 6.9583\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3853 - mae: 6.3853 - val_loss: 6.9786 - val_mae: 6.9786\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3699 - mae: 6.3699 - val_loss: 6.9443 - val_mae: 6.9443\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3683 - mae: 6.3683 - val_loss: 6.9254 - val_mae: 6.9254\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3559 - mae: 6.3559 - val_loss: 6.9135 - val_mae: 6.9135\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3291 - mae: 6.3291 - val_loss: 6.8426 - val_mae: 6.8426\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.2650 - mae: 6.2650 - val_loss: 6.6985 - val_mae: 6.6985\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.0431 - mae: 6.0431 - val_loss: 6.2188 - val_mae: 6.2188\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.5826 - mae: 5.5826 - val_loss: 5.6937 - val_mae: 5.6937\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.0585 - mae: 5.0585 - val_loss: 4.8823 - val_mae: 4.8823\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.7598 - mae: 4.7598 - val_loss: 4.7347 - val_mae: 4.7347\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.6807 - mae: 4.6807 - val_loss: 4.6470 - val_mae: 4.6470\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.5683 - mae: 4.5683 - val_loss: 4.5646 - val_mae: 4.5646\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.5315 - mae: 4.5315 - val_loss: 4.5272 - val_mae: 4.5272\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.4583 - mae: 4.4583 - val_loss: 4.4528 - val_mae: 4.4528\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.4019 - mae: 4.4019 - val_loss: 4.4134 - val_mae: 4.4134\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3210 - mae: 4.3210 - val_loss: 4.4068 - val_mae: 4.4068\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.2647 - mae: 4.2647 - val_loss: 4.4129 - val_mae: 4.4129\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.2214 - mae: 4.2214 - val_loss: 4.3092 - val_mae: 4.3092\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.1385 - mae: 4.1385 - val_loss: 4.2651 - val_mae: 4.2651\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0874 - mae: 4.0874 - val_loss: 4.2443 - val_mae: 4.2443\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0379 - mae: 4.0379 - val_loss: 4.2849 - val_mae: 4.2849\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.9943 - mae: 3.9943 - val_loss: 4.1448 - val_mae: 4.1448\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.9641 - mae: 3.9641 - val_loss: 4.1597 - val_mae: 4.1597\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9189 - mae: 3.9189 - val_loss: 4.0818 - val_mae: 4.0818\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8889 - mae: 3.8889 - val_loss: 4.0499 - val_mae: 4.0499\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8163 - mae: 3.8163 - val_loss: 4.0168 - val_mae: 4.0168\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8117 - mae: 3.8117 - val_loss: 3.9911 - val_mae: 3.9911\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8069 - mae: 3.8069 - val_loss: 3.9904 - val_mae: 3.9904\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7272 - mae: 3.7272 - val_loss: 3.9833 - val_mae: 3.9833\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.6702 - mae: 3.6702 - val_loss: 3.9164 - val_mae: 3.9164\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6465 - mae: 3.6465 - val_loss: 3.8983 - val_mae: 3.8983\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.6405 - mae: 3.6405 - val_loss: 3.8684 - val_mae: 3.8684\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5834 - mae: 3.5834 - val_loss: 3.8416 - val_mae: 3.8416\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5542 - mae: 3.5542 - val_loss: 3.8260 - val_mae: 3.8260\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5503 - mae: 3.5503 - val_loss: 3.8108 - val_mae: 3.8108\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5291 - mae: 3.5291 - val_loss: 3.7950 - val_mae: 3.7950\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.5054 - mae: 3.5054 - val_loss: 3.7484 - val_mae: 3.7484\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4643 - mae: 3.4643 - val_loss: 3.7324 - val_mae: 3.7324\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4511 - mae: 3.4511 - val_loss: 3.7186 - val_mae: 3.7186\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4295 - mae: 3.4295 - val_loss: 3.7032 - val_mae: 3.7032\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.4084 - mae: 3.4084 - val_loss: 3.6441 - val_mae: 3.6441\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3822 - mae: 3.3822 - val_loss: 3.6160 - val_mae: 3.6160\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3585 - mae: 3.3585 - val_loss: 3.6198 - val_mae: 3.6198\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3611 - mae: 3.3611 - val_loss: 3.6054 - val_mae: 3.6054\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3560 - mae: 3.3560 - val_loss: 3.5609 - val_mae: 3.5609\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3736 - mae: 3.3736 - val_loss: 3.5947 - val_mae: 3.5947\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.3129 - mae: 3.3129 - val_loss: 3.6364 - val_mae: 3.6364\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2865 - mae: 3.2865 - val_loss: 3.5101 - val_mae: 3.5101\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2942 - mae: 3.2942 - val_loss: 3.4973 - val_mae: 3.4973\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2339 - mae: 3.2339 - val_loss: 3.4474 - val_mae: 3.4474\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2266 - mae: 3.2266 - val_loss: 3.4441 - val_mae: 3.4441\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2239 - mae: 3.2239 - val_loss: 3.4038 - val_mae: 3.4038\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2041 - mae: 3.2041 - val_loss: 3.4242 - val_mae: 3.4242\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.2075 - mae: 3.2075 - val_loss: 3.4085 - val_mae: 3.4085\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1356 - mae: 3.1356 - val_loss: 3.4314 - val_mae: 3.4314\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1696 - mae: 3.1696 - val_loss: 3.3438 - val_mae: 3.3438\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1416 - mae: 3.1416 - val_loss: 3.3041 - val_mae: 3.3041\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1247 - mae: 3.1247 - val_loss: 3.3293 - val_mae: 3.3293\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1309 - mae: 3.1309 - val_loss: 3.2975 - val_mae: 3.2975\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1049 - mae: 3.1049 - val_loss: 3.3839 - val_mae: 3.3839\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0862 - mae: 3.0862 - val_loss: 3.2613 - val_mae: 3.2613\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0604 - mae: 3.0604 - val_loss: 3.2489 - val_mae: 3.2489\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0349 - mae: 3.0349 - val_loss: 3.2502 - val_mae: 3.2502\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0407 - mae: 3.0407 - val_loss: 3.3000 - val_mae: 3.3000\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0906 - mae: 3.0906 - val_loss: 3.2792 - val_mae: 3.2792\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0516 - mae: 3.0516 - val_loss: 3.1956 - val_mae: 3.1956\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9538 - mae: 2.9538 - val_loss: 3.3386 - val_mae: 3.3386\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9849 - mae: 2.9849 - val_loss: 3.1689 - val_mae: 3.1689\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9577 - mae: 2.9577 - val_loss: 3.1608 - val_mae: 3.1608\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9681 - mae: 2.9681 - val_loss: 3.2823 - val_mae: 3.2823\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9777 - mae: 2.9777 - val_loss: 3.1310 - val_mae: 3.1310\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9420 - mae: 2.9420 - val_loss: 3.1368 - val_mae: 3.1368\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9072 - mae: 2.9072 - val_loss: 3.1093 - val_mae: 3.1093\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9139 - mae: 2.9139 - val_loss: 3.1409 - val_mae: 3.1409\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8868 - mae: 2.8868 - val_loss: 3.1074 - val_mae: 3.1074\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9033 - mae: 2.9033 - val_loss: 3.0868 - val_mae: 3.0868\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8464 - mae: 2.8464 - val_loss: 3.0779 - val_mae: 3.0779\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8149 - mae: 2.8149 - val_loss: 3.1020 - val_mae: 3.1020\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8686 - mae: 2.8686 - val_loss: 3.0556 - val_mae: 3.0556\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8337 - mae: 2.8337 - val_loss: 3.0522 - val_mae: 3.0522\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.8408 - mae: 2.8408 - val_loss: 3.0535 - val_mae: 3.0535\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8060 - mae: 2.8060 - val_loss: 3.0233 - val_mae: 3.0233\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8129 - mae: 2.8129 - val_loss: 3.0083 - val_mae: 3.0083\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7714 - mae: 2.7714 - val_loss: 3.0449 - val_mae: 3.0449\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7686 - mae: 2.7686 - val_loss: 3.0006 - val_mae: 3.0006\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7711 - mae: 2.7711 - val_loss: 2.9924 - val_mae: 2.9924\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7644 - mae: 2.7644 - val_loss: 2.9720 - val_mae: 2.9720\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7336 - mae: 2.7336 - val_loss: 2.9727 - val_mae: 2.9727\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7558 - mae: 2.7558 - val_loss: 2.9718 - val_mae: 2.9718\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7086 - mae: 2.7086 - val_loss: 2.9630 - val_mae: 2.9630\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7362 - mae: 2.7362 - val_loss: 2.9576 - val_mae: 2.9576\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.6144 - mae: 3.6144\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 9ms/step - loss: 175.0059 - mae: 9.7754 - val_loss: 97.4569 - val_mae: 6.9779\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 83.4006 - mae: 6.3990 - val_loss: 90.2129 - val_mae: 6.9946\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.9315 - mae: 6.4257 - val_loss: 89.3009 - val_mae: 7.0854\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.5026 - mae: 6.4241 - val_loss: 89.1694 - val_mae: 7.1205\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 80.4057 - mae: 6.4730 - val_loss: 89.1185 - val_mae: 7.1497\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3743 - mae: 6.4761 - val_loss: 89.0990 - val_mae: 7.1509\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3586 - mae: 6.4577 - val_loss: 89.0835 - val_mae: 7.1365\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4080 - mae: 6.4825 - val_loss: 89.0511 - val_mae: 7.1442\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3766 - mae: 6.5002 - val_loss: 89.0298 - val_mae: 7.1691\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2871 - mae: 6.4777 - val_loss: 88.9786 - val_mae: 7.1392\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2188 - mae: 6.4689 - val_loss: 88.9229 - val_mae: 7.1467\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2005 - mae: 6.4721 - val_loss: 88.8554 - val_mae: 7.1349\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2463 - mae: 6.4576 - val_loss: 88.7790 - val_mae: 7.1093\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.0844 - mae: 6.4577 - val_loss: 88.6287 - val_mae: 7.1264\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.9507 - mae: 6.4431 - val_loss: 88.4040 - val_mae: 7.1063\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.9732 - mae: 6.4374 - val_loss: 88.0857 - val_mae: 7.1126\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.3705 - mae: 6.4302 - val_loss: 87.4019 - val_mae: 7.0618\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 78.5782 - mae: 6.3470 - val_loss: 85.9011 - val_mae: 6.9387\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 76.5973 - mae: 6.2170 - val_loss: 82.4569 - val_mae: 6.7171\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 72.7640 - mae: 5.8756 - val_loss: 75.9910 - val_mae: 6.3121\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 66.1145 - mae: 5.4689 - val_loss: 67.8176 - val_mae: 5.5834\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 59.8398 - mae: 5.0997 - val_loss: 62.0068 - val_mae: 5.2669\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 55.3608 - mae: 4.9334 - val_loss: 58.0537 - val_mae: 4.8846\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 52.4370 - mae: 4.7018 - val_loss: 55.8845 - val_mae: 4.9740\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 50.3385 - mae: 4.6775 - val_loss: 53.5692 - val_mae: 4.6953\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 48.3265 - mae: 4.6445 - val_loss: 52.0121 - val_mae: 4.7297\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 46.6137 - mae: 4.5438 - val_loss: 50.2814 - val_mae: 4.5242\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 44.6903 - mae: 4.4342 - val_loss: 48.5198 - val_mae: 4.3654\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 42.8848 - mae: 4.3126 - val_loss: 47.0495 - val_mae: 4.3980\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 41.2915 - mae: 4.2666 - val_loss: 45.2932 - val_mae: 4.1932\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 39.2758 - mae: 4.1278 - val_loss: 44.3360 - val_mae: 4.0271\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 38.0914 - mae: 4.0650 - val_loss: 42.5067 - val_mae: 4.0116\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 36.2052 - mae: 3.9301 - val_loss: 40.9174 - val_mae: 3.9423\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 34.9918 - mae: 3.8452 - val_loss: 40.5151 - val_mae: 3.8267\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 33.9692 - mae: 3.7799 - val_loss: 38.5741 - val_mae: 3.8168\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 32.6316 - mae: 3.7195 - val_loss: 37.2521 - val_mae: 3.7903\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 31.6520 - mae: 3.6729 - val_loss: 37.3052 - val_mae: 3.7307\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 30.5728 - mae: 3.5474 - val_loss: 35.2565 - val_mae: 3.8685\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 29.6574 - mae: 3.5348 - val_loss: 34.3022 - val_mae: 3.7231\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 29.0734 - mae: 3.5137 - val_loss: 33.4911 - val_mae: 3.6609\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 28.2629 - mae: 3.4651 - val_loss: 32.8622 - val_mae: 3.6136\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.9861 - mae: 3.4692 - val_loss: 32.1477 - val_mae: 3.7230\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.2483 - mae: 3.4418 - val_loss: 31.9853 - val_mae: 3.5311\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.6188 - mae: 3.4216 - val_loss: 31.4356 - val_mae: 3.5396\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.2256 - mae: 3.4009 - val_loss: 30.7133 - val_mae: 3.4939\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.5343 - mae: 3.3072 - val_loss: 29.8346 - val_mae: 3.5712\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.2656 - mae: 3.3710 - val_loss: 29.5786 - val_mae: 3.4460\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.7377 - mae: 3.2664 - val_loss: 28.8673 - val_mae: 3.5143\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.2876 - mae: 3.2694 - val_loss: 28.9693 - val_mae: 3.3745\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.1251 - mae: 3.2610 - val_loss: 28.2401 - val_mae: 3.3666\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.8920 - mae: 3.2771 - val_loss: 27.7455 - val_mae: 3.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.5232 - mae: 3.2062 - val_loss: 27.6294 - val_mae: 3.5679\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.0993 - mae: 3.2171 - val_loss: 27.0308 - val_mae: 3.3055\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.5530 - mae: 3.1526 - val_loss: 26.6336 - val_mae: 3.3056\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.5269 - mae: 3.1774 - val_loss: 26.1934 - val_mae: 3.3366\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.1797 - mae: 3.1657 - val_loss: 25.9388 - val_mae: 3.2803\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.8708 - mae: 3.1046 - val_loss: 25.7215 - val_mae: 3.2270\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.7267 - mae: 3.1206 - val_loss: 25.3739 - val_mae: 3.3107\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.5121 - mae: 3.0996 - val_loss: 25.0498 - val_mae: 3.2155\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.0099 - mae: 3.0828 - val_loss: 25.6749 - val_mae: 3.1796\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.1320 - mae: 3.0773 - val_loss: 24.5099 - val_mae: 3.1857\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.6299 - mae: 3.0291 - val_loss: 24.2915 - val_mae: 3.1971\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.5889 - mae: 3.0497 - val_loss: 24.0457 - val_mae: 3.1634\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.6557 - mae: 3.0386 - val_loss: 23.9123 - val_mae: 3.2331\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.0999 - mae: 3.0111 - val_loss: 23.7053 - val_mae: 3.1510\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.8637 - mae: 2.9751 - val_loss: 23.4612 - val_mae: 3.1609\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.6935 - mae: 2.9862 - val_loss: 23.8069 - val_mae: 3.0647\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.7698 - mae: 2.9608 - val_loss: 23.1326 - val_mae: 3.1529\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.7394 - mae: 3.0214 - val_loss: 23.9217 - val_mae: 3.0560\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.2265 - mae: 2.9089 - val_loss: 23.0762 - val_mae: 3.0155\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.8906 - mae: 2.8778 - val_loss: 22.7453 - val_mae: 3.1789\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.0651 - mae: 2.9470 - val_loss: 22.6717 - val_mae: 3.0126\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.6035 - mae: 2.9228 - val_loss: 22.2178 - val_mae: 3.0419\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.4415 - mae: 2.8641 - val_loss: 22.1606 - val_mae: 2.9970\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.4663 - mae: 2.8826 - val_loss: 22.2767 - val_mae: 2.9753\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.2697 - mae: 2.8983 - val_loss: 22.0766 - val_mae: 2.9711\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.0000 - mae: 2.8337 - val_loss: 22.0843 - val_mae: 2.9409\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.9325 - mae: 2.8125 - val_loss: 21.5169 - val_mae: 2.9930\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.7402 - mae: 2.8140 - val_loss: 21.7654 - val_mae: 2.9328\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.7733 - mae: 2.8533 - val_loss: 21.2820 - val_mae: 3.0150\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.5355 - mae: 2.7887 - val_loss: 21.2989 - val_mae: 3.0564\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.6656 - mae: 2.8256 - val_loss: 21.2508 - val_mae: 2.9098\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.4616 - mae: 2.7527 - val_loss: 21.4121 - val_mae: 2.8966\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.2931 - mae: 2.7981 - val_loss: 20.9523 - val_mae: 2.9157\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.3538 - mae: 2.7625 - val_loss: 21.1613 - val_mae: 2.8761\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.0780 - mae: 2.7580 - val_loss: 21.1002 - val_mae: 2.8832\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.0489 - mae: 2.7470 - val_loss: 20.5629 - val_mae: 2.8978\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.0903 - mae: 2.7636 - val_loss: 20.5599 - val_mae: 2.9143\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.9600 - mae: 2.7523 - val_loss: 20.4463 - val_mae: 2.9257\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.7276 - mae: 2.7227 - val_loss: 21.1268 - val_mae: 2.8721\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.7359 - mae: 2.7438 - val_loss: 20.7680 - val_mae: 2.8660\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.5886 - mae: 2.7034 - val_loss: 20.2040 - val_mae: 2.8677\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.6114 - mae: 2.7098 - val_loss: 20.1237 - val_mae: 2.9123\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.2971 - mae: 2.6959 - val_loss: 20.6460 - val_mae: 2.8395\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.3005 - mae: 2.6931 - val_loss: 20.1025 - val_mae: 2.9435\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.3031 - mae: 2.6815 - val_loss: 19.9719 - val_mae: 2.8396\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.1330 - mae: 2.6648 - val_loss: 19.8908 - val_mae: 2.8668\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.0400 - mae: 2.6835 - val_loss: 20.1793 - val_mae: 2.8194\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.0825 - mae: 2.6278 - val_loss: 19.8493 - val_mae: 2.9243\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 15.9477 - mae: 2.6753 - val_loss: 19.7284 - val_mae: 2.9029\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.0300 - mae: 3.0277\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 9ms/step - loss: 9.2826 - mae: 9.2826 - val_loss: 6.9194 - val_mae: 6.9194\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3784 - mae: 6.3784 - val_loss: 6.9868 - val_mae: 6.9868\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3911 - mae: 6.3911 - val_loss: 6.9716 - val_mae: 6.9716\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9603 - val_mae: 6.9603\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9662 - val_mae: 6.9662\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3847 - mae: 6.3847 - val_loss: 6.9676 - val_mae: 6.9676\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9571 - val_mae: 6.9571\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3830 - mae: 6.3830 - val_loss: 6.9644 - val_mae: 6.9644\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3823 - mae: 6.3823 - val_loss: 6.9647 - val_mae: 6.9647\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3788 - mae: 6.3788 - val_loss: 6.9647 - val_mae: 6.9647\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 6.3748 - mae: 6.3748 - val_loss: 6.9565 - val_mae: 6.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 6.3673 - mae: 6.3673 - val_loss: 6.9345 - val_mae: 6.9345\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3542 - mae: 6.3542 - val_loss: 6.9181 - val_mae: 6.9181\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3210 - mae: 6.3210 - val_loss: 6.8398 - val_mae: 6.8398\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 6.2496 - mae: 6.2496 - val_loss: 6.6644 - val_mae: 6.6644\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.0062 - mae: 6.0062 - val_loss: 6.1436 - val_mae: 6.1436\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.4743 - mae: 5.4743 - val_loss: 5.2432 - val_mae: 5.2432\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.9810 - mae: 4.9810 - val_loss: 4.9894 - val_mae: 4.9894\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.7379 - mae: 4.7379 - val_loss: 4.7732 - val_mae: 4.7732\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.6394 - mae: 4.6394 - val_loss: 4.6208 - val_mae: 4.6208\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.5653 - mae: 4.5653 - val_loss: 4.6141 - val_mae: 4.6141\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5065 - mae: 4.5065 - val_loss: 4.4772 - val_mae: 4.4772\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.4098 - mae: 4.4098 - val_loss: 4.4526 - val_mae: 4.4526\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.3331 - mae: 4.3331 - val_loss: 4.4555 - val_mae: 4.4555\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.2585 - mae: 4.2585 - val_loss: 4.3966 - val_mae: 4.3966\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.2098 - mae: 4.2098 - val_loss: 4.3178 - val_mae: 4.3178\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.1223 - mae: 4.1223 - val_loss: 4.3239 - val_mae: 4.3239\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0837 - mae: 4.0837 - val_loss: 4.3648 - val_mae: 4.3648\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0604 - mae: 4.0604 - val_loss: 4.2508 - val_mae: 4.2508\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9825 - mae: 3.9825 - val_loss: 4.1219 - val_mae: 4.1219\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9320 - mae: 3.9320 - val_loss: 4.1207 - val_mae: 4.1207\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9460 - mae: 3.9460 - val_loss: 4.0254 - val_mae: 4.0254\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8237 - mae: 3.8237 - val_loss: 4.0283 - val_mae: 4.0283\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.7718 - mae: 3.7718 - val_loss: 3.9621 - val_mae: 3.9621\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.7328 - mae: 3.7328 - val_loss: 3.9473 - val_mae: 3.9473\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.6995 - mae: 3.6995 - val_loss: 3.8995 - val_mae: 3.8995\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.6806 - mae: 3.6806 - val_loss: 3.8705 - val_mae: 3.8705\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6259 - mae: 3.6259 - val_loss: 3.8400 - val_mae: 3.8400\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5763 - mae: 3.5763 - val_loss: 3.8110 - val_mae: 3.8110\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5817 - mae: 3.5817 - val_loss: 3.8312 - val_mae: 3.8312\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5595 - mae: 3.5595 - val_loss: 3.7666 - val_mae: 3.7666\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5209 - mae: 3.5209 - val_loss: 3.7287 - val_mae: 3.7287\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.4730 - mae: 3.4730 - val_loss: 3.7218 - val_mae: 3.7218\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5058 - mae: 3.5058 - val_loss: 3.6968 - val_mae: 3.6968\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4515 - mae: 3.4515 - val_loss: 3.6680 - val_mae: 3.6680\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.3965 - mae: 3.3965 - val_loss: 3.6310 - val_mae: 3.6310\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.3738 - mae: 3.3738 - val_loss: 3.7242 - val_mae: 3.7242\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.3751 - mae: 3.3751 - val_loss: 3.6020 - val_mae: 3.6020\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3689 - mae: 3.3689 - val_loss: 3.5584 - val_mae: 3.5584\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3225 - mae: 3.3225 - val_loss: 3.6173 - val_mae: 3.6173\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3417 - mae: 3.3417 - val_loss: 3.6036 - val_mae: 3.6036\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3186 - mae: 3.3186 - val_loss: 3.4912 - val_mae: 3.4912\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2935 - mae: 3.2935 - val_loss: 3.5359 - val_mae: 3.5359\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2581 - mae: 3.2581 - val_loss: 3.5258 - val_mae: 3.5258\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.2536 - mae: 3.2536 - val_loss: 3.4322 - val_mae: 3.4322\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2184 - mae: 3.2184 - val_loss: 3.3999 - val_mae: 3.3999\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.2367 - mae: 3.2367 - val_loss: 3.6148 - val_mae: 3.6148\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1828 - mae: 3.1828 - val_loss: 3.3552 - val_mae: 3.3552\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1722 - mae: 3.1722 - val_loss: 3.4004 - val_mae: 3.4004\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1239 - mae: 3.1239 - val_loss: 3.3659 - val_mae: 3.3659\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1594 - mae: 3.1594 - val_loss: 3.4046 - val_mae: 3.4046\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1231 - mae: 3.1231 - val_loss: 3.3317 - val_mae: 3.3317\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1311 - mae: 3.1311 - val_loss: 3.2939 - val_mae: 3.2939\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0820 - mae: 3.0820 - val_loss: 3.2845 - val_mae: 3.2845\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0625 - mae: 3.0625 - val_loss: 3.2429 - val_mae: 3.2429\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0526 - mae: 3.0526 - val_loss: 3.2684 - val_mae: 3.2684\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0682 - mae: 3.0682 - val_loss: 3.2166 - val_mae: 3.2166\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0257 - mae: 3.0257 - val_loss: 3.2062 - val_mae: 3.2062\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.0197 - mae: 3.0197 - val_loss: 3.2070 - val_mae: 3.2070\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0043 - mae: 3.0043 - val_loss: 3.1777 - val_mae: 3.1777\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9647 - mae: 2.9647 - val_loss: 3.2080 - val_mae: 3.2080\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9468 - mae: 2.9468 - val_loss: 3.1753 - val_mae: 3.1753\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9737 - mae: 2.9737 - val_loss: 3.1360 - val_mae: 3.1360\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9275 - mae: 2.9275 - val_loss: 3.1473 - val_mae: 3.1473\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9208 - mae: 2.9208 - val_loss: 3.1319 - val_mae: 3.1319\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.9098 - mae: 2.9098 - val_loss: 3.1162 - val_mae: 3.1162\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.8962 - mae: 2.8962 - val_loss: 3.1223 - val_mae: 3.1223\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.8543 - mae: 2.8543 - val_loss: 3.0905 - val_mae: 3.0905\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.8774 - mae: 2.8774 - val_loss: 3.0749 - val_mae: 3.0749\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8669 - mae: 2.8669 - val_loss: 3.0681 - val_mae: 3.0681\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.8543 - mae: 2.8543 - val_loss: 3.0579 - val_mae: 3.0579\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8346 - mae: 2.8346 - val_loss: 3.0502 - val_mae: 3.0502\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8372 - mae: 2.8372 - val_loss: 3.0887 - val_mae: 3.0887\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8219 - mae: 2.8219 - val_loss: 3.0552 - val_mae: 3.0552\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7834 - mae: 2.7834 - val_loss: 3.0233 - val_mae: 3.0233\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8036 - mae: 2.8036 - val_loss: 3.0126 - val_mae: 3.0126\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7364 - mae: 2.7364 - val_loss: 3.0940 - val_mae: 3.0940\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7942 - mae: 2.7942 - val_loss: 3.0272 - val_mae: 3.0272\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7472 - mae: 2.7472 - val_loss: 3.0090 - val_mae: 3.0090\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7504 - mae: 2.7504 - val_loss: 2.9807 - val_mae: 2.9807\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7340 - mae: 2.7340 - val_loss: 2.9894 - val_mae: 2.9894\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7250 - mae: 2.7250 - val_loss: 3.0426 - val_mae: 3.0426\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7306 - mae: 2.7306 - val_loss: 2.9708 - val_mae: 2.9708\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7313 - mae: 2.7313 - val_loss: 2.9633 - val_mae: 2.9633\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7028 - mae: 2.7028 - val_loss: 2.9562 - val_mae: 2.9562\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6929 - mae: 2.6929 - val_loss: 2.9458 - val_mae: 2.9458\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6740 - mae: 2.6740 - val_loss: 2.9584 - val_mae: 2.9584\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.6735 - mae: 2.6735 - val_loss: 2.9451 - val_mae: 2.9451\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 2.6763 - mae: 2.6763 - val_loss: 2.9324 - val_mae: 2.9324\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7167 - mae: 3.7167\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 159.2087 - mae: 9.3353 - val_loss: 94.6041 - val_mae: 6.9290\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 81.9034 - mae: 6.3881 - val_loss: 89.5905 - val_mae: 7.0437\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.6391 - mae: 6.4382 - val_loss: 89.2101 - val_mae: 7.1075\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4292 - mae: 6.4484 - val_loss: 89.1377 - val_mae: 7.1349\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4592 - mae: 6.4638 - val_loss: 89.1317 - val_mae: 7.1243\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3855 - mae: 6.4608 - val_loss: 89.0853 - val_mae: 7.1409\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.3707 - mae: 6.4646 - val_loss: 89.0556 - val_mae: 7.1425\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.3362 - mae: 6.4572 - val_loss: 89.0286 - val_mae: 7.1290\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.2550 - mae: 6.4604 - val_loss: 88.9703 - val_mae: 7.1417\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2493 - mae: 6.4674 - val_loss: 88.9109 - val_mae: 7.1443\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2177 - mae: 6.4695 - val_loss: 88.8330 - val_mae: 7.1186\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2030 - mae: 6.4539 - val_loss: 88.6976 - val_mae: 7.1359\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.0209 - mae: 6.4605 - val_loss: 88.5099 - val_mae: 7.1251\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.9233 - mae: 6.4230 - val_loss: 88.1851 - val_mae: 7.0865\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 79.5585 - mae: 6.4362 - val_loss: 87.6331 - val_mae: 7.0611\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 78.9343 - mae: 6.3680 - val_loss: 86.5360 - val_mae: 6.9642\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 77.6414 - mae: 6.3082 - val_loss: 84.3343 - val_mae: 6.8475\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 75.1314 - mae: 6.0954 - val_loss: 79.8946 - val_mae: 6.5401\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 70.2828 - mae: 5.7713 - val_loss: 72.7215 - val_mae: 6.0315\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 63.4433 - mae: 5.3300 - val_loss: 65.5444 - val_mae: 5.3569\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 58.2174 - mae: 4.9950 - val_loss: 60.6127 - val_mae: 5.0316\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 53.7948 - mae: 4.7996 - val_loss: 56.9748 - val_mae: 4.9015\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 51.2050 - mae: 4.7355 - val_loss: 55.2604 - val_mae: 4.5292\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 49.0760 - mae: 4.5641 - val_loss: 53.0184 - val_mae: 4.8495\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 47.6326 - mae: 4.5975 - val_loss: 51.1760 - val_mae: 4.5396\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 45.8174 - mae: 4.4392 - val_loss: 49.5453 - val_mae: 4.6215\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 44.3663 - mae: 4.4671 - val_loss: 48.0131 - val_mae: 4.4437\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 42.1936 - mae: 4.3130 - val_loss: 46.4697 - val_mae: 4.3229\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 40.2625 - mae: 4.1913 - val_loss: 44.7336 - val_mae: 4.2607\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 38.6459 - mae: 4.0509 - val_loss: 43.2826 - val_mae: 4.2731\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 37.1559 - mae: 4.0022 - val_loss: 42.6431 - val_mae: 3.9493\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 35.9702 - mae: 3.9303 - val_loss: 41.3130 - val_mae: 4.3394\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 34.5478 - mae: 3.8828 - val_loss: 39.3299 - val_mae: 3.9545\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 33.3377 - mae: 3.8042 - val_loss: 39.1853 - val_mae: 3.8218\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 33.6353 - mae: 3.8559 - val_loss: 38.0157 - val_mae: 3.7960\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 31.2369 - mae: 3.6347 - val_loss: 37.7905 - val_mae: 4.2300\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 30.8022 - mae: 3.7056 - val_loss: 35.4968 - val_mae: 3.8673\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 29.9708 - mae: 3.6087 - val_loss: 34.6532 - val_mae: 3.7269\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 29.0803 - mae: 3.5155 - val_loss: 33.9065 - val_mae: 3.8124\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 28.5783 - mae: 3.4938 - val_loss: 33.3739 - val_mae: 3.8508\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.8013 - mae: 3.4970 - val_loss: 32.5345 - val_mae: 3.6534\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 27.1085 - mae: 3.3990 - val_loss: 32.0013 - val_mae: 3.7470\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 27.1615 - mae: 3.4997 - val_loss: 31.3653 - val_mae: 3.6954\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.2097 - mae: 3.3818 - val_loss: 31.0005 - val_mae: 3.7056\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 26.1140 - mae: 3.4113 - val_loss: 31.1034 - val_mae: 3.8401\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 25.4375 - mae: 3.3521 - val_loss: 29.7244 - val_mae: 3.5792\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 25.0959 - mae: 3.3274 - val_loss: 29.6521 - val_mae: 3.6816\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.6241 - mae: 3.3041 - val_loss: 28.8763 - val_mae: 3.4853\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.3421 - mae: 3.2577 - val_loss: 28.4650 - val_mae: 3.4984\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.3402 - mae: 3.3590 - val_loss: 28.2901 - val_mae: 3.5828\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 23.5993 - mae: 3.2308 - val_loss: 27.7996 - val_mae: 3.3931\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.5897 - mae: 3.2207 - val_loss: 27.3972 - val_mae: 3.4475\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 23.0709 - mae: 3.2243 - val_loss: 27.3447 - val_mae: 3.3264\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.7145 - mae: 3.1755 - val_loss: 27.1606 - val_mae: 3.2758\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.5451 - mae: 3.1687 - val_loss: 26.5834 - val_mae: 3.2654\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 22.1630 - mae: 3.1438 - val_loss: 26.0860 - val_mae: 3.3220\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 22.1867 - mae: 3.2176 - val_loss: 25.9115 - val_mae: 3.4031\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.7992 - mae: 3.1265 - val_loss: 25.5221 - val_mae: 3.2977\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 21.6981 - mae: 3.1698 - val_loss: 25.3144 - val_mae: 3.2622\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.2219 - mae: 3.0610 - val_loss: 25.0547 - val_mae: 3.2288\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.2060 - mae: 3.1142 - val_loss: 25.7341 - val_mae: 3.1783\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 20.5803 - mae: 3.0428 - val_loss: 24.7390 - val_mae: 3.3376\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 20.7480 - mae: 3.1334 - val_loss: 24.4395 - val_mae: 3.3060\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.3701 - mae: 3.0259 - val_loss: 24.0951 - val_mae: 3.1400\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.0551 - mae: 3.0618 - val_loss: 25.5278 - val_mae: 3.1680\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 20.3667 - mae: 3.0512 - val_loss: 23.7182 - val_mae: 3.1800\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.0961 - mae: 3.0684 - val_loss: 23.5553 - val_mae: 3.1175\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 20.0962 - mae: 3.0044 - val_loss: 24.2956 - val_mae: 3.0737\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.4169 - mae: 2.9388 - val_loss: 23.2620 - val_mae: 3.2007\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.4964 - mae: 3.0024 - val_loss: 23.0450 - val_mae: 3.0803\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.1240 - mae: 2.9390 - val_loss: 23.3250 - val_mae: 3.0401\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.0374 - mae: 2.9161 - val_loss: 22.6942 - val_mae: 3.1234\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.8616 - mae: 2.9139 - val_loss: 23.1690 - val_mae: 3.0070\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.8118 - mae: 2.8900 - val_loss: 22.4183 - val_mae: 3.0432\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 19.0712 - mae: 3.0231 - val_loss: 22.3373 - val_mae: 3.1189\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.3500 - mae: 2.9008 - val_loss: 22.3164 - val_mae: 2.9844\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.4746 - mae: 2.8812 - val_loss: 22.0829 - val_mae: 2.9861\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.4022 - mae: 2.9323 - val_loss: 22.0343 - val_mae: 3.1162\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.9210 - mae: 2.8545 - val_loss: 22.3880 - val_mae: 2.9513\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 18.0947 - mae: 2.8611 - val_loss: 21.6924 - val_mae: 2.9771\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.7325 - mae: 2.8371 - val_loss: 21.4656 - val_mae: 2.9978\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 17.7504 - mae: 2.8264 - val_loss: 21.9137 - val_mae: 3.1571\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 17.7862 - mae: 2.8082 - val_loss: 21.3452 - val_mae: 3.0344\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.4806 - mae: 2.8339 - val_loss: 21.2494 - val_mae: 3.0313\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.1714 - mae: 2.8140 - val_loss: 21.6866 - val_mae: 2.9204\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.2917 - mae: 2.7742 - val_loss: 20.9988 - val_mae: 2.9665\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 17.0901 - mae: 2.7702 - val_loss: 20.8982 - val_mae: 2.9625\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 17.1241 - mae: 2.7981 - val_loss: 21.0020 - val_mae: 2.8991\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.9966 - mae: 2.7488 - val_loss: 20.9678 - val_mae: 2.9003\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 17.0512 - mae: 2.7319 - val_loss: 20.6932 - val_mae: 2.9341\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.8389 - mae: 2.7939 - val_loss: 21.0403 - val_mae: 2.8837\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.6911 - mae: 2.7178 - val_loss: 20.5245 - val_mae: 2.9624\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 16.7277 - mae: 2.7437 - val_loss: 20.4438 - val_mae: 2.9576\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 16.5632 - mae: 2.7421 - val_loss: 20.3380 - val_mae: 2.9415\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 16.4332 - mae: 2.6764 - val_loss: 20.2511 - val_mae: 2.9231\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 16.5379 - mae: 2.7325 - val_loss: 20.1706 - val_mae: 2.8826\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 16.2070 - mae: 2.6762 - val_loss: 20.1257 - val_mae: 2.8913\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 16.1831 - mae: 2.6913 - val_loss: 20.3324 - val_mae: 2.8615\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 16.4593 - mae: 2.7177 - val_loss: 20.0614 - val_mae: 2.8810\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 16.1665 - mae: 2.7271 - val_loss: 21.0853 - val_mae: 2.8871\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.2869 - mae: 3.6385\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 8.9358 - mae: 8.9358 - val_loss: 6.9236 - val_mae: 6.9236\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9595 - val_mae: 6.9595\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3905 - mae: 6.3905 - val_loss: 6.9853 - val_mae: 6.9853\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3952 - mae: 6.3952 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9533 - val_mae: 6.9533\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3928 - mae: 6.3928 - val_loss: 6.9555 - val_mae: 6.9555\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9777 - val_mae: 6.9777\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 6.3819 - mae: 6.3819 - val_loss: 6.9580 - val_mae: 6.9580\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3818 - mae: 6.3818 - val_loss: 6.9588 - val_mae: 6.9588\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3792 - mae: 6.3792 - val_loss: 6.9473 - val_mae: 6.9473\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3765 - mae: 6.3765 - val_loss: 6.9426 - val_mae: 6.9426\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3723 - mae: 6.3723 - val_loss: 6.9427 - val_mae: 6.9427\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 6.3602 - mae: 6.3602 - val_loss: 6.9318 - val_mae: 6.9318\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3418 - mae: 6.3418 - val_loss: 6.9038 - val_mae: 6.9038\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.3051 - mae: 6.3051 - val_loss: 6.7867 - val_mae: 6.7867\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 6.1522 - mae: 6.1522 - val_loss: 6.4393 - val_mae: 6.4393\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7492 - mae: 5.7492 - val_loss: 5.7415 - val_mae: 5.7415\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 5.1659 - mae: 5.1659 - val_loss: 4.9932 - val_mae: 4.9932\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 4.7918 - mae: 4.7918 - val_loss: 4.6944 - val_mae: 4.6944\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.6622 - mae: 4.6622 - val_loss: 4.6156 - val_mae: 4.6156\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.6197 - mae: 4.6197 - val_loss: 4.5564 - val_mae: 4.5564\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.5100 - mae: 4.5100 - val_loss: 4.5798 - val_mae: 4.5798\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 4.4552 - mae: 4.4552 - val_loss: 4.4307 - val_mae: 4.4307\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3888 - mae: 4.3888 - val_loss: 4.4120 - val_mae: 4.4120\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.3211 - mae: 4.3211 - val_loss: 4.3731 - val_mae: 4.3731\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.2618 - mae: 4.2618 - val_loss: 4.3465 - val_mae: 4.3465\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.1866 - mae: 4.1866 - val_loss: 4.3414 - val_mae: 4.3414\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 4.1339 - mae: 4.1339 - val_loss: 4.2563 - val_mae: 4.2563\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0754 - mae: 4.0754 - val_loss: 4.3426 - val_mae: 4.3426\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 4.0337 - mae: 4.0337 - val_loss: 4.1923 - val_mae: 4.1923\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9795 - mae: 3.9795 - val_loss: 4.0793 - val_mae: 4.0793\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9425 - mae: 3.9425 - val_loss: 4.0471 - val_mae: 4.0471\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.9246 - mae: 3.9246 - val_loss: 4.0665 - val_mae: 4.0665\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.8122 - mae: 3.8122 - val_loss: 3.9774 - val_mae: 3.9774\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7892 - mae: 3.7892 - val_loss: 4.0789 - val_mae: 4.0789\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.7286 - mae: 3.7286 - val_loss: 3.9030 - val_mae: 3.9030\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6919 - mae: 3.6919 - val_loss: 3.8747 - val_mae: 3.8747\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.6560 - mae: 3.6560 - val_loss: 3.8351 - val_mae: 3.8351\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.6282 - mae: 3.6282 - val_loss: 3.8179 - val_mae: 3.8179\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5999 - mae: 3.5999 - val_loss: 3.7948 - val_mae: 3.7948\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.5352 - mae: 3.5352 - val_loss: 3.7823 - val_mae: 3.7823\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.5362 - mae: 3.5362 - val_loss: 3.7571 - val_mae: 3.7571\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.5383 - mae: 3.5383 - val_loss: 3.7051 - val_mae: 3.7051\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4864 - mae: 3.4864 - val_loss: 3.7279 - val_mae: 3.7279\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4501 - mae: 3.4501 - val_loss: 3.7551 - val_mae: 3.7551\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4197 - mae: 3.4197 - val_loss: 3.6251 - val_mae: 3.6251\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.4174 - mae: 3.4174 - val_loss: 3.6828 - val_mae: 3.6828\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3734 - mae: 3.3734 - val_loss: 3.6305 - val_mae: 3.6305\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3436 - mae: 3.3436 - val_loss: 3.5466 - val_mae: 3.5466\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3440 - mae: 3.3440 - val_loss: 3.5265 - val_mae: 3.5265\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.3316 - mae: 3.3316 - val_loss: 3.5025 - val_mae: 3.5025\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.3056 - mae: 3.3056 - val_loss: 3.4816 - val_mae: 3.4816\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2947 - mae: 3.2947 - val_loss: 3.4691 - val_mae: 3.4691\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.2791 - mae: 3.2791 - val_loss: 3.4357 - val_mae: 3.4357\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2531 - mae: 3.2531 - val_loss: 3.4958 - val_mae: 3.4958\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.2619 - mae: 3.2619 - val_loss: 3.3934 - val_mae: 3.3934\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.2197 - mae: 3.2197 - val_loss: 3.4014 - val_mae: 3.4014\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 3.2125 - mae: 3.2125 - val_loss: 3.4353 - val_mae: 3.4353\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1589 - mae: 3.1589 - val_loss: 3.3647 - val_mae: 3.3647\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1580 - mae: 3.1580 - val_loss: 3.3159 - val_mae: 3.3159\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1437 - mae: 3.1437 - val_loss: 3.3276 - val_mae: 3.3276\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.1147 - mae: 3.1147 - val_loss: 3.3834 - val_mae: 3.3834\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1086 - mae: 3.1086 - val_loss: 3.2564 - val_mae: 3.2564\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.1533 - mae: 3.1533 - val_loss: 3.2613 - val_mae: 3.2613\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0856 - mae: 3.0856 - val_loss: 3.3017 - val_mae: 3.3017\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0527 - mae: 3.0527 - val_loss: 3.2353 - val_mae: 3.2353\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 3.0396 - mae: 3.0396 - val_loss: 3.3000 - val_mae: 3.3000\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.0701 - mae: 3.0701 - val_loss: 3.1981 - val_mae: 3.1981\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0223 - mae: 3.0223 - val_loss: 3.2288 - val_mae: 3.2288\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0265 - mae: 3.0265 - val_loss: 3.1891 - val_mae: 3.1891\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 3.0536 - mae: 3.0536 - val_loss: 3.1855 - val_mae: 3.1855\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9793 - mae: 2.9793 - val_loss: 3.1724 - val_mae: 3.1724\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9726 - mae: 2.9726 - val_loss: 3.1299 - val_mae: 3.1299\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9666 - mae: 2.9666 - val_loss: 3.1836 - val_mae: 3.1836\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.9354 - mae: 2.9354 - val_loss: 3.1203 - val_mae: 3.1203\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9094 - mae: 2.9094 - val_loss: 3.0971 - val_mae: 3.0971\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9320 - mae: 2.9320 - val_loss: 3.0931 - val_mae: 3.0931\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.8873 - mae: 2.8873 - val_loss: 3.1420 - val_mae: 3.1420\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9015 - mae: 2.9015 - val_loss: 3.0677 - val_mae: 3.0677\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.9050 - mae: 2.9050 - val_loss: 3.1189 - val_mae: 3.1189\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8694 - mae: 2.8694 - val_loss: 3.0372 - val_mae: 3.0372\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8671 - mae: 2.8671 - val_loss: 3.0535 - val_mae: 3.0535\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8253 - mae: 2.8253 - val_loss: 3.0445 - val_mae: 3.0445\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8371 - mae: 2.8371 - val_loss: 3.1121 - val_mae: 3.1121\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8481 - mae: 2.8481 - val_loss: 3.0075 - val_mae: 3.0075\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7920 - mae: 2.7920 - val_loss: 3.0040 - val_mae: 3.0040\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7913 - mae: 2.7913 - val_loss: 2.9971 - val_mae: 2.9971\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7777 - mae: 2.7777 - val_loss: 3.1160 - val_mae: 3.1160\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8727 - mae: 2.8727 - val_loss: 3.0632 - val_mae: 3.0632\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.8037 - mae: 2.8037 - val_loss: 2.9607 - val_mae: 2.9607\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7675 - mae: 2.7675 - val_loss: 3.0820 - val_mae: 3.0820\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7615 - mae: 2.7615 - val_loss: 2.9545 - val_mae: 2.9545\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7283 - mae: 2.7283 - val_loss: 2.9416 - val_mae: 2.9416\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.7027 - mae: 2.7027 - val_loss: 2.9572 - val_mae: 2.9572\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.7231 - mae: 2.7231 - val_loss: 2.9393 - val_mae: 2.9393\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6958 - mae: 2.6958 - val_loss: 2.9280 - val_mae: 2.9280\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.6963 - mae: 2.6963 - val_loss: 2.9375 - val_mae: 2.9375\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6646 - mae: 2.6646 - val_loss: 2.9315 - val_mae: 2.9315\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6890 - mae: 2.6890 - val_loss: 2.9359 - val_mae: 2.9359\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.6670 - mae: 2.6670 - val_loss: 2.9690 - val_mae: 2.9690\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4158 - mae: 3.4158\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 295.1978 - mae: 14.1796 - val_loss: 70.2435 - val_mae: 6.1499\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 50.3268 - mae: 5.1354 - val_loss: 38.8683 - val_mae: 4.2835\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 32.6897 - mae: 3.9742 - val_loss: 29.5247 - val_mae: 3.6607\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 24.8493 - mae: 3.4029 - val_loss: 25.8641 - val_mae: 3.4961\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.3095 - mae: 3.1227 - val_loss: 22.4528 - val_mae: 3.2274\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 19.2611 - mae: 2.9885 - val_loss: 21.0513 - val_mae: 3.0859\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.7923 - mae: 2.8516 - val_loss: 19.8722 - val_mae: 2.9859\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.1796 - mae: 2.7360 - val_loss: 18.9464 - val_mae: 3.0351\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.7930 - mae: 2.6893 - val_loss: 18.9802 - val_mae: 2.9509\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.1629 - mae: 2.6058 - val_loss: 18.1498 - val_mae: 2.9126\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.6472 - mae: 2.6166 - val_loss: 17.9426 - val_mae: 2.8486\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.8052 - mae: 2.4778 - val_loss: 18.9936 - val_mae: 3.0033\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4870 - mae: 2.5289 - val_loss: 17.3912 - val_mae: 2.8257\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.8055 - mae: 2.4049 - val_loss: 17.7536 - val_mae: 2.8514\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4374 - mae: 2.3620 - val_loss: 16.6108 - val_mae: 2.7442\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.1725 - mae: 2.3501 - val_loss: 16.7490 - val_mae: 2.7868\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7809 - mae: 2.3072 - val_loss: 16.6817 - val_mae: 2.7457\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.3061 - mae: 2.2854 - val_loss: 16.1586 - val_mae: 2.7261\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1739 - mae: 2.2640 - val_loss: 16.1215 - val_mae: 2.6917\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3395 - mae: 2.1777 - val_loss: 17.0609 - val_mae: 2.8492\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9850 - mae: 2.2857 - val_loss: 15.6433 - val_mae: 2.6546\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.3518 - mae: 2.1842 - val_loss: 16.0909 - val_mae: 2.7147\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1321 - mae: 2.1569 - val_loss: 15.5206 - val_mae: 2.6822\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7718 - mae: 2.1127 - val_loss: 15.1441 - val_mae: 2.6140\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5942 - mae: 2.1095 - val_loss: 15.9142 - val_mae: 2.7204\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7946 - mae: 2.1328 - val_loss: 14.7669 - val_mae: 2.5714\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1028 - mae: 2.0251 - val_loss: 15.6414 - val_mae: 2.6371\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.3631 - mae: 2.0563 - val_loss: 14.7345 - val_mae: 2.5957\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6924 - mae: 2.0088 - val_loss: 14.5136 - val_mae: 2.5619\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5583 - mae: 1.9939 - val_loss: 14.6534 - val_mae: 2.5579\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6651 - mae: 1.9915 - val_loss: 14.3369 - val_mae: 2.5184\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0408 - mae: 1.9203 - val_loss: 14.4111 - val_mae: 2.5769\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9182 - mae: 1.9344 - val_loss: 14.6364 - val_mae: 2.5852\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8831 - mae: 1.9210 - val_loss: 14.1178 - val_mae: 2.5313\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6095 - mae: 1.8687 - val_loss: 14.4916 - val_mae: 2.6203\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5261 - mae: 1.8552 - val_loss: 14.0461 - val_mae: 2.5107\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.2864 - mae: 1.8194 - val_loss: 14.1347 - val_mae: 2.5494\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.0528 - mae: 1.7687 - val_loss: 14.2421 - val_mae: 2.6109\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.9665 - mae: 1.7637 - val_loss: 13.8879 - val_mae: 2.5209\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8405 - mae: 1.7766 - val_loss: 13.9479 - val_mae: 2.5136\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8499 - mae: 1.7674 - val_loss: 13.5962 - val_mae: 2.4906\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.5584 - mae: 1.7138 - val_loss: 14.0133 - val_mae: 2.5008\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4122 - mae: 1.6659 - val_loss: 13.7185 - val_mae: 2.4731\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.4293 - mae: 1.6986 - val_loss: 13.8449 - val_mae: 2.5479\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3177 - mae: 1.6750 - val_loss: 13.5389 - val_mae: 2.4467\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6975 - mae: 1.7809 - val_loss: 13.6634 - val_mae: 2.4833\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9246 - mae: 1.6015 - val_loss: 14.0606 - val_mae: 2.5806\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7762 - mae: 1.6079 - val_loss: 13.6794 - val_mae: 2.5762\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7912 - mae: 1.5811 - val_loss: 13.8443 - val_mae: 2.5608\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6922 - mae: 1.5696 - val_loss: 13.7911 - val_mae: 2.4312\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5121 - mae: 1.5394 - val_loss: 13.7032 - val_mae: 2.4432\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5530 - mae: 1.5523 - val_loss: 13.4576 - val_mae: 2.4659\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4839 - mae: 1.5750 - val_loss: 13.8703 - val_mae: 2.4276\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2666 - mae: 1.5014 - val_loss: 14.1442 - val_mae: 2.4079\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4532 - mae: 1.5699 - val_loss: 13.8068 - val_mae: 2.5275\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1201 - mae: 1.4811 - val_loss: 13.8492 - val_mae: 2.4195\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1244 - mae: 1.4898 - val_loss: 13.5467 - val_mae: 2.4637\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9637 - mae: 1.4627 - val_loss: 13.6208 - val_mae: 2.5003\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8693 - mae: 1.4543 - val_loss: 13.9653 - val_mae: 2.5517\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8384 - mae: 1.4353 - val_loss: 13.5966 - val_mae: 2.4307\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.7363 - mae: 1.4147 - val_loss: 13.7076 - val_mae: 2.4030\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6242 - mae: 1.3901 - val_loss: 13.9423 - val_mae: 2.5735\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0470 - mae: 1.5236 - val_loss: 13.7024 - val_mae: 2.4854\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6092 - mae: 1.3953 - val_loss: 13.7361 - val_mae: 2.5192\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.5338 - mae: 1.3785 - val_loss: 13.6321 - val_mae: 2.4675\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4403 - mae: 1.3704 - val_loss: 13.7628 - val_mae: 2.5101\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5112 - mae: 1.3938 - val_loss: 13.9297 - val_mae: 2.4200\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3312 - mae: 1.3179 - val_loss: 13.7695 - val_mae: 2.4740\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3698 - mae: 1.3672 - val_loss: 13.7876 - val_mae: 2.4160\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3107 - mae: 1.3399 - val_loss: 13.8843 - val_mae: 2.4845\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1472 - mae: 1.3033 - val_loss: 13.9803 - val_mae: 2.4801\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2116 - mae: 1.3321 - val_loss: 14.2701 - val_mae: 2.5188\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1245 - mae: 1.3132 - val_loss: 14.0151 - val_mae: 2.4366\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0624 - mae: 1.2840 - val_loss: 14.2163 - val_mae: 2.5149\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9821 - mae: 1.2683 - val_loss: 14.3385 - val_mae: 2.4555\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9666 - mae: 1.2601 - val_loss: 14.3369 - val_mae: 2.5001\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9114 - mae: 1.2539 - val_loss: 14.4118 - val_mae: 2.4417\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0737 - mae: 1.2980 - val_loss: 13.9343 - val_mae: 2.4655\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8850 - mae: 1.2399 - val_loss: 14.0258 - val_mae: 2.5083\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7612 - mae: 1.2281 - val_loss: 14.6166 - val_mae: 2.5907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8707 - mae: 1.2593 - val_loss: 14.1098 - val_mae: 2.5503\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7990 - mae: 1.2372 - val_loss: 14.3588 - val_mae: 2.4854\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7011 - mae: 1.1923 - val_loss: 13.8996 - val_mae: 2.4580\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6116 - mae: 1.1732 - val_loss: 14.3647 - val_mae: 2.4777\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6873 - mae: 1.2172 - val_loss: 14.2572 - val_mae: 2.4613\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5771 - mae: 1.1860 - val_loss: 14.1583 - val_mae: 2.4453\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4124 - mae: 1.1296 - val_loss: 14.5021 - val_mae: 2.4864\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6985 - mae: 1.2198 - val_loss: 13.7391 - val_mae: 2.5042\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6092 - mae: 1.1939 - val_loss: 14.9150 - val_mae: 2.6012\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5914 - mae: 1.1935 - val_loss: 14.2637 - val_mae: 2.4740\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3974 - mae: 1.1394 - val_loss: 14.4719 - val_mae: 2.4933\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4379 - mae: 1.1450 - val_loss: 14.4947 - val_mae: 2.5369\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3276 - mae: 1.1154 - val_loss: 14.4253 - val_mae: 2.5283\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3006 - mae: 1.1041 - val_loss: 14.6294 - val_mae: 2.5200\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2150 - mae: 1.0891 - val_loss: 14.6861 - val_mae: 2.4925\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4508 - mae: 1.1423 - val_loss: 15.2753 - val_mae: 2.5665\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2530 - mae: 1.1075 - val_loss: 14.4787 - val_mae: 2.4920\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2992 - mae: 1.1374 - val_loss: 15.0203 - val_mae: 2.5060\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1475 - mae: 1.0920 - val_loss: 14.3871 - val_mae: 2.5352\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2185 - mae: 1.0833 - val_loss: 15.0488 - val_mae: 2.5654\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.6958 - mae: 3.7732\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 13.9216 - mae: 13.9216 - val_loss: 6.1586 - val_mae: 6.1586\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.5083 - mae: 4.5083 - val_loss: 3.3848 - val_mae: 3.3848\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2891 - mae: 3.2891 - val_loss: 2.9378 - val_mae: 2.9378\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9897 - mae: 2.9897 - val_loss: 2.9072 - val_mae: 2.9072\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8375 - mae: 2.8375 - val_loss: 2.8340 - val_mae: 2.8340\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7846 - mae: 2.7846 - val_loss: 2.8771 - val_mae: 2.8771\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7474 - mae: 2.7474 - val_loss: 2.7033 - val_mae: 2.7033\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5664 - mae: 2.5664 - val_loss: 2.8290 - val_mae: 2.8290\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5478 - mae: 2.5478 - val_loss: 2.5990 - val_mae: 2.5990\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4412 - mae: 2.4412 - val_loss: 2.7345 - val_mae: 2.7345\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4516 - mae: 2.4516 - val_loss: 2.6160 - val_mae: 2.6160\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3811 - mae: 2.3811 - val_loss: 2.5512 - val_mae: 2.5512\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.3097 - mae: 2.3097 - val_loss: 2.5289 - val_mae: 2.5289\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2528 - mae: 2.2528 - val_loss: 2.4458 - val_mae: 2.4458\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1896 - mae: 2.1896 - val_loss: 2.5034 - val_mae: 2.5034\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1575 - mae: 2.1575 - val_loss: 2.5464 - val_mae: 2.5464\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1974 - mae: 2.1974 - val_loss: 2.5814 - val_mae: 2.5814\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1487 - mae: 2.1487 - val_loss: 2.4942 - val_mae: 2.4942\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1374 - mae: 2.1374 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0911 - mae: 2.0911 - val_loss: 2.4971 - val_mae: 2.4971\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0418 - mae: 2.0418 - val_loss: 2.4675 - val_mae: 2.4675\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0661 - mae: 2.0661 - val_loss: 2.5294 - val_mae: 2.5294\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0353 - mae: 2.0353 - val_loss: 2.4456 - val_mae: 2.4456\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0256 - mae: 2.0256 - val_loss: 2.4954 - val_mae: 2.4954\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 2.0364 - mae: 2.0364 - val_loss: 2.4639 - val_mae: 2.4639\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9413 - mae: 1.9413 - val_loss: 2.5282 - val_mae: 2.5282\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9499 - mae: 1.9499 - val_loss: 2.4927 - val_mae: 2.4927\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9310 - mae: 1.9310 - val_loss: 2.4674 - val_mae: 2.4674\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8878 - mae: 1.8878 - val_loss: 2.4989 - val_mae: 2.4989\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9184 - mae: 1.9184 - val_loss: 2.4905 - val_mae: 2.4905\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8708 - mae: 1.8708 - val_loss: 2.4917 - val_mae: 2.4917\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8586 - mae: 1.8586 - val_loss: 2.4744 - val_mae: 2.4744\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8478 - mae: 1.8478 - val_loss: 2.4980 - val_mae: 2.4980\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7933 - mae: 1.7933 - val_loss: 2.5817 - val_mae: 2.5817\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7971 - mae: 1.7971 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7844 - mae: 1.7844 - val_loss: 2.4679 - val_mae: 2.4679\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8206 - mae: 1.8206 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7655 - mae: 1.7655 - val_loss: 2.5829 - val_mae: 2.5829\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7397 - mae: 1.7397 - val_loss: 2.4760 - val_mae: 2.4760\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7183 - mae: 1.7183 - val_loss: 2.5512 - val_mae: 2.5512\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7688 - mae: 1.7688 - val_loss: 2.4966 - val_mae: 2.4966\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6755 - mae: 1.6755 - val_loss: 2.5127 - val_mae: 2.5127\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6836 - mae: 1.6836 - val_loss: 2.5088 - val_mae: 2.5088\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6826 - mae: 1.6826 - val_loss: 2.5114 - val_mae: 2.5114\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6430 - mae: 1.6430 - val_loss: 2.4633 - val_mae: 2.4633\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6255 - mae: 1.6255 - val_loss: 2.5797 - val_mae: 2.5797\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6238 - mae: 1.6238 - val_loss: 2.5230 - val_mae: 2.5230\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6310 - mae: 1.6310 - val_loss: 2.5537 - val_mae: 2.5537\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6128 - mae: 1.6128 - val_loss: 2.5077 - val_mae: 2.5077\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6302 - mae: 1.6302 - val_loss: 2.5598 - val_mae: 2.5598\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5723 - mae: 1.5723 - val_loss: 2.5742 - val_mae: 2.5742\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5839 - mae: 1.5839 - val_loss: 2.5594 - val_mae: 2.5594\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5703 - mae: 1.5703 - val_loss: 2.6635 - val_mae: 2.6635\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5808 - mae: 1.5808 - val_loss: 2.5115 - val_mae: 2.5115\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5376 - mae: 1.5376 - val_loss: 2.5865 - val_mae: 2.5865\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5052 - mae: 1.5052 - val_loss: 2.5384 - val_mae: 2.5384\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4961 - mae: 1.4961 - val_loss: 2.4859 - val_mae: 2.4859\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4975 - mae: 1.4975 - val_loss: 2.5713 - val_mae: 2.5713\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5029 - mae: 1.5029 - val_loss: 2.5804 - val_mae: 2.5804\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4794 - mae: 1.4794 - val_loss: 2.5512 - val_mae: 2.5512\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4508 - mae: 1.4508 - val_loss: 2.5898 - val_mae: 2.5898\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5278 - mae: 1.5278 - val_loss: 2.5767 - val_mae: 2.5767\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5050 - mae: 1.5050 - val_loss: 2.5977 - val_mae: 2.5977\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4438 - mae: 1.4438 - val_loss: 2.5149 - val_mae: 2.5149\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4577 - mae: 1.4577 - val_loss: 2.5439 - val_mae: 2.5439\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.4550 - mae: 1.4550 - val_loss: 2.4849 - val_mae: 2.4849\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4135 - mae: 1.4135 - val_loss: 2.5274 - val_mae: 2.5274\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4314 - mae: 1.4314 - val_loss: 2.5078 - val_mae: 2.5078\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4358 - mae: 1.4358 - val_loss: 2.5669 - val_mae: 2.5669\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3961 - mae: 1.3961 - val_loss: 2.5127 - val_mae: 2.5127\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3857 - mae: 1.3857 - val_loss: 2.6042 - val_mae: 2.6042\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3814 - mae: 1.3814 - val_loss: 2.5422 - val_mae: 2.5422\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3648 - mae: 1.3648 - val_loss: 2.5598 - val_mae: 2.5598\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3457 - mae: 1.3457 - val_loss: 2.5813 - val_mae: 2.5813\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3828 - mae: 1.3828 - val_loss: 2.5625 - val_mae: 2.5625\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3411 - mae: 1.3411 - val_loss: 2.5938 - val_mae: 2.5938\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3326 - mae: 1.3326 - val_loss: 2.5816 - val_mae: 2.5816\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3377 - mae: 1.3377 - val_loss: 2.6341 - val_mae: 2.6341\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3518 - mae: 1.3518 - val_loss: 2.5569 - val_mae: 2.5569\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3060 - mae: 1.3060 - val_loss: 2.5197 - val_mae: 2.5197\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2786 - mae: 1.2786 - val_loss: 2.5559 - val_mae: 2.5559\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2878 - mae: 1.2878 - val_loss: 2.5947 - val_mae: 2.5947\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3000 - mae: 1.3000 - val_loss: 2.5880 - val_mae: 2.5880\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2756 - mae: 1.2756 - val_loss: 2.5619 - val_mae: 2.5619\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2681 - mae: 1.2681 - val_loss: 2.6187 - val_mae: 2.6187\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2575 - mae: 1.2575 - val_loss: 2.5183 - val_mae: 2.5183\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2492 - mae: 1.2492 - val_loss: 2.5222 - val_mae: 2.5222\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2279 - mae: 1.2279 - val_loss: 2.5135 - val_mae: 2.5135\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1925 - mae: 1.1925 - val_loss: 2.5195 - val_mae: 2.5195\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2032 - mae: 1.2032 - val_loss: 2.5267 - val_mae: 2.5267\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2543 - mae: 1.2543 - val_loss: 2.5870 - val_mae: 2.5870\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2407 - mae: 1.2407 - val_loss: 2.5483 - val_mae: 2.5483\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2674 - mae: 1.2674 - val_loss: 2.5718 - val_mae: 2.5718\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2158 - mae: 1.2158 - val_loss: 2.6060 - val_mae: 2.6060\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1581 - mae: 1.1581 - val_loss: 2.5309 - val_mae: 2.5309\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2087 - mae: 1.2087 - val_loss: 2.6130 - val_mae: 2.6130\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1776 - mae: 1.1776 - val_loss: 2.6079 - val_mae: 2.6079\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1591 - mae: 1.1591 - val_loss: 2.5362 - val_mae: 2.5362\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1501 - mae: 1.1501 - val_loss: 2.5869 - val_mae: 2.5869\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1733 - mae: 1.1733 - val_loss: 2.5850 - val_mae: 2.5850\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2633 - mae: 3.2633\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 348.8598 - mae: 15.7276 - val_loss: 90.0905 - val_mae: 6.9031\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5398 - mae: 4.8558 - val_loss: 35.0152 - val_mae: 4.0095\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 25.2718 - mae: 3.5441 - val_loss: 25.9406 - val_mae: 3.3575\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 20.4385 - mae: 3.1705 - val_loss: 23.2473 - val_mae: 3.2695\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.6569 - mae: 2.9398 - val_loss: 21.3935 - val_mae: 3.2348\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 16.4096 - mae: 2.8658 - val_loss: 19.8417 - val_mae: 3.0924\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 15.3675 - mae: 2.7576 - val_loss: 19.2071 - val_mae: 3.0276\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 14.7526 - mae: 2.6737 - val_loss: 18.6007 - val_mae: 3.0347\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.3728 - mae: 2.6865 - val_loss: 17.5947 - val_mae: 2.9333\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 13.3013 - mae: 2.6012 - val_loss: 17.9009 - val_mae: 2.9906\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.1149 - mae: 2.5703 - val_loss: 17.7704 - val_mae: 2.9892\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4409 - mae: 2.5163 - val_loss: 16.6748 - val_mae: 2.8703\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.1713 - mae: 2.4846 - val_loss: 16.5489 - val_mae: 2.8371\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.9056 - mae: 2.4461 - val_loss: 16.4482 - val_mae: 2.8137\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5450 - mae: 2.3981 - val_loss: 16.5230 - val_mae: 2.8247\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.3389 - mae: 2.3633 - val_loss: 17.0552 - val_mae: 2.9242\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.8933 - mae: 2.3619 - val_loss: 16.6480 - val_mae: 2.8516\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7369 - mae: 2.3448 - val_loss: 15.6816 - val_mae: 2.7915\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4921 - mae: 2.3006 - val_loss: 15.3272 - val_mae: 2.7408\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9247 - mae: 2.2269 - val_loss: 15.2780 - val_mae: 2.7055\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.7134 - mae: 2.2067 - val_loss: 15.2548 - val_mae: 2.6868\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5240 - mae: 2.1669 - val_loss: 14.9545 - val_mae: 2.6194\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.4817 - mae: 2.1955 - val_loss: 14.7256 - val_mae: 2.6274\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1015 - mae: 2.1597 - val_loss: 14.8216 - val_mae: 2.6421\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8023 - mae: 2.1029 - val_loss: 14.8051 - val_mae: 2.6216\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5739 - mae: 2.0890 - val_loss: 14.4300 - val_mae: 2.5925\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4066 - mae: 2.0646 - val_loss: 14.1779 - val_mae: 2.5929\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3992 - mae: 2.0662 - val_loss: 14.2632 - val_mae: 2.6035\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.2151 - mae: 2.0555 - val_loss: 14.2451 - val_mae: 2.5664\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9389 - mae: 2.0172 - val_loss: 14.5527 - val_mae: 2.5756\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.6584 - mae: 2.0029 - val_loss: 13.7704 - val_mae: 2.5197\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5802 - mae: 1.9708 - val_loss: 14.0637 - val_mae: 2.5273\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.3510 - mae: 1.9448 - val_loss: 13.8154 - val_mae: 2.4842\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1446 - mae: 1.9339 - val_loss: 13.6029 - val_mae: 2.4850\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9218 - mae: 1.8911 - val_loss: 13.6667 - val_mae: 2.4920\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7374 - mae: 1.8719 - val_loss: 13.6073 - val_mae: 2.4703\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5672 - mae: 1.8487 - val_loss: 13.6443 - val_mae: 2.4750\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5987 - mae: 1.8676 - val_loss: 13.4430 - val_mae: 2.4862\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3439 - mae: 1.8349 - val_loss: 13.5196 - val_mae: 2.4800\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.1271 - mae: 1.7813 - val_loss: 13.4140 - val_mae: 2.4599\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8409 - mae: 1.7665 - val_loss: 13.3660 - val_mae: 2.4747\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.8831 - mae: 1.7910 - val_loss: 13.3007 - val_mae: 2.4374\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5606 - mae: 1.7248 - val_loss: 13.6175 - val_mae: 2.4569\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.5564 - mae: 1.7219 - val_loss: 13.3150 - val_mae: 2.4167\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.2950 - mae: 1.6831 - val_loss: 13.0110 - val_mae: 2.3930\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.2394 - mae: 1.6588 - val_loss: 13.2273 - val_mae: 2.3940\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.0259 - mae: 1.6540 - val_loss: 13.4423 - val_mae: 2.4027\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.9085 - mae: 1.6252 - val_loss: 13.1364 - val_mae: 2.3929\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8538 - mae: 1.6082 - val_loss: 13.5578 - val_mae: 2.4119\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 4.7263 - mae: 1.6086 - val_loss: 13.0554 - val_mae: 2.4243\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7591 - mae: 1.5994 - val_loss: 13.1060 - val_mae: 2.3936\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6229 - mae: 1.5835 - val_loss: 13.1317 - val_mae: 2.3718\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.3566 - mae: 1.5376 - val_loss: 12.9632 - val_mae: 2.4134\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2793 - mae: 1.5302 - val_loss: 12.9500 - val_mae: 2.3518\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2498 - mae: 1.5068 - val_loss: 13.4695 - val_mae: 2.3937\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.1333 - mae: 1.4809 - val_loss: 12.9120 - val_mae: 2.4061\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.2134 - mae: 1.5214 - val_loss: 13.0272 - val_mae: 2.3669\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.9006 - mae: 1.4515 - val_loss: 13.1801 - val_mae: 2.3877\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.0593 - mae: 1.5100 - val_loss: 12.7521 - val_mae: 2.3587\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7994 - mae: 1.4300 - val_loss: 12.8598 - val_mae: 2.3707\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.8050 - mae: 1.4392 - val_loss: 13.0490 - val_mae: 2.3618\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6208 - mae: 1.4089 - val_loss: 13.5839 - val_mae: 2.4428\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.6485 - mae: 1.4231 - val_loss: 13.4244 - val_mae: 2.3762\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4892 - mae: 1.3599 - val_loss: 12.7948 - val_mae: 2.3315\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4015 - mae: 1.3759 - val_loss: 13.3195 - val_mae: 2.3699\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3197 - mae: 1.3320 - val_loss: 13.8186 - val_mae: 2.4606\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3651 - mae: 1.3558 - val_loss: 13.1301 - val_mae: 2.3758\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3279 - mae: 1.3411 - val_loss: 12.7910 - val_mae: 2.3601\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.1264 - mae: 1.3072 - val_loss: 13.4075 - val_mae: 2.3776\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3204 - mae: 1.3429 - val_loss: 12.9112 - val_mae: 2.3439\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1623 - mae: 1.3074 - val_loss: 13.4261 - val_mae: 2.4096\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0218 - mae: 1.2579 - val_loss: 13.3577 - val_mae: 2.3601\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9593 - mae: 1.2614 - val_loss: 13.1217 - val_mae: 2.3571\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2049 - mae: 1.3245 - val_loss: 12.9803 - val_mae: 2.4030\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8725 - mae: 1.2588 - val_loss: 13.1879 - val_mae: 2.3696\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9886 - mae: 1.2665 - val_loss: 14.0262 - val_mae: 2.3852\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8310 - mae: 1.2167 - val_loss: 13.1671 - val_mae: 2.4147\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8381 - mae: 1.2395 - val_loss: 13.0482 - val_mae: 2.3886\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6647 - mae: 1.2000 - val_loss: 12.8785 - val_mae: 2.3451\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7136 - mae: 1.1963 - val_loss: 13.0818 - val_mae: 2.4116\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7018 - mae: 1.1883 - val_loss: 13.3186 - val_mae: 2.3959\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6184 - mae: 1.1844 - val_loss: 13.2621 - val_mae: 2.3658\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4966 - mae: 1.1515 - val_loss: 13.7683 - val_mae: 2.3926\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5731 - mae: 1.1764 - val_loss: 13.4057 - val_mae: 2.3709\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6132 - mae: 1.1824 - val_loss: 13.6674 - val_mae: 2.3820\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4996 - mae: 1.1602 - val_loss: 13.4514 - val_mae: 2.3963\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6719 - mae: 1.2168 - val_loss: 13.5047 - val_mae: 2.3759\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4896 - mae: 1.1511 - val_loss: 13.1076 - val_mae: 2.3304\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3880 - mae: 1.1483 - val_loss: 13.7571 - val_mae: 2.4281\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5068 - mae: 1.1721 - val_loss: 13.6479 - val_mae: 2.4478\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4002 - mae: 1.1286 - val_loss: 13.2458 - val_mae: 2.4123\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3461 - mae: 1.1432 - val_loss: 13.6065 - val_mae: 2.4287\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2930 - mae: 1.1124 - val_loss: 13.1813 - val_mae: 2.3694\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2614 - mae: 1.1136 - val_loss: 13.7181 - val_mae: 2.4227\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1755 - mae: 1.0839 - val_loss: 13.3291 - val_mae: 2.4382\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1017 - mae: 1.0596 - val_loss: 13.2529 - val_mae: 2.4093\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1051 - mae: 1.0595 - val_loss: 13.4653 - val_mae: 2.4319\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3329 - mae: 1.1031 - val_loss: 13.4461 - val_mae: 2.4189\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1859 - mae: 1.0872 - val_loss: 13.3636 - val_mae: 2.4080\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9853 - mae: 1.0242 - val_loss: 13.5332 - val_mae: 2.4314\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.3230 - mae: 3.7876\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 15.7075 - mae: 15.7075 - val_loss: 7.0743 - val_mae: 7.0743\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.0135 - mae: 5.0135 - val_loss: 3.9063 - val_mae: 3.9063\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5534 - mae: 3.5534 - val_loss: 3.3845 - val_mae: 3.3845\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0739 - mae: 3.0739 - val_loss: 3.1907 - val_mae: 3.1907\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8443 - mae: 2.8443 - val_loss: 3.0123 - val_mae: 3.0123\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6786 - mae: 2.6786 - val_loss: 2.8949 - val_mae: 2.8949\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6032 - mae: 2.6032 - val_loss: 2.7700 - val_mae: 2.7700\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5337 - mae: 2.5337 - val_loss: 2.8423 - val_mae: 2.8423\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4695 - mae: 2.4695 - val_loss: 2.7460 - val_mae: 2.7460\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4297 - mae: 2.4297 - val_loss: 2.7074 - val_mae: 2.7074\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3623 - mae: 2.3623 - val_loss: 2.6609 - val_mae: 2.6609\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3349 - mae: 2.3349 - val_loss: 2.6144 - val_mae: 2.6144\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3190 - mae: 2.3190 - val_loss: 2.5989 - val_mae: 2.5989\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2753 - mae: 2.2753 - val_loss: 2.6445 - val_mae: 2.6445\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2604 - mae: 2.2604 - val_loss: 2.5461 - val_mae: 2.5461\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2001 - mae: 2.2001 - val_loss: 2.5077 - val_mae: 2.5077\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1977 - mae: 2.1977 - val_loss: 2.6628 - val_mae: 2.6628\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2384 - mae: 2.2384 - val_loss: 2.5360 - val_mae: 2.5360\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1905 - mae: 2.1905 - val_loss: 2.5279 - val_mae: 2.5279\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1240 - mae: 2.1240 - val_loss: 2.4732 - val_mae: 2.4732\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1303 - mae: 2.1303 - val_loss: 2.5146 - val_mae: 2.5146\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0859 - mae: 2.0859 - val_loss: 2.4715 - val_mae: 2.4715\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0942 - mae: 2.0942 - val_loss: 2.4226 - val_mae: 2.4226\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0770 - mae: 2.0770 - val_loss: 2.4670 - val_mae: 2.4670\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0615 - mae: 2.0615 - val_loss: 2.4165 - val_mae: 2.4165\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9983 - mae: 1.9983 - val_loss: 2.3838 - val_mae: 2.3838\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0032 - mae: 2.0032 - val_loss: 2.4648 - val_mae: 2.4648\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0910 - mae: 2.0910 - val_loss: 2.4723 - val_mae: 2.4723\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9522 - mae: 1.9522 - val_loss: 2.3775 - val_mae: 2.3775\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9473 - mae: 1.9473 - val_loss: 2.3648 - val_mae: 2.3648\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9092 - mae: 1.9092 - val_loss: 2.3919 - val_mae: 2.3919\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8591 - mae: 1.8591 - val_loss: 2.3591 - val_mae: 2.3591\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8389 - mae: 1.8389 - val_loss: 2.4102 - val_mae: 2.4102\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8875 - mae: 1.8875 - val_loss: 2.4078 - val_mae: 2.4078\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8364 - mae: 1.8364 - val_loss: 2.3834 - val_mae: 2.3834\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8058 - mae: 1.8058 - val_loss: 2.3538 - val_mae: 2.3538\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7929 - mae: 1.7929 - val_loss: 2.4672 - val_mae: 2.4672\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7937 - mae: 1.7937 - val_loss: 2.3459 - val_mae: 2.3459\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7476 - mae: 1.7476 - val_loss: 2.3970 - val_mae: 2.3970\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7774 - mae: 1.7774 - val_loss: 2.3514 - val_mae: 2.3514\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7168 - mae: 1.7168 - val_loss: 2.3467 - val_mae: 2.3467\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7106 - mae: 1.7106 - val_loss: 2.4559 - val_mae: 2.4559\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6890 - mae: 1.6890 - val_loss: 2.3302 - val_mae: 2.3302\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6866 - mae: 1.6866 - val_loss: 2.3512 - val_mae: 2.3512\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6847 - mae: 1.6847 - val_loss: 2.3350 - val_mae: 2.3350\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6616 - mae: 1.6616 - val_loss: 2.5499 - val_mae: 2.5499\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7061 - mae: 1.7061 - val_loss: 2.3743 - val_mae: 2.3743\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6059 - mae: 1.6059 - val_loss: 2.3715 - val_mae: 2.3715\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5706 - mae: 1.5706 - val_loss: 2.3678 - val_mae: 2.3678\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5934 - mae: 1.5934 - val_loss: 2.3825 - val_mae: 2.3825\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5441 - mae: 1.5441 - val_loss: 2.3306 - val_mae: 2.3306\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5369 - mae: 1.5369 - val_loss: 2.3849 - val_mae: 2.3849\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5102 - mae: 1.5102 - val_loss: 2.3726 - val_mae: 2.3726\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5413 - mae: 1.5413 - val_loss: 2.3186 - val_mae: 2.3186\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4901 - mae: 1.4901 - val_loss: 2.3769 - val_mae: 2.3769\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4558 - mae: 1.4558 - val_loss: 2.3389 - val_mae: 2.3389\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4843 - mae: 1.4843 - val_loss: 2.3877 - val_mae: 2.3877\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4420 - mae: 1.4420 - val_loss: 2.3961 - val_mae: 2.3961\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4579 - mae: 1.4579 - val_loss: 2.3531 - val_mae: 2.3531\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3885 - mae: 1.3885 - val_loss: 2.4333 - val_mae: 2.4333\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4031 - mae: 1.4031 - val_loss: 2.3636 - val_mae: 2.3636\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4261 - mae: 1.4261 - val_loss: 2.4573 - val_mae: 2.4573\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4170 - mae: 1.4170 - val_loss: 2.3587 - val_mae: 2.3587\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3493 - mae: 1.3493 - val_loss: 2.3559 - val_mae: 2.3559\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3906 - mae: 1.3906 - val_loss: 2.3911 - val_mae: 2.3911\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3327 - mae: 1.3327 - val_loss: 2.3973 - val_mae: 2.3973\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3446 - mae: 1.3446 - val_loss: 2.3466 - val_mae: 2.3466\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3094 - mae: 1.3094 - val_loss: 2.3829 - val_mae: 2.3829\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3114 - mae: 1.3114 - val_loss: 2.4106 - val_mae: 2.4106\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2963 - mae: 1.2963 - val_loss: 2.2892 - val_mae: 2.2892\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3098 - mae: 1.3098 - val_loss: 2.4520 - val_mae: 2.4520\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2803 - mae: 1.2803 - val_loss: 2.3613 - val_mae: 2.3613\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2874 - mae: 1.2874 - val_loss: 2.4037 - val_mae: 2.4037\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2911 - mae: 1.2911 - val_loss: 2.3861 - val_mae: 2.3861\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2227 - mae: 1.2227 - val_loss: 2.3997 - val_mae: 2.3997\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2279 - mae: 1.2279 - val_loss: 2.3751 - val_mae: 2.3751\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2586 - mae: 1.2586 - val_loss: 2.3812 - val_mae: 2.3812\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2052 - mae: 1.2052 - val_loss: 2.3841 - val_mae: 2.3841\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2149 - mae: 1.2149 - val_loss: 2.5698 - val_mae: 2.5698\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2192 - mae: 1.2192 - val_loss: 2.3721 - val_mae: 2.3721\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1902 - mae: 1.1902 - val_loss: 2.3692 - val_mae: 2.3692\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2124 - mae: 1.2124 - val_loss: 2.3595 - val_mae: 2.3595\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2151 - mae: 1.2151 - val_loss: 2.3767 - val_mae: 2.3767\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1754 - mae: 1.1754 - val_loss: 2.4190 - val_mae: 2.4190\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1739 - mae: 1.1739 - val_loss: 2.3444 - val_mae: 2.3444\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1592 - mae: 1.1592 - val_loss: 2.3849 - val_mae: 2.3849\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1284 - mae: 1.1284 - val_loss: 2.3357 - val_mae: 2.3357\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1454 - mae: 1.1454 - val_loss: 2.4255 - val_mae: 2.4255\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1026 - mae: 1.1026 - val_loss: 2.3946 - val_mae: 2.3946\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1146 - mae: 1.1146 - val_loss: 2.4187 - val_mae: 2.4187\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1088 - mae: 1.1088 - val_loss: 2.4193 - val_mae: 2.4193\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0934 - mae: 1.0934 - val_loss: 2.4516 - val_mae: 2.4516\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0840 - mae: 1.0840 - val_loss: 2.3560 - val_mae: 2.3560\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0782 - mae: 1.0782 - val_loss: 2.4784 - val_mae: 2.4784\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0963 - mae: 1.0963 - val_loss: 2.4488 - val_mae: 2.4488\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0946 - mae: 1.0946 - val_loss: 2.4764 - val_mae: 2.4764\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0591 - mae: 1.0591 - val_loss: 2.4502 - val_mae: 2.4502\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0488 - mae: 1.0488 - val_loss: 2.4065 - val_mae: 2.4065\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0645 - mae: 1.0645 - val_loss: 2.4115 - val_mae: 2.4115\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0103 - mae: 1.0103 - val_loss: 2.5387 - val_mae: 2.5387\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4725 - mae: 3.4725\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 296.5889 - mae: 14.2675 - val_loss: 71.1996 - val_mae: 6.3881\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 43.5423 - mae: 4.9210 - val_loss: 34.1835 - val_mae: 4.0834\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 26.5240 - mae: 3.6550 - val_loss: 25.1345 - val_mae: 3.3419\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 21.1646 - mae: 3.2287 - val_loss: 23.2062 - val_mae: 3.1683\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 18.6269 - mae: 3.0141 - val_loss: 20.5286 - val_mae: 3.1589\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 17.2060 - mae: 2.9001 - val_loss: 19.9422 - val_mae: 3.0210\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 16.0319 - mae: 2.8180 - val_loss: 19.8358 - val_mae: 3.2359\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 15.2950 - mae: 2.7982 - val_loss: 18.2184 - val_mae: 2.9278\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.9873 - mae: 2.6384 - val_loss: 17.9486 - val_mae: 2.8861\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.2710 - mae: 2.6173 - val_loss: 17.3428 - val_mae: 3.0004\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.9397 - mae: 2.5830 - val_loss: 16.6287 - val_mae: 2.8772\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.3223 - mae: 2.5129 - val_loss: 16.3720 - val_mae: 2.8293\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.7897 - mae: 2.4532 - val_loss: 16.3024 - val_mae: 2.8350\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.4709 - mae: 2.4554 - val_loss: 15.9681 - val_mae: 2.8113\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0844 - mae: 2.3994 - val_loss: 15.2534 - val_mae: 2.7286\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.7380 - mae: 2.3573 - val_loss: 15.3843 - val_mae: 2.7585\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.2405 - mae: 2.3129 - val_loss: 15.1640 - val_mae: 2.7425\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 10.0981 - mae: 2.2880 - val_loss: 15.0028 - val_mae: 2.6981\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.6991 - mae: 2.2509 - val_loss: 14.9786 - val_mae: 2.6915\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 9.4558 - mae: 2.2407 - val_loss: 14.6317 - val_mae: 2.6800\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.0005 - mae: 2.1831 - val_loss: 14.5475 - val_mae: 2.6388\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.7885 - mae: 2.1560 - val_loss: 14.2268 - val_mae: 2.6006\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4384 - mae: 2.1215 - val_loss: 14.4439 - val_mae: 2.6402\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2564 - mae: 2.0968 - val_loss: 14.0552 - val_mae: 2.6149\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4531 - mae: 2.0996 - val_loss: 14.1476 - val_mae: 2.6431\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.8421 - mae: 2.0634 - val_loss: 13.7162 - val_mae: 2.5799\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.6006 - mae: 2.0199 - val_loss: 13.7953 - val_mae: 2.5730\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2556 - mae: 1.9807 - val_loss: 13.8813 - val_mae: 2.5758\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.3816 - mae: 2.0005 - val_loss: 13.5886 - val_mae: 2.5683\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8573 - mae: 1.9296 - val_loss: 13.6657 - val_mae: 2.5724\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6101 - mae: 1.8892 - val_loss: 13.6911 - val_mae: 2.6190\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3966 - mae: 1.8607 - val_loss: 13.8133 - val_mae: 2.5724\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3157 - mae: 1.8450 - val_loss: 13.8604 - val_mae: 2.5837\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.0871 - mae: 1.8300 - val_loss: 13.8794 - val_mae: 2.6441\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.8529 - mae: 1.8023 - val_loss: 14.4109 - val_mae: 2.6078\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7669 - mae: 1.8030 - val_loss: 13.5050 - val_mae: 2.6158\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6507 - mae: 1.7694 - val_loss: 13.9189 - val_mae: 2.6481\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.6780 - mae: 1.7741 - val_loss: 13.8559 - val_mae: 2.5836\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4399 - mae: 1.7636 - val_loss: 13.7029 - val_mae: 2.5844\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 5.1038 - mae: 1.6762 - val_loss: 13.5400 - val_mae: 2.6208\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.9441 - mae: 1.6477 - val_loss: 13.3968 - val_mae: 2.5868\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9131 - mae: 1.6604 - val_loss: 13.5657 - val_mae: 2.6001\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.7977 - mae: 1.6173 - val_loss: 13.7350 - val_mae: 2.5996\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.6478 - mae: 1.5841 - val_loss: 13.6492 - val_mae: 2.5932\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4743 - mae: 1.6048 - val_loss: 13.7194 - val_mae: 2.5928\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4330 - mae: 1.5572 - val_loss: 13.6858 - val_mae: 2.6062\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3182 - mae: 1.5506 - val_loss: 13.5350 - val_mae: 2.5883\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3892 - mae: 1.5559 - val_loss: 13.7639 - val_mae: 2.6208\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3994 - mae: 1.5694 - val_loss: 13.6325 - val_mae: 2.5708\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2698 - mae: 1.5562 - val_loss: 14.5614 - val_mae: 2.6074\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.4573 - mae: 1.6009 - val_loss: 13.6506 - val_mae: 2.6295\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9258 - mae: 1.4905 - val_loss: 13.9493 - val_mae: 2.6031\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7610 - mae: 1.4518 - val_loss: 13.9027 - val_mae: 2.6672\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.7714 - mae: 1.4291 - val_loss: 13.9018 - val_mae: 2.5868\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8788 - mae: 1.4653 - val_loss: 13.7601 - val_mae: 2.6163\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.5991 - mae: 1.4088 - val_loss: 13.5931 - val_mae: 2.6171\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4908 - mae: 1.3950 - val_loss: 13.7280 - val_mae: 2.5404\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4955 - mae: 1.3775 - val_loss: 13.9376 - val_mae: 2.6506\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.4333 - mae: 1.3721 - val_loss: 13.6841 - val_mae: 2.5591\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3000 - mae: 1.3385 - val_loss: 13.7051 - val_mae: 2.5636\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.3277 - mae: 1.3411 - val_loss: 13.6130 - val_mae: 2.5775\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.2132 - mae: 1.3326 - val_loss: 13.7671 - val_mae: 2.5643\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1487 - mae: 1.3080 - val_loss: 13.8586 - val_mae: 2.5872\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1562 - mae: 1.3078 - val_loss: 13.6215 - val_mae: 2.5605\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0924 - mae: 1.2875 - val_loss: 13.6139 - val_mae: 2.5609\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0349 - mae: 1.2894 - val_loss: 13.8564 - val_mae: 2.5805\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.1523 - mae: 1.3139 - val_loss: 13.6517 - val_mae: 2.5547\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0395 - mae: 1.2821 - val_loss: 13.9131 - val_mae: 2.5876\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 3.0014 - mae: 1.2732 - val_loss: 14.2487 - val_mae: 2.5669\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8603 - mae: 1.2474 - val_loss: 14.0398 - val_mae: 2.6066\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8966 - mae: 1.2564 - val_loss: 14.0425 - val_mae: 2.6065\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8123 - mae: 1.2162 - val_loss: 14.1192 - val_mae: 2.6013\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8606 - mae: 1.2615 - val_loss: 14.1311 - val_mae: 2.5808\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7041 - mae: 1.2105 - val_loss: 14.4843 - val_mae: 2.5771\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6070 - mae: 1.2081 - val_loss: 14.0437 - val_mae: 2.6318\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7149 - mae: 1.1996 - val_loss: 14.2443 - val_mae: 2.5993\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.7577 - mae: 1.2236 - val_loss: 14.4295 - val_mae: 2.6725\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7791 - mae: 1.2655 - val_loss: 14.5013 - val_mae: 2.5824\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5542 - mae: 1.1657 - val_loss: 14.3042 - val_mae: 2.5529\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5413 - mae: 1.1561 - val_loss: 14.2236 - val_mae: 2.5552\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3859 - mae: 1.1284 - val_loss: 14.1858 - val_mae: 2.5852\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5623 - mae: 1.1715 - val_loss: 14.0783 - val_mae: 2.5997\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5645 - mae: 1.1718 - val_loss: 14.4930 - val_mae: 2.6379\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4431 - mae: 1.1319 - val_loss: 14.6025 - val_mae: 2.6333\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3380 - mae: 1.1239 - val_loss: 14.4054 - val_mae: 2.6326\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3891 - mae: 1.1375 - val_loss: 14.2933 - val_mae: 2.6262\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3197 - mae: 1.1009 - val_loss: 14.2299 - val_mae: 2.5944\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3422 - mae: 1.0929 - val_loss: 14.4493 - val_mae: 2.6145\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2548 - mae: 1.0918 - val_loss: 14.6436 - val_mae: 2.5977\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2735 - mae: 1.0863 - val_loss: 14.0366 - val_mae: 2.5509\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3332 - mae: 1.0822 - val_loss: 14.4227 - val_mae: 2.5782\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.1527 - mae: 1.0590 - val_loss: 14.7356 - val_mae: 2.6073\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2559 - mae: 1.0934 - val_loss: 14.4342 - val_mae: 2.5783\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0889 - mae: 1.0300 - val_loss: 14.3374 - val_mae: 2.5759\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1263 - mae: 1.0550 - val_loss: 14.6362 - val_mae: 2.5849\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1568 - mae: 1.0698 - val_loss: 14.4580 - val_mae: 2.6634\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1811 - mae: 1.0804 - val_loss: 14.4063 - val_mae: 2.5673\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0858 - mae: 1.0429 - val_loss: 14.8854 - val_mae: 2.6623\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0578 - mae: 1.0405 - val_loss: 14.7482 - val_mae: 2.6216\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0266 - mae: 1.0237 - val_loss: 14.6686 - val_mae: 2.5528\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.7458 - mae: 3.5032\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 15.3772 - mae: 15.3772 - val_loss: 6.8367 - val_mae: 6.8367\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 4.8249 - mae: 4.8249 - val_loss: 3.3468 - val_mae: 3.3468\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.2701 - mae: 3.2701 - val_loss: 3.0159 - val_mae: 3.0159\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.9650 - mae: 2.9650 - val_loss: 2.8461 - val_mae: 2.8461\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.8039 - mae: 2.8039 - val_loss: 2.8137 - val_mae: 2.8137\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.7188 - mae: 2.7188 - val_loss: 3.2616 - val_mae: 3.2616\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6968 - mae: 2.6968 - val_loss: 2.7745 - val_mae: 2.7745\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.6046 - mae: 2.6046 - val_loss: 2.7042 - val_mae: 2.7042\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5374 - mae: 2.5374 - val_loss: 2.7078 - val_mae: 2.7078\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.5107 - mae: 2.5107 - val_loss: 2.8262 - val_mae: 2.8262\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.4906 - mae: 2.4906 - val_loss: 2.6554 - val_mae: 2.6554\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3668 - mae: 2.3668 - val_loss: 2.5917 - val_mae: 2.5917\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3431 - mae: 2.3431 - val_loss: 2.5876 - val_mae: 2.5876\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.3015 - mae: 2.3015 - val_loss: 2.5529 - val_mae: 2.5529\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2804 - mae: 2.2804 - val_loss: 2.5216 - val_mae: 2.5216\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2262 - mae: 2.2262 - val_loss: 2.5308 - val_mae: 2.5308\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.2223 - mae: 2.2223 - val_loss: 2.5807 - val_mae: 2.5807\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1615 - mae: 2.1615 - val_loss: 2.5952 - val_mae: 2.5952\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1739 - mae: 2.1739 - val_loss: 2.6412 - val_mae: 2.6412\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1402 - mae: 2.1402 - val_loss: 2.5419 - val_mae: 2.5419\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.1319 - mae: 2.1319 - val_loss: 2.5153 - val_mae: 2.5153\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0619 - mae: 2.0619 - val_loss: 2.5818 - val_mae: 2.5818\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0947 - mae: 2.0947 - val_loss: 2.4858 - val_mae: 2.4858\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 2.0325 - mae: 2.0325 - val_loss: 2.5534 - val_mae: 2.5534\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9845 - mae: 1.9845 - val_loss: 2.4694 - val_mae: 2.4694\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9924 - mae: 1.9924 - val_loss: 2.4751 - val_mae: 2.4751\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9536 - mae: 1.9536 - val_loss: 2.4931 - val_mae: 2.4931\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9311 - mae: 1.9311 - val_loss: 2.4408 - val_mae: 2.4408\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8916 - mae: 1.8916 - val_loss: 2.4435 - val_mae: 2.4435\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9384 - mae: 1.9384 - val_loss: 2.5105 - val_mae: 2.5105\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.9073 - mae: 1.9073 - val_loss: 2.4343 - val_mae: 2.4343\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8718 - mae: 1.8718 - val_loss: 2.4259 - val_mae: 2.4259\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8763 - mae: 1.8763 - val_loss: 2.4226 - val_mae: 2.4226\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8354 - mae: 1.8354 - val_loss: 2.4915 - val_mae: 2.4915\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8114 - mae: 1.8114 - val_loss: 2.3913 - val_mae: 2.3913\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7746 - mae: 1.7746 - val_loss: 2.3899 - val_mae: 2.3899\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7752 - mae: 1.7752 - val_loss: 2.3699 - val_mae: 2.3699\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7679 - mae: 1.7679 - val_loss: 2.4176 - val_mae: 2.4176\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7165 - mae: 1.7165 - val_loss: 2.4267 - val_mae: 2.4267\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7249 - mae: 1.7249 - val_loss: 2.4968 - val_mae: 2.4968\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7236 - mae: 1.7236 - val_loss: 2.3404 - val_mae: 2.3404\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6767 - mae: 1.6767 - val_loss: 2.4771 - val_mae: 2.4771\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7107 - mae: 1.7107 - val_loss: 2.5657 - val_mae: 2.5657\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6541 - mae: 1.6541 - val_loss: 2.4424 - val_mae: 2.4424\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.7188 - mae: 1.7188 - val_loss: 2.3801 - val_mae: 2.3801\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.6395 - mae: 1.6395 - val_loss: 2.3886 - val_mae: 2.3886\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5926 - mae: 1.5926 - val_loss: 2.4381 - val_mae: 2.4381\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.6972 - mae: 1.6972 - val_loss: 2.3678 - val_mae: 2.3678\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5564 - mae: 1.5564 - val_loss: 2.4864 - val_mae: 2.4864\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5739 - mae: 1.5739 - val_loss: 2.3985 - val_mae: 2.3985\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5664 - mae: 1.5664 - val_loss: 2.4194 - val_mae: 2.4194\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5479 - mae: 1.5479 - val_loss: 2.3815 - val_mae: 2.3815\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5433 - mae: 1.5433 - val_loss: 2.4348 - val_mae: 2.4348\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4899 - mae: 1.4899 - val_loss: 2.4496 - val_mae: 2.4496\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.5195 - mae: 1.5195 - val_loss: 2.4247 - val_mae: 2.4247\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4705 - mae: 1.4705 - val_loss: 2.3894 - val_mae: 2.3894\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4597 - mae: 1.4597 - val_loss: 2.4067 - val_mae: 2.4067\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4675 - mae: 1.4675 - val_loss: 2.4303 - val_mae: 2.4303\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.5025 - mae: 1.5025 - val_loss: 2.4272 - val_mae: 2.4272\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4329 - mae: 1.4329 - val_loss: 2.3942 - val_mae: 2.3942\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4346 - mae: 1.4346 - val_loss: 2.4533 - val_mae: 2.4533\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4083 - mae: 1.4083 - val_loss: 2.3750 - val_mae: 2.3750\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.4047 - mae: 1.4047 - val_loss: 2.3905 - val_mae: 2.3905\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3863 - mae: 1.3863 - val_loss: 2.4761 - val_mae: 2.4761\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3949 - mae: 1.3949 - val_loss: 2.3936 - val_mae: 2.3936\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3836 - mae: 1.3836 - val_loss: 2.3639 - val_mae: 2.3639\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3331 - mae: 1.3331 - val_loss: 2.4414 - val_mae: 2.4414\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3470 - mae: 1.3470 - val_loss: 2.4650 - val_mae: 2.4650\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3490 - mae: 1.3490 - val_loss: 2.4090 - val_mae: 2.4090\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3179 - mae: 1.3179 - val_loss: 2.4304 - val_mae: 2.4304\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3079 - mae: 1.3079 - val_loss: 2.4069 - val_mae: 2.4069\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.3233 - mae: 1.3233 - val_loss: 2.4693 - val_mae: 2.4693\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3118 - mae: 1.3118 - val_loss: 2.4018 - val_mae: 2.4018\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2886 - mae: 1.2886 - val_loss: 2.4026 - val_mae: 2.4026\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3243 - mae: 1.3243 - val_loss: 2.3747 - val_mae: 2.3747\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2575 - mae: 1.2575 - val_loss: 2.3512 - val_mae: 2.3512\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2750 - mae: 1.2750 - val_loss: 2.3935 - val_mae: 2.3935\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2209 - mae: 1.2209 - val_loss: 2.4657 - val_mae: 2.4657\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2636 - mae: 1.2636 - val_loss: 2.4270 - val_mae: 2.4270\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2743 - mae: 1.2743 - val_loss: 2.4861 - val_mae: 2.4861\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2137 - mae: 1.2137 - val_loss: 2.3893 - val_mae: 2.3893\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.2097 - mae: 1.2097 - val_loss: 2.3493 - val_mae: 2.3493\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1475 - mae: 1.1475 - val_loss: 2.4463 - val_mae: 2.4463\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1703 - mae: 1.1703 - val_loss: 2.3918 - val_mae: 2.3918\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1461 - mae: 1.1461 - val_loss: 2.3598 - val_mae: 2.3598\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1778 - mae: 1.1778 - val_loss: 2.3595 - val_mae: 2.3595\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1429 - mae: 1.1429 - val_loss: 2.4206 - val_mae: 2.4206\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1388 - mae: 1.1388 - val_loss: 2.4599 - val_mae: 2.4599\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1088 - mae: 1.1088 - val_loss: 2.3260 - val_mae: 2.3260\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1127 - mae: 1.1127 - val_loss: 2.3793 - val_mae: 2.3793\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1205 - mae: 1.1205 - val_loss: 2.3318 - val_mae: 2.3318\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0914 - mae: 1.0914 - val_loss: 2.3413 - val_mae: 2.3413\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.1144 - mae: 1.1144 - val_loss: 2.4373 - val_mae: 2.4373\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0862 - mae: 1.0862 - val_loss: 2.3904 - val_mae: 2.3904\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0982 - mae: 1.0982 - val_loss: 2.4762 - val_mae: 2.4762\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0814 - mae: 1.0814 - val_loss: 2.3546 - val_mae: 2.3546\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0534 - mae: 1.0534 - val_loss: 2.4091 - val_mae: 2.4091\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0729 - mae: 1.0729 - val_loss: 2.4877 - val_mae: 2.4877\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0949 - mae: 1.0949 - val_loss: 2.3775 - val_mae: 2.3775\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0289 - mae: 1.0289 - val_loss: 2.4148 - val_mae: 2.4148\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1223 - mae: 3.1223\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 428.6001 - mae: 18.5237 - val_loss: 320.6175 - val_mae: 15.2136\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 276.0847 - mae: 14.0664 - val_loss: 260.0345 - val_mae: 13.1540\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 236.6275 - mae: 12.7089 - val_loss: 232.7118 - val_mae: 12.1744\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 213.6284 - mae: 11.8570 - val_loss: 213.6083 - val_mae: 11.4552\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 196.9037 - mae: 11.2073 - val_loss: 198.4715 - val_mae: 10.8573\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 183.3214 - mae: 10.6637 - val_loss: 186.0608 - val_mae: 10.3667\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 171.6621 - mae: 10.1929 - val_loss: 175.2194 - val_mae: 9.9273\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 161.6715 - mae: 9.7642 - val_loss: 166.0556 - val_mae: 9.5557\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 153.1043 - mae: 9.4079 - val_loss: 158.4823 - val_mae: 9.2515\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 145.8797 - mae: 9.0954 - val_loss: 151.3870 - val_mae: 8.9719\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 139.3267 - mae: 8.8278 - val_loss: 145.4489 - val_mae: 8.7385\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 133.6361 - mae: 8.5855 - val_loss: 139.8928 - val_mae: 8.5236\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 128.5289 - mae: 8.3652 - val_loss: 134.9855 - val_mae: 8.3401\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 123.9138 - mae: 8.1663 - val_loss: 130.7632 - val_mae: 8.1903\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 119.8793 - mae: 7.9818 - val_loss: 126.7264 - val_mae: 8.0467\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 116.0958 - mae: 7.8221 - val_loss: 123.4711 - val_mae: 7.9330\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 112.7804 - mae: 7.6699 - val_loss: 120.1086 - val_mae: 7.8131\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 109.6879 - mae: 7.5289 - val_loss: 117.1542 - val_mae: 7.7066\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 106.9220 - mae: 7.3988 - val_loss: 114.5063 - val_mae: 7.6111\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 104.3766 - mae: 7.2819 - val_loss: 112.0193 - val_mae: 7.5258\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 102.0110 - mae: 7.1691 - val_loss: 109.8405 - val_mae: 7.4512\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 99.8528 - mae: 7.0721 - val_loss: 107.7104 - val_mae: 7.3745\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 97.8597 - mae: 6.9765 - val_loss: 105.8808 - val_mae: 7.3049\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 96.1167 - mae: 6.8899 - val_loss: 104.1411 - val_mae: 7.2351\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.4875 - mae: 6.8166 - val_loss: 102.6284 - val_mae: 7.1739\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.0624 - mae: 6.7555 - val_loss: 101.3255 - val_mae: 7.1259\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 91.7703 - mae: 6.6904 - val_loss: 100.0226 - val_mae: 7.0773\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 90.6048 - mae: 6.6396 - val_loss: 98.8630 - val_mae: 7.0314\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 89.5063 - mae: 6.5990 - val_loss: 97.9184 - val_mae: 6.9954\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.5319 - mae: 6.5534 - val_loss: 96.9615 - val_mae: 6.9688\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 87.6575 - mae: 6.5211 - val_loss: 96.1055 - val_mae: 6.9542\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.8631 - mae: 6.4931 - val_loss: 95.3207 - val_mae: 6.9423\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.0940 - mae: 6.4633 - val_loss: 94.6476 - val_mae: 6.9315\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.4207 - mae: 6.4417 - val_loss: 93.9893 - val_mae: 6.9224\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.8042 - mae: 6.4248 - val_loss: 93.4131 - val_mae: 6.9205\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.2752 - mae: 6.4136 - val_loss: 92.8858 - val_mae: 6.9204\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.8002 - mae: 6.4034 - val_loss: 92.4478 - val_mae: 6.9252\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.3992 - mae: 6.3983 - val_loss: 92.0554 - val_mae: 6.9314\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.0236 - mae: 6.3940 - val_loss: 91.7402 - val_mae: 6.9386\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.7107 - mae: 6.3902 - val_loss: 91.3997 - val_mae: 6.9494\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.4140 - mae: 6.3889 - val_loss: 91.1178 - val_mae: 6.9591\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.1531 - mae: 6.3860 - val_loss: 90.9098 - val_mae: 6.9668\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.9420 - mae: 6.3866 - val_loss: 90.6836 - val_mae: 6.9757\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.7523 - mae: 6.3885 - val_loss: 90.5030 - val_mae: 6.9842\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.5730 - mae: 6.3874 - val_loss: 90.3363 - val_mae: 6.9934\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.4072 - mae: 6.3890 - val_loss: 90.1746 - val_mae: 7.0030\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.2814 - mae: 6.3931 - val_loss: 90.0513 - val_mae: 7.0109\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.1541 - mae: 6.3928 - val_loss: 89.9525 - val_mae: 7.0181\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.0499 - mae: 6.3977 - val_loss: 89.8410 - val_mae: 7.0277\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.9636 - mae: 6.4005 - val_loss: 89.7583 - val_mae: 7.0355\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.8859 - mae: 6.4042 - val_loss: 89.6786 - val_mae: 7.0435\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.8221 - mae: 6.4070 - val_loss: 89.6211 - val_mae: 7.0498\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.7755 - mae: 6.4109 - val_loss: 89.5621 - val_mae: 7.0566\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.7187 - mae: 6.4155 - val_loss: 89.5079 - val_mae: 7.0643\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6768 - mae: 6.4156 - val_loss: 89.4865 - val_mae: 7.0677\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6438 - mae: 6.4194 - val_loss: 89.4420 - val_mae: 7.0750\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6047 - mae: 6.4250 - val_loss: 89.4068 - val_mae: 7.0814\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5885 - mae: 6.4251 - val_loss: 89.3838 - val_mae: 7.0859\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5659 - mae: 6.4311 - val_loss: 89.3568 - val_mae: 7.0916\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5292 - mae: 6.4323 - val_loss: 89.3360 - val_mae: 7.0963\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5244 - mae: 6.4330 - val_loss: 89.3239 - val_mae: 7.0993\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5246 - mae: 6.4386 - val_loss: 89.2996 - val_mae: 7.1058\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5037 - mae: 6.4389 - val_loss: 89.2965 - val_mae: 7.1067\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4805 - mae: 6.4399 - val_loss: 89.2890 - val_mae: 7.1090\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4724 - mae: 6.4427 - val_loss: 89.2805 - val_mae: 7.1121\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4697 - mae: 6.4461 - val_loss: 89.2728 - val_mae: 7.1150\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4551 - mae: 6.4487 - val_loss: 89.2534 - val_mae: 7.1234\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4448 - mae: 6.4536 - val_loss: 89.2473 - val_mae: 7.1265\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4403 - mae: 6.4549 - val_loss: 89.2441 - val_mae: 7.1282\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4485 - mae: 6.4588 - val_loss: 89.2342 - val_mae: 7.1344\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4362 - mae: 6.4574 - val_loss: 89.2382 - val_mae: 7.1317\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4271 - mae: 6.4588 - val_loss: 89.2345 - val_mae: 7.1341\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4229 - mae: 6.4598 - val_loss: 89.2330 - val_mae: 7.1352\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4248 - mae: 6.4620 - val_loss: 89.2254 - val_mae: 7.1415\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4241 - mae: 6.4668 - val_loss: 89.2229 - val_mae: 7.1441\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4211 - mae: 6.4682 - val_loss: 89.2227 - val_mae: 7.1442\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4508 - mae: 6.4636 - val_loss: 89.2298 - val_mae: 7.1375\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4611 - mae: 6.4704 - val_loss: 89.2233 - val_mae: 7.1435\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4169 - mae: 6.4666 - val_loss: 89.2215 - val_mae: 7.1456\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4250 - mae: 6.4693 - val_loss: 89.2188 - val_mae: 7.1494\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4464 - mae: 6.4683 - val_loss: 89.2205 - val_mae: 7.1467\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4123 - mae: 6.4714 - val_loss: 89.2182 - val_mae: 7.1505\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4196 - mae: 6.4719 - val_loss: 89.2186 - val_mae: 7.1495\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4147 - mae: 6.4710 - val_loss: 89.2184 - val_mae: 7.1499\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4140 - mae: 6.4735 - val_loss: 89.2173 - val_mae: 7.1521\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4217 - mae: 6.4710 - val_loss: 89.2194 - val_mae: 7.1480\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4113 - mae: 6.4725 - val_loss: 89.2175 - val_mae: 7.1513\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4133 - mae: 6.4712 - val_loss: 89.2181 - val_mae: 7.1499\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4142 - mae: 6.4711 - val_loss: 89.2177 - val_mae: 7.1507\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4196 - mae: 6.4770 - val_loss: 89.2160 - val_mae: 7.1553\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4275 - mae: 6.4759 - val_loss: 89.2176 - val_mae: 7.1505\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4158 - mae: 6.4741 - val_loss: 89.2163 - val_mae: 7.1536\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4119 - mae: 6.4748 - val_loss: 89.2162 - val_mae: 7.1537\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4215 - mae: 6.4734 - val_loss: 89.2169 - val_mae: 7.1516\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4145 - mae: 6.4733 - val_loss: 89.2168 - val_mae: 7.1516\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4227 - mae: 6.4773 - val_loss: 89.2160 - val_mae: 7.1535\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4126 - mae: 6.4740 - val_loss: 89.2163 - val_mae: 7.1522\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4225 - mae: 6.4716 - val_loss: 89.2170 - val_mae: 7.1505\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4238 - mae: 6.4762 - val_loss: 89.2160 - val_mae: 7.1526\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4274 - mae: 6.4731 - val_loss: 89.2159 - val_mae: 7.1526\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 105.3389 - mae: 6.5249\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 18.5165 - mae: 18.5165 - val_loss: 14.7373 - val_mae: 14.7373\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.5239 - mae: 13.5239 - val_loss: 12.5880 - val_mae: 12.5880\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.1208 - mae: 12.1208 - val_loss: 11.5798 - val_mae: 11.5798\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.2602 - mae: 11.2602 - val_loss: 10.8467 - val_mae: 10.8467\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.5950 - mae: 10.5950 - val_loss: 10.2660 - val_mae: 10.2660\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.0497 - mae: 10.0497 - val_loss: 9.7738 - val_mae: 9.7738\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5852 - mae: 9.5852 - val_loss: 9.3774 - val_mae: 9.3774\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.2111 - mae: 9.2111 - val_loss: 9.0561 - val_mae: 9.0561\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8898 - mae: 8.8898 - val_loss: 8.7801 - val_mae: 8.7801\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.6095 - mae: 8.6095 - val_loss: 8.5272 - val_mae: 8.5272\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3559 - mae: 8.3559 - val_loss: 8.3254 - val_mae: 8.3254\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1357 - mae: 8.1357 - val_loss: 8.1588 - val_mae: 8.1588\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.9323 - mae: 7.9323 - val_loss: 7.9991 - val_mae: 7.9991\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7464 - mae: 7.7464 - val_loss: 7.8611 - val_mae: 7.8611\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5775 - mae: 7.5775 - val_loss: 7.7424 - val_mae: 7.7424\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4287 - mae: 7.4287 - val_loss: 7.6230 - val_mae: 7.6230\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2882 - mae: 7.2882 - val_loss: 7.5305 - val_mae: 7.5305\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1657 - mae: 7.1657 - val_loss: 7.4418 - val_mae: 7.4418\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0542 - mae: 7.0542 - val_loss: 7.3618 - val_mae: 7.3618\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9590 - mae: 6.9590 - val_loss: 7.2841 - val_mae: 7.2841\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8691 - mae: 6.8691 - val_loss: 7.2170 - val_mae: 7.2170\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7977 - mae: 6.7977 - val_loss: 7.1538 - val_mae: 7.1538\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7284 - mae: 6.7284 - val_loss: 7.1049 - val_mae: 7.1049\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6649 - mae: 6.6649 - val_loss: 7.0542 - val_mae: 7.0542\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6105 - mae: 6.6105 - val_loss: 7.0091 - val_mae: 7.0091\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5669 - mae: 6.5669 - val_loss: 6.9765 - val_mae: 6.9765\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5334 - mae: 6.5334 - val_loss: 6.9599 - val_mae: 6.9599\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5049 - mae: 6.5049 - val_loss: 6.9495 - val_mae: 6.9495\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4827 - mae: 6.4827 - val_loss: 6.9413 - val_mae: 6.9413\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4649 - mae: 6.4649 - val_loss: 6.9330 - val_mae: 6.9330\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4498 - mae: 6.4498 - val_loss: 6.9261 - val_mae: 6.9261\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4387 - mae: 6.4387 - val_loss: 6.9219 - val_mae: 6.9219\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4299 - mae: 6.4299 - val_loss: 6.9211 - val_mae: 6.9211\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4224 - mae: 6.4224 - val_loss: 6.9204 - val_mae: 6.9204\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4162 - mae: 6.4162 - val_loss: 6.9198 - val_mae: 6.9198\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4115 - mae: 6.4115 - val_loss: 6.9203 - val_mae: 6.9203\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4070 - mae: 6.4070 - val_loss: 6.9220 - val_mae: 6.9220\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4037 - mae: 6.4037 - val_loss: 6.9250 - val_mae: 6.9250\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4009 - mae: 6.4009 - val_loss: 6.9263 - val_mae: 6.9263\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3993 - mae: 6.3993 - val_loss: 6.9294 - val_mae: 6.9294\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3976 - mae: 6.3976 - val_loss: 6.9300 - val_mae: 6.9300\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3950 - mae: 6.3950 - val_loss: 6.9331 - val_mae: 6.9331\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3940 - mae: 6.3940 - val_loss: 6.9348 - val_mae: 6.9348\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3929 - mae: 6.3929 - val_loss: 6.9367 - val_mae: 6.9367\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3923 - mae: 6.3923 - val_loss: 6.9392 - val_mae: 6.9392\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3919 - mae: 6.3919 - val_loss: 6.9391 - val_mae: 6.9391\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3920 - mae: 6.3920 - val_loss: 6.9435 - val_mae: 6.9435\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3910 - mae: 6.3910 - val_loss: 6.9436 - val_mae: 6.9436\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3911 - mae: 6.3911 - val_loss: 6.9467 - val_mae: 6.9467\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9476 - val_mae: 6.9476\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3894 - mae: 6.3894 - val_loss: 6.9498 - val_mae: 6.9498\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9515 - val_mae: 6.9515\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3894 - mae: 6.3894 - val_loss: 6.9535 - val_mae: 6.9535\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9519 - val_mae: 6.9519\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9548 - val_mae: 6.9548\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9552 - val_mae: 6.9552\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9559 - val_mae: 6.9559\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9571 - val_mae: 6.9571\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9592 - val_mae: 6.9592\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9608 - val_mae: 6.9608\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9598 - val_mae: 6.9598\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9624 - val_mae: 6.9624\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9634 - val_mae: 6.9634\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9651 - val_mae: 6.9651\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9675 - val_mae: 6.9675\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9679 - val_mae: 6.9679\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9689 - val_mae: 6.9689\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3860 - mae: 6.3860 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9703 - val_mae: 6.9703\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9704 - val_mae: 6.9704\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9705 - val_mae: 6.9705\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9698 - val_mae: 6.9698\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9710 - val_mae: 6.9710\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8024 - mae: 6.8024\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 410.9402 - mae: 18.1367 - val_loss: 306.3134 - val_mae: 14.7464\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 263.1443 - mae: 13.6404 - val_loss: 247.4271 - val_mae: 12.7078\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 223.9451 - mae: 12.2358 - val_loss: 219.9717 - val_mae: 11.6997\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 201.2212 - mae: 11.3849 - val_loss: 201.1332 - val_mae: 10.9612\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 184.6265 - mae: 10.7067 - val_loss: 186.3702 - val_mae: 10.3793\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 171.5369 - mae: 10.1711 - val_loss: 174.5982 - val_mae: 9.9018\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 160.7382 - mae: 9.7292 - val_loss: 164.9480 - val_mae: 9.5105\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 151.7243 - mae: 9.3474 - val_loss: 156.7525 - val_mae: 9.1837\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 143.9583 - mae: 9.0243 - val_loss: 149.4432 - val_mae: 8.8967\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 137.2984 - mae: 8.7204 - val_loss: 142.9024 - val_mae: 8.6390\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 131.3320 - mae: 8.4852 - val_loss: 137.3868 - val_mae: 8.4306\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 125.9674 - mae: 8.2544 - val_loss: 132.3911 - val_mae: 8.2466\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 121.0982 - mae: 8.0449 - val_loss: 127.8321 - val_mae: 8.0859\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 116.8025 - mae: 7.8509 - val_loss: 123.7982 - val_mae: 7.9443\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 112.9551 - mae: 7.6799 - val_loss: 120.0043 - val_mae: 7.8093\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 109.4153 - mae: 7.5137 - val_loss: 116.6228 - val_mae: 7.6871\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 106.2694 - mae: 7.3664 - val_loss: 113.6942 - val_mae: 7.5822\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 103.5300 - mae: 7.2427 - val_loss: 111.1009 - val_mae: 7.4948\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 101.0710 - mae: 7.1294 - val_loss: 108.9331 - val_mae: 7.4190\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 98.8852 - mae: 7.0201 - val_loss: 106.6565 - val_mae: 7.3349\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 96.7728 - mae: 6.9258 - val_loss: 104.6625 - val_mae: 7.2565\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.8672 - mae: 6.8368 - val_loss: 102.9457 - val_mae: 7.1864\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 93.2159 - mae: 6.7574 - val_loss: 101.3350 - val_mae: 7.1263\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 91.7282 - mae: 6.6908 - val_loss: 100.0359 - val_mae: 7.0778\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 90.4306 - mae: 6.6335 - val_loss: 98.7062 - val_mae: 7.0250\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 89.2466 - mae: 6.5848 - val_loss: 97.5849 - val_mae: 6.9835\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.2037 - mae: 6.5415 - val_loss: 96.6448 - val_mae: 6.9630\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 87.3057 - mae: 6.5087 - val_loss: 95.7280 - val_mae: 6.9486\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.4837 - mae: 6.4789 - val_loss: 94.9890 - val_mae: 6.9371\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 85.7551 - mae: 6.4542 - val_loss: 94.2911 - val_mae: 6.9261\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 85.1141 - mae: 6.4329 - val_loss: 93.7160 - val_mae: 6.9213\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 84.5618 - mae: 6.4199 - val_loss: 93.1567 - val_mae: 6.9198\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.0657 - mae: 6.4122 - val_loss: 92.6245 - val_mae: 6.9225\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.5846 - mae: 6.4043 - val_loss: 92.2080 - val_mae: 6.9289\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.1799 - mae: 6.3945 - val_loss: 91.8845 - val_mae: 6.9352\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 82.8398 - mae: 6.3920 - val_loss: 91.4939 - val_mae: 6.9462\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.5036 - mae: 6.3911 - val_loss: 91.2166 - val_mae: 6.9556\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 82.2340 - mae: 6.3845 - val_loss: 90.9698 - val_mae: 6.9645\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.9991 - mae: 6.3871 - val_loss: 90.7332 - val_mae: 6.9737\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.7739 - mae: 6.3847 - val_loss: 90.5474 - val_mae: 6.9819\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.5873 - mae: 6.3867 - val_loss: 90.3503 - val_mae: 6.9926\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.4331 - mae: 6.3886 - val_loss: 90.2203 - val_mae: 7.0002\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.2909 - mae: 6.3926 - val_loss: 90.0721 - val_mae: 7.0095\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.1754 - mae: 6.3943 - val_loss: 89.9587 - val_mae: 7.0176\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 81.0556 - mae: 6.3960 - val_loss: 89.8438 - val_mae: 7.0275\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.9662 - mae: 6.4009 - val_loss: 89.7578 - val_mae: 7.0355\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.8958 - mae: 6.4030 - val_loss: 89.6768 - val_mae: 7.0437\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.8185 - mae: 6.4077 - val_loss: 89.6189 - val_mae: 7.0500\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.7537 - mae: 6.4100 - val_loss: 89.5562 - val_mae: 7.0574\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.7096 - mae: 6.4141 - val_loss: 89.5098 - val_mae: 7.0641\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.6708 - mae: 6.4207 - val_loss: 89.4580 - val_mae: 7.0723\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6160 - mae: 6.4210 - val_loss: 89.4295 - val_mae: 7.0772\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5877 - mae: 6.4250 - val_loss: 89.3906 - val_mae: 7.0845\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5642 - mae: 6.4280 - val_loss: 89.3651 - val_mae: 7.0898\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5420 - mae: 6.4312 - val_loss: 89.3418 - val_mae: 7.0950\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5227 - mae: 6.4334 - val_loss: 89.3301 - val_mae: 7.0978\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5095 - mae: 6.4363 - val_loss: 89.3120 - val_mae: 7.1024\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5233 - mae: 6.4401 - val_loss: 89.2986 - val_mae: 7.1061\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4888 - mae: 6.4420 - val_loss: 89.2864 - val_mae: 7.1100\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4681 - mae: 6.4437 - val_loss: 89.2779 - val_mae: 7.1131\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4655 - mae: 6.4440 - val_loss: 89.2704 - val_mae: 7.1160\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4550 - mae: 6.4485 - val_loss: 89.2628 - val_mae: 7.1191\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4441 - mae: 6.4520 - val_loss: 89.2465 - val_mae: 7.1270\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4383 - mae: 6.4539 - val_loss: 89.2480 - val_mae: 7.1262\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4379 - mae: 6.4548 - val_loss: 89.2442 - val_mae: 7.1282\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4364 - mae: 6.4589 - val_loss: 89.2355 - val_mae: 7.1335\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4259 - mae: 6.4600 - val_loss: 89.2338 - val_mae: 7.1347\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4287 - mae: 6.4596 - val_loss: 89.2321 - val_mae: 7.1359\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4275 - mae: 6.4607 - val_loss: 89.2308 - val_mae: 7.1368\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4336 - mae: 6.4660 - val_loss: 89.2253 - val_mae: 7.1416\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4208 - mae: 6.4645 - val_loss: 89.2254 - val_mae: 7.1415\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4274 - mae: 6.4658 - val_loss: 89.2233 - val_mae: 7.1436\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4156 - mae: 6.4655 - val_loss: 89.2252 - val_mae: 7.1416\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4145 - mae: 6.4671 - val_loss: 89.2213 - val_mae: 7.1459\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4374 - mae: 6.4657 - val_loss: 89.2248 - val_mae: 7.1419\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4182 - mae: 6.4675 - val_loss: 89.2212 - val_mae: 7.1459\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4251 - mae: 6.4721 - val_loss: 89.2180 - val_mae: 7.1511\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4378 - mae: 6.4695 - val_loss: 89.2192 - val_mae: 7.1488\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4172 - mae: 6.4700 - val_loss: 89.2192 - val_mae: 7.1486\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4207 - mae: 6.4739 - val_loss: 89.2170 - val_mae: 7.1530\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4190 - mae: 6.4717 - val_loss: 89.2177 - val_mae: 7.1513\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4155 - mae: 6.4726 - val_loss: 89.2169 - val_mae: 7.1529\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4427 - mae: 6.4706 - val_loss: 89.2196 - val_mae: 7.1476\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4205 - mae: 6.4736 - val_loss: 89.2164 - val_mae: 7.1542\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4155 - mae: 6.4741 - val_loss: 89.2170 - val_mae: 7.1522\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4187 - mae: 6.4771 - val_loss: 89.2162 - val_mae: 7.1542\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4173 - mae: 6.4762 - val_loss: 89.2171 - val_mae: 7.1517\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4161 - mae: 6.4717 - val_loss: 89.2187 - val_mae: 7.1485\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4124 - mae: 6.4734 - val_loss: 89.2165 - val_mae: 7.1528\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4152 - mae: 6.4738 - val_loss: 89.2168 - val_mae: 7.1518\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4119 - mae: 6.4766 - val_loss: 89.2159 - val_mae: 7.1542\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4091 - mae: 6.4758 - val_loss: 89.2156 - val_mae: 7.1547\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4230 - mae: 6.4766 - val_loss: 89.2155 - val_mae: 7.1546\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4127 - mae: 6.4771 - val_loss: 89.2150 - val_mae: 7.1567\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4118 - mae: 6.4768 - val_loss: 89.2155 - val_mae: 7.1538\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4158 - mae: 6.4759 - val_loss: 89.2160 - val_mae: 7.1521\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4146 - mae: 6.4737 - val_loss: 89.2153 - val_mae: 7.1536\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4216 - mae: 6.4712 - val_loss: 89.2169 - val_mae: 7.1497\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4195 - mae: 6.4758 - val_loss: 89.2151 - val_mae: 7.1533\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4135 - mae: 6.4758 - val_loss: 89.2146 - val_mae: 7.1546\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 105.2797 - mae: 6.5243\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 18.2790 - mae: 18.2790 - val_loss: 14.9373 - val_mae: 14.9373\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.8521 - mae: 13.8521 - val_loss: 12.9247 - val_mae: 12.9247\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 12.4443 - mae: 12.4443 - val_loss: 11.8607 - val_mae: 11.8607\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.5176 - mae: 11.5176 - val_loss: 11.0724 - val_mae: 11.0724\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.7758 - mae: 10.7758 - val_loss: 10.3881 - val_mae: 10.3881\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.1312 - mae: 10.1312 - val_loss: 9.8125 - val_mae: 9.8125\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5953 - mae: 9.5953 - val_loss: 9.3703 - val_mae: 9.3703\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1763 - mae: 9.1763 - val_loss: 8.9955 - val_mae: 8.9955\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.8104 - mae: 8.8104 - val_loss: 8.6749 - val_mae: 8.6749\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.4982 - mae: 8.4982 - val_loss: 8.4250 - val_mae: 8.4250\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.2294 - mae: 8.2294 - val_loss: 8.2092 - val_mae: 8.2092\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.9865 - mae: 7.9865 - val_loss: 8.0219 - val_mae: 8.0219\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7636 - mae: 7.7636 - val_loss: 7.8697 - val_mae: 7.8697\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5709 - mae: 7.5709 - val_loss: 7.7124 - val_mae: 7.7124\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 7.3779 - mae: 7.3779 - val_loss: 7.5741 - val_mae: 7.5741\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2052 - mae: 7.2052 - val_loss: 7.4472 - val_mae: 7.4472\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0476 - mae: 7.0476 - val_loss: 7.3449 - val_mae: 7.3449\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9185 - mae: 6.9185 - val_loss: 7.2433 - val_mae: 7.2433\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8081 - mae: 6.8081 - val_loss: 7.1537 - val_mae: 7.1537\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7144 - mae: 6.7144 - val_loss: 7.0857 - val_mae: 7.0857\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6392 - mae: 6.6392 - val_loss: 7.0252 - val_mae: 7.0252\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5807 - mae: 6.5807 - val_loss: 6.9754 - val_mae: 6.9754\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5325 - mae: 6.5325 - val_loss: 6.9584 - val_mae: 6.9584\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5026 - mae: 6.5026 - val_loss: 6.9464 - val_mae: 6.9464\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4742 - mae: 6.4742 - val_loss: 6.9368 - val_mae: 6.9368\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4548 - mae: 6.4548 - val_loss: 6.9277 - val_mae: 6.9277\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4397 - mae: 6.4397 - val_loss: 6.9223 - val_mae: 6.9223\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4303 - mae: 6.4303 - val_loss: 6.9210 - val_mae: 6.9210\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4201 - mae: 6.4201 - val_loss: 6.9200 - val_mae: 6.9200\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4139 - mae: 6.4139 - val_loss: 6.9202 - val_mae: 6.9202\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4078 - mae: 6.4078 - val_loss: 6.9208 - val_mae: 6.9208\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4048 - mae: 6.4048 - val_loss: 6.9258 - val_mae: 6.9258\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3998 - mae: 6.3998 - val_loss: 6.9269 - val_mae: 6.9269\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3978 - mae: 6.3978 - val_loss: 6.9292 - val_mae: 6.9292\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3971 - mae: 6.3971 - val_loss: 6.9326 - val_mae: 6.9326\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3943 - mae: 6.3943 - val_loss: 6.9330 - val_mae: 6.9330\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3951 - mae: 6.3951 - val_loss: 6.9365 - val_mae: 6.9365\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3936 - mae: 6.3936 - val_loss: 6.9351 - val_mae: 6.9351\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3928 - mae: 6.3928 - val_loss: 6.9384 - val_mae: 6.9384\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3926 - mae: 6.3926 - val_loss: 6.9405 - val_mae: 6.9405\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3918 - mae: 6.3918 - val_loss: 6.9421 - val_mae: 6.9421\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3909 - mae: 6.3909 - val_loss: 6.9446 - val_mae: 6.9446\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3911 - mae: 6.3911 - val_loss: 6.9437 - val_mae: 6.9437\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9485 - val_mae: 6.9485\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9508 - val_mae: 6.9508\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9531 - val_mae: 6.9531\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9533 - val_mae: 6.9533\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9561 - val_mae: 6.9561\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9566 - val_mae: 6.9566\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9600 - val_mae: 6.9600\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9609 - val_mae: 6.9609\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9611 - val_mae: 6.9611\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9641 - val_mae: 6.9641\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9631 - val_mae: 6.9631\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9633 - val_mae: 6.9633\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9672 - val_mae: 6.9672\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9641 - val_mae: 6.9641\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9711 - val_mae: 6.9711\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9678 - val_mae: 6.9678\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9704 - val_mae: 6.9704\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9674 - val_mae: 6.9674\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9668 - val_mae: 6.9668\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9675 - val_mae: 6.9675\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9721 - val_mae: 6.9721\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9714 - val_mae: 6.9714\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9717 - val_mae: 6.9717\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.9710 - val_mae: 6.9710\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3859 - mae: 6.3859 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3860 - mae: 6.3860 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9673 - val_mae: 6.9673\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3858 - mae: 6.3858 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8026 - mae: 6.8026\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 410.2665 - mae: 18.0228 - val_loss: 302.4867 - val_mae: 14.6187\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 259.9090 - mae: 13.5160 - val_loss: 244.9251 - val_mae: 12.6189\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 221.9238 - mae: 12.1565 - val_loss: 218.6720 - val_mae: 11.6503\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 200.0098 - mae: 11.3352 - val_loss: 200.0896 - val_mae: 10.9204\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 183.9176 - mae: 10.6837 - val_loss: 186.1898 - val_mae: 10.3720\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 171.2121 - mae: 10.1687 - val_loss: 174.6505 - val_mae: 9.9040\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 160.5861 - mae: 9.7161 - val_loss: 164.4104 - val_mae: 9.4885\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 150.9967 - mae: 9.3043 - val_loss: 155.6093 - val_mae: 9.1385\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 142.8776 - mae: 8.9739 - val_loss: 147.9572 - val_mae: 8.8384\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 135.6854 - mae: 8.6662 - val_loss: 141.2793 - val_mae: 8.5765\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 129.3176 - mae: 8.4000 - val_loss: 135.3636 - val_mae: 8.3545\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 123.8041 - mae: 8.1591 - val_loss: 130.2478 - val_mae: 8.1722\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 118.9714 - mae: 7.9544 - val_loss: 125.6790 - val_mae: 8.0098\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 114.7296 - mae: 7.7587 - val_loss: 121.8051 - val_mae: 7.8744\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 110.9908 - mae: 7.5929 - val_loss: 118.2035 - val_mae: 7.7444\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 107.6236 - mae: 7.4354 - val_loss: 115.0924 - val_mae: 7.6321\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 104.6999 - mae: 7.2983 - val_loss: 112.2952 - val_mae: 7.5350\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 102.0933 - mae: 7.1726 - val_loss: 109.8178 - val_mae: 7.4505\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 99.7675 - mae: 7.0665 - val_loss: 107.4981 - val_mae: 7.3666\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 97.6090 - mae: 6.9657 - val_loss: 105.6173 - val_mae: 7.2946\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 95.8102 - mae: 6.8760 - val_loss: 103.6828 - val_mae: 7.2161\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 94.0872 - mae: 6.8020 - val_loss: 102.1599 - val_mae: 7.1562\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 92.5826 - mae: 6.7282 - val_loss: 100.7929 - val_mae: 7.1064\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 91.2133 - mae: 6.6688 - val_loss: 99.5186 - val_mae: 7.0577\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 90.0168 - mae: 6.6138 - val_loss: 98.2982 - val_mae: 7.0095\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 88.8843 - mae: 6.5693 - val_loss: 97.3742 - val_mae: 6.9777\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.9258 - mae: 6.5306 - val_loss: 96.3629 - val_mae: 6.9579\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 87.0376 - mae: 6.5010 - val_loss: 95.5144 - val_mae: 6.9453\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 86.2893 - mae: 6.4713 - val_loss: 94.7637 - val_mae: 6.9335\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 85.5941 - mae: 6.4489 - val_loss: 94.1040 - val_mae: 6.9238\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.9837 - mae: 6.4301 - val_loss: 93.5537 - val_mae: 6.9209\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 84.4339 - mae: 6.4140 - val_loss: 93.0428 - val_mae: 6.9200\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.9361 - mae: 6.4049 - val_loss: 92.5775 - val_mae: 6.9232\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.5054 - mae: 6.4000 - val_loss: 92.1811 - val_mae: 6.9294\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 83.1157 - mae: 6.3937 - val_loss: 91.7846 - val_mae: 6.9376\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.7641 - mae: 6.3903 - val_loss: 91.4807 - val_mae: 6.9467\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.4764 - mae: 6.3878 - val_loss: 91.1883 - val_mae: 6.9566\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 82.2190 - mae: 6.3877 - val_loss: 90.9389 - val_mae: 6.9657\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 81.9847 - mae: 6.3870 - val_loss: 90.7231 - val_mae: 6.9741\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.7945 - mae: 6.3871 - val_loss: 90.5239 - val_mae: 6.9832\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.6126 - mae: 6.3878 - val_loss: 90.3749 - val_mae: 6.9913\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.4603 - mae: 6.3894 - val_loss: 90.2485 - val_mae: 6.9986\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.3151 - mae: 6.3898 - val_loss: 90.0847 - val_mae: 7.0087\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.1824 - mae: 6.3948 - val_loss: 89.9473 - val_mae: 7.0185\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 81.0756 - mae: 6.3961 - val_loss: 89.8462 - val_mae: 7.0273\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.9744 - mae: 6.3994 - val_loss: 89.7692 - val_mae: 7.0345\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.8942 - mae: 6.4055 - val_loss: 89.6815 - val_mae: 7.0432\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.8183 - mae: 6.4086 - val_loss: 89.6031 - val_mae: 7.0518\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.7568 - mae: 6.4103 - val_loss: 89.5566 - val_mae: 7.0573\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.7059 - mae: 6.4168 - val_loss: 89.4855 - val_mae: 7.0678\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6475 - mae: 6.4189 - val_loss: 89.4569 - val_mae: 7.0725\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.6109 - mae: 6.4216 - val_loss: 89.4127 - val_mae: 7.0803\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5888 - mae: 6.4251 - val_loss: 89.3943 - val_mae: 7.0838\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5580 - mae: 6.4279 - val_loss: 89.3594 - val_mae: 7.0910\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5362 - mae: 6.4319 - val_loss: 89.3381 - val_mae: 7.0959\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5169 - mae: 6.4374 - val_loss: 89.3154 - val_mae: 7.1015\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.5095 - mae: 6.4391 - val_loss: 89.2980 - val_mae: 7.1063\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4923 - mae: 6.4395 - val_loss: 89.2988 - val_mae: 7.1061\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4776 - mae: 6.4441 - val_loss: 89.2773 - val_mae: 7.1134\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4562 - mae: 6.4464 - val_loss: 89.2665 - val_mae: 7.1177\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4505 - mae: 6.4497 - val_loss: 89.2582 - val_mae: 7.1213\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4493 - mae: 6.4530 - val_loss: 89.2509 - val_mae: 7.1248\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4490 - mae: 6.4513 - val_loss: 89.2473 - val_mae: 7.1266\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4386 - mae: 6.4578 - val_loss: 89.2360 - val_mae: 7.1333\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4315 - mae: 6.4570 - val_loss: 89.2393 - val_mae: 7.1312\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4444 - mae: 6.4612 - val_loss: 89.2331 - val_mae: 7.1353\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4585 - mae: 6.4664 - val_loss: 89.2268 - val_mae: 7.1404\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4271 - mae: 6.4612 - val_loss: 89.2317 - val_mae: 7.1363\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4258 - mae: 6.4635 - val_loss: 89.2249 - val_mae: 7.1422\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4153 - mae: 6.4641 - val_loss: 89.2265 - val_mae: 7.1406\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4160 - mae: 6.4642 - val_loss: 89.2244 - val_mae: 7.1426\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4197 - mae: 6.4691 - val_loss: 89.2199 - val_mae: 7.1483\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4132 - mae: 6.4689 - val_loss: 89.2203 - val_mae: 7.1476\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4192 - mae: 6.4727 - val_loss: 89.2184 - val_mae: 7.1509\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4171 - mae: 6.4747 - val_loss: 89.2180 - val_mae: 7.1517\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4141 - mae: 6.4708 - val_loss: 89.2192 - val_mae: 7.1491\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4239 - mae: 6.4714 - val_loss: 89.2191 - val_mae: 7.1493\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4174 - mae: 6.4696 - val_loss: 89.2203 - val_mae: 7.1473\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4108 - mae: 6.4706 - val_loss: 89.2189 - val_mae: 7.1494\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4215 - mae: 6.4745 - val_loss: 89.2179 - val_mae: 7.1513\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4340 - mae: 6.4781 - val_loss: 89.2164 - val_mae: 7.1559\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4218 - mae: 6.4724 - val_loss: 89.2192 - val_mae: 7.1487\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4325 - mae: 6.4770 - val_loss: 89.2164 - val_mae: 7.1553\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4178 - mae: 6.4740 - val_loss: 89.2181 - val_mae: 7.1504\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4166 - mae: 6.4726 - val_loss: 89.2171 - val_mae: 7.1525\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4152 - mae: 6.4747 - val_loss: 89.2177 - val_mae: 7.1510\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4282 - mae: 6.4705 - val_loss: 89.2184 - val_mae: 7.1496\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4164 - mae: 6.4732 - val_loss: 89.2169 - val_mae: 7.1525\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4217 - mae: 6.4770 - val_loss: 89.2163 - val_mae: 7.1540\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4183 - mae: 6.4739 - val_loss: 89.2168 - val_mae: 7.1525\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4143 - mae: 6.4734 - val_loss: 89.2169 - val_mae: 7.1519\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4137 - mae: 6.4744 - val_loss: 89.2161 - val_mae: 7.1539\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4141 - mae: 6.4758 - val_loss: 89.2160 - val_mae: 7.1541\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4122 - mae: 6.4756 - val_loss: 89.2159 - val_mae: 7.1541\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4185 - mae: 6.4754 - val_loss: 89.2160 - val_mae: 7.1532\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 80.4098 - mae: 6.4751 - val_loss: 89.2160 - val_mae: 7.1529\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4236 - mae: 6.4719 - val_loss: 89.2166 - val_mae: 7.1514\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4255 - mae: 6.4698 - val_loss: 89.2189 - val_mae: 7.1470\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4081 - mae: 6.4698 - val_loss: 89.2166 - val_mae: 7.1508\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 80.4172 - mae: 6.4722 - val_loss: 89.2165 - val_mae: 7.1506\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 105.3980 - mae: 6.5255\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 5ms/step - loss: 19.7445 - mae: 19.7445 - val_loss: 16.2563 - val_mae: 16.2563\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 14.9666 - mae: 14.9666 - val_loss: 13.9680 - val_mae: 13.9680\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 13.4307 - mae: 13.4307 - val_loss: 12.8141 - val_mae: 12.8141\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 12.4364 - mae: 12.4364 - val_loss: 11.9586 - val_mae: 11.9586\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.6556 - mae: 11.6556 - val_loss: 11.2473 - val_mae: 11.2473\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 11.0148 - mae: 11.0148 - val_loss: 10.6667 - val_mae: 10.6667\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 10.4642 - mae: 10.4642 - val_loss: 10.1629 - val_mae: 10.1629\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.9766 - mae: 9.9766 - val_loss: 9.7276 - val_mae: 9.7276\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.5496 - mae: 9.5496 - val_loss: 9.3450 - val_mae: 9.3450\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 9.1777 - mae: 9.1777 - val_loss: 9.0278 - val_mae: 9.0278\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 8.8663 - mae: 8.8663 - val_loss: 8.7656 - val_mae: 8.7656\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.5972 - mae: 8.5972 - val_loss: 8.5296 - val_mae: 8.5296\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.3551 - mae: 8.3551 - val_loss: 8.3295 - val_mae: 8.3295\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 8.1374 - mae: 8.1374 - val_loss: 8.1532 - val_mae: 8.1532\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 7.9343 - mae: 7.9343 - val_loss: 7.9985 - val_mae: 7.9985\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.7454 - mae: 7.7454 - val_loss: 7.8648 - val_mae: 7.8648\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.5764 - mae: 7.5764 - val_loss: 7.7368 - val_mae: 7.7368\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.4239 - mae: 7.4239 - val_loss: 7.6243 - val_mae: 7.6243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.2856 - mae: 7.2856 - val_loss: 7.5298 - val_mae: 7.5298\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.1580 - mae: 7.1580 - val_loss: 7.4348 - val_mae: 7.4348\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 7.0437 - mae: 7.0437 - val_loss: 7.3480 - val_mae: 7.3480\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.9395 - mae: 6.9395 - val_loss: 7.2720 - val_mae: 7.2720\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.8509 - mae: 6.8509 - val_loss: 7.1942 - val_mae: 7.1942\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7726 - mae: 6.7726 - val_loss: 7.1423 - val_mae: 7.1423\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.7082 - mae: 6.7082 - val_loss: 7.0867 - val_mae: 7.0867\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.6504 - mae: 6.6504 - val_loss: 7.0419 - val_mae: 7.0419\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.6038 - mae: 6.6038 - val_loss: 7.0006 - val_mae: 7.0006\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5626 - mae: 6.5626 - val_loss: 6.9728 - val_mae: 6.9728\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.5308 - mae: 6.5308 - val_loss: 6.9606 - val_mae: 6.9606\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.5044 - mae: 6.5044 - val_loss: 6.9499 - val_mae: 6.9499\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4815 - mae: 6.4815 - val_loss: 6.9407 - val_mae: 6.9407\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4623 - mae: 6.4623 - val_loss: 6.9315 - val_mae: 6.9315\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4469 - mae: 6.4469 - val_loss: 6.9258 - val_mae: 6.9258\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4367 - mae: 6.4367 - val_loss: 6.9215 - val_mae: 6.9215\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4270 - mae: 6.4270 - val_loss: 6.9209 - val_mae: 6.9209\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4205 - mae: 6.4205 - val_loss: 6.9201 - val_mae: 6.9201\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4145 - mae: 6.4145 - val_loss: 6.9200 - val_mae: 6.9200\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4109 - mae: 6.4109 - val_loss: 6.9206 - val_mae: 6.9206\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4066 - mae: 6.4066 - val_loss: 6.9215 - val_mae: 6.9215\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.4033 - mae: 6.4033 - val_loss: 6.9246 - val_mae: 6.9246\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.4005 - mae: 6.4005 - val_loss: 6.9279 - val_mae: 6.9279\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3983 - mae: 6.3983 - val_loss: 6.9301 - val_mae: 6.9301\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3967 - mae: 6.3967 - val_loss: 6.9304 - val_mae: 6.9304\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3954 - mae: 6.3954 - val_loss: 6.9349 - val_mae: 6.9349\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3935 - mae: 6.3935 - val_loss: 6.9349 - val_mae: 6.9349\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3929 - mae: 6.3929 - val_loss: 6.9375 - val_mae: 6.9375\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3929 - mae: 6.3929 - val_loss: 6.9407 - val_mae: 6.9407\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3927 - mae: 6.3927 - val_loss: 6.9414 - val_mae: 6.9414\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3914 - mae: 6.3914 - val_loss: 6.9434 - val_mae: 6.9434\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9433 - val_mae: 6.9433\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9457 - val_mae: 6.9457\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9486 - val_mae: 6.9486\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9495 - val_mae: 6.9495\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9519 - val_mae: 6.9519\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9525 - val_mae: 6.9525\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9558 - val_mae: 6.9558\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9581 - val_mae: 6.9581\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9583 - val_mae: 6.9583\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9587 - val_mae: 6.9587\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9624 - val_mae: 6.9624\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9627 - val_mae: 6.9627\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9624 - val_mae: 6.9624\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9646 - val_mae: 6.9646\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9659 - val_mae: 6.9659\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9676 - val_mae: 6.9676\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9669 - val_mae: 6.9669\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9688 - val_mae: 6.9688\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9705 - val_mae: 6.9705\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9698 - val_mae: 6.9698\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9698 - val_mae: 6.9698\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9668 - val_mae: 6.9668\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9671 - val_mae: 6.9671\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9716 - val_mae: 6.9716\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9726 - val_mae: 6.9726\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9714 - val_mae: 6.9714\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9703 - val_mae: 6.9703\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9682 - val_mae: 6.9682\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9683 - val_mae: 6.9683\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8091 - mae: 6.8091\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 176.7981 - mae: 10.0387 - val_loss: 37.4280 - val_mae: 4.1264\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.7558 - mae: 3.5026 - val_loss: 25.3118 - val_mae: 3.4359\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 19.7853 - mae: 3.1704 - val_loss: 20.8504 - val_mae: 3.2036\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 16.7556 - mae: 2.9389 - val_loss: 19.4998 - val_mae: 3.0692\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.2523 - mae: 2.7423 - val_loss: 18.4768 - val_mae: 2.9950\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.8660 - mae: 2.8073 - val_loss: 19.2031 - val_mae: 2.8902\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.3203 - mae: 2.7667 - val_loss: 18.0375 - val_mae: 2.9409\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.1445 - mae: 2.4867 - val_loss: 16.3540 - val_mae: 2.7653\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.6615 - mae: 2.4451 - val_loss: 15.9021 - val_mae: 2.7720\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6457 - mae: 2.3390 - val_loss: 16.1041 - val_mae: 2.6572\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.4619 - mae: 2.2948 - val_loss: 16.7754 - val_mae: 2.8153\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0947 - mae: 2.2861 - val_loss: 14.7460 - val_mae: 2.6497\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.1190 - mae: 2.1750 - val_loss: 14.6418 - val_mae: 2.5739\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.9229 - mae: 2.1476 - val_loss: 14.6487 - val_mae: 2.6286\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4593 - mae: 2.1586 - val_loss: 14.4026 - val_mae: 2.5246\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0156 - mae: 2.0575 - val_loss: 14.8190 - val_mae: 2.6049\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.9868 - mae: 2.0926 - val_loss: 14.7153 - val_mae: 2.4424\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2191 - mae: 1.9673 - val_loss: 14.0532 - val_mae: 2.4814\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9659 - mae: 1.9218 - val_loss: 14.7869 - val_mae: 2.7048\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8932 - mae: 1.9320 - val_loss: 13.4034 - val_mae: 2.4588\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2638 - mae: 1.8388 - val_loss: 15.0156 - val_mae: 2.5155\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.7990 - mae: 1.9207 - val_loss: 13.9700 - val_mae: 2.4552\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0703 - mae: 1.8112 - val_loss: 13.5388 - val_mae: 2.3781\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3823 - mae: 1.7176 - val_loss: 14.6158 - val_mae: 2.4671\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5371 - mae: 1.7447 - val_loss: 13.4742 - val_mae: 2.3849\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0381 - mae: 1.6687 - val_loss: 12.9606 - val_mae: 2.3528\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8113 - mae: 1.6264 - val_loss: 13.2107 - val_mae: 2.3750\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6894 - mae: 1.6189 - val_loss: 13.2542 - val_mae: 2.3154\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8707 - mae: 1.6635 - val_loss: 12.9769 - val_mae: 2.4930\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4872 - mae: 1.5821 - val_loss: 13.3937 - val_mae: 2.3548\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2533 - mae: 1.5509 - val_loss: 12.4329 - val_mae: 2.3385\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2143 - mae: 1.5201 - val_loss: 12.8265 - val_mae: 2.4986\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1954 - mae: 1.5331 - val_loss: 13.0721 - val_mae: 2.2813\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8285 - mae: 1.4535 - val_loss: 13.1412 - val_mae: 2.3990\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.8493 - mae: 1.4645 - val_loss: 13.0125 - val_mae: 2.3556\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5294 - mae: 1.3851 - val_loss: 12.9439 - val_mae: 2.2802\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3596 - mae: 1.3460 - val_loss: 14.2310 - val_mae: 2.6861\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6999 - mae: 1.4140 - val_loss: 13.0376 - val_mae: 2.4070\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1412 - mae: 1.3117 - val_loss: 12.9889 - val_mae: 2.3679\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2343 - mae: 1.3459 - val_loss: 13.1427 - val_mae: 2.3966\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1031 - mae: 1.2970 - val_loss: 12.9921 - val_mae: 2.3606\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9539 - mae: 1.2452 - val_loss: 13.5936 - val_mae: 2.3728\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8977 - mae: 1.2437 - val_loss: 13.2072 - val_mae: 2.2336\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8444 - mae: 1.2251 - val_loss: 13.3083 - val_mae: 2.3352\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7511 - mae: 1.2186 - val_loss: 13.0654 - val_mae: 2.3594\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0826 - mae: 1.3029 - val_loss: 13.9687 - val_mae: 2.3933\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6768 - mae: 1.2160 - val_loss: 13.3240 - val_mae: 2.3626\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4850 - mae: 1.1435 - val_loss: 14.2948 - val_mae: 2.4270\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8590 - mae: 1.2695 - val_loss: 13.7746 - val_mae: 2.3306\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4417 - mae: 1.1317 - val_loss: 13.8643 - val_mae: 2.4619\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2828 - mae: 1.0920 - val_loss: 13.6959 - val_mae: 2.4148\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3504 - mae: 1.1277 - val_loss: 13.8649 - val_mae: 2.3754\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3583 - mae: 1.1279 - val_loss: 13.1616 - val_mae: 2.3313\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4152 - mae: 1.1444 - val_loss: 13.9146 - val_mae: 2.4205\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3519 - mae: 1.1569 - val_loss: 13.3966 - val_mae: 2.3016\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4287 - mae: 1.1399 - val_loss: 13.8260 - val_mae: 2.4070\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1455 - mae: 1.0924 - val_loss: 13.4395 - val_mae: 2.3861\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1295 - mae: 1.0430 - val_loss: 13.6953 - val_mae: 2.3903\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0036 - mae: 1.0502 - val_loss: 13.5067 - val_mae: 2.4005\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9490 - mae: 1.0470 - val_loss: 14.6966 - val_mae: 2.4399\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1113 - mae: 1.0574 - val_loss: 13.9309 - val_mae: 2.3903\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9625 - mae: 1.0045 - val_loss: 13.7172 - val_mae: 2.4442\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1471 - mae: 1.0845 - val_loss: 13.9230 - val_mae: 2.4304\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0942 - mae: 1.0261 - val_loss: 14.1900 - val_mae: 2.3747\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1013 - mae: 1.0687 - val_loss: 13.8088 - val_mae: 2.4036\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9234 - mae: 1.0163 - val_loss: 15.0245 - val_mae: 2.5119\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9517 - mae: 1.0331 - val_loss: 14.2521 - val_mae: 2.4282\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7683 - mae: 0.9457 - val_loss: 14.7548 - val_mae: 2.4642\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7790 - mae: 0.9739 - val_loss: 13.7700 - val_mae: 2.3675\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8905 - mae: 1.0124 - val_loss: 14.8039 - val_mae: 2.4662\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6880 - mae: 0.9245 - val_loss: 14.0445 - val_mae: 2.4129\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7149 - mae: 0.9665 - val_loss: 13.8855 - val_mae: 2.3836\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6429 - mae: 0.9094 - val_loss: 14.2201 - val_mae: 2.4681\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7859 - mae: 0.9688 - val_loss: 14.9658 - val_mae: 2.4876\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5954 - mae: 0.9171 - val_loss: 15.0877 - val_mae: 2.4508\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5822 - mae: 0.9162 - val_loss: 14.3806 - val_mae: 2.4125\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4900 - mae: 0.8821 - val_loss: 14.7079 - val_mae: 2.4715\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3704 - mae: 0.8259 - val_loss: 14.9621 - val_mae: 2.4733\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4806 - mae: 0.8852 - val_loss: 14.2603 - val_mae: 2.3865\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4387 - mae: 0.8633 - val_loss: 14.0882 - val_mae: 2.4345\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3458 - mae: 0.8202 - val_loss: 13.6499 - val_mae: 2.3983\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3827 - mae: 0.8285 - val_loss: 14.4292 - val_mae: 2.3967\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3910 - mae: 0.8409 - val_loss: 14.3388 - val_mae: 2.4282\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3167 - mae: 0.8299 - val_loss: 14.2559 - val_mae: 2.3821\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3310 - mae: 0.8259 - val_loss: 14.4437 - val_mae: 2.4773\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4644 - mae: 0.8884 - val_loss: 14.4059 - val_mae: 2.4511\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5049 - mae: 0.9065 - val_loss: 15.0872 - val_mae: 2.5526\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3704 - mae: 0.8366 - val_loss: 14.3869 - val_mae: 2.4879\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3006 - mae: 0.8339 - val_loss: 14.7485 - val_mae: 2.4387\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2832 - mae: 0.8121 - val_loss: 14.3226 - val_mae: 2.4313\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1405 - mae: 0.7647 - val_loss: 14.7293 - val_mae: 2.4809\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2274 - mae: 0.7948 - val_loss: 14.1710 - val_mae: 2.4332\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1334 - mae: 0.7542 - val_loss: 14.6009 - val_mae: 2.4670\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1995 - mae: 0.7752 - val_loss: 13.9207 - val_mae: 2.4323\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3928 - mae: 0.8919 - val_loss: 14.3577 - val_mae: 2.4630\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1595 - mae: 0.7648 - val_loss: 14.5033 - val_mae: 2.4823\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1442 - mae: 0.7701 - val_loss: 15.2519 - val_mae: 2.5331\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1030 - mae: 0.7520 - val_loss: 14.3408 - val_mae: 2.3755\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1789 - mae: 0.7649 - val_loss: 14.0851 - val_mae: 2.4295\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1682 - mae: 0.7442 - val_loss: 15.4145 - val_mae: 2.4494\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9644 - mae: 3.4107\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 12.4830 - mae: 12.4830 - val_loss: 5.6053 - val_mae: 5.6053\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8612 - mae: 3.8612 - val_loss: 2.7751 - val_mae: 2.7751\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0076 - mae: 3.0076 - val_loss: 2.8100 - val_mae: 2.8100\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9803 - mae: 2.9803 - val_loss: 2.7116 - val_mae: 2.7116\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5527 - mae: 2.5527 - val_loss: 2.5245 - val_mae: 2.5245\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4289 - mae: 2.4289 - val_loss: 2.4701 - val_mae: 2.4701\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4884 - mae: 2.4884 - val_loss: 2.5772 - val_mae: 2.5772\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2849 - mae: 2.2849 - val_loss: 2.6579 - val_mae: 2.6579\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2903 - mae: 2.2903 - val_loss: 2.5768 - val_mae: 2.5768\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1742 - mae: 2.1742 - val_loss: 2.3797 - val_mae: 2.3797\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2251 - mae: 2.2251 - val_loss: 2.4021 - val_mae: 2.4021\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1218 - mae: 2.1218 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1099 - mae: 2.1099 - val_loss: 2.3621 - val_mae: 2.3621\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9790 - mae: 1.9790 - val_loss: 2.4790 - val_mae: 2.4790\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9658 - mae: 1.9658 - val_loss: 2.5997 - val_mae: 2.5997\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9062 - mae: 1.9062 - val_loss: 2.3595 - val_mae: 2.3595\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8902 - mae: 1.8902 - val_loss: 2.5006 - val_mae: 2.5006\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8696 - mae: 1.8696 - val_loss: 2.4256 - val_mae: 2.4256\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7559 - mae: 1.7559 - val_loss: 2.4413 - val_mae: 2.4413\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7465 - mae: 1.7465 - val_loss: 2.3752 - val_mae: 2.3752\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7440 - mae: 1.7440 - val_loss: 2.4215 - val_mae: 2.4215\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7018 - mae: 1.7018 - val_loss: 2.4088 - val_mae: 2.4088\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6319 - mae: 1.6319 - val_loss: 2.3344 - val_mae: 2.3344\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6299 - mae: 1.6299 - val_loss: 2.3816 - val_mae: 2.3816\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5704 - mae: 1.5704 - val_loss: 2.3607 - val_mae: 2.3607\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6502 - mae: 1.6502 - val_loss: 2.6534 - val_mae: 2.6534\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6350 - mae: 1.6350 - val_loss: 2.4031 - val_mae: 2.4031\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5556 - mae: 1.5556 - val_loss: 2.3105 - val_mae: 2.3105\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4757 - mae: 1.4757 - val_loss: 2.5066 - val_mae: 2.5066\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4473 - mae: 1.4473 - val_loss: 2.6139 - val_mae: 2.6139\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4543 - mae: 1.4543 - val_loss: 2.3724 - val_mae: 2.3724\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4032 - mae: 1.4032 - val_loss: 2.4346 - val_mae: 2.4346\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3795 - mae: 1.3795 - val_loss: 2.4534 - val_mae: 2.4534\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3533 - mae: 1.3533 - val_loss: 2.5275 - val_mae: 2.5275\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4412 - mae: 1.4412 - val_loss: 2.3631 - val_mae: 2.3631\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3238 - mae: 1.3238 - val_loss: 2.5031 - val_mae: 2.5031\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3515 - mae: 1.3515 - val_loss: 2.4034 - val_mae: 2.4034\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2653 - mae: 1.2653 - val_loss: 2.4833 - val_mae: 2.4833\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2426 - mae: 1.2426 - val_loss: 2.5036 - val_mae: 2.5036\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2550 - mae: 1.2550 - val_loss: 2.3920 - val_mae: 2.3920\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2685 - mae: 1.2685 - val_loss: 2.4205 - val_mae: 2.4205\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2364 - mae: 1.2364 - val_loss: 2.4699 - val_mae: 2.4699\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1794 - mae: 1.1794 - val_loss: 2.3949 - val_mae: 2.3949\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1709 - mae: 1.1709 - val_loss: 2.4651 - val_mae: 2.4651\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2073 - mae: 1.2073 - val_loss: 2.5263 - val_mae: 2.5263\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2966 - mae: 1.2966 - val_loss: 2.5324 - val_mae: 2.5324\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1565 - mae: 1.1565 - val_loss: 2.5334 - val_mae: 2.5334\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1346 - mae: 1.1346 - val_loss: 2.4570 - val_mae: 2.4570\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1177 - mae: 1.1177 - val_loss: 2.5574 - val_mae: 2.5574\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0747 - mae: 1.0747 - val_loss: 2.4168 - val_mae: 2.4168\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0801 - mae: 1.0801 - val_loss: 2.4533 - val_mae: 2.4533\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0718 - mae: 1.0718 - val_loss: 2.4061 - val_mae: 2.4061\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0284 - mae: 1.0284 - val_loss: 2.5111 - val_mae: 2.5111\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1011 - mae: 1.1011 - val_loss: 2.4275 - val_mae: 2.4275\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0893 - mae: 1.0893 - val_loss: 2.4177 - val_mae: 2.4177\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1005 - mae: 1.1005 - val_loss: 2.3923 - val_mae: 2.3923\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0406 - mae: 1.0406 - val_loss: 2.5143 - val_mae: 2.5143\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0446 - mae: 1.0446 - val_loss: 2.3561 - val_mae: 2.3561\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0315 - mae: 1.0315 - val_loss: 2.5011 - val_mae: 2.5011\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0647 - mae: 1.0647 - val_loss: 2.5226 - val_mae: 2.5226\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0697 - mae: 1.0697 - val_loss: 2.4033 - val_mae: 2.4033\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0781 - mae: 1.0781 - val_loss: 2.4462 - val_mae: 2.4462\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9875 - mae: 0.9875 - val_loss: 2.4326 - val_mae: 2.4326\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9467 - mae: 0.9467 - val_loss: 2.4051 - val_mae: 2.4051\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9315 - mae: 0.9315 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0538 - mae: 1.0538 - val_loss: 2.5381 - val_mae: 2.5381\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9742 - mae: 0.9742 - val_loss: 2.2961 - val_mae: 2.2961\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9143 - mae: 0.9143 - val_loss: 2.5442 - val_mae: 2.5442\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0044 - mae: 1.0044 - val_loss: 2.5507 - val_mae: 2.5507\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0309 - mae: 1.0309 - val_loss: 2.6045 - val_mae: 2.6045\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9378 - mae: 0.9378 - val_loss: 2.4406 - val_mae: 2.4406\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8908 - mae: 0.8908 - val_loss: 2.4783 - val_mae: 2.4783\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9222 - mae: 0.9222 - val_loss: 2.4533 - val_mae: 2.4533\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9147 - mae: 0.9147 - val_loss: 2.5226 - val_mae: 2.5226\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9037 - mae: 0.9037 - val_loss: 2.4575 - val_mae: 2.4575\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8683 - mae: 0.8683 - val_loss: 2.4303 - val_mae: 2.4303\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8869 - mae: 0.8869 - val_loss: 2.4652 - val_mae: 2.4652\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8427 - mae: 0.8427 - val_loss: 2.4713 - val_mae: 2.4713\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8314 - mae: 0.8314 - val_loss: 2.4156 - val_mae: 2.4156\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8590 - mae: 0.8590 - val_loss: 2.4383 - val_mae: 2.4383\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8144 - mae: 0.8144 - val_loss: 2.3666 - val_mae: 2.3666\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8114 - mae: 0.8114 - val_loss: 2.4777 - val_mae: 2.4777\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8543 - mae: 0.8543 - val_loss: 2.4788 - val_mae: 2.4788\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8276 - mae: 0.8276 - val_loss: 2.4280 - val_mae: 2.4280\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8067 - mae: 0.8067 - val_loss: 2.4676 - val_mae: 2.4676\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8005 - mae: 0.8005 - val_loss: 2.4481 - val_mae: 2.4481\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7895 - mae: 0.7895 - val_loss: 2.5418 - val_mae: 2.5418\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.8275 - mae: 0.8275 - val_loss: 2.4878 - val_mae: 2.4878\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7837 - mae: 0.7837 - val_loss: 2.4664 - val_mae: 2.4664\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7949 - mae: 0.7949 - val_loss: 2.4830 - val_mae: 2.4830\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7931 - mae: 0.7931 - val_loss: 2.4011 - val_mae: 2.4011\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7734 - mae: 0.7734 - val_loss: 2.4713 - val_mae: 2.4713\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7614 - mae: 0.7614 - val_loss: 2.5124 - val_mae: 2.5124\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7607 - mae: 0.7607 - val_loss: 2.4894 - val_mae: 2.4894\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8143 - mae: 0.8143 - val_loss: 2.5180 - val_mae: 2.5180\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7675 - mae: 0.7675 - val_loss: 2.5832 - val_mae: 2.5832\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7558 - mae: 0.7558 - val_loss: 2.4718 - val_mae: 2.4718\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7582 - mae: 0.7582 - val_loss: 2.4810 - val_mae: 2.4810\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7239 - mae: 0.7239 - val_loss: 2.4277 - val_mae: 2.4277\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7032 - mae: 0.7032 - val_loss: 2.5463 - val_mae: 2.5463\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.3375 - mae: 3.3375\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 209.2268 - mae: 11.1435 - val_loss: 53.8201 - val_mae: 5.1831\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 29.5502 - mae: 3.9109 - val_loss: 28.9876 - val_mae: 3.5501\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 21.8184 - mae: 3.3292 - val_loss: 24.2340 - val_mae: 3.2810\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 17.9374 - mae: 3.0183 - val_loss: 22.4728 - val_mae: 3.3480\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 14.6812 - mae: 2.7007 - val_loss: 18.7422 - val_mae: 3.0873\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.2435 - mae: 2.5953 - val_loss: 18.0414 - val_mae: 2.9275\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 11.9756 - mae: 2.5224 - val_loss: 18.1313 - val_mae: 2.9582\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.6350 - mae: 2.3700 - val_loss: 16.1143 - val_mae: 2.7329\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.3690 - mae: 2.3442 - val_loss: 17.8485 - val_mae: 2.9847\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0883 - mae: 2.3623 - val_loss: 15.3980 - val_mae: 2.6837\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2513 - mae: 2.1990 - val_loss: 15.2173 - val_mae: 2.6216\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8269 - mae: 2.1706 - val_loss: 15.6197 - val_mae: 2.5935\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2314 - mae: 2.0658 - val_loss: 14.7445 - val_mae: 2.5926\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.2027 - mae: 2.1165 - val_loss: 14.7145 - val_mae: 2.6213\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2914 - mae: 1.9905 - val_loss: 15.0602 - val_mae: 2.5668\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.2303 - mae: 2.0068 - val_loss: 14.6206 - val_mae: 2.4906\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.0321 - mae: 1.9674 - val_loss: 13.8045 - val_mae: 2.5274\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4008 - mae: 1.8544 - val_loss: 13.5338 - val_mae: 2.4775\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1562 - mae: 1.8821 - val_loss: 14.2711 - val_mae: 2.5624\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7039 - mae: 1.8048 - val_loss: 13.5889 - val_mae: 2.4526\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.6285 - mae: 1.8075 - val_loss: 13.6868 - val_mae: 2.5549\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8072 - mae: 1.8378 - val_loss: 13.4931 - val_mae: 2.5472\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0806 - mae: 1.7099 - val_loss: 13.7102 - val_mae: 2.4171\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1297 - mae: 1.6803 - val_loss: 14.0204 - val_mae: 2.4723\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0187 - mae: 1.6916 - val_loss: 13.3053 - val_mae: 2.3780\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6485 - mae: 1.6198 - val_loss: 14.1922 - val_mae: 2.4939\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7568 - mae: 1.6597 - val_loss: 14.8815 - val_mae: 2.5525\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6678 - mae: 1.6384 - val_loss: 15.3318 - val_mae: 2.6021\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1247 - mae: 1.5261 - val_loss: 13.4676 - val_mae: 2.4843\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5071 - mae: 1.6098 - val_loss: 14.4183 - val_mae: 2.5421\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9156 - mae: 1.4837 - val_loss: 13.6129 - val_mae: 2.4239\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8720 - mae: 1.4871 - val_loss: 13.4161 - val_mae: 2.4492\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8652 - mae: 1.4787 - val_loss: 13.3762 - val_mae: 2.4625\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7395 - mae: 1.4789 - val_loss: 13.0868 - val_mae: 2.4282\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.4757 - mae: 1.3932 - val_loss: 14.5701 - val_mae: 2.4629\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.3678 - mae: 1.3561 - val_loss: 13.9454 - val_mae: 2.4712\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2696 - mae: 1.3445 - val_loss: 13.1397 - val_mae: 2.3587\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2972 - mae: 1.3466 - val_loss: 14.1075 - val_mae: 2.5185\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2232 - mae: 1.3575 - val_loss: 13.3814 - val_mae: 2.3782\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1252 - mae: 1.3060 - val_loss: 13.8997 - val_mae: 2.4889\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9720 - mae: 1.2794 - val_loss: 14.2377 - val_mae: 2.4764\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0218 - mae: 1.2829 - val_loss: 14.6056 - val_mae: 2.5117\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1645 - mae: 1.3322 - val_loss: 14.5130 - val_mae: 2.4580\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7922 - mae: 1.2187 - val_loss: 14.0650 - val_mae: 2.4475\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9187 - mae: 1.2831 - val_loss: 14.5569 - val_mae: 2.5341\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7401 - mae: 1.2540 - val_loss: 14.3138 - val_mae: 2.4734\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7354 - mae: 1.2202 - val_loss: 14.3961 - val_mae: 2.4780\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5721 - mae: 1.1788 - val_loss: 14.8127 - val_mae: 2.5741\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9495 - mae: 1.2976 - val_loss: 14.2630 - val_mae: 2.4627\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6017 - mae: 1.1750 - val_loss: 14.3241 - val_mae: 2.4835\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3256 - mae: 1.1401 - val_loss: 14.8516 - val_mae: 2.5128\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8820 - mae: 1.3236 - val_loss: 14.0801 - val_mae: 2.4692\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3742 - mae: 1.1144 - val_loss: 14.7855 - val_mae: 2.5706\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7209 - mae: 1.2412 - val_loss: 15.5659 - val_mae: 2.4887\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6500 - mae: 1.2497 - val_loss: 14.2237 - val_mae: 2.4961\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2739 - mae: 1.1137 - val_loss: 14.4835 - val_mae: 2.4921\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1834 - mae: 1.0840 - val_loss: 14.7510 - val_mae: 2.4904\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1300 - mae: 1.0666 - val_loss: 14.7549 - val_mae: 2.5301\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1848 - mae: 1.1136 - val_loss: 14.2188 - val_mae: 2.4771\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2462 - mae: 1.1143 - val_loss: 14.8708 - val_mae: 2.5901\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1272 - mae: 1.0628 - val_loss: 15.1357 - val_mae: 2.5872\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9373 - mae: 1.0240 - val_loss: 14.3175 - val_mae: 2.4825\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5847 - mae: 1.2332 - val_loss: 14.2691 - val_mae: 2.4813\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9747 - mae: 1.0298 - val_loss: 14.7433 - val_mae: 2.5139\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9404 - mae: 1.0184 - val_loss: 15.1101 - val_mae: 2.5686\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8399 - mae: 1.0045 - val_loss: 14.9383 - val_mae: 2.6152\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9555 - mae: 1.0322 - val_loss: 15.4949 - val_mae: 2.6546\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7858 - mae: 0.9709 - val_loss: 15.0274 - val_mae: 2.5770\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6802 - mae: 0.9533 - val_loss: 15.4138 - val_mae: 2.6468\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9381 - mae: 0.9864 - val_loss: 15.9220 - val_mae: 2.6473\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8947 - mae: 1.0065 - val_loss: 15.3447 - val_mae: 2.6007\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7039 - mae: 0.9565 - val_loss: 15.5944 - val_mae: 2.6433\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8636 - mae: 1.0352 - val_loss: 15.2980 - val_mae: 2.5939\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6342 - mae: 0.9261 - val_loss: 16.4382 - val_mae: 2.7393\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6532 - mae: 0.9487 - val_loss: 15.7169 - val_mae: 2.6613\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6685 - mae: 0.9628 - val_loss: 15.1572 - val_mae: 2.5871\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5238 - mae: 0.8825 - val_loss: 15.2312 - val_mae: 2.5978\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5686 - mae: 0.8993 - val_loss: 16.2590 - val_mae: 2.6864\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8625 - mae: 1.0279 - val_loss: 15.0873 - val_mae: 2.6303\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4576 - mae: 0.8667 - val_loss: 15.1614 - val_mae: 2.6434\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5547 - mae: 0.9136 - val_loss: 15.4190 - val_mae: 2.6193\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5923 - mae: 0.8975 - val_loss: 15.4776 - val_mae: 2.6481\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5030 - mae: 0.8847 - val_loss: 15.5306 - val_mae: 2.6540\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3357 - mae: 0.8048 - val_loss: 15.3679 - val_mae: 2.6424\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3488 - mae: 0.8207 - val_loss: 15.6059 - val_mae: 2.6716\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3422 - mae: 0.8148 - val_loss: 15.6541 - val_mae: 2.6255\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4366 - mae: 0.8679 - val_loss: 15.7792 - val_mae: 2.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3184 - mae: 0.8003 - val_loss: 16.0086 - val_mae: 2.7382\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2979 - mae: 0.8221 - val_loss: 15.6454 - val_mae: 2.6528\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2268 - mae: 0.7739 - val_loss: 16.0075 - val_mae: 2.7031\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4673 - mae: 0.8889 - val_loss: 15.2440 - val_mae: 2.5869\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3680 - mae: 0.8370 - val_loss: 15.0373 - val_mae: 2.6225\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6491 - mae: 0.9223 - val_loss: 15.7355 - val_mae: 2.6460\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1764 - mae: 0.7597 - val_loss: 16.7341 - val_mae: 2.7580\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2454 - mae: 0.7922 - val_loss: 16.4446 - val_mae: 2.7417\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1385 - mae: 0.7440 - val_loss: 16.0138 - val_mae: 2.6883\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2106 - mae: 0.7781 - val_loss: 16.3234 - val_mae: 2.7116\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3406 - mae: 0.7987 - val_loss: 15.6350 - val_mae: 2.6687\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4848 - mae: 0.8610 - val_loss: 15.6941 - val_mae: 2.6752\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0473 - mae: 0.7096 - val_loss: 15.1353 - val_mae: 2.5806\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.2042 - mae: 3.5510\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 11.3299 - mae: 11.3299 - val_loss: 4.2378 - val_mae: 4.2378\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.7852 - mae: 3.7852 - val_loss: 2.7728 - val_mae: 2.7728\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8993 - mae: 2.8993 - val_loss: 2.7320 - val_mae: 2.7320\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7233 - mae: 2.7233 - val_loss: 3.0019 - val_mae: 3.0019\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6234 - mae: 2.6234 - val_loss: 2.4750 - val_mae: 2.4750\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5128 - mae: 2.5128 - val_loss: 2.7213 - val_mae: 2.7213\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5054 - mae: 2.5054 - val_loss: 2.4369 - val_mae: 2.4369\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3248 - mae: 2.3248 - val_loss: 2.6505 - val_mae: 2.6505\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3006 - mae: 2.3006 - val_loss: 2.5080 - val_mae: 2.5080\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2947 - mae: 2.2947 - val_loss: 2.6416 - val_mae: 2.6416\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1748 - mae: 2.1748 - val_loss: 2.5739 - val_mae: 2.5739\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1772 - mae: 2.1772 - val_loss: 2.4889 - val_mae: 2.4889\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1267 - mae: 2.1267 - val_loss: 2.4420 - val_mae: 2.4420\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0444 - mae: 2.0444 - val_loss: 2.3962 - val_mae: 2.3962\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0678 - mae: 2.0678 - val_loss: 2.4355 - val_mae: 2.4355\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9962 - mae: 1.9962 - val_loss: 2.3695 - val_mae: 2.3695\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0342 - mae: 2.0342 - val_loss: 2.3858 - val_mae: 2.3858\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9341 - mae: 1.9341 - val_loss: 2.6293 - val_mae: 2.6293\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9199 - mae: 1.9199 - val_loss: 2.4122 - val_mae: 2.4122\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9023 - mae: 1.9023 - val_loss: 2.3819 - val_mae: 2.3819\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9138 - mae: 1.9138 - val_loss: 2.4761 - val_mae: 2.4761\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7791 - mae: 1.7791 - val_loss: 2.5287 - val_mae: 2.5287\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8002 - mae: 1.8002 - val_loss: 2.5093 - val_mae: 2.5093\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7238 - mae: 1.7238 - val_loss: 2.5597 - val_mae: 2.5597\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7168 - mae: 1.7168 - val_loss: 2.4969 - val_mae: 2.4969\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7426 - mae: 1.7426 - val_loss: 2.4525 - val_mae: 2.4525\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6515 - mae: 1.6515 - val_loss: 2.4093 - val_mae: 2.4093\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6155 - mae: 1.6155 - val_loss: 2.3840 - val_mae: 2.3840\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6155 - mae: 1.6155 - val_loss: 2.4260 - val_mae: 2.4260\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6169 - mae: 1.6169 - val_loss: 2.5291 - val_mae: 2.5291\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6680 - mae: 1.6680 - val_loss: 2.3455 - val_mae: 2.3455\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5105 - mae: 1.5105 - val_loss: 2.4069 - val_mae: 2.4069\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5487 - mae: 1.5487 - val_loss: 2.5316 - val_mae: 2.5316\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5307 - mae: 1.5307 - val_loss: 2.4379 - val_mae: 2.4379\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4545 - mae: 1.4545 - val_loss: 2.4429 - val_mae: 2.4429\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4351 - mae: 1.4351 - val_loss: 2.5074 - val_mae: 2.5074\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4841 - mae: 1.4841 - val_loss: 2.4157 - val_mae: 2.4157\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4166 - mae: 1.4166 - val_loss: 2.3739 - val_mae: 2.3739\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3980 - mae: 1.3980 - val_loss: 2.4579 - val_mae: 2.4579\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3918 - mae: 1.3918 - val_loss: 2.4700 - val_mae: 2.4700\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4134 - mae: 1.4134 - val_loss: 2.5812 - val_mae: 2.5812\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3981 - mae: 1.3981 - val_loss: 2.3563 - val_mae: 2.3563\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3433 - mae: 1.3433 - val_loss: 2.4619 - val_mae: 2.4619\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.3478 - mae: 1.3478 - val_loss: 2.4657 - val_mae: 2.4657\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3716 - mae: 1.3716 - val_loss: 2.4257 - val_mae: 2.4257\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3151 - mae: 1.3151 - val_loss: 2.5184 - val_mae: 2.5184\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2386 - mae: 1.2386 - val_loss: 2.4463 - val_mae: 2.4463\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3251 - mae: 1.3251 - val_loss: 2.5464 - val_mae: 2.5464\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2276 - mae: 1.2276 - val_loss: 2.5036 - val_mae: 2.5036\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2264 - mae: 1.2264 - val_loss: 2.5864 - val_mae: 2.5864\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2302 - mae: 1.2302 - val_loss: 2.3972 - val_mae: 2.3972\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2339 - mae: 1.2339 - val_loss: 2.4677 - val_mae: 2.4677\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1641 - mae: 1.1641 - val_loss: 2.4712 - val_mae: 2.4712\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1515 - mae: 1.1515 - val_loss: 2.3762 - val_mae: 2.3762\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1322 - mae: 1.1322 - val_loss: 2.4864 - val_mae: 2.4864\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1393 - mae: 1.1393 - val_loss: 2.4627 - val_mae: 2.4627\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1696 - mae: 1.1696 - val_loss: 2.3886 - val_mae: 2.3886\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1482 - mae: 1.1482 - val_loss: 2.4050 - val_mae: 2.4050\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1430 - mae: 1.1430 - val_loss: 2.4155 - val_mae: 2.4155\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1194 - mae: 1.1194 - val_loss: 2.5319 - val_mae: 2.5319\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1106 - mae: 1.1106 - val_loss: 2.5202 - val_mae: 2.5202\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1302 - mae: 1.1302 - val_loss: 2.5706 - val_mae: 2.5706\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0631 - mae: 1.0631 - val_loss: 2.4032 - val_mae: 2.4032\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1843 - mae: 1.1843 - val_loss: 2.5878 - val_mae: 2.5878\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1036 - mae: 1.1036 - val_loss: 2.4786 - val_mae: 2.4786\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0755 - mae: 1.0755 - val_loss: 2.4871 - val_mae: 2.4871\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0306 - mae: 1.0306 - val_loss: 2.3771 - val_mae: 2.3771\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0017 - mae: 1.0017 - val_loss: 2.3555 - val_mae: 2.3555\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9907 - mae: 0.9907 - val_loss: 2.5384 - val_mae: 2.5384\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0699 - mae: 1.0699 - val_loss: 2.3607 - val_mae: 2.3607\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9871 - mae: 0.9871 - val_loss: 2.4650 - val_mae: 2.4650\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0011 - mae: 1.0011 - val_loss: 2.5752 - val_mae: 2.5752\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0021 - mae: 1.0021 - val_loss: 2.5268 - val_mae: 2.5268\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9965 - mae: 0.9965 - val_loss: 2.4522 - val_mae: 2.4522\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0302 - mae: 1.0302 - val_loss: 2.4447 - val_mae: 2.4447\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9499 - mae: 0.9499 - val_loss: 2.4605 - val_mae: 2.4605\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0026 - mae: 1.0026 - val_loss: 2.4382 - val_mae: 2.4382\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9056 - mae: 0.9056 - val_loss: 2.3947 - val_mae: 2.3947\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9686 - mae: 0.9686 - val_loss: 2.4368 - val_mae: 2.4368\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9768 - mae: 0.9768 - val_loss: 2.4450 - val_mae: 2.4450\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0935 - mae: 1.0935 - val_loss: 2.5380 - val_mae: 2.5380\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9786 - mae: 0.9786 - val_loss: 2.3401 - val_mae: 2.3401\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9116 - mae: 0.9116 - val_loss: 2.4578 - val_mae: 2.4578\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9482 - mae: 0.9482 - val_loss: 2.4622 - val_mae: 2.4622\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9172 - mae: 0.9172 - val_loss: 2.4502 - val_mae: 2.4502\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8850 - mae: 0.8850 - val_loss: 2.5525 - val_mae: 2.5525\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9570 - mae: 0.9570 - val_loss: 2.4686 - val_mae: 2.4686\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8861 - mae: 0.8861 - val_loss: 2.5271 - val_mae: 2.5271\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9323 - mae: 0.9323 - val_loss: 2.4395 - val_mae: 2.4395\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8808 - mae: 0.8808 - val_loss: 2.3758 - val_mae: 2.3758\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9275 - mae: 0.9275 - val_loss: 2.4524 - val_mae: 2.4524\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9023 - mae: 0.9023 - val_loss: 2.5429 - val_mae: 2.5429\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8280 - mae: 0.8280 - val_loss: 2.3670 - val_mae: 2.3670\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8615 - mae: 0.8615 - val_loss: 2.4557 - val_mae: 2.4557\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8047 - mae: 0.8047 - val_loss: 2.5778 - val_mae: 2.5778\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8362 - mae: 0.8362 - val_loss: 2.3507 - val_mae: 2.3507\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8499 - mae: 0.8499 - val_loss: 2.5647 - val_mae: 2.5647\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9205 - mae: 0.9205 - val_loss: 2.4656 - val_mae: 2.4656\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8763 - mae: 0.8763 - val_loss: 2.4073 - val_mae: 2.4073\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8606 - mae: 0.8606 - val_loss: 2.4705 - val_mae: 2.4705\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.3693 - mae: 3.3693\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 209.0509 - mae: 11.0137 - val_loss: 31.1160 - val_mae: 3.7203\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 24.2472 - mae: 3.5035 - val_loss: 22.1569 - val_mae: 3.2819\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 18.3412 - mae: 3.0759 - val_loss: 20.9422 - val_mae: 3.0716\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 15.2927 - mae: 2.8041 - val_loss: 17.8029 - val_mae: 2.9497\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 13.5711 - mae: 2.6363 - val_loss: 17.5827 - val_mae: 2.8616\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.3166 - mae: 2.5297 - val_loss: 16.8764 - val_mae: 2.7200\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 12.2713 - mae: 2.5507 - val_loss: 16.5868 - val_mae: 2.6574\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.9560 - mae: 2.3915 - val_loss: 15.5726 - val_mae: 2.6401\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 10.0874 - mae: 2.3176 - val_loss: 15.7379 - val_mae: 2.5671\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 9.9452 - mae: 2.3027 - val_loss: 15.2364 - val_mae: 2.5395\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8529 - mae: 2.1961 - val_loss: 17.4360 - val_mae: 2.9110\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.8650 - mae: 2.1987 - val_loss: 14.7592 - val_mae: 2.6166\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.5331 - mae: 2.1856 - val_loss: 15.0364 - val_mae: 2.5553\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.7726 - mae: 2.0253 - val_loss: 14.2070 - val_mae: 2.5638\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.6756 - mae: 2.0609 - val_loss: 14.6984 - val_mae: 2.5439\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.1979 - mae: 1.9867 - val_loss: 14.4520 - val_mae: 2.5160\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8208 - mae: 1.9732 - val_loss: 14.4197 - val_mae: 2.5176\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4817 - mae: 1.9011 - val_loss: 14.6533 - val_mae: 2.4754\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5387 - mae: 1.9142 - val_loss: 15.1013 - val_mae: 2.5463\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.1061 - mae: 1.8535 - val_loss: 14.3536 - val_mae: 2.5557\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.8959 - mae: 1.8071 - val_loss: 14.2207 - val_mae: 2.5197\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.0131 - mae: 1.8571 - val_loss: 14.4452 - val_mae: 2.4834\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 5.5030 - mae: 1.7551 - val_loss: 14.5902 - val_mae: 2.5334\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2719 - mae: 1.6955 - val_loss: 15.3586 - val_mae: 2.6668\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4811 - mae: 1.7579 - val_loss: 14.1881 - val_mae: 2.4757\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7083 - mae: 1.6302 - val_loss: 13.7425 - val_mae: 2.4585\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6910 - mae: 1.6196 - val_loss: 13.8839 - val_mae: 2.5109\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6635 - mae: 1.6263 - val_loss: 15.0272 - val_mae: 2.4961\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3232 - mae: 1.5729 - val_loss: 15.0432 - val_mae: 2.5394\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1190 - mae: 1.5062 - val_loss: 14.1250 - val_mae: 2.4509\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0127 - mae: 1.4779 - val_loss: 14.4456 - val_mae: 2.4830\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9042 - mae: 1.4645 - val_loss: 14.3826 - val_mae: 2.5825\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8581 - mae: 1.4477 - val_loss: 14.3065 - val_mae: 2.4969\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.6443 - mae: 1.4454 - val_loss: 14.2630 - val_mae: 2.5381\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5442 - mae: 1.3949 - val_loss: 14.6713 - val_mae: 2.5556\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5901 - mae: 1.4308 - val_loss: 14.8140 - val_mae: 2.6298\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.5602 - mae: 1.4028 - val_loss: 13.9851 - val_mae: 2.3548\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2710 - mae: 1.3522 - val_loss: 14.4406 - val_mae: 2.4228\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1065 - mae: 1.3126 - val_loss: 13.5926 - val_mae: 2.4270\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.1070 - mae: 1.3192 - val_loss: 14.2501 - val_mae: 2.4363\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.2492 - mae: 1.3448 - val_loss: 13.7634 - val_mae: 2.4418\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.9276 - mae: 1.2747 - val_loss: 13.5836 - val_mae: 2.4068\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8397 - mae: 1.2548 - val_loss: 14.0912 - val_mae: 2.4820\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0422 - mae: 1.2658 - val_loss: 16.4296 - val_mae: 2.7632\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0230 - mae: 1.3324 - val_loss: 14.6857 - val_mae: 2.4217\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6369 - mae: 1.2029 - val_loss: 14.3264 - val_mae: 2.4044\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6123 - mae: 1.1822 - val_loss: 14.5613 - val_mae: 2.4772\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.6359 - mae: 1.2241 - val_loss: 15.1844 - val_mae: 2.6685\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8526 - mae: 1.2703 - val_loss: 14.9173 - val_mae: 2.5440\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3813 - mae: 1.1466 - val_loss: 13.9392 - val_mae: 2.3915\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.3880 - mae: 1.1247 - val_loss: 14.4018 - val_mae: 2.4638\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5310 - mae: 1.1795 - val_loss: 14.6018 - val_mae: 2.5706\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2115 - mae: 1.0975 - val_loss: 14.5022 - val_mae: 2.4697\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5435 - mae: 1.1948 - val_loss: 14.6609 - val_mae: 2.4244\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1015 - mae: 1.0700 - val_loss: 15.1193 - val_mae: 2.4941\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1201 - mae: 1.0693 - val_loss: 14.4669 - val_mae: 2.4277\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2960 - mae: 1.1100 - val_loss: 14.6030 - val_mae: 2.4763\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1566 - mae: 1.0971 - val_loss: 14.1150 - val_mae: 2.4169\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9098 - mae: 1.0076 - val_loss: 14.6037 - val_mae: 2.5269\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0031 - mae: 1.0412 - val_loss: 14.5760 - val_mae: 2.5304\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0008 - mae: 1.0397 - val_loss: 14.0695 - val_mae: 2.4351\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8107 - mae: 1.0013 - val_loss: 14.6624 - val_mae: 2.4216\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8311 - mae: 0.9914 - val_loss: 14.9935 - val_mae: 2.5159\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7580 - mae: 0.9754 - val_loss: 13.9851 - val_mae: 2.4968\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7249 - mae: 0.9464 - val_loss: 13.8368 - val_mae: 2.3967\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7431 - mae: 0.9741 - val_loss: 14.2435 - val_mae: 2.4621\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6892 - mae: 0.9372 - val_loss: 14.5401 - val_mae: 2.4618\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6708 - mae: 0.9447 - val_loss: 14.5144 - val_mae: 2.4926\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6971 - mae: 0.9467 - val_loss: 14.7500 - val_mae: 2.4687\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7110 - mae: 0.9750 - val_loss: 14.0239 - val_mae: 2.4540\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6690 - mae: 0.9408 - val_loss: 14.3504 - val_mae: 2.4853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5908 - mae: 0.9037 - val_loss: 14.1931 - val_mae: 2.4937\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5548 - mae: 0.8931 - val_loss: 14.0854 - val_mae: 2.4271\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4628 - mae: 0.8673 - val_loss: 14.9237 - val_mae: 2.5538\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7345 - mae: 0.9522 - val_loss: 14.2041 - val_mae: 2.4533\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5240 - mae: 0.8772 - val_loss: 14.7845 - val_mae: 2.5262\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6058 - mae: 0.9607 - val_loss: 15.0522 - val_mae: 2.5505\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6361 - mae: 0.9353 - val_loss: 15.1642 - val_mae: 2.5565\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3471 - mae: 0.8440 - val_loss: 14.2163 - val_mae: 2.4817\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2402 - mae: 0.7910 - val_loss: 14.1233 - val_mae: 2.4886\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2907 - mae: 0.8360 - val_loss: 14.2457 - val_mae: 2.4684\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4005 - mae: 0.8496 - val_loss: 14.6264 - val_mae: 2.5075\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2419 - mae: 0.8073 - val_loss: 14.2955 - val_mae: 2.5529\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2956 - mae: 0.8302 - val_loss: 14.2469 - val_mae: 2.4979\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2214 - mae: 0.7836 - val_loss: 14.5600 - val_mae: 2.5449\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2131 - mae: 0.7883 - val_loss: 14.4003 - val_mae: 2.5047\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1943 - mae: 0.7799 - val_loss: 14.5825 - val_mae: 2.5234\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0975 - mae: 0.7451 - val_loss: 14.0541 - val_mae: 2.4824\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2665 - mae: 0.8064 - val_loss: 14.3275 - val_mae: 2.4708\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1570 - mae: 0.7722 - val_loss: 14.6160 - val_mae: 2.5377\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0711 - mae: 0.7217 - val_loss: 14.3194 - val_mae: 2.5332\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0215 - mae: 0.7057 - val_loss: 13.9627 - val_mae: 2.4744\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1254 - mae: 0.7504 - val_loss: 14.6717 - val_mae: 2.5283\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0491 - mae: 0.7331 - val_loss: 13.9096 - val_mae: 2.5142\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1134 - mae: 0.7523 - val_loss: 14.1462 - val_mae: 2.5048\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9703 - mae: 0.6883 - val_loss: 14.4930 - val_mae: 2.5704\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1156 - mae: 0.7625 - val_loss: 14.0491 - val_mae: 2.5091\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9374 - mae: 0.6944 - val_loss: 14.5193 - val_mae: 2.5318\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9743 - mae: 0.7210 - val_loss: 14.2384 - val_mae: 2.4972\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9175 - mae: 0.6713 - val_loss: 14.4988 - val_mae: 2.5508\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9789 - mae: 3.4430\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 10.4926 - mae: 10.4926 - val_loss: 4.4523 - val_mae: 4.4523\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8159 - mae: 3.8159 - val_loss: 3.0206 - val_mae: 3.0206\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.0698 - mae: 3.0698 - val_loss: 2.9016 - val_mae: 2.9016\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.8737 - mae: 2.8737 - val_loss: 3.0032 - val_mae: 3.0032\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.7093 - mae: 2.7093 - val_loss: 2.5959 - val_mae: 2.5959\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.5397 - mae: 2.5397 - val_loss: 2.5108 - val_mae: 2.5108\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4486 - mae: 2.4486 - val_loss: 2.5659 - val_mae: 2.5659\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.4606 - mae: 2.4606 - val_loss: 2.6266 - val_mae: 2.6266\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.2968 - mae: 2.2968 - val_loss: 2.4822 - val_mae: 2.4822\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1657 - mae: 2.1657 - val_loss: 2.4717 - val_mae: 2.4717\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1539 - mae: 2.1539 - val_loss: 2.4002 - val_mae: 2.4002\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1389 - mae: 2.1389 - val_loss: 2.3616 - val_mae: 2.3616\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.1711 - mae: 2.1711 - val_loss: 2.5411 - val_mae: 2.5411\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0641 - mae: 2.0641 - val_loss: 2.4685 - val_mae: 2.4685\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0096 - mae: 2.0096 - val_loss: 2.4305 - val_mae: 2.4305\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0084 - mae: 2.0084 - val_loss: 2.6214 - val_mae: 2.6214\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 2.0172 - mae: 2.0172 - val_loss: 2.4143 - val_mae: 2.4143\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9011 - mae: 1.9011 - val_loss: 2.4366 - val_mae: 2.4366\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8842 - mae: 1.8842 - val_loss: 2.4322 - val_mae: 2.4322\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.9621 - mae: 1.9621 - val_loss: 2.6424 - val_mae: 2.6424\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8113 - mae: 1.8113 - val_loss: 2.4155 - val_mae: 2.4155\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.8562 - mae: 1.8562 - val_loss: 2.4241 - val_mae: 2.4241\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.7801 - mae: 1.7801 - val_loss: 2.4740 - val_mae: 2.4740\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6885 - mae: 1.6885 - val_loss: 2.3590 - val_mae: 2.3590\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6647 - mae: 1.6647 - val_loss: 2.4614 - val_mae: 2.4614\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6831 - mae: 1.6831 - val_loss: 2.5111 - val_mae: 2.5111\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6492 - mae: 1.6492 - val_loss: 2.3546 - val_mae: 2.3546\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6210 - mae: 1.6210 - val_loss: 2.3888 - val_mae: 2.3888\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5943 - mae: 1.5943 - val_loss: 2.3776 - val_mae: 2.3776\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.6222 - mae: 1.6222 - val_loss: 2.4052 - val_mae: 2.4052\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6335 - mae: 1.6335 - val_loss: 2.6391 - val_mae: 2.6391\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.6261 - mae: 1.6261 - val_loss: 2.4623 - val_mae: 2.4623\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 1.5157 - mae: 1.5157 - val_loss: 2.4230 - val_mae: 2.4230\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4910 - mae: 1.4910 - val_loss: 2.4742 - val_mae: 2.4742\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4517 - mae: 1.4517 - val_loss: 2.3350 - val_mae: 2.3350\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4676 - mae: 1.4676 - val_loss: 2.4001 - val_mae: 2.4001\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4118 - mae: 1.4118 - val_loss: 2.3612 - val_mae: 2.3612\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4183 - mae: 1.4183 - val_loss: 2.3996 - val_mae: 2.3996\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3507 - mae: 1.3507 - val_loss: 2.4716 - val_mae: 2.4716\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3988 - mae: 1.3988 - val_loss: 2.4066 - val_mae: 2.4066\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3495 - mae: 1.3495 - val_loss: 2.3455 - val_mae: 2.3455\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.4079 - mae: 1.4079 - val_loss: 2.4007 - val_mae: 2.4007\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3358 - mae: 1.3358 - val_loss: 2.4377 - val_mae: 2.4377\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3373 - mae: 1.3373 - val_loss: 2.3860 - val_mae: 2.3860\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2792 - mae: 1.2792 - val_loss: 2.3044 - val_mae: 2.3044\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2840 - mae: 1.2840 - val_loss: 2.3974 - val_mae: 2.3974\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3255 - mae: 1.3255 - val_loss: 2.3782 - val_mae: 2.3782\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2151 - mae: 1.2151 - val_loss: 2.3601 - val_mae: 2.3601\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2908 - mae: 1.2908 - val_loss: 2.3221 - val_mae: 2.3221\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2410 - mae: 1.2410 - val_loss: 2.4744 - val_mae: 2.4744\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2418 - mae: 1.2418 - val_loss: 2.3377 - val_mae: 2.3377\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.2048 - mae: 1.2048 - val_loss: 2.4799 - val_mae: 2.4799\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.3504 - mae: 1.3504 - val_loss: 2.4351 - val_mae: 2.4351\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1728 - mae: 1.1728 - val_loss: 2.3653 - val_mae: 2.3653\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1463 - mae: 1.1463 - val_loss: 2.3385 - val_mae: 2.3385\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1055 - mae: 1.1055 - val_loss: 2.3521 - val_mae: 2.3521\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1928 - mae: 1.1928 - val_loss: 2.2801 - val_mae: 2.2801\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1394 - mae: 1.1394 - val_loss: 2.2816 - val_mae: 2.2816\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1300 - mae: 1.1300 - val_loss: 2.2848 - val_mae: 2.2848\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.1540 - mae: 1.1540 - val_loss: 2.3060 - val_mae: 2.3060\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1041 - mae: 1.1041 - val_loss: 2.2959 - val_mae: 2.2959\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.1152 - mae: 1.1152 - val_loss: 2.4364 - val_mae: 2.4364\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0713 - mae: 1.0713 - val_loss: 2.3400 - val_mae: 2.3400\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0497 - mae: 1.0497 - val_loss: 2.3633 - val_mae: 2.3633\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0141 - mae: 1.0141 - val_loss: 2.3109 - val_mae: 2.3109\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0249 - mae: 1.0249 - val_loss: 2.2701 - val_mae: 2.2701\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9904 - mae: 0.9904 - val_loss: 2.3211 - val_mae: 2.3211\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0331 - mae: 1.0331 - val_loss: 2.3318 - val_mae: 2.3318\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0145 - mae: 1.0145 - val_loss: 2.3426 - val_mae: 2.3426\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0105 - mae: 1.0105 - val_loss: 2.3907 - val_mae: 2.3907\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9759 - mae: 0.9759 - val_loss: 2.3645 - val_mae: 2.3645\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9772 - mae: 0.9772 - val_loss: 2.3549 - val_mae: 2.3549\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9289 - mae: 0.9289 - val_loss: 2.4415 - val_mae: 2.4415\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9892 - mae: 0.9892 - val_loss: 2.3980 - val_mae: 2.3980\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9454 - mae: 0.9454 - val_loss: 2.4272 - val_mae: 2.4272\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8819 - mae: 0.8819 - val_loss: 2.3483 - val_mae: 2.3483\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 1.0864 - mae: 1.0864 - val_loss: 2.2501 - val_mae: 2.2501\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9706 - mae: 0.9706 - val_loss: 2.3233 - val_mae: 2.3233\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9316 - mae: 0.9316 - val_loss: 2.3737 - val_mae: 2.3737\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9093 - mae: 0.9093 - val_loss: 2.3785 - val_mae: 2.3785\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8684 - mae: 0.8684 - val_loss: 2.5740 - val_mae: 2.5740\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9411 - mae: 0.9411 - val_loss: 2.4800 - val_mae: 2.4800\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9211 - mae: 0.9211 - val_loss: 2.3884 - val_mae: 2.3884\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8679 - mae: 0.8679 - val_loss: 2.4208 - val_mae: 2.4208\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.9171 - mae: 0.9171 - val_loss: 2.3664 - val_mae: 2.3664\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8315 - mae: 0.8315 - val_loss: 2.3684 - val_mae: 2.3684\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8360 - mae: 0.8360 - val_loss: 2.4382 - val_mae: 2.4382\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8610 - mae: 0.8610 - val_loss: 2.3745 - val_mae: 2.3745\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8487 - mae: 0.8487 - val_loss: 2.3528 - val_mae: 2.3528\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8995 - mae: 0.8995 - val_loss: 2.3058 - val_mae: 2.3058\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.8900 - mae: 0.8900 - val_loss: 2.4197 - val_mae: 2.4197\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8472 - mae: 0.8472 - val_loss: 2.3156 - val_mae: 2.3156\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8005 - mae: 0.8005 - val_loss: 2.3676 - val_mae: 2.3676\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7633 - mae: 0.7633 - val_loss: 2.3269 - val_mae: 2.3269\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7775 - mae: 0.7775 - val_loss: 2.3716 - val_mae: 2.3716\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7929 - mae: 0.7929 - val_loss: 2.3331 - val_mae: 2.3331\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7661 - mae: 0.7661 - val_loss: 2.4092 - val_mae: 2.4092\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.7695 - mae: 0.7695 - val_loss: 2.4032 - val_mae: 2.4032\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8697 - mae: 0.8697 - val_loss: 2.3259 - val_mae: 2.3259\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.8742 - mae: 0.8742 - val_loss: 2.3476 - val_mae: 2.3476\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.6065 - mae: 3.6065\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 310.9663 - mae: 14.7718 - val_loss: 196.7149 - val_mae: 10.7896\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 164.6660 - mae: 9.8670 - val_loss: 153.8801 - val_mae: 9.0700\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 133.6166 - mae: 8.5924 - val_loss: 132.5788 - val_mae: 8.2530\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 116.1594 - mae: 7.8291 - val_loss: 118.5750 - val_mae: 7.7576\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 105.0932 - mae: 7.3062 - val_loss: 109.4906 - val_mae: 7.4389\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 97.5060 - mae: 6.9598 - val_loss: 103.5876 - val_mae: 7.2121\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 92.3206 - mae: 6.7229 - val_loss: 99.1503 - val_mae: 7.0430\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 88.7125 - mae: 6.5645 - val_loss: 96.1687 - val_mae: 6.9551\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 86.1578 - mae: 6.4686 - val_loss: 94.0585 - val_mae: 6.9232\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 84.4401 - mae: 6.4185 - val_loss: 92.5328 - val_mae: 6.9239\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.2138 - mae: 6.3948 - val_loss: 91.6184 - val_mae: 6.9422\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 82.3929 - mae: 6.3884 - val_loss: 90.8833 - val_mae: 6.9678\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.8148 - mae: 6.3892 - val_loss: 90.3376 - val_mae: 6.9934\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.3520 - mae: 6.3899 - val_loss: 90.0207 - val_mae: 7.0130\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.0629 - mae: 6.3966 - val_loss: 89.7665 - val_mae: 7.0347\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.8730 - mae: 6.4048 - val_loss: 89.6367 - val_mae: 7.0481\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.7306 - mae: 6.4146 - val_loss: 89.4647 - val_mae: 7.0713\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.6243 - mae: 6.4261 - val_loss: 89.4015 - val_mae: 7.0825\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.6416 - mae: 6.4378 - val_loss: 89.3206 - val_mae: 7.1002\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5325 - mae: 6.4380 - val_loss: 89.2967 - val_mae: 7.1068\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5009 - mae: 6.4404 - val_loss: 89.2767 - val_mae: 7.1137\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4807 - mae: 6.4450 - val_loss: 89.2675 - val_mae: 7.1174\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4787 - mae: 6.4505 - val_loss: 89.2501 - val_mae: 7.1254\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4807 - mae: 6.4615 - val_loss: 89.2334 - val_mae: 7.1354\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4410 - mae: 6.4608 - val_loss: 89.2405 - val_mae: 7.1307\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4414 - mae: 6.4615 - val_loss: 89.2276 - val_mae: 7.1400\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4370 - mae: 6.4686 - val_loss: 89.2225 - val_mae: 7.1453\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4318 - mae: 6.4716 - val_loss: 89.2209 - val_mae: 7.1474\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4311 - mae: 6.4646 - val_loss: 89.2247 - val_mae: 7.1428\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4332 - mae: 6.4691 - val_loss: 89.2217 - val_mae: 7.1462\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4146 - mae: 6.4714 - val_loss: 89.2189 - val_mae: 7.1506\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4366 - mae: 6.4777 - val_loss: 89.2179 - val_mae: 7.1528\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4366 - mae: 6.4681 - val_loss: 89.2215 - val_mae: 7.1463\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4347 - mae: 6.4774 - val_loss: 89.2176 - val_mae: 7.1534\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4336 - mae: 6.4789 - val_loss: 89.2178 - val_mae: 7.1528\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4259 - mae: 6.4773 - val_loss: 89.2180 - val_mae: 7.1521\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4314 - mae: 6.4814 - val_loss: 89.2165 - val_mae: 7.1586\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4246 - mae: 6.4806 - val_loss: 89.2170 - val_mae: 7.1550\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 80.4596 - mae: 6.4845 - val_loss: 89.2165 - val_mae: 7.1575\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 80.4750 - mae: 6.4708 - val_loss: 89.2200 - val_mae: 7.1481\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4496 - mae: 6.4802 - val_loss: 89.2170 - val_mae: 7.1542\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4531 - mae: 6.4720 - val_loss: 89.2179 - val_mae: 7.1516\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4381 - mae: 6.4707 - val_loss: 89.2178 - val_mae: 7.1519\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 80.4307 - mae: 6.4766 - val_loss: 89.2161 - val_mae: 7.1600\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4279 - mae: 6.4819 - val_loss: 89.2161 - val_mae: 7.1587\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4602 - mae: 6.4725 - val_loss: 89.2211 - val_mae: 7.1460\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4672 - mae: 6.4809 - val_loss: 89.2175 - val_mae: 7.1520\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4241 - mae: 6.4756 - val_loss: 89.2162 - val_mae: 7.1558\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4237 - mae: 6.4762 - val_loss: 89.2159 - val_mae: 7.1582\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4297 - mae: 6.4821 - val_loss: 89.2160 - val_mae: 7.1624\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4310 - mae: 6.4780 - val_loss: 89.2157 - val_mae: 7.1581\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4472 - mae: 6.4806 - val_loss: 89.2159 - val_mae: 7.1558\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4528 - mae: 6.4776 - val_loss: 89.2155 - val_mae: 7.1602\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4476 - mae: 6.4781 - val_loss: 89.2154 - val_mae: 7.1604\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4373 - mae: 6.4863 - val_loss: 89.2162 - val_mae: 7.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4331 - mae: 6.4785 - val_loss: 89.2155 - val_mae: 7.1558\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4234 - mae: 6.4782 - val_loss: 89.2158 - val_mae: 7.1540\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4269 - mae: 6.4776 - val_loss: 89.2150 - val_mae: 7.1573\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4331 - mae: 6.4793 - val_loss: 89.2160 - val_mae: 7.1527\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4372 - mae: 6.4806 - val_loss: 89.2147 - val_mae: 7.1576\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4314 - mae: 6.4823 - val_loss: 89.2152 - val_mae: 7.1540\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4176 - mae: 6.4761 - val_loss: 89.2151 - val_mae: 7.1538\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4518 - mae: 6.4748 - val_loss: 89.2143 - val_mae: 7.1564\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4516 - mae: 6.4819 - val_loss: 89.2142 - val_mae: 7.1625\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4496 - mae: 6.4733 - val_loss: 89.2161 - val_mae: 7.1497\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4496 - mae: 6.4818 - val_loss: 89.2134 - val_mae: 7.1601\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4154 - mae: 6.4774 - val_loss: 89.2138 - val_mae: 7.1541\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4193 - mae: 6.4714 - val_loss: 89.2162 - val_mae: 7.1481\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4386 - mae: 6.4788 - val_loss: 89.2128 - val_mae: 7.1553\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4231 - mae: 6.4731 - val_loss: 89.2146 - val_mae: 7.1494\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4265 - mae: 6.4720 - val_loss: 89.2134 - val_mae: 7.1509\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4335 - mae: 6.4677 - val_loss: 89.2171 - val_mae: 7.1442\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4254 - mae: 6.4735 - val_loss: 89.2115 - val_mae: 7.1526\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4611 - mae: 6.4704 - val_loss: 89.2112 - val_mae: 7.1516\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4247 - mae: 6.4737 - val_loss: 89.2093 - val_mae: 7.1551\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4219 - mae: 6.4737 - val_loss: 89.2084 - val_mae: 7.1543\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4361 - mae: 6.4848 - val_loss: 89.2071 - val_mae: 7.1615\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4466 - mae: 6.4738 - val_loss: 89.2096 - val_mae: 7.1459\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.4365 - mae: 6.4774 - val_loss: 89.2035 - val_mae: 7.1595\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4280 - mae: 6.4734 - val_loss: 89.2018 - val_mae: 7.1526\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4209 - mae: 6.4826 - val_loss: 89.1982 - val_mae: 7.1610\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.3934 - mae: 6.4783 - val_loss: 89.1931 - val_mae: 7.1560\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4005 - mae: 6.4754 - val_loss: 89.1859 - val_mae: 7.1551\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.3899 - mae: 6.4769 - val_loss: 89.1745 - val_mae: 7.1564\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4570 - mae: 6.4671 - val_loss: 89.1529 - val_mae: 7.1470\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.3632 - mae: 6.4708 - val_loss: 89.0961 - val_mae: 7.1451\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 80.2712 - mae: 6.4716 - val_loss: 88.9162 - val_mae: 7.1391\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 79.8163 - mae: 6.4293 - val_loss: 87.3969 - val_mae: 7.0129\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 75.8725 - mae: 6.0612 - val_loss: 77.3646 - val_mae: 6.1971\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 66.5947 - mae: 5.3837 - val_loss: 69.7182 - val_mae: 5.4659\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 62.0508 - mae: 5.1293 - val_loss: 66.3856 - val_mae: 5.2262\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 59.1673 - mae: 5.0425 - val_loss: 64.1821 - val_mae: 5.0690\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 57.1257 - mae: 4.9465 - val_loss: 61.9677 - val_mae: 4.9829\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 55.4776 - mae: 4.9164 - val_loss: 60.0947 - val_mae: 4.8162\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 53.9754 - mae: 4.8604 - val_loss: 58.5924 - val_mae: 4.8658\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 52.5396 - mae: 4.7979 - val_loss: 57.1041 - val_mae: 4.7562\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 51.0310 - mae: 4.6857 - val_loss: 55.7468 - val_mae: 4.7667\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 49.7304 - mae: 4.6804 - val_loss: 54.3997 - val_mae: 4.6763\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 48.1826 - mae: 4.6138 - val_loss: 53.5313 - val_mae: 4.5064\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 46.5872 - mae: 4.4602 - val_loss: 51.7991 - val_mae: 4.5666\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 72.2391 - mae: 5.5103\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 13.6142 - mae: 13.6142 - val_loss: 9.2655 - val_mae: 9.2655\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.4728 - mae: 8.4728 - val_loss: 7.9993 - val_mae: 7.9993\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.4431 - mae: 7.4431 - val_loss: 7.4251 - val_mae: 7.4251\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8703 - mae: 6.8703 - val_loss: 7.0791 - val_mae: 7.0791\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.5777 - mae: 6.5777 - val_loss: 6.9489 - val_mae: 6.9489\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4620 - mae: 6.4620 - val_loss: 6.9217 - val_mae: 6.9217\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.4276 - mae: 6.4276 - val_loss: 6.9220 - val_mae: 6.9220\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.4057 - mae: 6.4057 - val_loss: 6.9254 - val_mae: 6.9254\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3974 - mae: 6.3974 - val_loss: 6.9337 - val_mae: 6.9337\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3952 - mae: 6.3952 - val_loss: 6.9389 - val_mae: 6.9389\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3928 - mae: 6.3928 - val_loss: 6.9526 - val_mae: 6.9526\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9489 - val_mae: 6.9489\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3903 - mae: 6.3903 - val_loss: 6.9627 - val_mae: 6.9627\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9627 - val_mae: 6.9627\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9672 - val_mae: 6.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9711 - val_mae: 6.9711\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3900 - mae: 6.3900 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9750 - val_mae: 6.9750\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9781 - val_mae: 6.9781\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9776 - val_mae: 6.9776\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9716 - val_mae: 6.9716\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3896 - mae: 6.3896 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9646 - val_mae: 6.9646\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9711 - val_mae: 6.9711\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9682 - val_mae: 6.9682\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9669 - val_mae: 6.9669\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3865 - mae: 6.3865 - val_loss: 6.9724 - val_mae: 6.9724\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9728 - val_mae: 6.9728\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9746 - val_mae: 6.9746\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9750 - val_mae: 6.9750\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9708 - val_mae: 6.9708\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9724 - val_mae: 6.9724\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9626 - val_mae: 6.9626\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3859 - mae: 6.3859 - val_loss: 6.9703 - val_mae: 6.9703\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3851 - mae: 6.3851 - val_loss: 6.9673 - val_mae: 6.9673\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9676 - val_mae: 6.9676\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3809 - mae: 6.3809 - val_loss: 6.9548 - val_mae: 6.9548\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3668 - mae: 6.3668 - val_loss: 6.9194 - val_mae: 6.9194\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2544 - mae: 6.2544 - val_loss: 6.4777 - val_mae: 6.4777\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.8316 - mae: 5.8316 - val_loss: 5.7703 - val_mae: 5.7703\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.4868 - mae: 5.4868 - val_loss: 5.3828 - val_mae: 5.3828\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.2594 - mae: 5.2594 - val_loss: 5.2307 - val_mae: 5.2307\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0748 - mae: 5.0748 - val_loss: 5.1926 - val_mae: 5.1926\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9668 - mae: 4.9668 - val_loss: 5.1318 - val_mae: 5.1318\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9133 - mae: 4.9133 - val_loss: 5.0900 - val_mae: 5.0900\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8598 - mae: 4.8598 - val_loss: 5.0458 - val_mae: 5.0458\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8152 - mae: 4.8152 - val_loss: 5.0263 - val_mae: 5.0263\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7828 - mae: 4.7828 - val_loss: 5.0603 - val_mae: 5.0603\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7761 - mae: 4.7761 - val_loss: 4.9622 - val_mae: 4.9622\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7466 - mae: 4.7466 - val_loss: 4.9800 - val_mae: 4.9800\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7294 - mae: 4.7294 - val_loss: 4.9281 - val_mae: 4.9281\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7150 - mae: 4.7150 - val_loss: 4.8576 - val_mae: 4.8576\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6841 - mae: 4.6841 - val_loss: 4.8006 - val_mae: 4.8006\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6550 - mae: 4.6550 - val_loss: 4.7826 - val_mae: 4.7826\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6261 - mae: 4.6261 - val_loss: 4.7665 - val_mae: 4.7665\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6033 - mae: 4.6033 - val_loss: 4.7362 - val_mae: 4.7362\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5778 - mae: 4.5778 - val_loss: 4.6951 - val_mae: 4.6951\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5318 - mae: 4.5318 - val_loss: 4.6389 - val_mae: 4.6389\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4943 - mae: 4.4943 - val_loss: 4.5923 - val_mae: 4.5923\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4462 - mae: 4.4462 - val_loss: 4.6154 - val_mae: 4.6154\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4321 - mae: 4.4321 - val_loss: 4.5387 - val_mae: 4.5387\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3780 - mae: 4.3780 - val_loss: 4.4653 - val_mae: 4.4653\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3204 - mae: 4.3204 - val_loss: 4.4304 - val_mae: 4.4304\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3026 - mae: 4.3026 - val_loss: 4.4286 - val_mae: 4.4286\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2575 - mae: 4.2575 - val_loss: 4.3966 - val_mae: 4.3966\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2139 - mae: 4.2139 - val_loss: 4.4225 - val_mae: 4.4225\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1661 - mae: 4.1661 - val_loss: 4.3194 - val_mae: 4.3194\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1675 - mae: 4.1675 - val_loss: 4.3113 - val_mae: 4.3113\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1084 - mae: 4.1084 - val_loss: 4.2516 - val_mae: 4.2516\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0898 - mae: 4.0898 - val_loss: 4.2479 - val_mae: 4.2479\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0326 - mae: 4.0326 - val_loss: 4.2355 - val_mae: 4.2355\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0315 - mae: 4.0315 - val_loss: 4.1880 - val_mae: 4.1880\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9825 - mae: 3.9825 - val_loss: 4.1619 - val_mae: 4.1619\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9333 - mae: 3.9333 - val_loss: 4.1806 - val_mae: 4.1806\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9575 - mae: 3.9575 - val_loss: 4.1082 - val_mae: 4.1082\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9115 - mae: 3.9115 - val_loss: 4.0771 - val_mae: 4.0771\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8519 - mae: 3.8519 - val_loss: 4.0405 - val_mae: 4.0405\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.8242 - mae: 3.8242 - val_loss: 4.0578 - val_mae: 4.0578\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4981 - mae: 5.4981\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 274.3340 - mae: 13.7109 - val_loss: 168.1640 - val_mae: 9.6411\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 139.5296 - mae: 8.8119 - val_loss: 133.6169 - val_mae: 8.2883\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 115.5129 - mae: 7.7801 - val_loss: 116.5238 - val_mae: 7.6835\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 102.7204 - mae: 7.1831 - val_loss: 106.5101 - val_mae: 7.3292\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 94.6276 - mae: 6.8323 - val_loss: 100.8633 - val_mae: 7.1090\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 89.6136 - mae: 6.5944 - val_loss: 96.6226 - val_mae: 6.9626\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 86.4864 - mae: 6.4855 - val_loss: 93.9996 - val_mae: 6.9225\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 84.3494 - mae: 6.4181 - val_loss: 92.4431 - val_mae: 6.9253\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 83.1011 - mae: 6.3934 - val_loss: 91.2635 - val_mae: 6.9540\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 82.1737 - mae: 6.3918 - val_loss: 90.6299 - val_mae: 6.9779\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.5929 - mae: 6.3888 - val_loss: 90.1896 - val_mae: 7.0021\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.2439 - mae: 6.3987 - val_loss: 89.8773 - val_mae: 7.0245\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.9958 - mae: 6.4060 - val_loss: 89.6403 - val_mae: 7.0477\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.8038 - mae: 6.4161 - val_loss: 89.5191 - val_mae: 7.0627\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.6702 - mae: 6.4211 - val_loss: 89.4246 - val_mae: 7.0781\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5800 - mae: 6.4276 - val_loss: 89.3503 - val_mae: 7.0931\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5476 - mae: 6.4367 - val_loss: 89.3144 - val_mae: 7.1018\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4972 - mae: 6.4438 - val_loss: 89.2820 - val_mae: 7.1117\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4935 - mae: 6.4526 - val_loss: 89.2530 - val_mae: 7.1238\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5113 - mae: 6.4662 - val_loss: 89.2311 - val_mae: 7.1369\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4472 - mae: 6.4600 - val_loss: 89.2438 - val_mae: 7.1286\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5268 - mae: 6.4711 - val_loss: 89.2201 - val_mae: 7.1483\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4299 - mae: 6.4601 - val_loss: 89.2349 - val_mae: 7.1341\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4507 - mae: 6.4596 - val_loss: 89.2242 - val_mae: 7.1430\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4387 - mae: 6.4655 - val_loss: 89.2232 - val_mae: 7.1441\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4363 - mae: 6.4646 - val_loss: 89.2223 - val_mae: 7.1450\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4271 - mae: 6.4664 - val_loss: 89.2248 - val_mae: 7.1423\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4302 - mae: 6.4720 - val_loss: 89.2199 - val_mae: 7.1483\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4299 - mae: 6.4742 - val_loss: 89.2174 - val_mae: 7.1532\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4472 - mae: 6.4744 - val_loss: 89.2174 - val_mae: 7.1531\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4251 - mae: 6.4705 - val_loss: 89.2209 - val_mae: 7.1466\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4285 - mae: 6.4747 - val_loss: 89.2168 - val_mae: 7.1546\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4216 - mae: 6.4780 - val_loss: 89.2165 - val_mae: 7.1557\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4900 - mae: 6.4692 - val_loss: 89.2195 - val_mae: 7.1484\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4973 - mae: 6.4686 - val_loss: 89.2175 - val_mae: 7.1520\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4351 - mae: 6.4710 - val_loss: 89.2175 - val_mae: 7.1520\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4252 - mae: 6.4733 - val_loss: 89.2167 - val_mae: 7.1540\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4253 - mae: 6.4777 - val_loss: 89.2158 - val_mae: 7.1588\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4542 - mae: 6.4785 - val_loss: 89.2157 - val_mae: 7.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4529 - mae: 6.4850 - val_loss: 89.2158 - val_mae: 7.1616\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4350 - mae: 6.4756 - val_loss: 89.2170 - val_mae: 7.1523\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4190 - mae: 6.4802 - val_loss: 89.2159 - val_mae: 7.1630\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4290 - mae: 6.4816 - val_loss: 89.2155 - val_mae: 7.1616\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4438 - mae: 6.4848 - val_loss: 89.2156 - val_mae: 7.1627\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4163 - mae: 6.4822 - val_loss: 89.2158 - val_mae: 7.1543\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4345 - mae: 6.4736 - val_loss: 89.2179 - val_mae: 7.1492\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4194 - mae: 6.4739 - val_loss: 89.2158 - val_mae: 7.1537\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4392 - mae: 6.4821 - val_loss: 89.2150 - val_mae: 7.1565\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4230 - mae: 6.4840 - val_loss: 89.2148 - val_mae: 7.1616\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4606 - mae: 6.4728 - val_loss: 89.2160 - val_mae: 7.1520\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4250 - mae: 6.4793 - val_loss: 89.2145 - val_mae: 7.1566\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4626 - mae: 6.4855 - val_loss: 89.2151 - val_mae: 7.1649\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4149 - mae: 6.4856 - val_loss: 89.2142 - val_mae: 7.1625\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4145 - mae: 6.4779 - val_loss: 89.2153 - val_mae: 7.1516\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4115 - mae: 6.4738 - val_loss: 89.2148 - val_mae: 7.1521\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4327 - mae: 6.4713 - val_loss: 89.2165 - val_mae: 7.1483\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4302 - mae: 6.4784 - val_loss: 89.2138 - val_mae: 7.1534\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4317 - mae: 6.4758 - val_loss: 89.2127 - val_mae: 7.1564\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4466 - mae: 6.4791 - val_loss: 89.2135 - val_mae: 7.1522\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4172 - mae: 6.4775 - val_loss: 89.2118 - val_mae: 7.1587\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4162 - mae: 6.4798 - val_loss: 89.2113 - val_mae: 7.1588\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4094 - mae: 6.4812 - val_loss: 89.2108 - val_mae: 7.1605\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4653 - mae: 6.4933 - val_loss: 89.2130 - val_mae: 7.1687\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4578 - mae: 6.4922 - val_loss: 89.2095 - val_mae: 7.1597\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4585 - mae: 6.4929 - val_loss: 89.2092 - val_mae: 7.1627\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4504 - mae: 6.4761 - val_loss: 89.2089 - val_mae: 7.1525\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4627 - mae: 6.4889 - val_loss: 89.2087 - val_mae: 7.1665\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4227 - mae: 6.4810 - val_loss: 89.2056 - val_mae: 7.1572\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4124 - mae: 6.4802 - val_loss: 89.2040 - val_mae: 7.1594\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4433 - mae: 6.4732 - val_loss: 89.2029 - val_mae: 7.1527\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4353 - mae: 6.4835 - val_loss: 89.2005 - val_mae: 7.1627\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4175 - mae: 6.4843 - val_loss: 89.1965 - val_mae: 7.1566\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4239 - mae: 6.4816 - val_loss: 89.1931 - val_mae: 7.1610\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4038 - mae: 6.4776 - val_loss: 89.1862 - val_mae: 7.1564\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4277 - mae: 6.4850 - val_loss: 89.1773 - val_mae: 7.1567\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4425 - mae: 6.4646 - val_loss: 89.1658 - val_mae: 7.1391\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4221 - mae: 6.4797 - val_loss: 89.1331 - val_mae: 7.1520\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.3743 - mae: 6.4717 - val_loss: 89.0670 - val_mae: 7.1478\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.2389 - mae: 6.4550 - val_loss: 88.8234 - val_mae: 7.1214\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 79.7917 - mae: 6.4192 - val_loss: 87.3482 - val_mae: 6.9974\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 75.6135 - mae: 6.1042 - val_loss: 77.3505 - val_mae: 6.0464\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 66.8912 - mae: 5.4162 - val_loss: 69.8527 - val_mae: 5.3511\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 62.0113 - mae: 5.1330 - val_loss: 67.0991 - val_mae: 5.4010\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 59.5517 - mae: 5.0769 - val_loss: 64.2751 - val_mae: 5.1616\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 57.2840 - mae: 4.9826 - val_loss: 62.1413 - val_mae: 4.9882\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 55.6235 - mae: 4.9080 - val_loss: 60.3278 - val_mae: 4.7953\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 54.5085 - mae: 4.9093 - val_loss: 58.7719 - val_mae: 4.7380\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.8605 - mae: 4.8028 - val_loss: 57.3731 - val_mae: 4.7553\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 51.3769 - mae: 4.7349 - val_loss: 56.2733 - val_mae: 4.8560\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 50.0833 - mae: 4.7407 - val_loss: 54.8594 - val_mae: 4.6290\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 48.2710 - mae: 4.5868 - val_loss: 53.5799 - val_mae: 4.7265\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 46.9575 - mae: 4.5073 - val_loss: 52.3502 - val_mae: 4.6360\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 45.3180 - mae: 4.4427 - val_loss: 51.3803 - val_mae: 4.4384\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 43.8455 - mae: 4.3170 - val_loss: 49.7202 - val_mae: 4.4918\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 42.6418 - mae: 4.2626 - val_loss: 48.4829 - val_mae: 4.4111\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.6668 - mae: 4.2407 - val_loss: 47.4137 - val_mae: 4.2457\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.0924 - mae: 4.1101 - val_loss: 45.8546 - val_mae: 4.2705\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 39.2293 - mae: 4.0971 - val_loss: 44.6776 - val_mae: 4.1967\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 37.9914 - mae: 4.0018 - val_loss: 43.3684 - val_mae: 4.0754\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 36.8035 - mae: 3.9217 - val_loss: 42.1162 - val_mae: 4.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 58.4838 - mae: 4.8540\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 13.7003 - mae: 13.7003 - val_loss: 9.6565 - val_mae: 9.6565\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.7282 - mae: 8.7282 - val_loss: 8.1271 - val_mae: 8.1271\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.5297 - mae: 7.5297 - val_loss: 7.4742 - val_mae: 7.4742\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.9169 - mae: 6.9169 - val_loss: 7.1052 - val_mae: 7.1052\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6024 - mae: 6.6024 - val_loss: 6.9608 - val_mae: 6.9608\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4714 - mae: 6.4714 - val_loss: 6.9219 - val_mae: 6.9219\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4202 - mae: 6.4202 - val_loss: 6.9205 - val_mae: 6.9205\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4020 - mae: 6.4020 - val_loss: 6.9295 - val_mae: 6.9295\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3968 - mae: 6.3968 - val_loss: 6.9383 - val_mae: 6.9383\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3921 - mae: 6.3921 - val_loss: 6.9421 - val_mae: 6.9421\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3946 - mae: 6.3946 - val_loss: 6.9520 - val_mae: 6.9520\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3900 - mae: 6.3900 - val_loss: 6.9549 - val_mae: 6.9549\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9614 - val_mae: 6.9614\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9577 - val_mae: 6.9577\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9680 - val_mae: 6.9680\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3938 - mae: 6.3938 - val_loss: 6.9621 - val_mae: 6.9621\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9660 - val_mae: 6.9660\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9688 - val_mae: 6.9688\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9712 - val_mae: 6.9712\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9724 - val_mae: 6.9724\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3900 - mae: 6.3900 - val_loss: 6.9772 - val_mae: 6.9772\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9768 - val_mae: 6.9768\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9698 - val_mae: 6.9698\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9769 - val_mae: 6.9769\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9759 - val_mae: 6.9759\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3916 - mae: 6.3916 - val_loss: 6.9775 - val_mae: 6.9775\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9737 - val_mae: 6.9737\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9720 - val_mae: 6.9720\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9730 - val_mae: 6.9730\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9720 - val_mae: 6.9720\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9679 - val_mae: 6.9679\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3911 - mae: 6.3911 - val_loss: 6.9633 - val_mae: 6.9633\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9720 - val_mae: 6.9720\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9675 - val_mae: 6.9675\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3900 - mae: 6.3900 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3908 - mae: 6.3908 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9710 - val_mae: 6.9710\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3908 - mae: 6.3908 - val_loss: 6.9615 - val_mae: 6.9615\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9672 - val_mae: 6.9672\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3855 - mae: 6.3855 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3841 - mae: 6.3841 - val_loss: 6.9658 - val_mae: 6.9658\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3804 - mae: 6.3804 - val_loss: 6.9550 - val_mae: 6.9550\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3578 - mae: 6.3578 - val_loss: 6.8714 - val_mae: 6.8714\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.1036 - mae: 6.1036 - val_loss: 6.0762 - val_mae: 6.0762\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.5729 - mae: 5.5729 - val_loss: 5.4286 - val_mae: 5.4286\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3494 - mae: 5.3494 - val_loss: 5.4760 - val_mae: 5.4760\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1090 - mae: 5.1090 - val_loss: 5.2339 - val_mae: 5.2339\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9665 - mae: 4.9665 - val_loss: 5.1789 - val_mae: 5.1789\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9087 - mae: 4.9087 - val_loss: 5.1639 - val_mae: 5.1639\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8630 - mae: 4.8630 - val_loss: 5.1008 - val_mae: 5.1008\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8263 - mae: 4.8263 - val_loss: 5.0833 - val_mae: 5.0833\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8185 - mae: 4.8185 - val_loss: 5.0653 - val_mae: 5.0653\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7925 - mae: 4.7925 - val_loss: 5.0661 - val_mae: 5.0661\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7874 - mae: 4.7874 - val_loss: 5.0215 - val_mae: 5.0215\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7509 - mae: 4.7509 - val_loss: 4.9971 - val_mae: 4.9971\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7620 - mae: 4.7620 - val_loss: 4.9592 - val_mae: 4.9592\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7095 - mae: 4.7095 - val_loss: 4.9726 - val_mae: 4.9726\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6913 - mae: 4.6913 - val_loss: 4.9337 - val_mae: 4.9337\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6814 - mae: 4.6814 - val_loss: 4.8515 - val_mae: 4.8515\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6525 - mae: 4.6525 - val_loss: 4.9000 - val_mae: 4.9000\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6373 - mae: 4.6373 - val_loss: 4.8038 - val_mae: 4.8038\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6254 - mae: 4.6254 - val_loss: 4.7668 - val_mae: 4.7668\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5856 - mae: 4.5856 - val_loss: 4.7552 - val_mae: 4.7552\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5471 - mae: 4.5471 - val_loss: 4.8501 - val_mae: 4.8501\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5446 - mae: 4.5446 - val_loss: 4.7238 - val_mae: 4.7238\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5002 - mae: 4.5002 - val_loss: 4.6409 - val_mae: 4.6409\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4681 - mae: 4.4681 - val_loss: 4.5642 - val_mae: 4.5642\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4423 - mae: 4.4423 - val_loss: 4.5613 - val_mae: 4.5613\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4004 - mae: 4.4004 - val_loss: 4.5701 - val_mae: 4.5701\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3719 - mae: 4.3719 - val_loss: 4.4750 - val_mae: 4.4750\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3263 - mae: 4.3263 - val_loss: 4.4454 - val_mae: 4.4454\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2888 - mae: 4.2888 - val_loss: 4.4119 - val_mae: 4.4119\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2654 - mae: 4.2654 - val_loss: 4.3847 - val_mae: 4.3847\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2272 - mae: 4.2272 - val_loss: 4.3649 - val_mae: 4.3649\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2034 - mae: 4.2034 - val_loss: 4.3438 - val_mae: 4.3438\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1407 - mae: 4.1407 - val_loss: 4.3486 - val_mae: 4.3486\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9762 - mae: 5.9762\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 7ms/step - loss: 282.0837 - mae: 13.8838 - val_loss: 175.5693 - val_mae: 9.9415\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 146.7421 - mae: 9.1337 - val_loss: 139.1239 - val_mae: 8.4946\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 121.4715 - mae: 8.0504 - val_loss: 122.4315 - val_mae: 7.8966\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 107.3400 - mae: 7.4156 - val_loss: 110.9346 - val_mae: 7.4891\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 98.2028 - mae: 7.0013 - val_loss: 103.8934 - val_mae: 7.2249\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 92.4670 - mae: 6.7081 - val_loss: 99.0716 - val_mae: 7.0399\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 88.5550 - mae: 6.5533 - val_loss: 95.9733 - val_mae: 6.9522\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 85.9521 - mae: 6.4641 - val_loss: 93.8804 - val_mae: 6.9218\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 84.1782 - mae: 6.4017 - val_loss: 92.4526 - val_mae: 6.9251\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 82.9867 - mae: 6.3958 - val_loss: 91.3766 - val_mae: 6.9501\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 82.2082 - mae: 6.3884 - val_loss: 90.6504 - val_mae: 6.9771\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.6479 - mae: 6.3897 - val_loss: 90.2568 - val_mae: 6.9981\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.2605 - mae: 6.3939 - val_loss: 89.9018 - val_mae: 7.0224\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 81.0024 - mae: 6.4026 - val_loss: 89.6920 - val_mae: 7.0422\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.8590 - mae: 6.4147 - val_loss: 89.5267 - val_mae: 7.0616\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.7028 - mae: 6.4204 - val_loss: 89.4593 - val_mae: 7.0721\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.6713 - mae: 6.4200 - val_loss: 89.4199 - val_mae: 7.0790\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5655 - mae: 6.4255 - val_loss: 89.3545 - val_mae: 7.0921\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.5148 - mae: 6.4386 - val_loss: 89.3022 - val_mae: 7.1051\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.5282 - mae: 6.4499 - val_loss: 89.2682 - val_mae: 7.1170\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4612 - mae: 6.4458 - val_loss: 89.2567 - val_mae: 7.1220\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4397 - mae: 6.4526 - val_loss: 89.2458 - val_mae: 7.1275\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4590 - mae: 6.4633 - val_loss: 89.2262 - val_mae: 7.1412\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4370 - mae: 6.4671 - val_loss: 89.2242 - val_mae: 7.1432\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4805 - mae: 6.4737 - val_loss: 89.2211 - val_mae: 7.1469\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4443 - mae: 6.4630 - val_loss: 89.2318 - val_mae: 7.1363\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4605 - mae: 6.4711 - val_loss: 89.2207 - val_mae: 7.1474\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4302 - mae: 6.4721 - val_loss: 89.2209 - val_mae: 7.1469\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4301 - mae: 6.4656 - val_loss: 89.2248 - val_mae: 7.1424\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4296 - mae: 6.4628 - val_loss: 89.2247 - val_mae: 7.1424\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4312 - mae: 6.4721 - val_loss: 89.2183 - val_mae: 7.1513\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4405 - mae: 6.4679 - val_loss: 89.2214 - val_mae: 7.1461\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4231 - mae: 6.4749 - val_loss: 89.2180 - val_mae: 7.1516\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4290 - mae: 6.4723 - val_loss: 89.2200 - val_mae: 7.1480\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4062 - mae: 6.4756 - val_loss: 89.2162 - val_mae: 7.1595\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4433 - mae: 6.4873 - val_loss: 89.2173 - val_mae: 7.1656\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4220 - mae: 6.4784 - val_loss: 89.2165 - val_mae: 7.1557\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4617 - mae: 6.4741 - val_loss: 89.2168 - val_mae: 7.1542\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4234 - mae: 6.4787 - val_loss: 89.2163 - val_mae: 7.1557\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4197 - mae: 6.4784 - val_loss: 89.2160 - val_mae: 7.1578\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4392 - mae: 6.4788 - val_loss: 89.2178 - val_mae: 7.1510\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4966 - mae: 6.4668 - val_loss: 89.2199 - val_mae: 7.1472\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4626 - mae: 6.4776 - val_loss: 89.2181 - val_mae: 7.1501\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4405 - mae: 6.4804 - val_loss: 89.2157 - val_mae: 7.1614\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4307 - mae: 6.4775 - val_loss: 89.2172 - val_mae: 7.1514\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4561 - mae: 6.4772 - val_loss: 89.2156 - val_mae: 7.1563\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4315 - mae: 6.4757 - val_loss: 89.2159 - val_mae: 7.1546\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4309 - mae: 6.4725 - val_loss: 89.2177 - val_mae: 7.1499\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4181 - mae: 6.4727 - val_loss: 89.2156 - val_mae: 7.1549\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4488 - mae: 6.4801 - val_loss: 89.2159 - val_mae: 7.1535\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4125 - mae: 6.4763 - val_loss: 89.2148 - val_mae: 7.1580\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4829 - mae: 6.4755 - val_loss: 89.2168 - val_mae: 7.1504\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4277 - mae: 6.4778 - val_loss: 89.2147 - val_mae: 7.1561\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4517 - mae: 6.4726 - val_loss: 89.2153 - val_mae: 7.1532\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4973 - mae: 6.4905 - val_loss: 89.2152 - val_mae: 7.1651\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4148 - mae: 6.4815 - val_loss: 89.2140 - val_mae: 7.1582\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4426 - mae: 6.4725 - val_loss: 89.2152 - val_mae: 7.1518\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4169 - mae: 6.4771 - val_loss: 89.2140 - val_mae: 7.1549\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4193 - mae: 6.4762 - val_loss: 89.2146 - val_mae: 7.1522\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4367 - mae: 6.4778 - val_loss: 89.2131 - val_mae: 7.1565\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4423 - mae: 6.4760 - val_loss: 89.2130 - val_mae: 7.1554\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4227 - mae: 6.4834 - val_loss: 89.2126 - val_mae: 7.1622\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4435 - mae: 6.4822 - val_loss: 89.2127 - val_mae: 7.1537\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4759 - mae: 6.4700 - val_loss: 89.2123 - val_mae: 7.1535\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4279 - mae: 6.4792 - val_loss: 89.2112 - val_mae: 7.1560\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4677 - mae: 6.4734 - val_loss: 89.2106 - val_mae: 7.1563\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4297 - mae: 6.4746 - val_loss: 89.2101 - val_mae: 7.1560\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4106 - mae: 6.4788 - val_loss: 89.2092 - val_mae: 7.1573\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4238 - mae: 6.4823 - val_loss: 89.2096 - val_mae: 7.1650\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4088 - mae: 6.4855 - val_loss: 89.2084 - val_mae: 7.1643\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4356 - mae: 6.4799 - val_loss: 89.2062 - val_mae: 7.1578\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4089 - mae: 6.4794 - val_loss: 89.2049 - val_mae: 7.1594\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4186 - mae: 6.4770 - val_loss: 89.2033 - val_mae: 7.1573\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4181 - mae: 6.4837 - val_loss: 89.2013 - val_mae: 7.1602\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 80.4101 - mae: 6.4805 - val_loss: 89.1989 - val_mae: 7.1610\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4197 - mae: 6.4856 - val_loss: 89.1968 - val_mae: 7.1651\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.3940 - mae: 6.4824 - val_loss: 89.1901 - val_mae: 7.1593\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4446 - mae: 6.4723 - val_loss: 89.1826 - val_mae: 7.1524\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.4264 - mae: 6.4735 - val_loss: 89.1710 - val_mae: 7.1508\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.3815 - mae: 6.4713 - val_loss: 89.1492 - val_mae: 7.1504\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.3543 - mae: 6.4691 - val_loss: 89.1016 - val_mae: 7.1436\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.2966 - mae: 6.4699 - val_loss: 89.0027 - val_mae: 7.1480\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 80.1337 - mae: 6.4571 - val_loss: 88.5445 - val_mae: 7.1144\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 78.8011 - mae: 6.3505 - val_loss: 84.4961 - val_mae: 6.7697\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 72.0247 - mae: 5.8204 - val_loss: 74.3531 - val_mae: 5.8825\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 65.1164 - mae: 5.2930 - val_loss: 68.7430 - val_mae: 5.2929\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 61.6623 - mae: 5.1572 - val_loss: 66.1265 - val_mae: 5.2484\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 59.0890 - mae: 5.0557 - val_loss: 63.7103 - val_mae: 4.9683\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 57.0510 - mae: 4.9206 - val_loss: 61.8987 - val_mae: 5.0258\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 55.3732 - mae: 4.9213 - val_loss: 60.1703 - val_mae: 4.9152\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 53.9007 - mae: 4.8052 - val_loss: 58.3139 - val_mae: 4.7856\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 52.3008 - mae: 4.7439 - val_loss: 57.1014 - val_mae: 4.8446\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 50.8264 - mae: 4.7009 - val_loss: 55.4427 - val_mae: 4.7310\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 49.0948 - mae: 4.6031 - val_loss: 54.2517 - val_mae: 4.6158\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 47.7104 - mae: 4.5069 - val_loss: 53.3577 - val_mae: 4.5010\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 46.3073 - mae: 4.4583 - val_loss: 51.6903 - val_mae: 4.5500\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 44.6834 - mae: 4.3518 - val_loss: 50.4469 - val_mae: 4.4521\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 43.1799 - mae: 4.2705 - val_loss: 48.9714 - val_mae: 4.4311\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 41.8235 - mae: 4.1811 - val_loss: 47.5662 - val_mae: 4.3340\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 40.9159 - mae: 4.1308 - val_loss: 46.3636 - val_mae: 4.1897\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 65.8702 - mae: 5.2182\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 6ms/step - loss: 14.6746 - mae: 14.6746 - val_loss: 10.1576 - val_mae: 10.1576\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 9.2355 - mae: 9.2355 - val_loss: 8.5409 - val_mae: 8.5409\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 8.0298 - mae: 8.0298 - val_loss: 7.8182 - val_mae: 7.8182\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 7.3119 - mae: 7.3119 - val_loss: 7.4044 - val_mae: 7.4044\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.8875 - mae: 6.8875 - val_loss: 7.1267 - val_mae: 7.1267\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.6252 - mae: 6.6252 - val_loss: 6.9734 - val_mae: 6.9734\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4943 - mae: 6.4943 - val_loss: 6.9314 - val_mae: 6.9314\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4356 - mae: 6.4356 - val_loss: 6.9205 - val_mae: 6.9205\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4130 - mae: 6.4130 - val_loss: 6.9208 - val_mae: 6.9208\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.4011 - mae: 6.4011 - val_loss: 6.9282 - val_mae: 6.9282\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3976 - mae: 6.3976 - val_loss: 6.9372 - val_mae: 6.9372\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3953 - mae: 6.3953 - val_loss: 6.9418 - val_mae: 6.9418\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9469 - val_mae: 6.9469\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3894 - mae: 6.3894 - val_loss: 6.9513 - val_mae: 6.9513\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9547 - val_mae: 6.9547\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9602 - val_mae: 6.9602\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9598 - val_mae: 6.9598\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9623 - val_mae: 6.9623\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9665 - val_mae: 6.9665\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3903 - mae: 6.3903 - val_loss: 6.9679 - val_mae: 6.9679\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9679 - val_mae: 6.9679\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9721 - val_mae: 6.9721\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9704 - val_mae: 6.9704\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9680 - val_mae: 6.9680\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9715 - val_mae: 6.9715\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9680 - val_mae: 6.9680\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9700 - val_mae: 6.9700\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9641 - val_mae: 6.9641\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9673 - val_mae: 6.9673\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9665 - val_mae: 6.9665\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9738 - val_mae: 6.9738\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9698 - val_mae: 6.9698\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9734 - val_mae: 6.9734\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9751 - val_mae: 6.9751\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9713 - val_mae: 6.9713\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9678 - val_mae: 6.9678\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9659 - val_mae: 6.9659\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9686 - val_mae: 6.9686\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3864 - mae: 6.3864 - val_loss: 6.9663 - val_mae: 6.9663\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9659 - val_mae: 6.9659\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3858 - mae: 6.3858 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3862 - mae: 6.3862 - val_loss: 6.9694 - val_mae: 6.9694\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3863 - mae: 6.3863 - val_loss: 6.9689 - val_mae: 6.9689\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3859 - mae: 6.3859 - val_loss: 6.9710 - val_mae: 6.9710\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3861 - mae: 6.3861 - val_loss: 6.9689 - val_mae: 6.9689\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9661 - val_mae: 6.9661\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3855 - mae: 6.3855 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3856 - mae: 6.3856 - val_loss: 6.9666 - val_mae: 6.9666\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3810 - mae: 6.3810 - val_loss: 6.9595 - val_mae: 6.9595\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.3702 - mae: 6.3702 - val_loss: 6.9220 - val_mae: 6.9220\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 6.2342 - mae: 6.2342 - val_loss: 6.4002 - val_mae: 6.4002\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.7373 - mae: 5.7373 - val_loss: 5.5569 - val_mae: 5.5569\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.3615 - mae: 5.3615 - val_loss: 5.2539 - val_mae: 5.2539\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.1558 - mae: 5.1558 - val_loss: 5.1816 - val_mae: 5.1816\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 5.0240 - mae: 5.0240 - val_loss: 5.1108 - val_mae: 5.1108\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.9392 - mae: 4.9392 - val_loss: 5.0354 - val_mae: 5.0354\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8464 - mae: 4.8464 - val_loss: 4.9878 - val_mae: 4.9878\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.8084 - mae: 4.8084 - val_loss: 4.9290 - val_mae: 4.9290\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7728 - mae: 4.7728 - val_loss: 4.8873 - val_mae: 4.8873\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.7293 - mae: 4.7293 - val_loss: 4.9157 - val_mae: 4.9157\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6986 - mae: 4.6986 - val_loss: 4.8342 - val_mae: 4.8342\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6687 - mae: 4.6687 - val_loss: 4.7857 - val_mae: 4.7857\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6552 - mae: 4.6552 - val_loss: 4.7758 - val_mae: 4.7758\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.6373 - mae: 4.6373 - val_loss: 4.6968 - val_mae: 4.6968\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5705 - mae: 4.5705 - val_loss: 4.7527 - val_mae: 4.7527\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5403 - mae: 4.5403 - val_loss: 4.6370 - val_mae: 4.6370\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.5037 - mae: 4.5037 - val_loss: 4.6185 - val_mae: 4.6185\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4693 - mae: 4.4693 - val_loss: 4.5462 - val_mae: 4.5462\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.4240 - mae: 4.4240 - val_loss: 4.4890 - val_mae: 4.4890\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3805 - mae: 4.3805 - val_loss: 4.6270 - val_mae: 4.6270\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.3252 - mae: 4.3252 - val_loss: 4.4621 - val_mae: 4.4621\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2944 - mae: 4.2944 - val_loss: 4.4228 - val_mae: 4.4228\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2643 - mae: 4.2643 - val_loss: 4.3805 - val_mae: 4.3805\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2296 - mae: 4.2296 - val_loss: 4.4190 - val_mae: 4.4190\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.2064 - mae: 4.2064 - val_loss: 4.3605 - val_mae: 4.3605\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1488 - mae: 4.1488 - val_loss: 4.2950 - val_mae: 4.2950\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.1173 - mae: 4.1173 - val_loss: 4.2538 - val_mae: 4.2538\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0733 - mae: 4.0733 - val_loss: 4.2846 - val_mae: 4.2846\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0615 - mae: 4.0615 - val_loss: 4.2215 - val_mae: 4.2215\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 3.9880 - mae: 3.9880 - val_loss: 4.2187 - val_mae: 4.2187\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 4.0242 - mae: 4.0242 - val_loss: 4.2163 - val_mae: 4.2163\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.3241 - mae: 5.3241\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 146.3623 - mae: 9.0365 - val_loss: 33.3439 - val_mae: 4.1153\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.0316 - mae: 3.3966 - val_loss: 20.6120 - val_mae: 3.0957\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 18.5570 - mae: 3.0138 - val_loss: 17.7163 - val_mae: 2.8115\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 15.4285 - mae: 2.9025 - val_loss: 19.4634 - val_mae: 3.1848\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 12.7530 - mae: 2.6370 - val_loss: 17.3050 - val_mae: 2.9796\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 11.4812 - mae: 2.4707 - val_loss: 14.2942 - val_mae: 2.6371\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 9.7429 - mae: 2.2550 - val_loss: 14.4048 - val_mae: 2.5863\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 10.5103 - mae: 2.4373 - val_loss: 15.7265 - val_mae: 2.6400\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 8.8324 - mae: 2.2380 - val_loss: 13.9782 - val_mae: 2.6103\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.7121 - mae: 2.0616 - val_loss: 13.2849 - val_mae: 2.4996\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 7.0709 - mae: 1.9728 - val_loss: 13.4294 - val_mae: 2.4723\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.6547 - mae: 1.9208 - val_loss: 15.5004 - val_mae: 2.8551\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.5894 - mae: 1.9868 - val_loss: 12.9154 - val_mae: 2.4534\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.7515 - mae: 1.8163 - val_loss: 13.2100 - val_mae: 2.4677\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.6034 - mae: 1.7651 - val_loss: 13.8202 - val_mae: 2.4351\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.3563 - mae: 1.7481 - val_loss: 13.1779 - val_mae: 2.4191\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8822 - mae: 1.6722 - val_loss: 13.0460 - val_mae: 2.4531\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.5602 - mae: 1.6003 - val_loss: 12.8427 - val_mae: 2.5057\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.2634 - mae: 1.5043 - val_loss: 13.7907 - val_mae: 2.4730\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0644 - mae: 1.5086 - val_loss: 13.1067 - val_mae: 2.5167\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.0005 - mae: 1.4819 - val_loss: 13.0014 - val_mae: 2.3170\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8857 - mae: 1.4326 - val_loss: 12.7738 - val_mae: 2.3695\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9768 - mae: 1.4593 - val_loss: 13.2201 - val_mae: 2.3694\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 3.8288 - mae: 1.4665 - val_loss: 13.8644 - val_mae: 2.6627\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9724 - mae: 1.5406 - val_loss: 13.3216 - val_mae: 2.4157\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2423 - mae: 1.3267 - val_loss: 13.2060 - val_mae: 2.4150\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.2176 - mae: 1.3250 - val_loss: 13.2868 - val_mae: 2.5147\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9361 - mae: 1.2679 - val_loss: 13.8220 - val_mae: 2.4441\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.3320 - mae: 1.3731 - val_loss: 14.0937 - val_mae: 2.5183\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.9882 - mae: 1.2760 - val_loss: 12.8514 - val_mae: 2.3571\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 2.7724 - mae: 1.2337 - val_loss: 12.6221 - val_mae: 2.4334\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1664 - mae: 1.3358 - val_loss: 13.8167 - val_mae: 2.4426\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3581 - mae: 1.3834 - val_loss: 13.5366 - val_mae: 2.4032\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5130 - mae: 1.1694 - val_loss: 12.9083 - val_mae: 2.3288\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.4592 - mae: 1.1483 - val_loss: 13.8010 - val_mae: 2.4907\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.7256 - mae: 1.2372 - val_loss: 13.2403 - val_mae: 2.4659\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3035 - mae: 1.1211 - val_loss: 13.0904 - val_mae: 2.4029\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1857 - mae: 1.0711 - val_loss: 13.9334 - val_mae: 2.4507\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.3329 - mae: 1.1593 - val_loss: 12.6008 - val_mae: 2.4173\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1322 - mae: 1.0690 - val_loss: 14.0819 - val_mae: 2.4929\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.1632 - mae: 1.0920 - val_loss: 14.1970 - val_mae: 2.5069\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.2900 - mae: 1.1183 - val_loss: 14.6304 - val_mae: 2.5854\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0421 - mae: 1.0291 - val_loss: 14.1144 - val_mae: 2.5499\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9901 - mae: 1.0277 - val_loss: 12.9207 - val_mae: 2.3329\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0226 - mae: 1.0447 - val_loss: 12.8134 - val_mae: 2.3981\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9267 - mae: 0.9930 - val_loss: 12.6786 - val_mae: 2.3427\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1366 - mae: 1.0774 - val_loss: 13.2018 - val_mae: 2.3373\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8200 - mae: 0.9992 - val_loss: 13.3767 - val_mae: 2.4424\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.7555 - mae: 0.9790 - val_loss: 12.9517 - val_mae: 2.3436\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.5699 - mae: 0.9059 - val_loss: 13.3539 - val_mae: 2.4396\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6065 - mae: 0.9253 - val_loss: 13.2992 - val_mae: 2.4553\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8431 - mae: 0.9630 - val_loss: 13.1443 - val_mae: 2.4130\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0279 - mae: 1.0385 - val_loss: 15.6991 - val_mae: 2.6850\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8023 - mae: 0.9800 - val_loss: 13.3255 - val_mae: 2.4366\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.4221 - mae: 0.8449 - val_loss: 13.0000 - val_mae: 2.4331\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5871 - mae: 0.8984 - val_loss: 13.5830 - val_mae: 2.3918\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5503 - mae: 0.9082 - val_loss: 14.4643 - val_mae: 2.5865\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.7384 - mae: 0.9578 - val_loss: 13.4220 - val_mae: 2.5111\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8801 - mae: 1.0019 - val_loss: 13.7241 - val_mae: 2.4921\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.5387 - mae: 0.8733 - val_loss: 12.5162 - val_mae: 2.3561\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3745 - mae: 0.8382 - val_loss: 13.6246 - val_mae: 2.5287\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2985 - mae: 0.8024 - val_loss: 13.1785 - val_mae: 2.4067\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3312 - mae: 0.8330 - val_loss: 12.4649 - val_mae: 2.3674\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.4919 - mae: 0.8867 - val_loss: 13.0631 - val_mae: 2.4253\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3735 - mae: 0.8167 - val_loss: 14.0518 - val_mae: 2.4961\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.4900 - mae: 0.8510 - val_loss: 13.5348 - val_mae: 2.4903\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3836 - mae: 0.8180 - val_loss: 14.0527 - val_mae: 2.5285\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3903 - mae: 0.8415 - val_loss: 14.0394 - val_mae: 2.5090\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3718 - mae: 0.8545 - val_loss: 13.5236 - val_mae: 2.4793\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1359 - mae: 0.7457 - val_loss: 13.6898 - val_mae: 2.4934\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1486 - mae: 0.7565 - val_loss: 13.8496 - val_mae: 2.3959\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1054 - mae: 0.7516 - val_loss: 12.6190 - val_mae: 2.3828\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2654 - mae: 0.8360 - val_loss: 13.6417 - val_mae: 2.4445\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2225 - mae: 0.8130 - val_loss: 13.2765 - val_mae: 2.4490\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0824 - mae: 0.7288 - val_loss: 13.2985 - val_mae: 2.3749\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1873 - mae: 0.7842 - val_loss: 13.0821 - val_mae: 2.4176\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1748 - mae: 0.7905 - val_loss: 13.3617 - val_mae: 2.4461\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9786 - mae: 0.6731 - val_loss: 14.7902 - val_mae: 2.5476\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6153 - mae: 0.9172 - val_loss: 12.5324 - val_mae: 2.3803\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.9393 - mae: 0.6790 - val_loss: 13.5170 - val_mae: 2.4895\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0106 - mae: 0.7018 - val_loss: 14.5081 - val_mae: 2.4849\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3684 - mae: 0.8077 - val_loss: 14.1600 - val_mae: 2.5191\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.5619 - mae: 0.8886 - val_loss: 14.0596 - val_mae: 2.4486\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1506 - mae: 0.7919 - val_loss: 13.7866 - val_mae: 2.4647\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.9944 - mae: 0.6608 - val_loss: 13.6767 - val_mae: 2.3928\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1265 - mae: 0.7879 - val_loss: 13.7601 - val_mae: 2.5281\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1482 - mae: 0.7931 - val_loss: 12.6765 - val_mae: 2.3983\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0359 - mae: 0.7294 - val_loss: 13.2887 - val_mae: 2.4131\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0284 - mae: 0.7194 - val_loss: 13.2065 - val_mae: 2.3864\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.9321 - mae: 0.6586 - val_loss: 12.9594 - val_mae: 2.3811\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8834 - mae: 0.6437 - val_loss: 14.0100 - val_mae: 2.5083\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8561 - mae: 0.6042 - val_loss: 13.8335 - val_mae: 2.4914\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9886 - mae: 0.6916 - val_loss: 13.7773 - val_mae: 2.5006\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9867 - mae: 0.6811 - val_loss: 13.7977 - val_mae: 2.5061\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9407 - mae: 0.6740 - val_loss: 13.7106 - val_mae: 2.5003\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8899 - mae: 0.6605 - val_loss: 13.2435 - val_mae: 2.4542\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8310 - mae: 0.6293 - val_loss: 14.0296 - val_mae: 2.4904\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7925 - mae: 0.6043 - val_loss: 13.2638 - val_mae: 2.4266\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8499 - mae: 0.6259 - val_loss: 14.0128 - val_mae: 2.4981\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7975 - mae: 0.6164 - val_loss: 14.5886 - val_mae: 2.5116\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.3229 - mae: 3.3298\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 8.5952 - mae: 8.5952 - val_loss: 3.5605 - val_mae: 3.5605\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3538 - mae: 3.3538 - val_loss: 2.9886 - val_mae: 2.9886\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.2013 - mae: 3.2013 - val_loss: 2.8371 - val_mae: 2.8371\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6915 - mae: 2.6915 - val_loss: 2.6958 - val_mae: 2.6958\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.7402 - mae: 2.7402 - val_loss: 3.2244 - val_mae: 3.2244\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.3970 - mae: 2.3970 - val_loss: 2.7024 - val_mae: 2.7024\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3633 - mae: 2.3633 - val_loss: 2.6639 - val_mae: 2.6639\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.4314 - mae: 2.4314 - val_loss: 2.6928 - val_mae: 2.6928\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.3132 - mae: 2.3132 - val_loss: 2.5048 - val_mae: 2.5048\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1322 - mae: 2.1322 - val_loss: 2.6966 - val_mae: 2.6966\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1033 - mae: 2.1033 - val_loss: 2.7159 - val_mae: 2.7159\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0128 - mae: 2.0128 - val_loss: 2.7177 - val_mae: 2.7177\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8888 - mae: 1.8888 - val_loss: 2.4196 - val_mae: 2.4196\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.8465 - mae: 1.8465 - val_loss: 2.4555 - val_mae: 2.4555\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8973 - mae: 1.8973 - val_loss: 2.3434 - val_mae: 2.3434\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.9102 - mae: 1.9102 - val_loss: 2.5615 - val_mae: 2.5615\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7509 - mae: 1.7509 - val_loss: 2.5833 - val_mae: 2.5833\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.2426 - mae: 2.2426 - val_loss: 2.5048 - val_mae: 2.5048\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.7223 - mae: 1.7223 - val_loss: 2.5191 - val_mae: 2.5191\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7695 - mae: 1.7695 - val_loss: 2.3700 - val_mae: 2.3700\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5688 - mae: 1.5688 - val_loss: 2.3909 - val_mae: 2.3909\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.6014 - mae: 1.6014 - val_loss: 2.4860 - val_mae: 2.4860\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6378 - mae: 1.6378 - val_loss: 2.3697 - val_mae: 2.3697\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5860 - mae: 1.5860 - val_loss: 2.4936 - val_mae: 2.4936\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6064 - mae: 1.6064 - val_loss: 2.5759 - val_mae: 2.5759\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4784 - mae: 1.4784 - val_loss: 2.4994 - val_mae: 2.4994\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.3775 - mae: 1.3775 - val_loss: 2.5194 - val_mae: 2.5194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.4027 - mae: 1.4027 - val_loss: 2.4749 - val_mae: 2.4749\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 1.3304 - mae: 1.3304 - val_loss: 2.3752 - val_mae: 2.3752\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.3440 - mae: 1.3440 - val_loss: 2.4595 - val_mae: 2.4595\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3744 - mae: 1.3744 - val_loss: 2.5282 - val_mae: 2.5282\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3388 - mae: 1.3388 - val_loss: 2.5287 - val_mae: 2.5287\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 1.2434 - mae: 1.2434 - val_loss: 2.5443 - val_mae: 2.5443\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2144 - mae: 1.2144 - val_loss: 2.4641 - val_mae: 2.4641\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2330 - mae: 1.2330 - val_loss: 2.3922 - val_mae: 2.3922\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2271 - mae: 1.2271 - val_loss: 2.3750 - val_mae: 2.3750\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2083 - mae: 1.2083 - val_loss: 2.5278 - val_mae: 2.5278\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.1559 - mae: 1.1559 - val_loss: 2.4644 - val_mae: 2.4644\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 1.1688 - mae: 1.1688 - val_loss: 2.5751 - val_mae: 2.5751\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.2404 - mae: 1.2404 - val_loss: 2.4061 - val_mae: 2.4061\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1429 - mae: 1.1429 - val_loss: 2.3334 - val_mae: 2.3334\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1094 - mae: 1.1094 - val_loss: 2.6924 - val_mae: 2.6924\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1237 - mae: 1.1237 - val_loss: 2.4129 - val_mae: 2.4129\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0385 - mae: 1.0385 - val_loss: 2.4995 - val_mae: 2.4995\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0011 - mae: 1.0011 - val_loss: 2.5106 - val_mae: 2.5106\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0593 - mae: 1.0593 - val_loss: 2.4732 - val_mae: 2.4732\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0286 - mae: 1.0286 - val_loss: 2.4347 - val_mae: 2.4347\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0500 - mae: 1.0500 - val_loss: 2.4720 - val_mae: 2.4720\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9999 - mae: 0.9999 - val_loss: 2.4763 - val_mae: 2.4763\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.0078 - mae: 1.0078 - val_loss: 2.5532 - val_mae: 2.5532\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9938 - mae: 0.9938 - val_loss: 2.4634 - val_mae: 2.4634\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9637 - mae: 0.9637 - val_loss: 2.5194 - val_mae: 2.5194\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1013 - mae: 1.1013 - val_loss: 2.4780 - val_mae: 2.4780\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9586 - mae: 0.9586 - val_loss: 2.4856 - val_mae: 2.4856\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.9878 - mae: 0.9878 - val_loss: 2.4074 - val_mae: 2.4074\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9275 - mae: 0.9275 - val_loss: 2.5953 - val_mae: 2.5953\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0344 - mae: 1.0344 - val_loss: 2.4828 - val_mae: 2.4828\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9377 - mae: 0.9377 - val_loss: 2.4133 - val_mae: 2.4133\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9257 - mae: 0.9257 - val_loss: 2.4729 - val_mae: 2.4729\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0667 - mae: 1.0667 - val_loss: 2.7360 - val_mae: 2.7360\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9729 - mae: 0.9729 - val_loss: 2.4271 - val_mae: 2.4271\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8804 - mae: 0.8804 - val_loss: 2.4643 - val_mae: 2.4643\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8929 - mae: 0.8929 - val_loss: 2.5039 - val_mae: 2.5039\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9462 - mae: 0.9462 - val_loss: 2.3812 - val_mae: 2.3812\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9000 - mae: 0.9000 - val_loss: 2.5065 - val_mae: 2.5065\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8878 - mae: 0.8878 - val_loss: 2.4664 - val_mae: 2.4664\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8591 - mae: 0.8591 - val_loss: 2.4763 - val_mae: 2.4763\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8717 - mae: 0.8717 - val_loss: 2.4738 - val_mae: 2.4738\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8146 - mae: 0.8146 - val_loss: 2.5009 - val_mae: 2.5009\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9327 - mae: 0.9327 - val_loss: 2.7129 - val_mae: 2.7129\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1002 - mae: 1.1002 - val_loss: 2.5048 - val_mae: 2.5048\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8586 - mae: 0.8586 - val_loss: 2.4444 - val_mae: 2.4444\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8402 - mae: 0.8402 - val_loss: 2.3662 - val_mae: 2.3662\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8813 - mae: 0.8813 - val_loss: 2.6952 - val_mae: 2.6952\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9582 - mae: 0.9582 - val_loss: 2.5473 - val_mae: 2.5473\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8527 - mae: 0.8527 - val_loss: 2.4179 - val_mae: 2.4179\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8121 - mae: 0.8121 - val_loss: 2.4038 - val_mae: 2.4038\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8012 - mae: 0.8012 - val_loss: 2.5930 - val_mae: 2.5930\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7932 - mae: 0.7932 - val_loss: 2.4444 - val_mae: 2.4444\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.7222 - mae: 0.7222 - val_loss: 2.4353 - val_mae: 2.4353\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7787 - mae: 0.7787 - val_loss: 2.5093 - val_mae: 2.5093\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7914 - mae: 0.7914 - val_loss: 2.4363 - val_mae: 2.4363\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7344 - mae: 0.7344 - val_loss: 2.4657 - val_mae: 2.4657\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7240 - mae: 0.7240 - val_loss: 2.4929 - val_mae: 2.4929\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7293 - mae: 0.7293 - val_loss: 2.4500 - val_mae: 2.4500\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7776 - mae: 0.7776 - val_loss: 2.5504 - val_mae: 2.5504\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7315 - mae: 0.7315 - val_loss: 2.5993 - val_mae: 2.5993\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.8177 - mae: 0.8177 - val_loss: 2.5165 - val_mae: 2.5165\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8838 - mae: 0.8838 - val_loss: 2.5321 - val_mae: 2.5321\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7382 - mae: 0.7382 - val_loss: 2.5697 - val_mae: 2.5697\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7213 - mae: 0.7213 - val_loss: 2.4203 - val_mae: 2.4203\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7249 - mae: 0.7249 - val_loss: 2.5541 - val_mae: 2.5541\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7570 - mae: 0.7570 - val_loss: 2.6407 - val_mae: 2.6407\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8112 - mae: 0.8112 - val_loss: 2.5612 - val_mae: 2.5612\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7322 - mae: 0.7322 - val_loss: 2.5568 - val_mae: 2.5568\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8736 - mae: 0.8736 - val_loss: 2.5182 - val_mae: 2.5182\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7425 - mae: 0.7425 - val_loss: 2.4778 - val_mae: 2.4778\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8124 - mae: 0.8124 - val_loss: 2.6258 - val_mae: 2.6258\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7344 - mae: 0.7344 - val_loss: 2.5511 - val_mae: 2.5511\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7159 - mae: 0.7159 - val_loss: 2.4755 - val_mae: 2.4755\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4834 - mae: 3.4834\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 145.8807 - mae: 8.9765 - val_loss: 27.9617 - val_mae: 3.8184\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.5325 - mae: 3.4772 - val_loss: 23.9759 - val_mae: 3.3037\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 19.1003 - mae: 3.0969 - val_loss: 18.3469 - val_mae: 3.0376\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 15.3379 - mae: 2.9047 - val_loss: 18.1545 - val_mae: 2.9154\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 12.7485 - mae: 2.5281 - val_loss: 16.7511 - val_mae: 2.6800\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 11.7691 - mae: 2.4442 - val_loss: 16.6255 - val_mae: 2.7262\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 11.1518 - mae: 2.3973 - val_loss: 15.8694 - val_mae: 2.6674\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 10.8184 - mae: 2.4147 - val_loss: 14.0764 - val_mae: 2.5377\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 9.7571 - mae: 2.3080 - val_loss: 15.0730 - val_mae: 2.6823\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 8.6294 - mae: 2.1932 - val_loss: 14.4387 - val_mae: 2.6329\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 8.5782 - mae: 2.1392 - val_loss: 14.0524 - val_mae: 2.3864\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 7.7219 - mae: 2.0519 - val_loss: 13.1908 - val_mae: 2.4255\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 7.3202 - mae: 2.0201 - val_loss: 13.8541 - val_mae: 2.4621\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.7755 - mae: 1.9102 - val_loss: 13.4850 - val_mae: 2.4123\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.2658 - mae: 1.9006 - val_loss: 13.8025 - val_mae: 2.4544\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.8184 - mae: 1.8012 - val_loss: 13.9358 - val_mae: 2.5904\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.9643 - mae: 1.8419 - val_loss: 12.9935 - val_mae: 2.3915\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.8710 - mae: 1.8324 - val_loss: 12.9509 - val_mae: 2.3974\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.4330 - mae: 1.7664 - val_loss: 12.7878 - val_mae: 2.3297\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.0580 - mae: 1.7027 - val_loss: 12.6685 - val_mae: 2.4059\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.5665 - mae: 1.6284 - val_loss: 12.1172 - val_mae: 2.3992\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.4973 - mae: 1.5949 - val_loss: 13.0085 - val_mae: 2.3860\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.5187 - mae: 1.6016 - val_loss: 12.3947 - val_mae: 2.3513\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0909 - mae: 1.5413 - val_loss: 13.2221 - val_mae: 2.3995\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.8920 - mae: 1.4874 - val_loss: 12.1440 - val_mae: 2.2810\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9166 - mae: 1.4951 - val_loss: 12.5336 - val_mae: 2.2174\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9749 - mae: 1.4773 - val_loss: 12.3357 - val_mae: 2.2659\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.7468 - mae: 1.4631 - val_loss: 12.9208 - val_mae: 2.3194\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.2294 - mae: 1.3563 - val_loss: 12.9959 - val_mae: 2.3681\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.6860 - mae: 1.4629 - val_loss: 13.8271 - val_mae: 2.4319\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.5285 - mae: 1.4583 - val_loss: 13.2756 - val_mae: 2.4640\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.1188 - mae: 1.3117 - val_loss: 12.2499 - val_mae: 2.2860\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.3316 - mae: 1.4112 - val_loss: 13.7728 - val_mae: 2.3963\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.2506 - mae: 1.3390 - val_loss: 12.5837 - val_mae: 2.3598\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 2.8101 - mae: 1.2602 - val_loss: 12.3473 - val_mae: 2.3397\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 2.7999 - mae: 1.2545 - val_loss: 13.9586 - val_mae: 2.4678\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.7421 - mae: 1.2527 - val_loss: 13.2926 - val_mae: 2.5147\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5543 - mae: 1.2012 - val_loss: 12.5194 - val_mae: 2.3450\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.8365 - mae: 1.2774 - val_loss: 13.1896 - val_mae: 2.3617\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.5957 - mae: 1.2070 - val_loss: 12.9393 - val_mae: 2.4096\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 2.4359 - mae: 1.1731 - val_loss: 14.5036 - val_mae: 2.5351\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5512 - mae: 1.1895 - val_loss: 12.8464 - val_mae: 2.3243\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 2.1432 - mae: 1.0848 - val_loss: 11.7694 - val_mae: 2.2369\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 2.2323 - mae: 1.1013 - val_loss: 13.4618 - val_mae: 2.3370\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 2.4559 - mae: 1.1758 - val_loss: 14.6130 - val_mae: 2.4085\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.6203 - mae: 1.2028 - val_loss: 12.7215 - val_mae: 2.3045\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 2.1802 - mae: 1.1272 - val_loss: 12.9896 - val_mae: 2.3649\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 2.5258 - mae: 1.1707 - val_loss: 15.0949 - val_mae: 2.4373\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.5344 - mae: 1.1445 - val_loss: 12.3381 - val_mae: 2.3222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0265 - mae: 1.0605 - val_loss: 13.1998 - val_mae: 2.3023\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8723 - mae: 1.0197 - val_loss: 14.1458 - val_mae: 2.5719\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8581 - mae: 0.9851 - val_loss: 12.8098 - val_mae: 2.3593\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 1.8467 - mae: 0.9781 - val_loss: 12.3920 - val_mae: 2.2534\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.2039 - mae: 1.0834 - val_loss: 12.7775 - val_mae: 2.3923\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.1088 - mae: 1.1043 - val_loss: 12.9081 - val_mae: 2.3632\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8856 - mae: 1.0171 - val_loss: 13.0195 - val_mae: 2.2853\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0367 - mae: 1.0718 - val_loss: 13.2137 - val_mae: 2.3714\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.8545 - mae: 1.0026 - val_loss: 12.9152 - val_mae: 2.3916\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.9078 - mae: 0.9709 - val_loss: 12.9305 - val_mae: 2.3076\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7386 - mae: 0.9728 - val_loss: 12.9644 - val_mae: 2.3705\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8061 - mae: 0.9828 - val_loss: 12.0881 - val_mae: 2.2085\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.6508 - mae: 0.9276 - val_loss: 14.8947 - val_mae: 2.5194\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7490 - mae: 0.9810 - val_loss: 13.6385 - val_mae: 2.3794\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5722 - mae: 0.8882 - val_loss: 12.6061 - val_mae: 2.3329\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7311 - mae: 0.9501 - val_loss: 12.6437 - val_mae: 2.3402\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6354 - mae: 0.9335 - val_loss: 13.1829 - val_mae: 2.3674\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5175 - mae: 0.9070 - val_loss: 13.9493 - val_mae: 2.4574\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.6016 - mae: 0.9386 - val_loss: 12.8832 - val_mae: 2.3818\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5744 - mae: 0.9285 - val_loss: 12.9400 - val_mae: 2.3706\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5691 - mae: 0.9098 - val_loss: 12.8101 - val_mae: 2.3954\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4079 - mae: 0.8481 - val_loss: 13.1489 - val_mae: 2.3698\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4828 - mae: 0.8637 - val_loss: 12.8326 - val_mae: 2.3254\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3660 - mae: 0.8193 - val_loss: 13.4164 - val_mae: 2.3940\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2716 - mae: 0.7921 - val_loss: 13.8884 - val_mae: 2.4133\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2781 - mae: 0.7813 - val_loss: 13.0350 - val_mae: 2.3750\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4070 - mae: 0.8600 - val_loss: 12.9801 - val_mae: 2.4293\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.4956 - mae: 0.8981 - val_loss: 12.1152 - val_mae: 2.2469\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.5291 - mae: 0.8785 - val_loss: 13.1523 - val_mae: 2.2853\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7932 - mae: 0.9620 - val_loss: 15.5340 - val_mae: 2.5257\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5848 - mae: 0.9395 - val_loss: 12.7838 - val_mae: 2.3105\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.6073 - mae: 0.9392 - val_loss: 12.7059 - val_mae: 2.3251\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3146 - mae: 0.8389 - val_loss: 14.5213 - val_mae: 2.4353\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2480 - mae: 0.8026 - val_loss: 13.7452 - val_mae: 2.4516\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1166 - mae: 0.7260 - val_loss: 14.1696 - val_mae: 2.4436\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4452 - mae: 0.8796 - val_loss: 13.5693 - val_mae: 2.3973\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.2933 - mae: 0.7981 - val_loss: 13.7043 - val_mae: 2.5163\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2097 - mae: 0.7757 - val_loss: 13.1696 - val_mae: 2.3251\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1237 - mae: 0.7449 - val_loss: 13.4599 - val_mae: 2.3600\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1379 - mae: 0.7601 - val_loss: 13.9428 - val_mae: 2.4315\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.1746 - mae: 0.7467 - val_loss: 14.0536 - val_mae: 2.3987\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.3566 - mae: 0.8488 - val_loss: 13.6201 - val_mae: 2.4168\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1034 - mae: 0.7589 - val_loss: 13.4443 - val_mae: 2.4228\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1050 - mae: 0.7375 - val_loss: 13.1536 - val_mae: 2.3469\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9708 - mae: 0.6726 - val_loss: 13.8191 - val_mae: 2.4324\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1754 - mae: 0.7691 - val_loss: 13.9354 - val_mae: 2.3676\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0658 - mae: 0.7174 - val_loss: 13.3215 - val_mae: 2.3771\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9158 - mae: 0.6509 - val_loss: 13.9918 - val_mae: 2.5099\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0981 - mae: 0.7442 - val_loss: 13.3313 - val_mae: 2.3875\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9755 - mae: 0.6899 - val_loss: 12.9919 - val_mae: 2.3727\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.9697 - mae: 0.6708 - val_loss: 14.0820 - val_mae: 2.4761\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0252 - mae: 3.5063\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 9.0173 - mae: 9.0173 - val_loss: 3.2663 - val_mae: 3.2663\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.2566 - mae: 3.2566 - val_loss: 2.7637 - val_mae: 2.7637\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.9538 - mae: 2.9538 - val_loss: 2.8592 - val_mae: 2.8592\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.6254 - mae: 2.6254 - val_loss: 2.5242 - val_mae: 2.5242\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.7115 - mae: 2.7115 - val_loss: 2.4322 - val_mae: 2.4322\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5876 - mae: 2.5876 - val_loss: 2.9118 - val_mae: 2.9118\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.4165 - mae: 2.4165 - val_loss: 2.4944 - val_mae: 2.4944\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.2678 - mae: 2.2678 - val_loss: 2.6993 - val_mae: 2.6993\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.1933 - mae: 2.1933 - val_loss: 2.6687 - val_mae: 2.6687\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1551 - mae: 2.1551 - val_loss: 2.4187 - val_mae: 2.4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0928 - mae: 2.0928 - val_loss: 2.5072 - val_mae: 2.5072\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1796 - mae: 2.1796 - val_loss: 2.7182 - val_mae: 2.7182\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0741 - mae: 2.0741 - val_loss: 2.6171 - val_mae: 2.6171\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9399 - mae: 1.9399 - val_loss: 2.4972 - val_mae: 2.4972\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8360 - mae: 1.8360 - val_loss: 2.4207 - val_mae: 2.4207\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8948 - mae: 1.8948 - val_loss: 2.5693 - val_mae: 2.5693\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.8693 - mae: 1.8693 - val_loss: 2.4730 - val_mae: 2.4730\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6601 - mae: 1.6601 - val_loss: 2.3974 - val_mae: 2.3974\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5836 - mae: 1.5836 - val_loss: 2.4470 - val_mae: 2.4470\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5599 - mae: 1.5599 - val_loss: 2.6969 - val_mae: 2.6969\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6634 - mae: 1.6634 - val_loss: 2.5415 - val_mae: 2.5415\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6181 - mae: 1.6181 - val_loss: 2.5838 - val_mae: 2.5838\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5273 - mae: 1.5273 - val_loss: 2.6027 - val_mae: 2.6027\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6423 - mae: 1.6423 - val_loss: 2.3379 - val_mae: 2.3379\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5106 - mae: 1.5106 - val_loss: 2.6053 - val_mae: 2.6053\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6625 - mae: 1.6625 - val_loss: 2.8894 - val_mae: 2.8894\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.4772 - mae: 1.4772 - val_loss: 2.6339 - val_mae: 2.6339\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5558 - mae: 1.5558 - val_loss: 2.7217 - val_mae: 2.7217\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6229 - mae: 1.6229 - val_loss: 2.4536 - val_mae: 2.4536\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3321 - mae: 1.3321 - val_loss: 2.4927 - val_mae: 2.4927\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2696 - mae: 1.2696 - val_loss: 2.4055 - val_mae: 2.4055\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2530 - mae: 1.2530 - val_loss: 2.6471 - val_mae: 2.6471\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2891 - mae: 1.2891 - val_loss: 2.3901 - val_mae: 2.3901\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.2969 - mae: 1.2969 - val_loss: 2.4114 - val_mae: 2.4114\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.2348 - mae: 1.2348 - val_loss: 2.3866 - val_mae: 2.3866\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2769 - mae: 1.2769 - val_loss: 2.4871 - val_mae: 2.4871\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2106 - mae: 1.2106 - val_loss: 2.4405 - val_mae: 2.4405\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2009 - mae: 1.2009 - val_loss: 2.4400 - val_mae: 2.4400\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1240 - mae: 1.1240 - val_loss: 2.3771 - val_mae: 2.3771\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2081 - mae: 1.2081 - val_loss: 2.5927 - val_mae: 2.5927\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1941 - mae: 1.1941 - val_loss: 2.4580 - val_mae: 2.4580\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1535 - mae: 1.1535 - val_loss: 2.4667 - val_mae: 2.4667\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0793 - mae: 1.0793 - val_loss: 2.4621 - val_mae: 2.4621\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1650 - mae: 1.1650 - val_loss: 2.4477 - val_mae: 2.4477\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0811 - mae: 1.0811 - val_loss: 2.3707 - val_mae: 2.3707\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1553 - mae: 1.1553 - val_loss: 2.5445 - val_mae: 2.5445\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0288 - mae: 1.0288 - val_loss: 2.5585 - val_mae: 2.5585\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1348 - mae: 1.1348 - val_loss: 2.4795 - val_mae: 2.4795\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1744 - mae: 1.1744 - val_loss: 2.5106 - val_mae: 2.5106\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0712 - mae: 1.0712 - val_loss: 2.3465 - val_mae: 2.3465\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0037 - mae: 1.0037 - val_loss: 2.3497 - val_mae: 2.3497\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0362 - mae: 1.0362 - val_loss: 2.3485 - val_mae: 2.3485\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1327 - mae: 1.1327 - val_loss: 2.4565 - val_mae: 2.4565\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.1270 - mae: 1.1270 - val_loss: 2.4393 - val_mae: 2.4393\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9926 - mae: 0.9926 - val_loss: 2.3485 - val_mae: 2.3485\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.1268 - mae: 1.1268 - val_loss: 2.5585 - val_mae: 2.5585\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1239 - mae: 1.1239 - val_loss: 2.5189 - val_mae: 2.5189\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.0342 - mae: 1.0342 - val_loss: 2.3628 - val_mae: 2.3628\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0406 - mae: 1.0406 - val_loss: 2.4216 - val_mae: 2.4216\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0129 - mae: 1.0129 - val_loss: 2.3006 - val_mae: 2.3006\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9389 - mae: 0.9389 - val_loss: 2.4808 - val_mae: 2.4808\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8827 - mae: 0.8827 - val_loss: 2.4517 - val_mae: 2.4517\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0770 - mae: 1.0770 - val_loss: 2.5167 - val_mae: 2.5167\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9628 - mae: 0.9628 - val_loss: 2.4215 - val_mae: 2.4215\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9506 - mae: 0.9506 - val_loss: 2.3880 - val_mae: 2.3880\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9826 - mae: 0.9826 - val_loss: 2.4779 - val_mae: 2.4779\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8812 - mae: 0.8812 - val_loss: 2.4064 - val_mae: 2.4064\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9080 - mae: 0.9080 - val_loss: 2.4487 - val_mae: 2.4487\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8989 - mae: 0.8989 - val_loss: 2.4461 - val_mae: 2.4461\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8328 - mae: 0.8328 - val_loss: 2.4258 - val_mae: 2.4258\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8582 - mae: 0.8582 - val_loss: 2.4146 - val_mae: 2.4146\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9375 - mae: 0.9375 - val_loss: 2.4383 - val_mae: 2.4383\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8508 - mae: 0.8508 - val_loss: 2.5842 - val_mae: 2.5842\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9194 - mae: 0.9194 - val_loss: 2.4949 - val_mae: 2.4949\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8136 - mae: 0.8136 - val_loss: 2.4626 - val_mae: 2.4626\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0371 - mae: 1.0371 - val_loss: 2.3805 - val_mae: 2.3805\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8720 - mae: 0.8720 - val_loss: 2.4549 - val_mae: 2.4549\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7693 - mae: 0.7693 - val_loss: 2.3592 - val_mae: 2.3592\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8746 - mae: 0.8746 - val_loss: 2.4329 - val_mae: 2.4329\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.8307 - mae: 0.8307 - val_loss: 2.4350 - val_mae: 2.4350\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8521 - mae: 0.8521 - val_loss: 2.3460 - val_mae: 2.3460\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.8816 - mae: 0.8816 - val_loss: 2.5418 - val_mae: 2.5418\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8073 - mae: 0.8073 - val_loss: 2.4803 - val_mae: 2.4803\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8750 - mae: 0.8750 - val_loss: 2.5554 - val_mae: 2.5554\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9035 - mae: 0.9035 - val_loss: 2.3961 - val_mae: 2.3961\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7999 - mae: 0.7999 - val_loss: 2.3647 - val_mae: 2.3647\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7893 - mae: 0.7893 - val_loss: 2.4293 - val_mae: 2.4293\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8059 - mae: 0.8059 - val_loss: 2.4388 - val_mae: 2.4388\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7865 - mae: 0.7865 - val_loss: 2.3473 - val_mae: 2.3473\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8529 - mae: 0.8529 - val_loss: 2.3336 - val_mae: 2.3336\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.9826 - mae: 0.9826 - val_loss: 2.5676 - val_mae: 2.5676\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8378 - mae: 0.8378 - val_loss: 2.4603 - val_mae: 2.4603\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8304 - mae: 0.8304 - val_loss: 2.3998 - val_mae: 2.3998\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7894 - mae: 0.7894 - val_loss: 2.3742 - val_mae: 2.3742\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7502 - mae: 0.7502 - val_loss: 2.3635 - val_mae: 2.3635\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7501 - mae: 0.7501 - val_loss: 2.3810 - val_mae: 2.3810\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9507 - mae: 0.9507 - val_loss: 2.3896 - val_mae: 2.3896\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7294 - mae: 0.7294 - val_loss: 2.4544 - val_mae: 2.4544\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7058 - mae: 0.7058 - val_loss: 2.4404 - val_mae: 2.4404\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7677 - mae: 0.7677 - val_loss: 2.5165 - val_mae: 2.5165\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0519 - mae: 4.0519\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 143.9610 - mae: 8.4072 - val_loss: 32.4322 - val_mae: 4.4501\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 25.0129 - mae: 3.6961 - val_loss: 27.1257 - val_mae: 3.9790\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 18.2483 - mae: 3.1234 - val_loss: 22.2565 - val_mae: 3.5776\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 16.1899 - mae: 2.8135 - val_loss: 16.7263 - val_mae: 2.7552\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 14.3349 - mae: 2.7973 - val_loss: 17.5719 - val_mae: 2.8244\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 12.9470 - mae: 2.6023 - val_loss: 16.2196 - val_mae: 2.6046\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 12.0421 - mae: 2.5031 - val_loss: 15.4388 - val_mae: 2.5152\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 9.9005 - mae: 2.2520 - val_loss: 14.3750 - val_mae: 2.4637\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 8.9532 - mae: 2.2074 - val_loss: 13.7801 - val_mae: 2.4680\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 9.8173 - mae: 2.2824 - val_loss: 12.9804 - val_mae: 2.3541\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 8.0329 - mae: 2.0966 - val_loss: 14.1020 - val_mae: 2.4139\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 7.3811 - mae: 1.9950 - val_loss: 14.5315 - val_mae: 2.5312\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 7.1305 - mae: 2.0162 - val_loss: 14.2719 - val_mae: 2.4506\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.9611 - mae: 2.0109 - val_loss: 14.5007 - val_mae: 2.4469\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.0518 - mae: 1.8278 - val_loss: 16.2616 - val_mae: 2.7728\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3405 - mae: 1.9459 - val_loss: 13.2085 - val_mae: 2.3741\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 5.5268 - mae: 1.7547 - val_loss: 13.1547 - val_mae: 2.2737\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.0827 - mae: 1.7047 - val_loss: 13.8227 - val_mae: 2.3105\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.8784 - mae: 1.6698 - val_loss: 14.6628 - val_mae: 2.4700\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.7222 - mae: 1.6235 - val_loss: 13.4146 - val_mae: 2.3506\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.2334 - mae: 1.5505 - val_loss: 12.3878 - val_mae: 2.3402\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0763 - mae: 1.5333 - val_loss: 12.9752 - val_mae: 2.5288\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0564 - mae: 1.5645 - val_loss: 14.7090 - val_mae: 2.4485\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.4594 - mae: 1.6201 - val_loss: 13.9443 - val_mae: 2.3633\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9540 - mae: 1.4776 - val_loss: 13.1293 - val_mae: 2.3380\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9608 - mae: 1.4870 - val_loss: 13.2825 - val_mae: 2.4372\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.4180 - mae: 1.4040 - val_loss: 14.1622 - val_mae: 2.4752\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1091 - mae: 1.3245 - val_loss: 13.2941 - val_mae: 2.4058\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.0549 - mae: 1.2866 - val_loss: 12.8292 - val_mae: 2.3049\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.1922 - mae: 1.3329 - val_loss: 13.0372 - val_mae: 2.3247\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.7159 - mae: 1.2226 - val_loss: 16.9454 - val_mae: 2.7588\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.5534 - mae: 1.4624 - val_loss: 11.6456 - val_mae: 2.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.3426 - mae: 1.3733 - val_loss: 14.2476 - val_mae: 2.4539\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.1480 - mae: 1.3230 - val_loss: 12.8451 - val_mae: 2.3364\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5795 - mae: 1.1987 - val_loss: 13.9139 - val_mae: 2.4092\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 2.4873 - mae: 1.1831 - val_loss: 13.6174 - val_mae: 2.3594\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5045 - mae: 1.1619 - val_loss: 14.2657 - val_mae: 2.4262\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 2.3337 - mae: 1.1048 - val_loss: 12.9874 - val_mae: 2.3352\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.4429 - mae: 1.1779 - val_loss: 13.9584 - val_mae: 2.5403\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.3692 - mae: 1.1809 - val_loss: 13.4510 - val_mae: 2.5092\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.3410 - mae: 1.1480 - val_loss: 14.5609 - val_mae: 2.5123\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2639 - mae: 1.1504 - val_loss: 13.9643 - val_mae: 2.5439\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.2650 - mae: 1.1346 - val_loss: 13.5568 - val_mae: 2.3808\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9424 - mae: 1.0057 - val_loss: 13.6237 - val_mae: 2.4474\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 1.9637 - mae: 1.0273 - val_loss: 13.1189 - val_mae: 2.3838\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.8905 - mae: 0.9923 - val_loss: 13.6599 - val_mae: 2.5258\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9552 - mae: 1.0002 - val_loss: 12.7840 - val_mae: 2.3314\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.2623 - mae: 1.0868 - val_loss: 14.4225 - val_mae: 2.4336\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0439 - mae: 1.0987 - val_loss: 14.5489 - val_mae: 2.6350\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9925 - mae: 1.0425 - val_loss: 13.9600 - val_mae: 2.4360\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.9319 - mae: 1.0208 - val_loss: 13.5678 - val_mae: 2.3742\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6000 - mae: 0.9021 - val_loss: 13.3537 - val_mae: 2.4162\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.4896 - mae: 0.8622 - val_loss: 13.7492 - val_mae: 2.4119\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5284 - mae: 0.9016 - val_loss: 14.9361 - val_mae: 2.4775\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6291 - mae: 0.9361 - val_loss: 13.6103 - val_mae: 2.4361\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.6053 - mae: 0.9308 - val_loss: 13.7197 - val_mae: 2.4148\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5388 - mae: 0.9037 - val_loss: 13.8748 - val_mae: 2.4288\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5103 - mae: 0.8856 - val_loss: 13.5857 - val_mae: 2.4426\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4697 - mae: 0.8544 - val_loss: 13.8740 - val_mae: 2.4332\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.6815 - mae: 0.9320 - val_loss: 15.6568 - val_mae: 2.5599\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6851 - mae: 0.9851 - val_loss: 13.5476 - val_mae: 2.3811\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5901 - mae: 0.9115 - val_loss: 13.5762 - val_mae: 2.4045\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3691 - mae: 0.8171 - val_loss: 13.3986 - val_mae: 2.4293\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 1.4441 - mae: 0.9062 - val_loss: 15.7672 - val_mae: 2.5964\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4494 - mae: 0.9065 - val_loss: 13.8509 - val_mae: 2.3942\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3971 - mae: 0.8425 - val_loss: 14.1619 - val_mae: 2.4490\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2531 - mae: 0.7823 - val_loss: 14.8728 - val_mae: 2.4751\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.6119 - mae: 0.9027 - val_loss: 13.3907 - val_mae: 2.3548\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1899 - mae: 0.7891 - val_loss: 13.9124 - val_mae: 2.4879\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.1346 - mae: 0.7373 - val_loss: 15.5531 - val_mae: 2.5409\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.2671 - mae: 0.7826 - val_loss: 14.8037 - val_mae: 2.4940\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0258 - mae: 0.7063 - val_loss: 15.4010 - val_mae: 2.5217\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3009 - mae: 0.7981 - val_loss: 13.7973 - val_mae: 2.4476\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1806 - mae: 0.7666 - val_loss: 14.3288 - val_mae: 2.4331\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.1216 - mae: 0.7497 - val_loss: 14.6436 - val_mae: 2.5439\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.4001 - mae: 0.8444 - val_loss: 15.1172 - val_mae: 2.5258\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2974 - mae: 0.8063 - val_loss: 16.5997 - val_mae: 2.7280\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3685 - mae: 0.8684 - val_loss: 14.4206 - val_mae: 2.4994\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.7475 - mae: 0.9441 - val_loss: 13.3194 - val_mae: 2.4200\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2707 - mae: 0.8016 - val_loss: 13.6625 - val_mae: 2.4933\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.0829 - mae: 0.7394 - val_loss: 14.4375 - val_mae: 2.4770\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.0222 - mae: 0.6936 - val_loss: 13.9180 - val_mae: 2.4506\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1122 - mae: 0.7581 - val_loss: 15.3795 - val_mae: 2.5612\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0706 - mae: 0.7304 - val_loss: 14.9394 - val_mae: 2.5404\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0046 - mae: 0.7136 - val_loss: 13.8378 - val_mae: 2.3983\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0944 - mae: 0.7510 - val_loss: 14.8496 - val_mae: 2.4997\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0131 - mae: 0.7029 - val_loss: 15.4672 - val_mae: 2.6573\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0837 - mae: 0.7166 - val_loss: 14.3627 - val_mae: 2.4822\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7941 - mae: 0.6082 - val_loss: 14.8888 - val_mae: 2.5102\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7974 - mae: 0.5957 - val_loss: 14.2695 - val_mae: 2.5034\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0202 - mae: 0.7126 - val_loss: 15.8987 - val_mae: 2.5866\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3558 - mae: 0.8520 - val_loss: 13.4684 - val_mae: 2.4701\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8947 - mae: 0.6654 - val_loss: 15.0928 - val_mae: 2.5139\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1098 - mae: 0.7278 - val_loss: 14.7515 - val_mae: 2.5184\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0214 - mae: 0.6916 - val_loss: 15.1531 - val_mae: 2.5762\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1018 - mae: 0.7438 - val_loss: 13.6932 - val_mae: 2.4223\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9071 - mae: 0.6878 - val_loss: 14.4503 - val_mae: 2.5573\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8469 - mae: 0.6448 - val_loss: 16.5616 - val_mae: 2.6350\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2289 - mae: 0.8172 - val_loss: 14.6912 - val_mae: 2.4941\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9287 - mae: 0.6825 - val_loss: 15.8479 - val_mae: 2.6025\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0689 - mae: 3.2131\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 9.1060 - mae: 9.1060 - val_loss: 5.3803 - val_mae: 5.3803\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.7835 - mae: 3.7835 - val_loss: 3.2246 - val_mae: 3.2246\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.8120 - mae: 2.8120 - val_loss: 2.7954 - val_mae: 2.7954\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.8588 - mae: 2.8588 - val_loss: 2.7409 - val_mae: 2.7409\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.5657 - mae: 2.5657 - val_loss: 2.5729 - val_mae: 2.5729\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.4977 - mae: 2.4977 - val_loss: 2.6493 - val_mae: 2.6493\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.5121 - mae: 2.5121 - val_loss: 2.8902 - val_mae: 2.8902\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.3206 - mae: 2.3206 - val_loss: 2.5295 - val_mae: 2.5295\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.2937 - mae: 2.2937 - val_loss: 2.4516 - val_mae: 2.4516\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.1962 - mae: 2.1962 - val_loss: 2.4263 - val_mae: 2.4263\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.0653 - mae: 2.0653 - val_loss: 2.3967 - val_mae: 2.3967\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9623 - mae: 1.9623 - val_loss: 2.3887 - val_mae: 2.3887\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9700 - mae: 1.9700 - val_loss: 2.4753 - val_mae: 2.4753\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 2.0538 - mae: 2.0538 - val_loss: 2.5327 - val_mae: 2.5327\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9423 - mae: 1.9423 - val_loss: 2.4960 - val_mae: 2.4960\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.9022 - mae: 1.9022 - val_loss: 2.6714 - val_mae: 2.6714\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.9077 - mae: 1.9077 - val_loss: 2.4100 - val_mae: 2.4100\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7290 - mae: 1.7290 - val_loss: 2.4977 - val_mae: 2.4977\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7474 - mae: 1.7474 - val_loss: 2.4610 - val_mae: 2.4610\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.6281 - mae: 1.6281 - val_loss: 2.5852 - val_mae: 2.5852\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5933 - mae: 1.5933 - val_loss: 2.5515 - val_mae: 2.5515\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.7289 - mae: 1.7289 - val_loss: 2.4986 - val_mae: 2.4986\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.6016 - mae: 1.6016 - val_loss: 2.5513 - val_mae: 2.5513\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.5561 - mae: 1.5561 - val_loss: 2.4719 - val_mae: 2.4719\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.5274 - mae: 1.5274 - val_loss: 2.6467 - val_mae: 2.6467\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.4237 - mae: 1.4237 - val_loss: 2.5209 - val_mae: 2.5209\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.5377 - mae: 1.5377 - val_loss: 2.5581 - val_mae: 2.5581\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3965 - mae: 1.3965 - val_loss: 2.4796 - val_mae: 2.4796\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3974 - mae: 1.3974 - val_loss: 2.4263 - val_mae: 2.4263\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.3348 - mae: 1.3348 - val_loss: 2.4745 - val_mae: 2.4745\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3672 - mae: 1.3672 - val_loss: 2.4716 - val_mae: 2.4716\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3468 - mae: 1.3468 - val_loss: 2.4467 - val_mae: 2.4467\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2990 - mae: 1.2990 - val_loss: 2.3847 - val_mae: 2.3847\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.3132 - mae: 1.3132 - val_loss: 2.4992 - val_mae: 2.4992\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2953 - mae: 1.2953 - val_loss: 2.3524 - val_mae: 2.3524\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.2320 - mae: 1.2320 - val_loss: 2.5118 - val_mae: 2.5118\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2815 - mae: 1.2815 - val_loss: 2.5818 - val_mae: 2.5818\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2357 - mae: 1.2357 - val_loss: 2.5630 - val_mae: 2.5630\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1594 - mae: 1.1594 - val_loss: 2.4254 - val_mae: 2.4254\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1320 - mae: 1.1320 - val_loss: 2.4075 - val_mae: 2.4075\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1554 - mae: 1.1554 - val_loss: 2.3967 - val_mae: 2.3967\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1192 - mae: 1.1192 - val_loss: 2.5373 - val_mae: 2.5373\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.1473 - mae: 1.1473 - val_loss: 2.4775 - val_mae: 2.4775\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.2332 - mae: 1.2332 - val_loss: 2.3878 - val_mae: 2.3878\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0988 - mae: 1.0988 - val_loss: 2.5571 - val_mae: 2.5571\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0950 - mae: 1.0950 - val_loss: 2.3521 - val_mae: 2.3521\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1991 - mae: 1.1991 - val_loss: 2.5138 - val_mae: 2.5138\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.1400 - mae: 1.1400 - val_loss: 2.4571 - val_mae: 2.4571\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0777 - mae: 1.0777 - val_loss: 2.5570 - val_mae: 2.5570\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0139 - mae: 1.0139 - val_loss: 2.4584 - val_mae: 2.4584\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9921 - mae: 0.9921 - val_loss: 2.4166 - val_mae: 2.4166\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0433 - mae: 1.0433 - val_loss: 2.4455 - val_mae: 2.4455\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0941 - mae: 1.0941 - val_loss: 2.5044 - val_mae: 2.5044\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0479 - mae: 1.0479 - val_loss: 2.3292 - val_mae: 2.3292\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 11ms/step - loss: 1.0222 - mae: 1.0222 - val_loss: 2.7369 - val_mae: 2.7369\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 1.1170 - mae: 1.1170 - val_loss: 2.4889 - val_mae: 2.4889\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0803 - mae: 1.0803 - val_loss: 2.5441 - val_mae: 2.5441\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0423 - mae: 1.0423 - val_loss: 2.4038 - val_mae: 2.4038\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 1.0252 - mae: 1.0252 - val_loss: 2.6251 - val_mae: 2.6251\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 1.0328 - mae: 1.0328 - val_loss: 2.4304 - val_mae: 2.4304\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.1696 - mae: 1.1696 - val_loss: 2.4372 - val_mae: 2.4372\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.9453 - mae: 0.9453 - val_loss: 2.3287 - val_mae: 2.3287\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9634 - mae: 0.9634 - val_loss: 2.3962 - val_mae: 2.3962\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9874 - mae: 0.9874 - val_loss: 2.5701 - val_mae: 2.5701\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9673 - mae: 0.9673 - val_loss: 2.3467 - val_mae: 2.3467\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.9628 - mae: 0.9628 - val_loss: 2.3706 - val_mae: 2.3706\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8503 - mae: 0.8503 - val_loss: 2.3538 - val_mae: 2.3538\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9403 - mae: 0.9403 - val_loss: 2.4604 - val_mae: 2.4604\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8505 - mae: 0.8505 - val_loss: 2.4783 - val_mae: 2.4783\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.8722 - mae: 0.8722 - val_loss: 2.4105 - val_mae: 2.4105\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.8820 - mae: 0.8820 - val_loss: 2.4279 - val_mae: 2.4279\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.8048 - mae: 0.8048 - val_loss: 2.2995 - val_mae: 2.2995\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.8921 - mae: 0.8921 - val_loss: 2.4352 - val_mae: 2.4352\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8748 - mae: 0.8748 - val_loss: 2.4428 - val_mae: 2.4428\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.8816 - mae: 0.8816 - val_loss: 2.4002 - val_mae: 2.4002\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8800 - mae: 0.8800 - val_loss: 2.4993 - val_mae: 2.4993\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8937 - mae: 0.8937 - val_loss: 2.4098 - val_mae: 2.4098\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.9052 - mae: 0.9052 - val_loss: 2.3830 - val_mae: 2.3830\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8403 - mae: 0.8403 - val_loss: 2.3696 - val_mae: 2.3696\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8999 - mae: 0.8999 - val_loss: 2.5300 - val_mae: 2.5300\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 1.0192 - mae: 1.0192 - val_loss: 2.5609 - val_mae: 2.5609\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.8912 - mae: 0.8912 - val_loss: 2.4520 - val_mae: 2.4520\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7869 - mae: 0.7869 - val_loss: 2.4722 - val_mae: 2.4722\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7805 - mae: 0.7805 - val_loss: 2.3628 - val_mae: 2.3628\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7661 - mae: 0.7661 - val_loss: 2.4432 - val_mae: 2.4432\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8709 - mae: 0.8709 - val_loss: 2.3725 - val_mae: 2.3725\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8046 - mae: 0.8046 - val_loss: 2.3743 - val_mae: 2.3743\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7628 - mae: 0.7628 - val_loss: 2.4346 - val_mae: 2.4346\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7241 - mae: 0.7241 - val_loss: 2.4328 - val_mae: 2.4328\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7494 - mae: 0.7494 - val_loss: 2.4434 - val_mae: 2.4434\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.8252 - mae: 0.8252 - val_loss: 2.3927 - val_mae: 2.3927\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7732 - mae: 0.7732 - val_loss: 2.4071 - val_mae: 2.4071\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7183 - mae: 0.7183 - val_loss: 2.3798 - val_mae: 2.3798\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7607 - mae: 0.7607 - val_loss: 2.5675 - val_mae: 2.5675\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.7254 - mae: 0.7254 - val_loss: 2.4543 - val_mae: 2.4543\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7607 - mae: 0.7607 - val_loss: 2.3733 - val_mae: 2.3733\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7445 - mae: 0.7445 - val_loss: 2.4301 - val_mae: 2.4301\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7550 - mae: 0.7550 - val_loss: 2.4025 - val_mae: 2.4025\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7103 - mae: 0.7103 - val_loss: 2.4287 - val_mae: 2.4287\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.7093 - mae: 0.7093 - val_loss: 2.4724 - val_mae: 2.4724\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0168 - mae: 3.0168\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 176.9456 - mae: 9.8321 - val_loss: 98.3263 - val_mae: 7.0106\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 84.0858 - mae: 6.3877 - val_loss: 90.2049 - val_mae: 7.0013\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.9594 - mae: 6.4131 - val_loss: 89.3793 - val_mae: 7.0870\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5424 - mae: 6.4396 - val_loss: 89.2485 - val_mae: 7.1265\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4571 - mae: 6.4561 - val_loss: 89.2315 - val_mae: 7.1372\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4921 - mae: 6.4775 - val_loss: 89.2204 - val_mae: 7.1492\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4641 - mae: 6.4687 - val_loss: 89.2338 - val_mae: 7.1355\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4808 - mae: 6.4735 - val_loss: 89.2176 - val_mae: 7.1621\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4985 - mae: 6.4827 - val_loss: 89.2201 - val_mae: 7.1497\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5231 - mae: 6.4869 - val_loss: 89.2275 - val_mae: 7.1782\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5258 - mae: 6.4888 - val_loss: 89.2195 - val_mae: 7.1507\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4054 - mae: 6.4791 - val_loss: 89.2304 - val_mae: 7.1807\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4502 - mae: 6.5012 - val_loss: 89.2236 - val_mae: 7.1742\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.6764 - mae: 6.4645 - val_loss: 89.2262 - val_mae: 7.1418\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4424 - mae: 6.4918 - val_loss: 89.2348 - val_mae: 7.1843\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4782 - mae: 6.5006 - val_loss: 89.2289 - val_mae: 7.1796\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4233 - mae: 6.4903 - val_loss: 89.2173 - val_mae: 7.1579\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4643 - mae: 6.4814 - val_loss: 89.2194 - val_mae: 7.1508\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5129 - mae: 6.4831 - val_loss: 89.2173 - val_mae: 7.1606\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4253 - mae: 6.4778 - val_loss: 89.2215 - val_mae: 7.1471\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4345 - mae: 6.4755 - val_loss: 89.2195 - val_mae: 7.1505\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4199 - mae: 6.4809 - val_loss: 89.2172 - val_mae: 7.1607\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4591 - mae: 6.4717 - val_loss: 89.2190 - val_mae: 7.1515\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5094 - mae: 6.5020 - val_loss: 89.2309 - val_mae: 7.1813\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4459 - mae: 6.4848 - val_loss: 89.2178 - val_mae: 7.1545\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4846 - mae: 6.4802 - val_loss: 89.2173 - val_mae: 7.1567\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4900 - mae: 6.4886 - val_loss: 89.2178 - val_mae: 7.1544\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4793 - mae: 6.4766 - val_loss: 89.2174 - val_mae: 7.1560\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4398 - mae: 6.4801 - val_loss: 89.2170 - val_mae: 7.1588\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5032 - mae: 6.4906 - val_loss: 89.2219 - val_mae: 7.1725\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4819 - mae: 6.4738 - val_loss: 89.2187 - val_mae: 7.1516\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4222 - mae: 6.4803 - val_loss: 89.2170 - val_mae: 7.1604\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5088 - mae: 6.4769 - val_loss: 89.2176 - val_mae: 7.1641\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4376 - mae: 6.4838 - val_loss: 89.2180 - val_mae: 7.1657\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4576 - mae: 6.4824 - val_loss: 89.2176 - val_mae: 7.1646\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 80.4974 - mae: 6.5000 - val_loss: 89.2232 - val_mae: 7.1744\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4415 - mae: 6.4825 - val_loss: 89.2168 - val_mae: 7.1584\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4816 - mae: 6.4579 - val_loss: 89.2324 - val_mae: 7.1360\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4668 - mae: 6.4663 - val_loss: 89.2241 - val_mae: 7.1432\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4443 - mae: 6.4727 - val_loss: 89.2168 - val_mae: 7.1569\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 80.4352 - mae: 6.4853 - val_loss: 89.2168 - val_mae: 7.1621\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 80.4604 - mae: 6.4759 - val_loss: 89.2169 - val_mae: 7.1554\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4616 - mae: 6.4820 - val_loss: 89.2169 - val_mae: 7.1554\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 80.4759 - mae: 6.4759 - val_loss: 89.2209 - val_mae: 7.1467\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5098 - mae: 6.4632 - val_loss: 89.2259 - val_mae: 7.1409\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4232 - mae: 6.4726 - val_loss: 89.2166 - val_mae: 7.1551\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4699 - mae: 6.4858 - val_loss: 89.2162 - val_mae: 7.1617\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.5489 - mae: 6.5019 - val_loss: 89.2245 - val_mae: 7.1766\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 80.4266 - mae: 6.4807 - val_loss: 89.2178 - val_mae: 7.1508\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 80.4601 - mae: 6.4726 - val_loss: 89.2158 - val_mae: 7.1569\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4916 - mae: 6.4908 - val_loss: 89.2154 - val_mae: 7.1595\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4387 - mae: 6.4763 - val_loss: 89.2169 - val_mae: 7.1515\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4400 - mae: 6.4746 - val_loss: 89.2154 - val_mae: 7.1554\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4529 - mae: 6.4876 - val_loss: 89.2149 - val_mae: 7.1621\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.4310 - mae: 6.4823 - val_loss: 89.2156 - val_mae: 7.1525\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4366 - mae: 6.4650 - val_loss: 89.2262 - val_mae: 7.1383\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 80.4090 - mae: 6.4687 - val_loss: 89.2144 - val_mae: 7.1529\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.5469 - mae: 6.4961 - val_loss: 89.2127 - val_mae: 7.1606\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4789 - mae: 6.4785 - val_loss: 89.2126 - val_mae: 7.1644\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.4520 - mae: 6.4731 - val_loss: 89.2140 - val_mae: 7.1476\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.4976 - mae: 6.4725 - val_loss: 89.2113 - val_mae: 7.1491\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4577 - mae: 6.4703 - val_loss: 89.2064 - val_mae: 7.1584\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 80.4518 - mae: 6.4830 - val_loss: 89.2036 - val_mae: 7.1634\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4292 - mae: 6.4858 - val_loss: 89.1972 - val_mae: 7.1578\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.4337 - mae: 6.4685 - val_loss: 89.1917 - val_mae: 7.1427\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.3894 - mae: 6.4687 - val_loss: 89.1672 - val_mae: 7.1523\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4108 - mae: 6.4656 - val_loss: 89.1288 - val_mae: 7.1338\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.3358 - mae: 6.4725 - val_loss: 89.0219 - val_mae: 7.1459\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 80.1542 - mae: 6.4666 - val_loss: 88.6482 - val_mae: 7.1114\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 78.9873 - mae: 6.3652 - val_loss: 85.1106 - val_mae: 6.7901\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 72.1510 - mae: 5.8035 - val_loss: 71.6351 - val_mae: 5.6533\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 62.4324 - mae: 5.2684 - val_loss: 64.8239 - val_mae: 5.1468\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 58.0228 - mae: 5.0222 - val_loss: 61.8720 - val_mae: 5.0398\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 55.0375 - mae: 4.9163 - val_loss: 59.4684 - val_mae: 5.1775\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 53.3533 - mae: 4.9582 - val_loss: 57.7030 - val_mae: 5.1336\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 52.0033 - mae: 4.8984 - val_loss: 54.8837 - val_mae: 4.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 49.1780 - mae: 4.6847 - val_loss: 52.7198 - val_mae: 4.6933\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 47.0252 - mae: 4.6140 - val_loss: 50.3561 - val_mae: 4.5877\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 44.9740 - mae: 4.4735 - val_loss: 48.1315 - val_mae: 4.2983\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 41.6700 - mae: 4.1888 - val_loss: 46.3417 - val_mae: 4.3856\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 39.4509 - mae: 4.0738 - val_loss: 44.1135 - val_mae: 4.2850\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 37.1855 - mae: 3.9083 - val_loss: 41.4190 - val_mae: 3.8640\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 35.1264 - mae: 3.7851 - val_loss: 39.9836 - val_mae: 3.6658\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 33.8251 - mae: 3.7237 - val_loss: 37.9956 - val_mae: 3.6175\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 31.8334 - mae: 3.5801 - val_loss: 35.8739 - val_mae: 3.6998\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 30.4374 - mae: 3.4301 - val_loss: 34.2156 - val_mae: 3.4142\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 29.1798 - mae: 3.4534 - val_loss: 33.3410 - val_mae: 3.3187\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 28.2220 - mae: 3.3001 - val_loss: 31.9300 - val_mae: 3.3068\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 28.0989 - mae: 3.3841 - val_loss: 31.3954 - val_mae: 3.4633\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 26.2807 - mae: 3.3003 - val_loss: 30.7667 - val_mae: 3.1756\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 25.7177 - mae: 3.1710 - val_loss: 29.7194 - val_mae: 3.2026\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 24.7744 - mae: 3.1086 - val_loss: 28.9954 - val_mae: 3.2285\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.9179 - mae: 3.0205 - val_loss: 28.7953 - val_mae: 3.1839\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.6739 - mae: 3.0563 - val_loss: 28.4435 - val_mae: 3.1030\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.7776 - mae: 3.0280 - val_loss: 27.5270 - val_mae: 3.1331\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.3736 - mae: 2.9581 - val_loss: 27.7026 - val_mae: 3.0581\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.8977 - mae: 2.9285 - val_loss: 26.9957 - val_mae: 3.0528\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.5046 - mae: 2.9284 - val_loss: 26.9457 - val_mae: 3.0365\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.5205 - mae: 2.9386 - val_loss: 26.7155 - val_mae: 3.3160\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.0617 - mae: 2.9169 - val_loss: 25.7574 - val_mae: 3.0603\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.0536 - mae: 3.7515\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 9.9106 - mae: 9.9106 - val_loss: 7.0315 - val_mae: 7.0315\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.4703 - mae: 6.4703 - val_loss: 6.9371 - val_mae: 6.9371\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.4022 - mae: 6.4022 - val_loss: 6.9538 - val_mae: 6.9538\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3951 - mae: 6.3951 - val_loss: 6.9533 - val_mae: 6.9533\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3914 - mae: 6.3914 - val_loss: 6.9723 - val_mae: 6.9723\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3954 - mae: 6.3954 - val_loss: 6.9764 - val_mae: 6.9764\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9660 - val_mae: 6.9660\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3917 - mae: 6.3917 - val_loss: 6.9651 - val_mae: 6.9651\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3975 - mae: 6.3975 - val_loss: 6.9818 - val_mae: 6.9818\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3905 - mae: 6.3905 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9720 - val_mae: 6.9720\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9675 - val_mae: 6.9675\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9621 - val_mae: 6.9621\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9711 - val_mae: 6.9711\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3938 - mae: 6.3938 - val_loss: 6.9629 - val_mae: 6.9629\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9733 - val_mae: 6.9733\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9672 - val_mae: 6.9672\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9653 - val_mae: 6.9653\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3908 - mae: 6.3908 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9746 - val_mae: 6.9746\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9786 - val_mae: 6.9786\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9715 - val_mae: 6.9715\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9679 - val_mae: 6.9679\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9787 - val_mae: 6.9787\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9774 - val_mae: 6.9774\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9750 - val_mae: 6.9750\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9670 - val_mae: 6.9670\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9632 - val_mae: 6.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9721 - val_mae: 6.9721\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9772 - val_mae: 6.9772\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9785 - val_mae: 6.9785\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9775 - val_mae: 6.9775\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9764 - val_mae: 6.9764\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.4029 - mae: 6.4029 - val_loss: 6.9721 - val_mae: 6.9721\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9802 - val_mae: 6.9802\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3898 - mae: 6.3898 - val_loss: 6.9828 - val_mae: 6.9828\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9759 - val_mae: 6.9759\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9811 - val_mae: 6.9811\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9739 - val_mae: 6.9739\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9741 - val_mae: 6.9741\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9769 - val_mae: 6.9769\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9776 - val_mae: 6.9776\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3904 - mae: 6.3904 - val_loss: 6.9716 - val_mae: 6.9716\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9733 - val_mae: 6.9733\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9780 - val_mae: 6.9780\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9777 - val_mae: 6.9777\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9804 - val_mae: 6.9804\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9739 - val_mae: 6.9739\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9754 - val_mae: 6.9754\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9676 - val_mae: 6.9676\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3918 - mae: 6.3918 - val_loss: 6.9628 - val_mae: 6.9628\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9747 - val_mae: 6.9747\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9636 - val_mae: 6.9636\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9762 - val_mae: 6.9762\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9738 - val_mae: 6.9738\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9680 - val_mae: 6.9680\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3931 - mae: 6.3931 - val_loss: 6.9704 - val_mae: 6.9704\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9752 - val_mae: 6.9752\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3901 - mae: 6.3901 - val_loss: 6.9687 - val_mae: 6.9687\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9688 - val_mae: 6.9688\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3851 - mae: 6.3851 - val_loss: 6.9620 - val_mae: 6.9620\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3774 - mae: 6.3774 - val_loss: 6.9495 - val_mae: 6.9495\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.2852 - mae: 6.2852 - val_loss: 6.5224 - val_mae: 6.5224\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 5.6970 - mae: 5.6970 - val_loss: 5.4214 - val_mae: 5.4214\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 5.1327 - mae: 5.1327 - val_loss: 5.1598 - val_mae: 5.1598\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.9276 - mae: 4.9276 - val_loss: 5.1431 - val_mae: 5.1431\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 4.8588 - mae: 4.8588 - val_loss: 5.0399 - val_mae: 5.0399\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 4.7741 - mae: 4.7741 - val_loss: 4.9851 - val_mae: 4.9851\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.7625 - mae: 4.7625 - val_loss: 5.1270 - val_mae: 5.1270\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 4.6273 - mae: 4.6273 - val_loss: 4.9402 - val_mae: 4.9402\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 4.5600 - mae: 4.5600 - val_loss: 4.5492 - val_mae: 4.5492\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.4303 - mae: 4.4303 - val_loss: 4.4617 - val_mae: 4.4617\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.3423 - mae: 4.3423 - val_loss: 4.5220 - val_mae: 4.5220\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 4.2699 - mae: 4.2699 - val_loss: 4.3409 - val_mae: 4.3409\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.1770 - mae: 4.1770 - val_loss: 4.3534 - val_mae: 4.3534\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.1034 - mae: 4.1034 - val_loss: 4.2048 - val_mae: 4.2048\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.1052 - mae: 4.1052 - val_loss: 4.3420 - val_mae: 4.3420\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 4.0121 - mae: 4.0121 - val_loss: 4.1179 - val_mae: 4.1179\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.9595 - mae: 3.9595 - val_loss: 4.2454 - val_mae: 4.2454\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9124 - mae: 3.9124 - val_loss: 4.0009 - val_mae: 4.0009\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.8082 - mae: 3.8082 - val_loss: 3.9309 - val_mae: 3.9309\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.7332 - mae: 3.7332 - val_loss: 3.8632 - val_mae: 3.8632\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 3.6911 - mae: 3.6911 - val_loss: 3.8632 - val_mae: 3.8632\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 3.6549 - mae: 3.6549 - val_loss: 3.9665 - val_mae: 3.9665\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 3.5991 - mae: 3.5991 - val_loss: 3.7075 - val_mae: 3.7075\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.5214 - mae: 3.5214 - val_loss: 3.6483 - val_mae: 3.6483\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.0116 - mae: 5.0116\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 164.7477 - mae: 9.6575 - val_loss: 96.2302 - val_mae: 6.9560\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 82.6781 - mae: 6.3804 - val_loss: 90.0460 - val_mae: 7.0113\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.6411 - mae: 6.4276 - val_loss: 89.3044 - val_mae: 7.1047\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4840 - mae: 6.4679 - val_loss: 89.2236 - val_mae: 7.1448\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4404 - mae: 6.4817 - val_loss: 89.2190 - val_mae: 7.1669\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.5547 - mae: 6.4732 - val_loss: 89.2174 - val_mae: 7.1595\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5714 - mae: 6.4703 - val_loss: 89.2175 - val_mae: 7.1573\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4627 - mae: 6.4874 - val_loss: 89.2204 - val_mae: 7.1697\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4496 - mae: 6.4932 - val_loss: 89.2177 - val_mae: 7.1627\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4531 - mae: 6.4713 - val_loss: 89.2247 - val_mae: 7.1434\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4609 - mae: 6.4622 - val_loss: 89.2212 - val_mae: 7.1477\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4591 - mae: 6.4793 - val_loss: 89.2196 - val_mae: 7.1505\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5655 - mae: 6.4991 - val_loss: 89.2196 - val_mae: 7.1505\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4841 - mae: 6.4762 - val_loss: 89.2181 - val_mae: 7.1541\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4599 - mae: 6.4798 - val_loss: 89.2193 - val_mae: 7.1509\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4927 - mae: 6.4812 - val_loss: 89.2234 - val_mae: 7.1448\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4546 - mae: 6.4773 - val_loss: 89.2179 - val_mae: 7.1641\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4825 - mae: 6.4732 - val_loss: 89.2234 - val_mae: 7.1447\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4736 - mae: 6.4779 - val_loss: 89.2178 - val_mae: 7.1550\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4218 - mae: 6.4842 - val_loss: 89.2177 - val_mae: 7.1635\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.5056 - mae: 6.4964 - val_loss: 89.2174 - val_mae: 7.1569\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4785 - mae: 6.4951 - val_loss: 89.2189 - val_mae: 7.1673\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4740 - mae: 6.4958 - val_loss: 89.2176 - val_mae: 7.1553\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4243 - mae: 6.4775 - val_loss: 89.2172 - val_mae: 7.1582\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4429 - mae: 6.4778 - val_loss: 89.2172 - val_mae: 7.1577\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4546 - mae: 6.4725 - val_loss: 89.2175 - val_mae: 7.1555\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.5768 - mae: 6.5089 - val_loss: 89.2178 - val_mae: 7.1646\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4841 - mae: 6.4721 - val_loss: 89.2226 - val_mae: 7.1455\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4824 - mae: 6.4904 - val_loss: 89.2171 - val_mae: 7.1573\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4360 - mae: 6.4748 - val_loss: 89.2209 - val_mae: 7.1478\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4609 - mae: 6.4773 - val_loss: 89.2170 - val_mae: 7.1608\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.5038 - mae: 6.4805 - val_loss: 89.2230 - val_mae: 7.1449\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4568 - mae: 6.4686 - val_loss: 89.2187 - val_mae: 7.1514\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4941 - mae: 6.4678 - val_loss: 89.2189 - val_mae: 7.1509\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4419 - mae: 6.4698 - val_loss: 89.2192 - val_mae: 7.1503\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4852 - mae: 6.4823 - val_loss: 89.2174 - val_mae: 7.1548\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4405 - mae: 6.4798 - val_loss: 89.2168 - val_mae: 7.1584\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4723 - mae: 6.4895 - val_loss: 89.2201 - val_mae: 7.1703\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4481 - mae: 6.4873 - val_loss: 89.2166 - val_mae: 7.1594\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.6389 - mae: 6.4688 - val_loss: 89.2176 - val_mae: 7.1535\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4296 - mae: 6.4838 - val_loss: 89.2179 - val_mae: 7.1662\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5335 - mae: 6.5022 - val_loss: 89.2168 - val_mae: 7.1626\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.5715 - mae: 6.4773 - val_loss: 89.2234 - val_mae: 7.1437\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4913 - mae: 6.4883 - val_loss: 89.2164 - val_mae: 7.1573\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4215 - mae: 6.4830 - val_loss: 89.2162 - val_mae: 7.1589\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4723 - mae: 6.4810 - val_loss: 89.2173 - val_mae: 7.1528\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4402 - mae: 6.4795 - val_loss: 89.2167 - val_mae: 7.1643\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5094 - mae: 6.4791 - val_loss: 89.2162 - val_mae: 7.1630\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4468 - mae: 6.4785 - val_loss: 89.2158 - val_mae: 7.1609\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4296 - mae: 6.4781 - val_loss: 89.2186 - val_mae: 7.1489\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4384 - mae: 6.4716 - val_loss: 89.2205 - val_mae: 7.1458\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.5560 - mae: 6.4903 - val_loss: 89.2151 - val_mae: 7.1588\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4785 - mae: 6.4901 - val_loss: 89.2149 - val_mae: 7.1605\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4523 - mae: 6.4650 - val_loss: 89.2217 - val_mae: 7.1432\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4454 - mae: 6.4780 - val_loss: 89.2148 - val_mae: 7.1540\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4276 - mae: 6.4742 - val_loss: 89.2170 - val_mae: 7.1481\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4737 - mae: 6.4650 - val_loss: 89.2149 - val_mae: 7.1506\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5456 - mae: 6.4919 - val_loss: 89.2131 - val_mae: 7.1526\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5157 - mae: 6.4814 - val_loss: 89.2120 - val_mae: 7.1524\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4758 - mae: 6.4618 - val_loss: 89.2178 - val_mae: 7.1414\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5649 - mae: 6.4969 - val_loss: 89.2085 - val_mae: 7.1512\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4864 - mae: 6.4706 - val_loss: 89.2043 - val_mae: 7.1536\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4246 - mae: 6.4802 - val_loss: 89.1985 - val_mae: 7.1594\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5779 - mae: 6.4687 - val_loss: 89.2076 - val_mae: 7.1315\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4520 - mae: 6.4876 - val_loss: 89.1764 - val_mae: 7.1607\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4308 - mae: 6.4910 - val_loss: 89.1559 - val_mae: 7.1700\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4465 - mae: 6.4896 - val_loss: 89.0819 - val_mae: 7.1436\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.2817 - mae: 6.4670 - val_loss: 88.8636 - val_mae: 7.1283\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 79.7449 - mae: 6.4212 - val_loss: 87.4354 - val_mae: 7.0101\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 73.8751 - mae: 5.9212 - val_loss: 72.5518 - val_mae: 5.7983\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 62.6235 - mae: 5.2203 - val_loss: 65.7981 - val_mae: 5.0473\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 58.0301 - mae: 4.9524 - val_loss: 62.2335 - val_mae: 5.1475\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 55.2439 - mae: 4.9373 - val_loss: 59.3615 - val_mae: 4.9266\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 52.2402 - mae: 4.7973 - val_loss: 58.6028 - val_mae: 5.3717\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 51.7521 - mae: 4.9559 - val_loss: 54.2130 - val_mae: 4.5495\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 48.0978 - mae: 4.5623 - val_loss: 52.2331 - val_mae: 4.4318\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 45.4953 - mae: 4.4516 - val_loss: 50.2024 - val_mae: 4.2811\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 43.4209 - mae: 4.3413 - val_loss: 47.3220 - val_mae: 4.2738\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 40.6828 - mae: 4.1655 - val_loss: 45.3256 - val_mae: 4.0191\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 38.0505 - mae: 3.9634 - val_loss: 42.6604 - val_mae: 4.0339\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 36.1372 - mae: 3.8819 - val_loss: 40.4074 - val_mae: 3.8328\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 35.0643 - mae: 3.7972 - val_loss: 40.8836 - val_mae: 3.7315\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 32.6615 - mae: 3.6151 - val_loss: 37.6816 - val_mae: 3.9131\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 31.6367 - mae: 3.5916 - val_loss: 35.5905 - val_mae: 3.5631\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 30.1815 - mae: 3.4606 - val_loss: 34.3612 - val_mae: 3.3994\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 28.5033 - mae: 3.3309 - val_loss: 32.9270 - val_mae: 3.4537\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 28.1288 - mae: 3.3647 - val_loss: 32.2643 - val_mae: 3.2754\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 27.0026 - mae: 3.2828 - val_loss: 31.2909 - val_mae: 3.2263\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 25.8601 - mae: 3.1577 - val_loss: 30.5873 - val_mae: 3.1597\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 25.1630 - mae: 3.1395 - val_loss: 29.5339 - val_mae: 3.2749\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 24.2432 - mae: 3.0607 - val_loss: 29.0997 - val_mae: 3.3534\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 23.9330 - mae: 3.0218 - val_loss: 29.1040 - val_mae: 3.4913\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.3976 - mae: 3.0797 - val_loss: 27.8923 - val_mae: 3.2343\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.7136 - mae: 2.9739 - val_loss: 28.3418 - val_mae: 3.5060\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 22.5907 - mae: 3.1252 - val_loss: 27.2006 - val_mae: 3.0426\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.0401 - mae: 2.9261 - val_loss: 26.8097 - val_mae: 3.0452\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.6187 - mae: 2.9934 - val_loss: 26.7331 - val_mae: 3.0125\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 20.8838 - mae: 2.8642 - val_loss: 26.0221 - val_mae: 3.0001\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 20.4771 - mae: 2.8877 - val_loss: 25.9689 - val_mae: 2.9856\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 20.4288 - mae: 2.8632 - val_loss: 25.3547 - val_mae: 3.0270\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.0461 - mae: 3.7348\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 9.9603 - mae: 9.9603 - val_loss: 7.0637 - val_mae: 7.0637\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.4444 - mae: 6.4444 - val_loss: 6.9464 - val_mae: 6.9464\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3934 - mae: 6.3934 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3945 - mae: 6.3945 - val_loss: 6.9642 - val_mae: 6.9642\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9663 - val_mae: 6.9663\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9690 - val_mae: 6.9690\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3945 - mae: 6.3945 - val_loss: 6.9790 - val_mae: 6.9790\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3901 - mae: 6.3901 - val_loss: 6.9666 - val_mae: 6.9666\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9703 - val_mae: 6.9703\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3950 - mae: 6.3950 - val_loss: 6.9721 - val_mae: 6.9721\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9749 - val_mae: 6.9749\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3958 - mae: 6.3958 - val_loss: 6.9757 - val_mae: 6.9757\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3928 - mae: 6.3928 - val_loss: 6.9598 - val_mae: 6.9598\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3942 - mae: 6.3942 - val_loss: 6.9650 - val_mae: 6.9650\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3905 - mae: 6.3905 - val_loss: 6.9655 - val_mae: 6.9655\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3912 - mae: 6.3912 - val_loss: 6.9715 - val_mae: 6.9715\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3915 - mae: 6.3915 - val_loss: 6.9670 - val_mae: 6.9670\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9717 - val_mae: 6.9717\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3945 - mae: 6.3945 - val_loss: 6.9745 - val_mae: 6.9745\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9707 - val_mae: 6.9707\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9670 - val_mae: 6.9670\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9759 - val_mae: 6.9759\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9756 - val_mae: 6.9756\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9696 - val_mae: 6.9696\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9742 - val_mae: 6.9742\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3907 - mae: 6.3907 - val_loss: 6.9795 - val_mae: 6.9795\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3894 - mae: 6.3894 - val_loss: 6.9753 - val_mae: 6.9753\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3899 - mae: 6.3899 - val_loss: 6.9805 - val_mae: 6.9805\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3914 - mae: 6.3914 - val_loss: 6.9681 - val_mae: 6.9681\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3907 - mae: 6.3907 - val_loss: 6.9704 - val_mae: 6.9704\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3905 - mae: 6.3905 - val_loss: 6.9768 - val_mae: 6.9768\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3900 - mae: 6.3900 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9722 - val_mae: 6.9722\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9692 - val_mae: 6.9692\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9734 - val_mae: 6.9734\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3911 - mae: 6.3911 - val_loss: 6.9805 - val_mae: 6.9805\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3915 - mae: 6.3915 - val_loss: 6.9739 - val_mae: 6.9739\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3910 - mae: 6.3910 - val_loss: 6.9684 - val_mae: 6.9684\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9746 - val_mae: 6.9746\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9734 - val_mae: 6.9734\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9668 - val_mae: 6.9668\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9765 - val_mae: 6.9765\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9719 - val_mae: 6.9719\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3909 - mae: 6.3909 - val_loss: 6.9667 - val_mae: 6.9667\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3925 - mae: 6.3925 - val_loss: 6.9759 - val_mae: 6.9759\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3872 - mae: 6.3872 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9691 - val_mae: 6.9691\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3933 - mae: 6.3933 - val_loss: 6.9685 - val_mae: 6.9685\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9750 - val_mae: 6.9750\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9741 - val_mae: 6.9741\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3914 - mae: 6.3914 - val_loss: 6.9781 - val_mae: 6.9781\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9726 - val_mae: 6.9726\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9628 - val_mae: 6.9628\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9705 - val_mae: 6.9705\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3873 - mae: 6.3873 - val_loss: 6.9672 - val_mae: 6.9672\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9717 - val_mae: 6.9717\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3923 - mae: 6.3923 - val_loss: 6.9718 - val_mae: 6.9718\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9738 - val_mae: 6.9738\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3937 - mae: 6.3937 - val_loss: 6.9675 - val_mae: 6.9675\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3867 - mae: 6.3867 - val_loss: 6.9785 - val_mae: 6.9785\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9773 - val_mae: 6.9773\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9726 - val_mae: 6.9726\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3869 - mae: 6.3869 - val_loss: 6.9648 - val_mae: 6.9648\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9702 - val_mae: 6.9702\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3886 - mae: 6.3886 - val_loss: 6.9677 - val_mae: 6.9677\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3868 - mae: 6.3868 - val_loss: 6.9740 - val_mae: 6.9740\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3909 - mae: 6.3909 - val_loss: 6.9736 - val_mae: 6.9736\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9661 - val_mae: 6.9661\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3875 - mae: 6.3875 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3845 - mae: 6.3845 - val_loss: 6.9622 - val_mae: 6.9622\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3718 - mae: 6.3718 - val_loss: 6.9146 - val_mae: 6.9146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.1824 - mae: 6.1824 - val_loss: 6.2343 - val_mae: 6.2343\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.5414 - mae: 5.5414 - val_loss: 5.3501 - val_mae: 5.3501\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 5.1023 - mae: 5.1023 - val_loss: 5.1525 - val_mae: 5.1525\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.1270 - mae: 5.1270 - val_loss: 5.2610 - val_mae: 5.2610\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.9348 - mae: 4.9348 - val_loss: 5.0823 - val_mae: 5.0823\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8766 - mae: 4.8766 - val_loss: 5.0743 - val_mae: 5.0743\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.8398 - mae: 4.8398 - val_loss: 4.9808 - val_mae: 4.9808\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.7463 - mae: 4.7463 - val_loss: 5.0550 - val_mae: 5.0550\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.6819 - mae: 4.6819 - val_loss: 4.8515 - val_mae: 4.8515\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.6072 - mae: 4.6072 - val_loss: 4.6849 - val_mae: 4.6849\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.5128 - mae: 4.5128 - val_loss: 4.5750 - val_mae: 4.5750\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.4755 - mae: 4.4755 - val_loss: 4.4842 - val_mae: 4.4842\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.3339 - mae: 4.3339 - val_loss: 4.4328 - val_mae: 4.4328\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2207 - mae: 4.2207 - val_loss: 4.3488 - val_mae: 4.3488\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1610 - mae: 4.1610 - val_loss: 4.2667 - val_mae: 4.2667\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.1331 - mae: 4.1331 - val_loss: 4.2958 - val_mae: 4.2958\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0103 - mae: 4.0103 - val_loss: 4.2170 - val_mae: 4.2170\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.9783 - mae: 3.9783 - val_loss: 4.1266 - val_mae: 4.1266\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9351 - mae: 3.9351 - val_loss: 4.0394 - val_mae: 4.0394\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8096 - mae: 3.8096 - val_loss: 4.0607 - val_mae: 4.0607\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.3678 - mae: 5.3678\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 171.6307 - mae: 9.7290 - val_loss: 97.5992 - val_mae: 6.9840\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 83.7473 - mae: 6.3896 - val_loss: 90.5854 - val_mae: 6.9800\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.8475 - mae: 6.3987 - val_loss: 89.3614 - val_mae: 7.0908\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.5973 - mae: 6.4543 - val_loss: 89.2305 - val_mae: 7.1381\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5279 - mae: 6.4762 - val_loss: 89.2179 - val_mae: 7.1554\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4808 - mae: 6.4630 - val_loss: 89.2317 - val_mae: 7.1371\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5662 - mae: 6.4873 - val_loss: 89.2178 - val_mae: 7.1558\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5209 - mae: 6.4642 - val_loss: 89.2191 - val_mae: 7.1519\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4634 - mae: 6.4720 - val_loss: 89.2192 - val_mae: 7.1516\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4739 - mae: 6.4812 - val_loss: 89.2175 - val_mae: 7.1610\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4549 - mae: 6.4755 - val_loss: 89.2208 - val_mae: 7.1486\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4872 - mae: 6.4793 - val_loss: 89.2176 - val_mae: 7.1566\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4796 - mae: 6.4867 - val_loss: 89.2174 - val_mae: 7.1595\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4469 - mae: 6.4787 - val_loss: 89.2174 - val_mae: 7.1605\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4622 - mae: 6.4696 - val_loss: 89.2224 - val_mae: 7.1462\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4538 - mae: 6.4748 - val_loss: 89.2183 - val_mae: 7.1535\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5370 - mae: 6.4869 - val_loss: 89.2176 - val_mae: 7.1561\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4714 - mae: 6.4780 - val_loss: 89.2183 - val_mae: 7.1536\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4648 - mae: 6.4789 - val_loss: 89.2173 - val_mae: 7.1608\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4618 - mae: 6.4821 - val_loss: 89.2190 - val_mae: 7.1672\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4261 - mae: 6.4790 - val_loss: 89.2197 - val_mae: 7.1502\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5142 - mae: 6.4674 - val_loss: 89.2240 - val_mae: 7.1441\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4857 - mae: 6.4699 - val_loss: 89.2203 - val_mae: 7.1491\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5092 - mae: 6.4676 - val_loss: 89.2190 - val_mae: 7.1517\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4885 - mae: 6.4788 - val_loss: 89.2198 - val_mae: 7.1498\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4639 - mae: 6.4895 - val_loss: 89.2187 - val_mae: 7.1666\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4532 - mae: 6.4760 - val_loss: 89.2172 - val_mae: 7.1595\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5352 - mae: 6.4789 - val_loss: 89.2315 - val_mae: 7.1370\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4249 - mae: 6.4806 - val_loss: 89.2186 - val_mae: 7.1667\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4862 - mae: 6.4760 - val_loss: 89.2174 - val_mae: 7.1561\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4525 - mae: 6.4804 - val_loss: 89.2171 - val_mae: 7.1577\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4338 - mae: 6.4790 - val_loss: 89.2174 - val_mae: 7.1556\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5151 - mae: 6.4652 - val_loss: 89.2256 - val_mae: 7.1421\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5175 - mae: 6.4848 - val_loss: 89.2212 - val_mae: 7.1715\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4613 - mae: 6.4844 - val_loss: 89.2179 - val_mae: 7.1653\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4715 - mae: 6.4820 - val_loss: 89.2171 - val_mae: 7.1616\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4334 - mae: 6.4918 - val_loss: 89.2262 - val_mae: 7.1774\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4866 - mae: 6.4792 - val_loss: 89.2169 - val_mae: 7.1609\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4525 - mae: 6.4770 - val_loss: 89.2172 - val_mae: 7.1630\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4754 - mae: 6.4916 - val_loss: 89.2169 - val_mae: 7.1575\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4202 - mae: 6.4898 - val_loss: 89.2209 - val_mae: 7.1715\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4627 - mae: 6.4811 - val_loss: 89.2182 - val_mae: 7.1520\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4781 - mae: 6.4876 - val_loss: 89.2190 - val_mae: 7.1685\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4889 - mae: 6.4878 - val_loss: 89.2184 - val_mae: 7.1675\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4443 - mae: 6.4836 - val_loss: 89.2165 - val_mae: 7.1597\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4421 - mae: 6.4779 - val_loss: 89.2175 - val_mae: 7.1531\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4619 - mae: 6.4838 - val_loss: 89.2167 - val_mae: 7.1631\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5831 - mae: 6.5079 - val_loss: 89.2204 - val_mae: 7.1714\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 80.4641 - mae: 6.4777 - val_loss: 89.2168 - val_mae: 7.1543\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4269 - mae: 6.4794 - val_loss: 89.2164 - val_mae: 7.1555\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.4593 - mae: 6.4733 - val_loss: 89.2161 - val_mae: 7.1563\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5007 - mae: 6.4639 - val_loss: 89.2253 - val_mae: 7.1410\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4532 - mae: 6.4652 - val_loss: 89.2213 - val_mae: 7.1451\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 80.4258 - mae: 6.4740 - val_loss: 89.2155 - val_mae: 7.1566\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 80.4303 - mae: 6.4750 - val_loss: 89.2178 - val_mae: 7.1494\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4386 - mae: 6.4729 - val_loss: 89.2152 - val_mae: 7.1557\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4693 - mae: 6.4713 - val_loss: 89.2156 - val_mae: 7.1528\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4841 - mae: 6.4652 - val_loss: 89.2154 - val_mae: 7.1522\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4599 - mae: 6.4866 - val_loss: 89.2142 - val_mae: 7.1639\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4685 - mae: 6.4758 - val_loss: 89.2135 - val_mae: 7.1546\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4569 - mae: 6.4832 - val_loss: 89.2123 - val_mae: 7.1610\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 80.4876 - mae: 6.4870 - val_loss: 89.2224 - val_mae: 7.1787\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4388 - mae: 6.4898 - val_loss: 89.2128 - val_mae: 7.1692\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4622 - mae: 6.4852 - val_loss: 89.2079 - val_mae: 7.1612\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.5199 - mae: 6.5034 - val_loss: 89.2085 - val_mae: 7.1696\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4892 - mae: 6.4903 - val_loss: 89.2015 - val_mae: 7.1645\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4417 - mae: 6.4801 - val_loss: 89.1927 - val_mae: 7.1526\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4760 - mae: 6.4669 - val_loss: 89.1807 - val_mae: 7.1464\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.4019 - mae: 6.4654 - val_loss: 89.1535 - val_mae: 7.1400\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 80.3478 - mae: 6.4634 - val_loss: 89.0875 - val_mae: 7.1402\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 80.2706 - mae: 6.4666 - val_loss: 88.8942 - val_mae: 7.1287\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 79.8889 - mae: 6.4302 - val_loss: 88.0315 - val_mae: 7.0611\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 76.5530 - mae: 6.1453 - val_loss: 77.5389 - val_mae: 6.1518\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 66.0961 - mae: 5.4379 - val_loss: 66.7153 - val_mae: 5.3337\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 58.8888 - mae: 5.0208 - val_loss: 62.0958 - val_mae: 4.9876\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 55.4286 - mae: 4.8868 - val_loss: 58.8371 - val_mae: 4.9583\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 52.7368 - mae: 4.9006 - val_loss: 57.0869 - val_mae: 5.1347\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 49.5545 - mae: 4.6058 - val_loss: 53.1396 - val_mae: 4.4969\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 47.1494 - mae: 4.5550 - val_loss: 50.7815 - val_mae: 4.2891\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 43.7373 - mae: 4.3152 - val_loss: 49.4101 - val_mae: 4.8134\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 42.3876 - mae: 4.3059 - val_loss: 45.6124 - val_mae: 4.2125\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 39.1617 - mae: 4.0539 - val_loss: 43.4035 - val_mae: 4.1542\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 36.9280 - mae: 3.8982 - val_loss: 41.5528 - val_mae: 3.7332\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 35.1110 - mae: 3.7662 - val_loss: 39.5602 - val_mae: 3.6650\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 33.5611 - mae: 3.6662 - val_loss: 37.2817 - val_mae: 3.5976\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 32.0951 - mae: 3.5508 - val_loss: 36.2045 - val_mae: 3.7768\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 30.7263 - mae: 3.4647 - val_loss: 34.9298 - val_mae: 3.6094\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 29.8755 - mae: 3.4831 - val_loss: 33.7500 - val_mae: 3.4054\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 28.8327 - mae: 3.3571 - val_loss: 32.4283 - val_mae: 3.3942\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 27.3985 - mae: 3.2437 - val_loss: 31.7618 - val_mae: 3.3560\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 26.5369 - mae: 3.2194 - val_loss: 30.5604 - val_mae: 3.3060\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 25.4505 - mae: 3.1256 - val_loss: 30.2774 - val_mae: 3.1642\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 24.9105 - mae: 3.1088 - val_loss: 29.4068 - val_mae: 3.3011\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 24.3196 - mae: 3.0872 - val_loss: 29.1336 - val_mae: 3.1252\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.7153 - mae: 3.0709 - val_loss: 30.6499 - val_mae: 3.2653\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 23.3660 - mae: 3.0636 - val_loss: 27.7944 - val_mae: 3.2388\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 23.0764 - mae: 3.0390 - val_loss: 28.4888 - val_mae: 3.1948\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 22.3461 - mae: 3.0106 - val_loss: 27.2229 - val_mae: 3.2628\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 21.7136 - mae: 2.9435 - val_loss: 27.1088 - val_mae: 3.3140\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 21.2660 - mae: 2.8959 - val_loss: 26.3888 - val_mae: 3.1281\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 32.9694 - mae: 3.7303\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 13ms/step - loss: 8.7531 - mae: 8.7531 - val_loss: 6.9505 - val_mae: 6.9505\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3938 - mae: 6.3938 - val_loss: 6.9748 - val_mae: 6.9748\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9786 - val_mae: 6.9786\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3903 - mae: 6.3903 - val_loss: 6.9757 - val_mae: 6.9757\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3926 - mae: 6.3926 - val_loss: 6.9614 - val_mae: 6.9614\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3959 - mae: 6.3959 - val_loss: 6.9784 - val_mae: 6.9784\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3870 - mae: 6.3870 - val_loss: 6.9689 - val_mae: 6.9689\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9625 - val_mae: 6.9625\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9731 - val_mae: 6.9731\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3901 - mae: 6.3901 - val_loss: 6.9822 - val_mae: 6.9822\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9680 - val_mae: 6.9680\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3918 - mae: 6.3918 - val_loss: 6.9667 - val_mae: 6.9667\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9668 - val_mae: 6.9668\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3885 - mae: 6.3885 - val_loss: 6.9699 - val_mae: 6.9699\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3884 - mae: 6.3884 - val_loss: 6.9758 - val_mae: 6.9758\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3878 - mae: 6.3878 - val_loss: 6.9727 - val_mae: 6.9727\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.4000 - mae: 6.4000 - val_loss: 6.9599 - val_mae: 6.9599\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3874 - mae: 6.3874 - val_loss: 6.9789 - val_mae: 6.9789\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3913 - mae: 6.3913 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3887 - mae: 6.3887 - val_loss: 6.9788 - val_mae: 6.9788\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9842 - val_mae: 6.9842\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9741 - val_mae: 6.9741\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3919 - mae: 6.3919 - val_loss: 6.9719 - val_mae: 6.9719\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3871 - mae: 6.3871 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9710 - val_mae: 6.9710\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3958 - mae: 6.3958 - val_loss: 6.9763 - val_mae: 6.9763\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3880 - mae: 6.3880 - val_loss: 6.9764 - val_mae: 6.9764\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9644 - val_mae: 6.9644\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3909 - mae: 6.3909 - val_loss: 6.9662 - val_mae: 6.9662\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3888 - mae: 6.3888 - val_loss: 6.9737 - val_mae: 6.9737\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3881 - mae: 6.3881 - val_loss: 6.9734 - val_mae: 6.9734\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3895 - mae: 6.3895 - val_loss: 6.9683 - val_mae: 6.9683\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3919 - mae: 6.3919 - val_loss: 6.9709 - val_mae: 6.9709\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9741 - val_mae: 6.9741\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9701 - val_mae: 6.9701\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3902 - mae: 6.3902 - val_loss: 6.9695 - val_mae: 6.9695\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3889 - mae: 6.3889 - val_loss: 6.9693 - val_mae: 6.9693\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3879 - mae: 6.3879 - val_loss: 6.9736 - val_mae: 6.9736\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3943 - mae: 6.3943 - val_loss: 6.9638 - val_mae: 6.9638\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3882 - mae: 6.3882 - val_loss: 6.9762 - val_mae: 6.9762\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3905 - mae: 6.3905 - val_loss: 6.9770 - val_mae: 6.9770\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3901 - mae: 6.3901 - val_loss: 6.9735 - val_mae: 6.9735\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3876 - mae: 6.3876 - val_loss: 6.9664 - val_mae: 6.9664\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9713 - val_mae: 6.9713\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3893 - mae: 6.3893 - val_loss: 6.9793 - val_mae: 6.9793\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3892 - mae: 6.3892 - val_loss: 6.9724 - val_mae: 6.9724\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3921 - mae: 6.3921 - val_loss: 6.9779 - val_mae: 6.9779\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3916 - mae: 6.3916 - val_loss: 6.9760 - val_mae: 6.9760\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3897 - mae: 6.3897 - val_loss: 6.9762 - val_mae: 6.9762\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3890 - mae: 6.3890 - val_loss: 6.9757 - val_mae: 6.9757\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3916 - mae: 6.3916 - val_loss: 6.9697 - val_mae: 6.9697\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3891 - mae: 6.3891 - val_loss: 6.9720 - val_mae: 6.9720\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3877 - mae: 6.3877 - val_loss: 6.9729 - val_mae: 6.9729\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3883 - mae: 6.3883 - val_loss: 6.9682 - val_mae: 6.9682\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3866 - mae: 6.3866 - val_loss: 6.9706 - val_mae: 6.9706\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 6.3901 - mae: 6.3901 - val_loss: 6.9527 - val_mae: 6.9527\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 6.3842 - mae: 6.3842 - val_loss: 6.9644 - val_mae: 6.9644\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.3663 - mae: 6.3663 - val_loss: 6.8868 - val_mae: 6.8868\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 6.1758 - mae: 6.1758 - val_loss: 6.1410 - val_mae: 6.1410\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 5.3779 - mae: 5.3779 - val_loss: 5.2254 - val_mae: 5.2254\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.9921 - mae: 4.9921 - val_loss: 5.1234 - val_mae: 5.1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.8829 - mae: 4.8829 - val_loss: 5.1011 - val_mae: 5.1011\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.8421 - mae: 4.8421 - val_loss: 5.1213 - val_mae: 5.1213\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.8265 - mae: 4.8265 - val_loss: 5.0026 - val_mae: 5.0026\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.7681 - mae: 4.7681 - val_loss: 5.0381 - val_mae: 5.0381\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.7473 - mae: 4.7473 - val_loss: 4.8857 - val_mae: 4.8857\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.6671 - mae: 4.6671 - val_loss: 4.8249 - val_mae: 4.8249\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.6196 - mae: 4.6196 - val_loss: 4.8914 - val_mae: 4.8914\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.6183 - mae: 4.6183 - val_loss: 4.7916 - val_mae: 4.7916\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.5099 - mae: 4.5099 - val_loss: 4.7618 - val_mae: 4.7618\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.4359 - mae: 4.4359 - val_loss: 4.5558 - val_mae: 4.5558\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.3695 - mae: 4.3695 - val_loss: 4.5390 - val_mae: 4.5390\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.2710 - mae: 4.2710 - val_loss: 4.4107 - val_mae: 4.4107\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.2316 - mae: 4.2316 - val_loss: 4.3434 - val_mae: 4.3434\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1388 - mae: 4.1388 - val_loss: 4.3370 - val_mae: 4.3370\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 4.1652 - mae: 4.1652 - val_loss: 4.2586 - val_mae: 4.2586\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 4.0568 - mae: 4.0568 - val_loss: 4.2124 - val_mae: 4.2124\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.9924 - mae: 3.9924 - val_loss: 4.3127 - val_mae: 4.3127\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9553 - mae: 3.9553 - val_loss: 4.1187 - val_mae: 4.1187\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.9152 - mae: 3.9152 - val_loss: 4.0911 - val_mae: 4.0911\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8660 - mae: 3.8660 - val_loss: 3.9552 - val_mae: 3.9552\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.8051 - mae: 3.8051 - val_loss: 3.9850 - val_mae: 3.9850\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.7421 - mae: 3.7421 - val_loss: 3.8299 - val_mae: 3.8299\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.6617 - mae: 3.6617 - val_loss: 3.8454 - val_mae: 3.8454\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.6115 - mae: 3.6115 - val_loss: 3.7601 - val_mae: 3.7601\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.5455 - mae: 3.5455 - val_loss: 3.7012 - val_mae: 3.7012\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.4591 - mae: 3.4591 - val_loss: 3.6386 - val_mae: 3.6386\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3753 - mae: 3.3753 - val_loss: 3.5855 - val_mae: 3.5855\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.3902 - mae: 3.3902 - val_loss: 3.5195 - val_mae: 3.5195\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 3.2830 - mae: 3.2830 - val_loss: 3.5619 - val_mae: 3.5619\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.3135 - mae: 3.3135 - val_loss: 3.4553 - val_mae: 3.4553\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.2187 - mae: 3.2187 - val_loss: 3.3826 - val_mae: 3.3826\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.1535 - mae: 3.1535 - val_loss: 3.3372 - val_mae: 3.3372\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.1035 - mae: 3.1035 - val_loss: 3.3426 - val_mae: 3.3426\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 3.0723 - mae: 3.0723 - val_loss: 3.2983 - val_mae: 3.2983\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 3.0584 - mae: 3.0584 - val_loss: 3.2880 - val_mae: 3.2880\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.9746 - mae: 2.9746 - val_loss: 3.3668 - val_mae: 3.3668\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 3.1316 - mae: 3.1316 - val_loss: 3.2599 - val_mae: 3.2599\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 2.9988 - mae: 2.9988 - val_loss: 3.2187 - val_mae: 3.2187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4232 - mae: 4.4232\n"
     ]
    }
   ],
   "source": [
    "epochs_ = 100\n",
    "\n",
    "for layer in count_hidden_layers:\n",
    "    for neorons in setting_neurons:\n",
    "        for activate_ in activate_fn:\n",
    "            for optimazer in optim_:\n",
    "                for loss_ in loss_fn:\n",
    "                    dict_train, dict_eval = model_boston_house(layer,\n",
    "                                                               neorons,\n",
    "                                                               activate_, \n",
    "                                                               optimazer, \n",
    "                                                               loss_,\n",
    "                                                               epochs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"425.27625pt\" version=\"1.1\" viewBox=\"0 0 723.765625 425.27625\" width=\"723.765625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 425.27625 \n",
       "L 723.765625 425.27625 \n",
       "L 723.765625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 387.72 \n",
       "L 716.565625 387.72 \n",
       "L 716.565625 7.2 \n",
       "L 46.965625 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m41c0563a61\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"77.401989\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(74.220739 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.377195\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(194.014695 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.352402\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(316.989902 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"446.327608\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(439.965108 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"569.302815\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(562.940315 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"692.278022\" xlink:href=\"#m41c0563a61\" y=\"387.72\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(682.734272 402.318438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(366.454687 415.996562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m5ecb28b557\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"372.525586\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(33.603125 376.324805)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"325.817797\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 50 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(27.240625 329.617016)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"279.110007\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.878125 282.909226)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"232.402217\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(20.878125 236.201436)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"185.694428\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(20.878125 189.493646)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"138.986638\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(20.878125 142.785857)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"92.278848\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 300 -->\n",
       "      <defs>\n",
       "       <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 96.078067)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m5ecb28b557\" y=\"45.571059\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 350 -->\n",
       "      <g transform=\"translate(20.878125 49.370277)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Loss -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 208.427188)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 74.249453 \n",
       "L 83.550749 261.106768 \n",
       "L 89.699509 306.50113 \n",
       "L 95.84827 322.797014 \n",
       "L 101.99703 332.362967 \n",
       "L 108.14579 338.490524 \n",
       "L 114.294551 342.244997 \n",
       "L 120.443311 344.663769 \n",
       "L 126.592071 346.637196 \n",
       "L 132.740832 347.921665 \n",
       "L 138.889592 349.013808 \n",
       "L 145.038352 349.77127 \n",
       "L 151.187113 350.497829 \n",
       "L 157.335873 351.187371 \n",
       "L 163.484633 351.6145 \n",
       "L 169.633394 352.019838 \n",
       "L 175.782154 352.440644 \n",
       "L 181.930914 352.821274 \n",
       "L 188.079675 353.067414 \n",
       "L 194.228435 353.37203 \n",
       "L 200.377195 353.615624 \n",
       "L 206.525956 353.764727 \n",
       "L 212.674716 354.073517 \n",
       "L 218.823476 354.204745 \n",
       "L 224.972237 354.456301 \n",
       "L 231.120997 354.61367 \n",
       "L 237.269757 354.81794 \n",
       "L 243.418518 354.958578 \n",
       "L 249.567278 355.063116 \n",
       "L 255.716038 355.299481 \n",
       "L 261.864799 355.370101 \n",
       "L 268.013559 355.516734 \n",
       "L 274.162319 355.590806 \n",
       "L 280.31108 355.648485 \n",
       "L 286.45984 355.78776 \n",
       "L 292.6086 355.910184 \n",
       "L 298.757361 356.016012 \n",
       "L 304.906121 356.189112 \n",
       "L 311.054881 356.224245 \n",
       "L 317.203642 356.324315 \n",
       "L 323.352402 356.378176 \n",
       "L 329.501162 356.525519 \n",
       "L 335.649923 356.560629 \n",
       "L 341.798683 356.639357 \n",
       "L 347.947443 356.75385 \n",
       "L 354.096204 356.798267 \n",
       "L 360.244964 356.782488 \n",
       "L 366.393724 356.964237 \n",
       "L 372.542485 356.97157 \n",
       "L 378.691245 357.027192 \n",
       "L 384.840005 357.07224 \n",
       "L 390.988765 357.16765 \n",
       "L 397.137526 357.221897 \n",
       "L 403.286286 357.330144 \n",
       "L 409.435046 357.397131 \n",
       "L 415.583807 357.436352 \n",
       "L 421.732567 357.469414 \n",
       "L 427.881327 357.534015 \n",
       "L 434.030088 357.66044 \n",
       "L 440.178848 357.725305 \n",
       "L 446.327608 357.692232 \n",
       "L 452.476369 357.729114 \n",
       "L 458.625129 357.767301 \n",
       "L 464.773889 357.876327 \n",
       "L 470.92265 357.880421 \n",
       "L 477.07141 357.960015 \n",
       "L 483.22017 358.042058 \n",
       "L 489.368931 358.002832 \n",
       "L 495.517691 358.089032 \n",
       "L 501.666451 358.059597 \n",
       "L 507.815212 358.132745 \n",
       "L 513.963972 358.259162 \n",
       "L 520.112732 358.253092 \n",
       "L 526.261493 358.303313 \n",
       "L 532.410253 358.351882 \n",
       "L 538.559013 358.322788 \n",
       "L 544.707774 358.319277 \n",
       "L 550.856534 358.45226 \n",
       "L 557.005294 358.444453 \n",
       "L 563.154055 358.551008 \n",
       "L 569.302815 358.500171 \n",
       "L 575.451575 358.633934 \n",
       "L 581.600336 358.67524 \n",
       "L 587.749096 358.667274 \n",
       "L 593.897856 358.617284 \n",
       "L 600.046617 358.811698 \n",
       "L 606.195377 358.77457 \n",
       "L 612.344137 358.802588 \n",
       "L 618.492898 358.788416 \n",
       "L 624.641658 358.861977 \n",
       "L 630.790418 358.925287 \n",
       "L 636.939179 358.940814 \n",
       "L 643.087939 358.971552 \n",
       "L 649.236699 358.947337 \n",
       "L 655.38546 359.005842 \n",
       "L 661.53422 359.055632 \n",
       "L 667.68298 359.121426 \n",
       "L 673.831741 359.069202 \n",
       "L 679.980501 359.144327 \n",
       "L 686.129261 359.079974 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 356.693158 \n",
       "L 83.550749 363.321104 \n",
       "L 89.699509 366.560505 \n",
       "L 95.84827 367.880989 \n",
       "L 101.99703 368.6152 \n",
       "L 108.14579 368.978616 \n",
       "L 114.294551 369.163619 \n",
       "L 120.443311 369.254619 \n",
       "L 126.592071 369.303806 \n",
       "L 132.740832 369.376642 \n",
       "L 138.889592 369.419956 \n",
       "L 145.038352 369.481465 \n",
       "L 151.187113 369.519081 \n",
       "L 157.335873 369.522047 \n",
       "L 163.484633 369.569983 \n",
       "L 169.633394 369.624202 \n",
       "L 175.782154 369.607811 \n",
       "L 181.930914 369.664352 \n",
       "L 188.079675 369.684103 \n",
       "L 194.228435 369.727371 \n",
       "L 200.377195 369.732812 \n",
       "L 206.525956 369.75017 \n",
       "L 212.674716 369.760364 \n",
       "L 218.823476 369.768139 \n",
       "L 224.972237 369.791759 \n",
       "L 231.120997 369.786172 \n",
       "L 237.269757 369.796434 \n",
       "L 243.418518 369.797952 \n",
       "L 249.567278 369.802118 \n",
       "L 255.716038 369.82816 \n",
       "L 261.864799 369.838817 \n",
       "L 268.013559 369.853955 \n",
       "L 274.162319 369.863258 \n",
       "L 280.31108 369.867778 \n",
       "L 286.45984 369.903239 \n",
       "L 292.6086 369.907229 \n",
       "L 298.757361 369.912948 \n",
       "L 304.906121 369.916602 \n",
       "L 311.054881 369.930017 \n",
       "L 317.203642 369.941502 \n",
       "L 323.352402 369.969697 \n",
       "L 329.501162 369.964709 \n",
       "L 335.649923 369.969115 \n",
       "L 341.798683 369.99159 \n",
       "L 347.947443 370.004287 \n",
       "L 354.096204 370.006791 \n",
       "L 360.244964 370.001396 \n",
       "L 366.393724 370.030219 \n",
       "L 372.542485 370.025341 \n",
       "L 378.691245 370.052655 \n",
       "L 384.840005 370.046388 \n",
       "L 390.988765 370.061719 \n",
       "L 397.137526 370.053965 \n",
       "L 403.286286 370.079517 \n",
       "L 409.435046 370.089419 \n",
       "L 415.583807 370.089011 \n",
       "L 421.732567 370.089427 \n",
       "L 427.881327 370.103485 \n",
       "L 434.030088 370.101309 \n",
       "L 440.178848 370.123362 \n",
       "L 446.327608 370.112047 \n",
       "L 452.476369 370.113313 \n",
       "L 458.625129 370.116473 \n",
       "L 464.773889 370.129493 \n",
       "L 470.92265 370.156396 \n",
       "L 477.07141 370.146691 \n",
       "L 483.22017 370.150559 \n",
       "L 489.368931 370.145373 \n",
       "L 495.517691 370.182975 \n",
       "L 501.666451 370.163884 \n",
       "L 507.815212 370.170048 \n",
       "L 513.963972 370.1762 \n",
       "L 520.112732 370.161001 \n",
       "L 526.261493 370.197521 \n",
       "L 532.410253 370.199689 \n",
       "L 538.559013 370.193415 \n",
       "L 544.707774 370.202267 \n",
       "L 550.856534 370.205343 \n",
       "L 557.005294 370.203244 \n",
       "L 563.154055 370.212689 \n",
       "L 569.302815 370.219113 \n",
       "L 575.451575 370.214167 \n",
       "L 581.600336 370.207225 \n",
       "L 587.749096 370.225148 \n",
       "L 593.897856 370.228773 \n",
       "L 600.046617 370.226778 \n",
       "L 606.195377 370.239931 \n",
       "L 612.344137 370.228595 \n",
       "L 618.492898 370.246253 \n",
       "L 624.641658 370.245542 \n",
       "L 630.790418 370.241354 \n",
       "L 636.939179 370.256612 \n",
       "L 643.087939 370.246861 \n",
       "L 649.236699 370.245385 \n",
       "L 655.38546 370.247252 \n",
       "L 661.53422 370.2576 \n",
       "L 667.68298 370.250045 \n",
       "L 673.831741 370.268835 \n",
       "L 679.980501 370.260992 \n",
       "L 686.129261 370.257626 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 30.934136 \n",
       "L 83.550749 224.841351 \n",
       "L 89.699509 300.909316 \n",
       "L 95.84827 320.010646 \n",
       "L 101.99703 331.73997 \n",
       "L 108.14579 337.793168 \n",
       "L 114.294551 341.77644 \n",
       "L 120.443311 344.645376 \n",
       "L 126.592071 346.489882 \n",
       "L 132.740832 347.866983 \n",
       "L 138.889592 348.760101 \n",
       "L 145.038352 349.655324 \n",
       "L 151.187113 350.308131 \n",
       "L 157.335873 350.88853 \n",
       "L 163.484633 351.358258 \n",
       "L 169.633394 351.821751 \n",
       "L 175.782154 352.085453 \n",
       "L 181.930914 352.48231 \n",
       "L 188.079675 352.792262 \n",
       "L 194.228435 353.042086 \n",
       "L 200.377195 353.314827 \n",
       "L 206.525956 353.519346 \n",
       "L 212.674716 353.70331 \n",
       "L 218.823476 353.912223 \n",
       "L 224.972237 354.136538 \n",
       "L 231.120997 354.30245 \n",
       "L 237.269757 354.556458 \n",
       "L 243.418518 354.658086 \n",
       "L 249.567278 354.81461 \n",
       "L 255.716038 354.929448 \n",
       "L 261.864799 355.061302 \n",
       "L 268.013559 355.261884 \n",
       "L 274.162319 355.363843 \n",
       "L 280.31108 355.48974 \n",
       "L 286.45984 355.565423 \n",
       "L 292.6086 355.6457 \n",
       "L 298.757361 355.845517 \n",
       "L 304.906121 355.890651 \n",
       "L 311.054881 356.04194 \n",
       "L 317.203642 356.133213 \n",
       "L 323.352402 356.22508 \n",
       "L 329.501162 356.380175 \n",
       "L 335.649923 356.401405 \n",
       "L 341.798683 356.464267 \n",
       "L 347.947443 356.589074 \n",
       "L 354.096204 356.651876 \n",
       "L 360.244964 356.676431 \n",
       "L 366.393724 356.831928 \n",
       "L 372.542485 356.899283 \n",
       "L 378.691245 356.952677 \n",
       "L 384.840005 357.037353 \n",
       "L 390.988765 357.131227 \n",
       "L 397.137526 357.145999 \n",
       "L 403.286286 357.215214 \n",
       "L 409.435046 357.304606 \n",
       "L 415.583807 357.353991 \n",
       "L 421.732567 357.446467 \n",
       "L 427.881327 357.541506 \n",
       "L 434.030088 357.530721 \n",
       "L 440.178848 357.650417 \n",
       "L 446.327608 357.691135 \n",
       "L 452.476369 357.779584 \n",
       "L 458.625129 357.868718 \n",
       "L 464.773889 357.878035 \n",
       "L 470.92265 357.906682 \n",
       "L 477.07141 358.015216 \n",
       "L 483.22017 358.093419 \n",
       "L 489.368931 358.117452 \n",
       "L 495.517691 358.195905 \n",
       "L 501.666451 358.273011 \n",
       "L 507.815212 358.320001 \n",
       "L 513.963972 358.292426 \n",
       "L 520.112732 358.33199 \n",
       "L 526.261493 358.366166 \n",
       "L 532.410253 358.497729 \n",
       "L 538.559013 358.546581 \n",
       "L 544.707774 358.505023 \n",
       "L 550.856534 358.543996 \n",
       "L 557.005294 358.666931 \n",
       "L 563.154055 358.607856 \n",
       "L 569.302815 358.673302 \n",
       "L 575.451575 358.779994 \n",
       "L 581.600336 358.804824 \n",
       "L 587.749096 358.818118 \n",
       "L 593.897856 358.927743 \n",
       "L 600.046617 358.911674 \n",
       "L 606.195377 358.971836 \n",
       "L 612.344137 359.005317 \n",
       "L 618.492898 359.006151 \n",
       "L 624.641658 359.134142 \n",
       "L 630.790418 359.06665 \n",
       "L 636.939179 359.192139 \n",
       "L 643.087939 359.167274 \n",
       "L 649.236699 359.229623 \n",
       "L 655.38546 359.254249 \n",
       "L 661.53422 359.293112 \n",
       "L 667.68298 359.338742 \n",
       "L 673.831741 359.332344 \n",
       "L 679.980501 359.340005 \n",
       "L 686.129261 359.398476 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 357.044514 \n",
       "L 83.550749 363.466692 \n",
       "L 89.699509 367.03576 \n",
       "L 95.84827 368.244123 \n",
       "L 101.99703 368.839086 \n",
       "L 108.14579 369.216224 \n",
       "L 114.294551 369.395077 \n",
       "L 120.443311 369.472275 \n",
       "L 126.592071 369.522177 \n",
       "L 132.740832 369.554325 \n",
       "L 138.889592 369.588501 \n",
       "L 145.038352 369.597506 \n",
       "L 151.187113 369.611463 \n",
       "L 157.335873 369.662282 \n",
       "L 163.484633 369.686176 \n",
       "L 169.633394 369.688162 \n",
       "L 175.782154 369.764333 \n",
       "L 181.930914 369.802829 \n",
       "L 188.079675 369.757936 \n",
       "L 194.228435 369.818405 \n",
       "L 200.377195 369.817702 \n",
       "L 206.525956 369.814664 \n",
       "L 212.674716 369.858137 \n",
       "L 218.823476 369.848904 \n",
       "L 224.972237 369.884043 \n",
       "L 231.120997 369.883484 \n",
       "L 237.269757 369.88354 \n",
       "L 243.418518 369.8925 \n",
       "L 249.567278 369.908206 \n",
       "L 255.716038 369.903501 \n",
       "L 261.864799 369.938746 \n",
       "L 268.013559 369.934699 \n",
       "L 274.162319 369.953699 \n",
       "L 280.31108 369.967459 \n",
       "L 286.45984 369.984611 \n",
       "L 292.6086 369.985761 \n",
       "L 298.757361 369.981423 \n",
       "L 304.906121 370.000544 \n",
       "L 311.054881 370.006955 \n",
       "L 317.203642 370.003904 \n",
       "L 323.352402 370.047559 \n",
       "L 329.501162 370.061565 \n",
       "L 335.649923 370.0722 \n",
       "L 341.798683 370.059551 \n",
       "L 347.947443 370.083935 \n",
       "L 354.096204 370.072678 \n",
       "L 360.244964 370.093869 \n",
       "L 366.393724 370.113376 \n",
       "L 372.542485 370.121946 \n",
       "L 378.691245 370.122088 \n",
       "L 384.840005 370.131519 \n",
       "L 390.988765 370.156919 \n",
       "L 397.137526 370.15045 \n",
       "L 403.286286 370.171818 \n",
       "L 409.435046 370.177812 \n",
       "L 415.583807 370.179845 \n",
       "L 421.732567 370.180508 \n",
       "L 427.881327 370.204731 \n",
       "L 434.030088 370.187365 \n",
       "L 440.178848 370.209942 \n",
       "L 446.327608 370.214598 \n",
       "L 452.476369 370.213427 \n",
       "L 458.625129 370.194954 \n",
       "L 464.773889 370.216886 \n",
       "L 470.92265 370.217793 \n",
       "L 477.07141 370.240628 \n",
       "L 483.22017 370.237144 \n",
       "L 489.368931 370.246737 \n",
       "L 495.517691 370.239544 \n",
       "L 501.666451 370.252909 \n",
       "L 507.815212 370.260776 \n",
       "L 513.963972 370.259061 \n",
       "L 520.112732 370.264329 \n",
       "L 526.261493 370.28015 \n",
       "L 532.410253 370.266752 \n",
       "L 538.559013 370.251482 \n",
       "L 544.707774 370.281478 \n",
       "L 550.856534 370.290422 \n",
       "L 557.005294 370.2708 \n",
       "L 563.154055 370.28734 \n",
       "L 569.302815 370.290517 \n",
       "L 575.451575 370.263883 \n",
       "L 581.600336 370.282698 \n",
       "L 587.749096 370.276725 \n",
       "L 593.897856 370.281816 \n",
       "L 600.046617 370.267829 \n",
       "L 606.195377 370.286949 \n",
       "L 612.344137 370.288098 \n",
       "L 618.492898 370.278752 \n",
       "L 624.641658 370.277518 \n",
       "L 630.790418 370.294601 \n",
       "L 636.939179 370.29057 \n",
       "L 643.087939 370.299821 \n",
       "L 649.236699 370.290984 \n",
       "L 655.38546 370.297847 \n",
       "L 661.53422 370.283242 \n",
       "L 667.68298 370.291883 \n",
       "L 673.831741 370.296132 \n",
       "L 679.980501 370.304841 \n",
       "L 686.129261 370.306363 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 31.015042 \n",
       "L 83.550749 233.735231 \n",
       "L 89.699509 306.595171 \n",
       "L 95.84827 325.713574 \n",
       "L 101.99703 334.939632 \n",
       "L 108.14579 340.387454 \n",
       "L 114.294551 343.60411 \n",
       "L 120.443311 345.87168 \n",
       "L 126.592071 347.560527 \n",
       "L 132.740832 348.945782 \n",
       "L 138.889592 349.798731 \n",
       "L 145.038352 350.541026 \n",
       "L 151.187113 351.166775 \n",
       "L 157.335873 351.709161 \n",
       "L 163.484633 352.085858 \n",
       "L 169.633394 352.564255 \n",
       "L 175.782154 352.886846 \n",
       "L 181.930914 353.300562 \n",
       "L 188.079675 353.550934 \n",
       "L 194.228435 353.864605 \n",
       "L 200.377195 354.120774 \n",
       "L 206.525956 354.378757 \n",
       "L 212.674716 354.421473 \n",
       "L 218.823476 354.672873 \n",
       "L 224.972237 354.865518 \n",
       "L 231.120997 354.994726 \n",
       "L 237.269757 355.144282 \n",
       "L 243.418518 355.350006 \n",
       "L 249.567278 355.414046 \n",
       "L 255.716038 355.586499 \n",
       "L 261.864799 355.701546 \n",
       "L 268.013559 355.810338 \n",
       "L 274.162319 355.940585 \n",
       "L 280.31108 356.070685 \n",
       "L 286.45984 356.173548 \n",
       "L 292.6086 356.213631 \n",
       "L 298.757361 356.342593 \n",
       "L 304.906121 356.465406 \n",
       "L 311.054881 356.506846 \n",
       "L 317.203642 356.63813 \n",
       "L 323.352402 356.786228 \n",
       "L 329.501162 356.780765 \n",
       "L 335.649923 356.879387 \n",
       "L 341.798683 357.038294 \n",
       "L 347.947443 357.08829 \n",
       "L 354.096204 357.142564 \n",
       "L 360.244964 357.217993 \n",
       "L 366.393724 357.327434 \n",
       "L 372.542485 357.412472 \n",
       "L 378.691245 357.397254 \n",
       "L 384.840005 357.505003 \n",
       "L 390.988765 357.575915 \n",
       "L 397.137526 357.694858 \n",
       "L 403.286286 357.683852 \n",
       "L 409.435046 357.799338 \n",
       "L 415.583807 357.880747 \n",
       "L 421.732567 357.958538 \n",
       "L 427.881327 357.933282 \n",
       "L 434.030088 358.08063 \n",
       "L 440.178848 358.160244 \n",
       "L 446.327608 358.19785 \n",
       "L 452.476369 358.246608 \n",
       "L 458.625129 358.285021 \n",
       "L 464.773889 358.258075 \n",
       "L 470.92265 358.331381 \n",
       "L 477.07141 358.384822 \n",
       "L 483.22017 358.484942 \n",
       "L 489.368931 358.491146 \n",
       "L 495.517691 358.526852 \n",
       "L 501.666451 358.531146 \n",
       "L 507.815212 358.688734 \n",
       "L 513.963972 358.668261 \n",
       "L 520.112732 358.699373 \n",
       "L 526.261493 358.817889 \n",
       "L 532.410253 358.846021 \n",
       "L 538.559013 358.800306 \n",
       "L 544.707774 358.923774 \n",
       "L 550.856534 358.942906 \n",
       "L 557.005294 358.934918 \n",
       "L 563.154055 359.028222 \n",
       "L 569.302815 359.053605 \n",
       "L 575.451575 359.062896 \n",
       "L 581.600336 359.11105 \n",
       "L 587.749096 359.120452 \n",
       "L 593.897856 359.160527 \n",
       "L 600.046617 359.155143 \n",
       "L 606.195377 359.272214 \n",
       "L 612.344137 359.29679 \n",
       "L 618.492898 359.345498 \n",
       "L 624.641658 359.314408 \n",
       "L 630.790418 359.361888 \n",
       "L 636.939179 359.465259 \n",
       "L 643.087939 359.489757 \n",
       "L 649.236699 359.517615 \n",
       "L 655.38546 359.591937 \n",
       "L 661.53422 359.544115 \n",
       "L 667.68298 359.565561 \n",
       "L 673.831741 359.634739 \n",
       "L 679.980501 359.617045 \n",
       "L 686.129261 359.674623 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 359.145562 \n",
       "L 83.550749 365.98557 \n",
       "L 89.699509 367.36213 \n",
       "L 95.84827 368.289689 \n",
       "L 101.99703 368.929664 \n",
       "L 108.14579 369.23145 \n",
       "L 114.294551 369.404444 \n",
       "L 120.443311 369.473567 \n",
       "L 126.592071 369.498708 \n",
       "L 132.740832 369.519266 \n",
       "L 138.889592 369.567298 \n",
       "L 145.038352 369.610432 \n",
       "L 151.187113 369.681744 \n",
       "L 157.335873 369.695443 \n",
       "L 163.484633 369.735645 \n",
       "L 169.633394 369.753296 \n",
       "L 175.782154 369.793504 \n",
       "L 181.930914 369.808169 \n",
       "L 188.079675 369.811563 \n",
       "L 194.228435 369.865097 \n",
       "L 200.377195 369.859267 \n",
       "L 206.525956 369.870441 \n",
       "L 212.674716 369.864289 \n",
       "L 218.823476 369.896841 \n",
       "L 224.972237 369.911299 \n",
       "L 231.120997 369.910894 \n",
       "L 237.269757 369.924627 \n",
       "L 243.418518 369.940958 \n",
       "L 249.567278 369.937789 \n",
       "L 255.716038 369.942215 \n",
       "L 261.864799 369.957397 \n",
       "L 268.013559 369.951089 \n",
       "L 274.162319 369.981525 \n",
       "L 280.31108 369.996325 \n",
       "L 286.45984 369.978854 \n",
       "L 292.6086 370.012655 \n",
       "L 298.757361 370.014116 \n",
       "L 304.906121 370.037385 \n",
       "L 311.054881 370.027534 \n",
       "L 317.203642 370.043443 \n",
       "L 323.352402 370.043447 \n",
       "L 329.501162 370.049642 \n",
       "L 335.649923 370.049983 \n",
       "L 341.798683 370.06363 \n",
       "L 347.947443 370.063492 \n",
       "L 354.096204 370.064534 \n",
       "L 360.244964 370.093159 \n",
       "L 366.393724 370.079876 \n",
       "L 372.542485 370.101534 \n",
       "L 378.691245 370.096276 \n",
       "L 384.840005 370.09554 \n",
       "L 390.988765 370.102975 \n",
       "L 397.137526 370.103916 \n",
       "L 403.286286 370.122693 \n",
       "L 409.435046 370.137273 \n",
       "L 415.583807 370.144712 \n",
       "L 421.732567 370.131214 \n",
       "L 427.881327 370.14383 \n",
       "L 434.030088 370.132195 \n",
       "L 440.178848 370.152201 \n",
       "L 446.327608 370.15151 \n",
       "L 452.476369 370.145425 \n",
       "L 458.625129 370.164883 \n",
       "L 464.773889 370.163067 \n",
       "L 470.92265 370.159535 \n",
       "L 477.07141 370.167749 \n",
       "L 483.22017 370.167887 \n",
       "L 489.368931 370.16989 \n",
       "L 495.517691 370.167891 \n",
       "L 501.666451 370.180083 \n",
       "L 507.815212 370.171072 \n",
       "L 513.963972 370.157659 \n",
       "L 520.112732 370.190266 \n",
       "L 526.261493 370.178934 \n",
       "L 532.410253 370.177656 \n",
       "L 538.559013 370.190931 \n",
       "L 544.707774 370.196773 \n",
       "L 550.856534 370.182482 \n",
       "L 557.005294 370.185116 \n",
       "L 563.154055 370.180781 \n",
       "L 569.302815 370.186643 \n",
       "L 575.451575 370.192653 \n",
       "L 581.600336 370.208579 \n",
       "L 587.749096 370.207439 \n",
       "L 593.897856 370.201483 \n",
       "L 600.046617 370.194745 \n",
       "L 606.195377 370.210516 \n",
       "L 612.344137 370.193234 \n",
       "L 618.492898 370.204275 \n",
       "L 624.641658 370.205021 \n",
       "L 630.790418 370.210477 \n",
       "L 636.939179 370.20963 \n",
       "L 643.087939 370.202395 \n",
       "L 649.236699 370.199107 \n",
       "L 655.38546 370.204133 \n",
       "L 661.53422 370.204405 \n",
       "L 667.68298 370.201769 \n",
       "L 673.831741 370.206815 \n",
       "L 679.980501 370.193674 \n",
       "L 686.129261 370.213555 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 24.496364 \n",
       "L 83.550749 96.727349 \n",
       "L 89.699509 133.531842 \n",
       "L 95.84827 158.33981 \n",
       "L 101.99703 177.347591 \n",
       "L 108.14579 192.539254 \n",
       "L 114.294551 205.303332 \n",
       "L 120.443311 215.830559 \n",
       "L 126.592071 224.600001 \n",
       "L 132.740832 232.605709 \n",
       "L 138.889592 239.392934 \n",
       "L 145.038352 245.73261 \n",
       "L 151.187113 251.278661 \n",
       "L 157.335873 256.380327 \n",
       "L 163.484633 261.146637 \n",
       "L 169.633394 265.116721 \n",
       "L 175.782154 268.766686 \n",
       "L 181.930914 271.969807 \n",
       "L 188.079675 274.883129 \n",
       "L 194.228435 277.567751 \n",
       "L 200.377195 280.004494 \n",
       "L 206.525956 282.27502 \n",
       "L 212.674716 284.371297 \n",
       "L 218.823476 286.465443 \n",
       "L 224.972237 288.284593 \n",
       "L 231.120997 290.035194 \n",
       "L 237.269757 291.775996 \n",
       "L 243.418518 293.27296 \n",
       "L 249.567278 294.885788 \n",
       "L 255.716038 296.278534 \n",
       "L 261.864799 297.65989 \n",
       "L 268.013559 298.986732 \n",
       "L 274.162319 300.193461 \n",
       "L 280.31108 301.405914 \n",
       "L 286.45984 302.556896 \n",
       "L 292.6086 303.620614 \n",
       "L 298.757361 304.635184 \n",
       "L 304.906121 305.58817 \n",
       "L 311.054881 306.46471 \n",
       "L 317.203642 307.388667 \n",
       "L 323.352402 308.192719 \n",
       "L 329.501162 308.966381 \n",
       "L 335.649923 309.712276 \n",
       "L 341.798683 310.349818 \n",
       "L 347.947443 311.040721 \n",
       "L 354.096204 311.648907 \n",
       "L 360.244964 312.258127 \n",
       "L 366.393724 312.856339 \n",
       "L 372.542485 313.388212 \n",
       "L 378.691245 313.898829 \n",
       "L 384.840005 314.423429 \n",
       "L 390.988765 314.94169 \n",
       "L 397.137526 315.384048 \n",
       "L 403.286286 315.820964 \n",
       "L 409.435046 316.223168 \n",
       "L 415.583807 316.651037 \n",
       "L 421.732567 317.058807 \n",
       "L 427.881327 317.401504 \n",
       "L 434.030088 317.808087 \n",
       "L 440.178848 318.152861 \n",
       "L 446.327608 318.489418 \n",
       "L 452.476369 318.843557 \n",
       "L 458.625129 319.171366 \n",
       "L 464.773889 319.507755 \n",
       "L 470.92265 319.831426 \n",
       "L 477.07141 320.12103 \n",
       "L 483.22017 320.405189 \n",
       "L 489.368931 320.740669 \n",
       "L 495.517691 321.03936 \n",
       "L 501.666451 321.334398 \n",
       "L 507.815212 321.611826 \n",
       "L 513.963972 321.910313 \n",
       "L 520.112732 322.218048 \n",
       "L 526.261493 322.493088 \n",
       "L 532.410253 322.761731 \n",
       "L 538.559013 323.048082 \n",
       "L 544.707774 323.344506 \n",
       "L 550.856534 323.639993 \n",
       "L 557.005294 323.934558 \n",
       "L 563.154055 324.224261 \n",
       "L 569.302815 324.499244 \n",
       "L 575.451575 324.815147 \n",
       "L 581.600336 325.065719 \n",
       "L 587.749096 325.374466 \n",
       "L 593.897856 325.644724 \n",
       "L 600.046617 325.965177 \n",
       "L 606.195377 326.245954 \n",
       "L 612.344137 326.552559 \n",
       "L 618.492898 326.831394 \n",
       "L 624.641658 327.158394 \n",
       "L 630.790418 327.44215 \n",
       "L 636.939179 327.745968 \n",
       "L 643.087939 328.027864 \n",
       "L 649.236699 328.347519 \n",
       "L 655.38546 328.611858 \n",
       "L 661.53422 328.917547 \n",
       "L 667.68298 329.210398 \n",
       "L 673.831741 329.50989 \n",
       "L 679.980501 329.743372 \n",
       "L 686.129261 330.043884 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.096187 \n",
       "L 83.550749 360.531038 \n",
       "L 89.699509 361.808516 \n",
       "L 95.84827 362.684417 \n",
       "L 101.99703 363.40154 \n",
       "L 108.14579 363.956724 \n",
       "L 114.294551 364.391753 \n",
       "L 120.443311 364.735589 \n",
       "L 126.592071 365.005703 \n",
       "L 132.740832 365.241646 \n",
       "L 138.889592 365.454768 \n",
       "L 145.038352 365.646222 \n",
       "L 151.187113 365.817298 \n",
       "L 157.335873 365.974675 \n",
       "L 163.484633 366.130516 \n",
       "L 169.633394 366.263814 \n",
       "L 175.782154 366.387264 \n",
       "L 181.930914 366.508969 \n",
       "L 188.079675 366.618809 \n",
       "L 194.228435 366.714229 \n",
       "L 200.377195 366.815748 \n",
       "L 206.525956 366.912922 \n",
       "L 212.674716 367.008086 \n",
       "L 218.823476 367.093421 \n",
       "L 224.972237 367.184298 \n",
       "L 231.120997 367.259306 \n",
       "L 237.269757 367.337792 \n",
       "L 243.418518 367.415632 \n",
       "L 249.567278 367.477814 \n",
       "L 255.716038 367.536264 \n",
       "L 261.864799 367.592424 \n",
       "L 268.013559 367.641773 \n",
       "L 274.162319 367.691081 \n",
       "L 280.31108 367.758619 \n",
       "L 286.45984 367.808897 \n",
       "L 292.6086 367.842033 \n",
       "L 298.757361 367.909402 \n",
       "L 304.906121 367.942161 \n",
       "L 311.054881 367.974703 \n",
       "L 317.203642 368.009818 \n",
       "L 323.352402 368.026821 \n",
       "L 329.501162 368.065592 \n",
       "L 335.649923 368.07795 \n",
       "L 341.798683 368.103944 \n",
       "L 347.947443 368.129808 \n",
       "L 354.096204 368.144899 \n",
       "L 360.244964 368.161177 \n",
       "L 366.393724 368.176144 \n",
       "L 372.542485 368.189192 \n",
       "L 378.691245 368.198469 \n",
       "L 384.840005 368.205695 \n",
       "L 390.988765 368.221734 \n",
       "L 397.137526 368.235143 \n",
       "L 403.286286 368.254603 \n",
       "L 409.435046 368.260134 \n",
       "L 415.583807 368.281852 \n",
       "L 421.732567 368.296275 \n",
       "L 427.881327 368.297983 \n",
       "L 434.030088 368.309293 \n",
       "L 440.178848 368.322754 \n",
       "L 446.327608 368.333026 \n",
       "L 452.476369 368.343488 \n",
       "L 458.625129 368.354476 \n",
       "L 464.773889 368.364164 \n",
       "L 470.92265 368.37754 \n",
       "L 477.07141 368.384857 \n",
       "L 483.22017 368.392564 \n",
       "L 489.368931 368.405221 \n",
       "L 495.517691 368.413848 \n",
       "L 501.666451 368.422561 \n",
       "L 507.815212 368.428098 \n",
       "L 513.963972 368.438078 \n",
       "L 520.112732 368.442799 \n",
       "L 526.261493 368.449565 \n",
       "L 532.410253 368.457629 \n",
       "L 538.559013 368.463744 \n",
       "L 544.707774 368.469064 \n",
       "L 550.856534 368.476624 \n",
       "L 557.005294 368.481183 \n",
       "L 563.154055 368.488607 \n",
       "L 569.302815 368.496563 \n",
       "L 575.451575 368.504367 \n",
       "L 581.600336 368.510757 \n",
       "L 587.749096 368.518484 \n",
       "L 593.897856 368.525843 \n",
       "L 600.046617 368.531377 \n",
       "L 606.195377 368.537817 \n",
       "L 612.344137 368.545446 \n",
       "L 618.492898 368.552439 \n",
       "L 624.641658 368.557821 \n",
       "L 630.790418 368.56618 \n",
       "L 636.939179 368.574397 \n",
       "L 643.087939 368.582214 \n",
       "L 649.236699 368.589956 \n",
       "L 655.38546 368.593253 \n",
       "L 661.53422 368.598134 \n",
       "L 667.68298 368.602368 \n",
       "L 673.831741 368.611354 \n",
       "L 679.980501 368.614886 \n",
       "L 686.129261 368.62427 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 48.107716 \n",
       "L 83.550749 113.566556 \n",
       "L 89.699509 147.062433 \n",
       "L 95.84827 170.490777 \n",
       "L 101.99703 188.236972 \n",
       "L 108.14579 203.029078 \n",
       "L 114.294551 214.881622 \n",
       "L 120.443311 224.729171 \n",
       "L 126.592071 233.283034 \n",
       "L 132.740832 240.674847 \n",
       "L 138.889592 246.932362 \n",
       "L 145.038352 252.320763 \n",
       "L 151.187113 257.065792 \n",
       "L 157.335873 261.375444 \n",
       "L 163.484633 265.144659 \n",
       "L 169.633394 268.659189 \n",
       "L 175.782154 271.872174 \n",
       "L 181.930914 274.589972 \n",
       "L 188.079675 277.367858 \n",
       "L 194.228435 279.702022 \n",
       "L 200.377195 282.005817 \n",
       "L 206.525956 284.194604 \n",
       "L 212.674716 286.178231 \n",
       "L 218.823476 288.097073 \n",
       "L 224.972237 289.931731 \n",
       "L 231.120997 291.571086 \n",
       "L 237.269757 293.208902 \n",
       "L 243.418518 294.684328 \n",
       "L 249.567278 296.141951 \n",
       "L 255.716038 297.509859 \n",
       "L 261.864799 298.769649 \n",
       "L 268.013559 300.046452 \n",
       "L 274.162319 301.255555 \n",
       "L 280.31108 302.383602 \n",
       "L 286.45984 303.437242 \n",
       "L 292.6086 304.400612 \n",
       "L 298.757361 305.442158 \n",
       "L 304.906121 306.362744 \n",
       "L 311.054881 307.213755 \n",
       "L 317.203642 308.031192 \n",
       "L 323.352402 308.807776 \n",
       "L 329.501162 309.547292 \n",
       "L 335.649923 310.239527 \n",
       "L 341.798683 310.879443 \n",
       "L 347.947443 311.523649 \n",
       "L 354.096204 312.1255 \n",
       "L 360.244964 312.680668 \n",
       "L 366.393724 313.261999 \n",
       "L 372.542485 313.811623 \n",
       "L 378.691245 314.29459 \n",
       "L 384.840005 314.75293 \n",
       "L 390.988765 315.232171 \n",
       "L 397.137526 315.665883 \n",
       "L 403.286286 316.087273 \n",
       "L 409.435046 316.492503 \n",
       "L 415.583807 316.923336 \n",
       "L 421.732567 317.304754 \n",
       "L 427.881327 317.67701 \n",
       "L 434.030088 318.029015 \n",
       "L 440.178848 318.403441 \n",
       "L 446.327608 318.703504 \n",
       "L 452.476369 319.097711 \n",
       "L 458.625129 319.396495 \n",
       "L 464.773889 319.740852 \n",
       "L 470.92265 320.04981 \n",
       "L 477.07141 320.359925 \n",
       "L 483.22017 320.638674 \n",
       "L 489.368931 320.952254 \n",
       "L 495.517691 321.267721 \n",
       "L 501.666451 321.584522 \n",
       "L 507.815212 321.905 \n",
       "L 513.963972 322.164642 \n",
       "L 520.112732 322.447732 \n",
       "L 526.261493 322.752281 \n",
       "L 532.410253 323.028026 \n",
       "L 538.559013 323.31577 \n",
       "L 544.707774 323.566802 \n",
       "L 550.856534 323.881251 \n",
       "L 557.005294 324.189656 \n",
       "L 563.154055 324.461585 \n",
       "L 569.302815 324.723956 \n",
       "L 575.451575 325.052652 \n",
       "L 581.600336 325.314941 \n",
       "L 587.749096 325.584258 \n",
       "L 593.897856 325.906176 \n",
       "L 600.046617 326.170161 \n",
       "L 606.195377 326.476118 \n",
       "L 612.344137 326.759753 \n",
       "L 618.492898 327.071408 \n",
       "L 624.641658 327.354426 \n",
       "L 630.790418 327.602426 \n",
       "L 636.939179 327.919433 \n",
       "L 643.087939 328.221232 \n",
       "L 649.236699 328.499985 \n",
       "L 655.38546 328.785024 \n",
       "L 661.53422 329.010733 \n",
       "L 667.68298 329.29542 \n",
       "L 673.831741 329.576004 \n",
       "L 679.980501 329.852979 \n",
       "L 686.129261 330.117692 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 357.83603 \n",
       "L 83.550749 360.285157 \n",
       "L 89.699509 361.589629 \n",
       "L 95.84827 362.514022 \n",
       "L 101.99703 363.204045 \n",
       "L 108.14579 363.765364 \n",
       "L 114.294551 364.199447 \n",
       "L 120.443311 364.578531 \n",
       "L 126.592071 364.874079 \n",
       "L 132.740832 365.10855 \n",
       "L 138.889592 365.317258 \n",
       "L 145.038352 365.507757 \n",
       "L 151.187113 365.673171 \n",
       "L 157.335873 365.81916 \n",
       "L 163.484633 365.959259 \n",
       "L 169.633394 366.097433 \n",
       "L 175.782154 366.217737 \n",
       "L 181.930914 366.337008 \n",
       "L 188.079675 366.458589 \n",
       "L 194.228435 366.577056 \n",
       "L 200.377195 366.68986 \n",
       "L 206.525956 366.799687 \n",
       "L 212.674716 366.899258 \n",
       "L 218.823476 367.001481 \n",
       "L 224.972237 367.102821 \n",
       "L 231.120997 367.1881 \n",
       "L 237.269757 367.265419 \n",
       "L 243.418518 367.348025 \n",
       "L 249.567278 367.413806 \n",
       "L 255.716038 367.470065 \n",
       "L 261.864799 367.534861 \n",
       "L 268.013559 367.575122 \n",
       "L 274.162319 367.654046 \n",
       "L 280.31108 367.705623 \n",
       "L 286.45984 367.755527 \n",
       "L 292.6086 367.812331 \n",
       "L 298.757361 367.850692 \n",
       "L 304.906121 367.890258 \n",
       "L 311.054881 367.931227 \n",
       "L 317.203642 367.960616 \n",
       "L 323.352402 367.99115 \n",
       "L 329.501162 368.025164 \n",
       "L 335.649923 368.039221 \n",
       "L 341.798683 368.066642 \n",
       "L 347.947443 368.084184 \n",
       "L 354.096204 368.101333 \n",
       "L 360.244964 368.125266 \n",
       "L 366.393724 368.137726 \n",
       "L 372.542485 368.153241 \n",
       "L 378.691245 368.16753 \n",
       "L 384.840005 368.175227 \n",
       "L 390.988765 368.189854 \n",
       "L 397.137526 368.194906 \n",
       "L 403.286286 368.211693 \n",
       "L 409.435046 368.225285 \n",
       "L 415.583807 368.226258 \n",
       "L 421.732567 368.253361 \n",
       "L 427.881327 368.253595 \n",
       "L 434.030088 368.271306 \n",
       "L 440.178848 368.285595 \n",
       "L 446.327608 368.291403 \n",
       "L 452.476369 368.30256 \n",
       "L 458.625129 368.312111 \n",
       "L 464.773889 368.321673 \n",
       "L 470.92265 368.330377 \n",
       "L 477.07141 368.34181 \n",
       "L 483.22017 368.34265 \n",
       "L 489.368931 368.354424 \n",
       "L 495.517691 368.369209 \n",
       "L 501.666451 368.378807 \n",
       "L 507.815212 368.389598 \n",
       "L 513.963972 368.398558 \n",
       "L 520.112732 368.404696 \n",
       "L 526.261493 368.411257 \n",
       "L 532.410253 368.419564 \n",
       "L 538.559013 368.425819 \n",
       "L 544.707774 368.432976 \n",
       "L 550.856534 368.437838 \n",
       "L 557.005294 368.444647 \n",
       "L 563.154055 368.450545 \n",
       "L 569.302815 368.457999 \n",
       "L 575.451575 368.46433 \n",
       "L 581.600336 368.47017 \n",
       "L 587.749096 368.476993 \n",
       "L 593.897856 368.482037 \n",
       "L 600.046617 368.486553 \n",
       "L 606.195377 368.497943 \n",
       "L 612.344137 368.499081 \n",
       "L 618.492898 368.507862 \n",
       "L 624.641658 368.514922 \n",
       "L 630.790418 368.522088 \n",
       "L 636.939179 368.527847 \n",
       "L 643.087939 368.53491 \n",
       "L 649.236699 368.543286 \n",
       "L 655.38546 368.550094 \n",
       "L 661.53422 368.560076 \n",
       "L 667.68298 368.567251 \n",
       "L 673.831741 368.575134 \n",
       "L 679.980501 368.582391 \n",
       "L 686.129261 368.589119 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 47.293779 \n",
       "L 83.550749 117.053248 \n",
       "L 89.699509 150.548056 \n",
       "L 95.84827 172.765016 \n",
       "L 101.99703 189.353794 \n",
       "L 108.14579 202.244291 \n",
       "L 114.294551 213.240064 \n",
       "L 120.443311 222.095686 \n",
       "L 126.592071 230.165623 \n",
       "L 132.740832 237.104968 \n",
       "L 138.889592 243.585047 \n",
       "L 145.038352 248.880426 \n",
       "L 151.187113 253.900843 \n",
       "L 157.335873 258.515632 \n",
       "L 163.484633 262.489001 \n",
       "L 169.633394 266.343819 \n",
       "L 175.782154 269.691812 \n",
       "L 181.930914 272.780787 \n",
       "L 188.079675 275.5722 \n",
       "L 194.228435 278.234008 \n",
       "L 200.377195 280.667722 \n",
       "L 206.525956 282.802207 \n",
       "L 212.674716 284.970347 \n",
       "L 218.823476 286.95639 \n",
       "L 224.972237 288.731651 \n",
       "L 231.120997 290.510603 \n",
       "L 237.269757 292.084034 \n",
       "L 243.418518 293.632954 \n",
       "L 249.567278 295.142854 \n",
       "L 255.716038 296.493599 \n",
       "L 261.864799 297.791662 \n",
       "L 268.013559 299.094792 \n",
       "L 274.162319 300.312419 \n",
       "L 280.31108 301.438249 \n",
       "L 286.45984 302.509786 \n",
       "L 292.6086 303.508684 \n",
       "L 298.757361 304.535919 \n",
       "L 304.906121 305.385868 \n",
       "L 311.054881 306.327928 \n",
       "L 317.203642 307.14947 \n",
       "L 323.352402 307.931213 \n",
       "L 329.501162 308.679254 \n",
       "L 335.649923 309.380134 \n",
       "L 341.798683 310.057923 \n",
       "L 347.947443 310.715849 \n",
       "L 354.096204 311.369263 \n",
       "L 360.244964 311.930924 \n",
       "L 366.393724 312.474354 \n",
       "L 372.542485 313.027028 \n",
       "L 378.691245 313.542865 \n",
       "L 384.840005 314.032935 \n",
       "L 390.988765 314.513808 \n",
       "L 397.137526 314.981548 \n",
       "L 403.286286 315.406217 \n",
       "L 409.435046 315.859953 \n",
       "L 415.583807 316.266711 \n",
       "L 421.732567 316.678946 \n",
       "L 427.881327 317.072306 \n",
       "L 434.030088 317.409874 \n",
       "L 440.178848 317.770378 \n",
       "L 446.327608 318.122899 \n",
       "L 452.476369 318.484483 \n",
       "L 458.625129 318.799502 \n",
       "L 464.773889 319.127114 \n",
       "L 470.92265 319.417003 \n",
       "L 477.07141 319.755163 \n",
       "L 483.22017 320.082409 \n",
       "L 489.368931 320.382397 \n",
       "L 495.517691 320.693542 \n",
       "L 501.666451 321.001423 \n",
       "L 507.815212 321.304176 \n",
       "L 513.963972 321.624277 \n",
       "L 520.112732 321.924218 \n",
       "L 526.261493 322.211296 \n",
       "L 532.410253 322.501972 \n",
       "L 538.559013 322.783889 \n",
       "L 544.707774 323.089212 \n",
       "L 550.856534 323.369547 \n",
       "L 557.005294 323.678052 \n",
       "L 563.154055 323.953672 \n",
       "L 569.302815 324.241035 \n",
       "L 575.451575 324.569328 \n",
       "L 581.600336 324.86732 \n",
       "L 587.749096 325.123106 \n",
       "L 593.897856 325.401161 \n",
       "L 600.046617 325.725662 \n",
       "L 606.195377 325.980454 \n",
       "L 612.344137 326.293021 \n",
       "L 618.492898 326.596587 \n",
       "L 624.641658 326.887684 \n",
       "L 630.790418 327.178 \n",
       "L 636.939179 327.477788 \n",
       "L 643.087939 327.779416 \n",
       "L 649.236699 328.045122 \n",
       "L 655.38546 328.333518 \n",
       "L 661.53422 328.639789 \n",
       "L 667.68298 328.922665 \n",
       "L 673.831741 329.170048 \n",
       "L 679.980501 329.459634 \n",
       "L 686.129261 329.736901 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 357.7698 \n",
       "L 83.550749 360.128548 \n",
       "L 89.699509 361.391428 \n",
       "L 95.84827 362.312991 \n",
       "L 101.99703 363.058382 \n",
       "L 108.14579 363.672077 \n",
       "L 114.294551 364.127639 \n",
       "L 120.443311 364.497479 \n",
       "L 126.592071 364.797294 \n",
       "L 132.740832 365.034455 \n",
       "L 138.889592 365.254808 \n",
       "L 145.038352 365.43838 \n",
       "L 151.187113 365.604653 \n",
       "L 157.335873 365.750033 \n",
       "L 163.484633 365.882535 \n",
       "L 169.633394 366.008376 \n",
       "L 175.782154 366.134262 \n",
       "L 181.930914 366.245408 \n",
       "L 188.079675 366.358046 \n",
       "L 194.228435 366.471416 \n",
       "L 200.377195 366.582674 \n",
       "L 206.525956 366.689078 \n",
       "L 212.674716 366.793879 \n",
       "L 218.823476 366.885675 \n",
       "L 224.972237 366.977944 \n",
       "L 231.120997 367.074966 \n",
       "L 237.269757 367.169544 \n",
       "L 243.418518 367.249206 \n",
       "L 249.567278 367.3276 \n",
       "L 255.716038 367.382693 \n",
       "L 261.864799 367.454884 \n",
       "L 268.013559 367.508364 \n",
       "L 274.162319 367.573016 \n",
       "L 280.31108 367.625872 \n",
       "L 286.45984 367.675332 \n",
       "L 292.6086 367.73236 \n",
       "L 298.757361 367.785402 \n",
       "L 304.906121 367.822518 \n",
       "L 311.054881 367.865844 \n",
       "L 317.203642 367.917411 \n",
       "L 323.352402 367.941211 \n",
       "L 329.501162 367.966981 \n",
       "L 335.649923 368.00065 \n",
       "L 341.798683 368.015284 \n",
       "L 347.947443 368.045882 \n",
       "L 354.096204 368.070745 \n",
       "L 360.244964 368.092749 \n",
       "L 366.393724 368.122819 \n",
       "L 372.542485 368.135617 \n",
       "L 378.691245 368.14517 \n",
       "L 384.840005 368.159002 \n",
       "L 390.988765 368.168233 \n",
       "L 397.137526 368.182171 \n",
       "L 403.286286 368.20218 \n",
       "L 409.435046 368.2093 \n",
       "L 415.583807 368.222692 \n",
       "L 421.732567 368.231506 \n",
       "L 427.881327 368.223396 \n",
       "L 434.030088 368.256602 \n",
       "L 440.178848 368.264294 \n",
       "L 446.327608 368.272956 \n",
       "L 452.476369 368.285005 \n",
       "L 458.625129 368.295257 \n",
       "L 464.773889 368.30556 \n",
       "L 470.92265 368.316835 \n",
       "L 477.07141 368.321595 \n",
       "L 483.22017 368.335401 \n",
       "L 489.368931 368.34063 \n",
       "L 495.517691 368.350247 \n",
       "L 501.666451 368.363899 \n",
       "L 507.815212 368.371389 \n",
       "L 513.963972 368.381376 \n",
       "L 520.112732 368.385673 \n",
       "L 526.261493 368.39502 \n",
       "L 532.410253 368.403403 \n",
       "L 538.559013 368.408156 \n",
       "L 544.707774 368.420865 \n",
       "L 550.856534 368.425385 \n",
       "L 557.005294 368.43154 \n",
       "L 563.154055 368.437926 \n",
       "L 569.302815 368.444994 \n",
       "L 575.451575 368.448465 \n",
       "L 581.600336 368.455615 \n",
       "L 587.749096 368.461684 \n",
       "L 593.897856 368.466902 \n",
       "L 600.046617 368.474115 \n",
       "L 606.195377 368.479669 \n",
       "L 612.344137 368.486046 \n",
       "L 618.492898 368.489615 \n",
       "L 624.641658 368.497646 \n",
       "L 630.790418 368.502599 \n",
       "L 636.939179 368.50838 \n",
       "L 643.087939 368.513789 \n",
       "L 649.236699 368.520847 \n",
       "L 655.38546 368.527132 \n",
       "L 661.53422 368.533931 \n",
       "L 667.68298 368.53956 \n",
       "L 673.831741 368.544324 \n",
       "L 679.980501 368.553586 \n",
       "L 686.129261 368.561143 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_27\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 211.604422 \n",
       "L 83.550749 326.205394 \n",
       "L 89.699509 340.849607 \n",
       "L 95.84827 345.877973 \n",
       "L 101.99703 348.3873 \n",
       "L 108.14579 350.090289 \n",
       "L 114.294551 351.08681 \n",
       "L 120.443311 351.685904 \n",
       "L 126.592071 352.268695 \n",
       "L 132.740832 352.784085 \n",
       "L 138.889592 353.131774 \n",
       "L 145.038352 353.48563 \n",
       "L 151.187113 353.802174 \n",
       "L 157.335873 354.205029 \n",
       "L 163.484633 354.429935 \n",
       "L 169.633394 354.631359 \n",
       "L 175.782154 354.866741 \n",
       "L 181.930914 355.084994 \n",
       "L 188.079675 355.190852 \n",
       "L 194.228435 355.512392 \n",
       "L 200.377195 355.591996 \n",
       "L 206.525956 355.73203 \n",
       "L 212.674716 355.900317 \n",
       "L 218.823476 356.02986 \n",
       "L 224.972237 356.317413 \n",
       "L 231.120997 356.396847 \n",
       "L 237.269757 356.487801 \n",
       "L 243.418518 356.675333 \n",
       "L 249.567278 356.694936 \n",
       "L 255.716038 356.943743 \n",
       "L 261.864799 356.916407 \n",
       "L 268.013559 357.053629 \n",
       "L 274.162319 357.114068 \n",
       "L 280.31108 357.140276 \n",
       "L 286.45984 357.23151 \n",
       "L 292.6086 357.168455 \n",
       "L 298.757361 357.538056 \n",
       "L 304.906121 357.488965 \n",
       "L 311.054881 357.623979 \n",
       "L 317.203642 357.64959 \n",
       "L 323.352402 357.723258 \n",
       "L 329.501162 357.6839 \n",
       "L 335.649923 357.892138 \n",
       "L 341.798683 358.036319 \n",
       "L 347.947443 358.044722 \n",
       "L 354.096204 358.165903 \n",
       "L 360.244964 358.111036 \n",
       "L 366.393724 358.18116 \n",
       "L 372.542485 358.354961 \n",
       "L 378.691245 358.277375 \n",
       "L 384.840005 358.395991 \n",
       "L 390.988765 358.386553 \n",
       "L 397.137526 358.421807 \n",
       "L 403.286286 358.517201 \n",
       "L 409.435046 358.597322 \n",
       "L 415.583807 358.639345 \n",
       "L 421.732567 358.663039 \n",
       "L 427.881327 358.728293 \n",
       "L 434.030088 358.802355 \n",
       "L 440.178848 358.775716 \n",
       "L 446.327608 358.770837 \n",
       "L 452.476369 358.918617 \n",
       "L 458.625129 358.972536 \n",
       "L 464.773889 358.886501 \n",
       "L 470.92265 358.985515 \n",
       "L 477.07141 359.119382 \n",
       "L 483.22017 359.150088 \n",
       "L 489.368931 359.143277 \n",
       "L 495.517691 359.158819 \n",
       "L 501.666451 359.222278 \n",
       "L 507.815212 359.108753 \n",
       "L 513.963972 359.30622 \n",
       "L 520.112732 359.178435 \n",
       "L 526.261493 359.331959 \n",
       "L 532.410253 359.312491 \n",
       "L 538.559013 359.376612 \n",
       "L 544.707774 359.34631 \n",
       "L 550.856534 359.422298 \n",
       "L 557.005294 359.402199 \n",
       "L 563.154055 359.481531 \n",
       "L 569.302815 359.365155 \n",
       "L 575.451575 359.308791 \n",
       "L 581.600336 359.528268 \n",
       "L 587.749096 359.590036 \n",
       "L 593.897856 359.525633 \n",
       "L 600.046617 359.662956 \n",
       "L 606.195377 359.555326 \n",
       "L 612.344137 359.590919 \n",
       "L 618.492898 359.609711 \n",
       "L 624.641658 359.491105 \n",
       "L 630.790418 359.541808 \n",
       "L 636.939179 359.695063 \n",
       "L 643.087939 359.798207 \n",
       "L 649.236699 359.823498 \n",
       "L 655.38546 359.706316 \n",
       "L 661.53422 359.703643 \n",
       "L 667.68298 359.86005 \n",
       "L 673.831741 359.575052 \n",
       "L 679.980501 359.814964 \n",
       "L 686.129261 359.840316 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_28\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 361.542643 \n",
       "L 83.550749 367.318649 \n",
       "L 89.699509 368.707584 \n",
       "L 95.84827 369.254213 \n",
       "L 101.99703 369.452271 \n",
       "L 108.14579 369.500177 \n",
       "L 114.294551 369.614638 \n",
       "L 120.443311 369.710603 \n",
       "L 126.592071 369.717878 \n",
       "L 132.740832 369.712996 \n",
       "L 138.889592 369.730098 \n",
       "L 145.038352 369.76471 \n",
       "L 151.187113 369.820607 \n",
       "L 157.335873 369.805925 \n",
       "L 163.484633 369.831173 \n",
       "L 169.633394 369.873237 \n",
       "L 175.782154 369.853971 \n",
       "L 181.930914 369.910464 \n",
       "L 188.079675 369.971394 \n",
       "L 194.228435 369.923747 \n",
       "L 200.377195 369.978155 \n",
       "L 206.525956 369.975195 \n",
       "L 212.674716 369.964702 \n",
       "L 218.823476 369.974472 \n",
       "L 224.972237 370.016576 \n",
       "L 231.120997 370.039289 \n",
       "L 237.269757 370.022757 \n",
       "L 243.418518 370.027072 \n",
       "L 249.567278 370.017927 \n",
       "L 255.716038 370.022806 \n",
       "L 261.864799 370.068893 \n",
       "L 268.013559 370.04237 \n",
       "L 274.162319 370.053013 \n",
       "L 280.31108 370.095696 \n",
       "L 286.45984 370.082435 \n",
       "L 292.6086 370.104133 \n",
       "L 298.757361 370.122753 \n",
       "L 304.906121 370.12468 \n",
       "L 311.054881 370.140733 \n",
       "L 317.203642 370.147893 \n",
       "L 323.352402 370.153823 \n",
       "L 329.501162 370.181508 \n",
       "L 335.649923 370.151466 \n",
       "L 341.798683 370.189975 \n",
       "L 347.947443 370.181949 \n",
       "L 354.096204 370.172174 \n",
       "L 360.244964 370.17513 \n",
       "L 366.393724 370.16485 \n",
       "L 372.542485 370.225942 \n",
       "L 378.691245 370.177661 \n",
       "L 384.840005 370.192231 \n",
       "L 390.988765 370.208447 \n",
       "L 397.137526 370.222154 \n",
       "L 403.286286 370.23924 \n",
       "L 409.435046 370.226271 \n",
       "L 415.583807 370.255431 \n",
       "L 421.732567 370.253545 \n",
       "L 427.881327 370.21591 \n",
       "L 434.030088 370.254662 \n",
       "L 440.178848 370.269042 \n",
       "L 446.327608 370.257925 \n",
       "L 452.476369 370.241224 \n",
       "L 458.625129 370.241686 \n",
       "L 464.773889 370.252532 \n",
       "L 470.92265 370.260708 \n",
       "L 477.07141 370.291528 \n",
       "L 483.22017 370.280829 \n",
       "L 489.368931 370.271828 \n",
       "L 495.517691 370.283349 \n",
       "L 501.666451 370.289491 \n",
       "L 507.815212 370.290339 \n",
       "L 513.963972 370.312696 \n",
       "L 520.112732 370.289358 \n",
       "L 526.261493 370.291333 \n",
       "L 532.410253 370.3284 \n",
       "L 538.559013 370.277873 \n",
       "L 544.707774 370.28251 \n",
       "L 550.856534 370.296749 \n",
       "L 557.005294 370.288027 \n",
       "L 563.154055 370.301585 \n",
       "L 569.302815 370.307999 \n",
       "L 575.451575 370.316265 \n",
       "L 581.600336 370.300377 \n",
       "L 587.749096 370.293442 \n",
       "L 593.897856 370.306695 \n",
       "L 600.046617 370.257182 \n",
       "L 606.195377 370.333039 \n",
       "L 612.344137 370.298328 \n",
       "L 618.492898 370.30453 \n",
       "L 624.641658 370.305611 \n",
       "L 630.790418 370.325892 \n",
       "L 636.939179 370.299532 \n",
       "L 643.087939 370.340006 \n",
       "L 649.236699 370.333087 \n",
       "L 655.38546 370.326541 \n",
       "L 661.53422 370.347898 \n",
       "L 667.68298 370.334002 \n",
       "L 673.831741 370.34224 \n",
       "L 679.980501 370.309848 \n",
       "L 686.129261 370.329489 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 215.013159 \n",
       "L 83.550749 314.5188 \n",
       "L 89.699509 334.707611 \n",
       "L 95.84827 341.784601 \n",
       "L 101.99703 345.461599 \n",
       "L 108.14579 348.003195 \n",
       "L 114.294551 349.581605 \n",
       "L 120.443311 350.689793 \n",
       "L 126.592071 351.601705 \n",
       "L 132.740832 352.148385 \n",
       "L 138.889592 352.893749 \n",
       "L 145.038352 353.223841 \n",
       "L 151.187113 353.662534 \n",
       "L 157.335873 354.08766 \n",
       "L 163.484633 354.406143 \n",
       "L 169.633394 354.701263 \n",
       "L 175.782154 355.003405 \n",
       "L 181.930914 355.191839 \n",
       "L 188.079675 355.407992 \n",
       "L 194.228435 355.624944 \n",
       "L 200.377195 355.895483 \n",
       "L 206.525956 356.036467 \n",
       "L 212.674716 356.160484 \n",
       "L 218.823476 356.293306 \n",
       "L 224.972237 356.498775 \n",
       "L 231.120997 356.692794 \n",
       "L 237.269757 356.991629 \n",
       "L 243.418518 356.890782 \n",
       "L 249.567278 357.021524 \n",
       "L 255.716038 357.213646 \n",
       "L 261.864799 357.338871 \n",
       "L 268.013559 357.421518 \n",
       "L 274.162319 357.492005 \n",
       "L 280.31108 357.691713 \n",
       "L 286.45984 357.726887 \n",
       "L 292.6086 357.863222 \n",
       "L 298.757361 357.971749 \n",
       "L 304.906121 357.96992 \n",
       "L 311.054881 358.123243 \n",
       "L 317.203642 358.164177 \n",
       "L 323.352402 358.234892 \n",
       "L 329.501162 358.346463 \n",
       "L 335.649923 358.525096 \n",
       "L 341.798683 358.49531 \n",
       "L 347.947443 358.525325 \n",
       "L 354.096204 358.535903 \n",
       "L 360.244964 358.642302 \n",
       "L 366.393724 358.731359 \n",
       "L 372.542485 358.722663 \n",
       "L 378.691245 358.836681 \n",
       "L 384.840005 358.843016 \n",
       "L 390.988765 358.874644 \n",
       "L 397.137526 358.969723 \n",
       "L 403.286286 358.971307 \n",
       "L 409.435046 359.104367 \n",
       "L 415.583807 359.141296 \n",
       "L 421.732567 359.066354 \n",
       "L 427.881327 359.070186 \n",
       "L 434.030088 359.189714 \n",
       "L 440.178848 359.305334 \n",
       "L 446.327608 359.198983 \n",
       "L 452.476369 359.272565 \n",
       "L 458.625129 359.267488 \n",
       "L 464.773889 359.405474 \n",
       "L 470.92265 359.33439 \n",
       "L 477.07141 359.425107 \n",
       "L 483.22017 359.363136 \n",
       "L 489.368931 359.475112 \n",
       "L 495.517691 359.508558 \n",
       "L 501.666451 359.668402 \n",
       "L 507.815212 359.595648 \n",
       "L 513.963972 359.579885 \n",
       "L 520.112732 359.530754 \n",
       "L 526.261493 359.678686 \n",
       "L 532.410253 359.632509 \n",
       "L 538.559013 359.781385 \n",
       "L 544.707774 359.668875 \n",
       "L 550.856534 359.819934 \n",
       "L 557.005294 359.75449 \n",
       "L 563.154055 359.840065 \n",
       "L 569.302815 359.994381 \n",
       "L 575.451575 359.827499 \n",
       "L 581.600336 359.966957 \n",
       "L 587.749096 359.921076 \n",
       "L 593.897856 359.860728 \n",
       "L 600.046617 360.029071 \n",
       "L 606.195377 359.991119 \n",
       "L 612.344137 360.059479 \n",
       "L 618.492898 359.933573 \n",
       "L 624.641658 359.937164 \n",
       "L 630.790418 359.994453 \n",
       "L 636.939179 359.933733 \n",
       "L 643.087939 360.043492 \n",
       "L 649.236699 360.102184 \n",
       "L 655.38546 359.93635 \n",
       "L 661.53422 359.981162 \n",
       "L 667.68298 360.218273 \n",
       "L 673.831741 360.02924 \n",
       "L 679.980501 360.191925 \n",
       "L 686.129261 360.218085 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.442695 \n",
       "L 83.550749 367.604885 \n",
       "L 89.699509 369.211689 \n",
       "L 95.84827 369.515673 \n",
       "L 101.99703 369.649298 \n",
       "L 108.14579 369.798842 \n",
       "L 114.294551 369.819545 \n",
       "L 120.443311 369.918121 \n",
       "L 126.592071 369.907949 \n",
       "L 132.740832 369.965388 \n",
       "L 138.889592 369.953231 \n",
       "L 145.038352 370.011805 \n",
       "L 151.187113 370.000627 \n",
       "L 157.335873 370.023912 \n",
       "L 163.484633 370.029954 \n",
       "L 169.633394 370.060614 \n",
       "L 175.782154 370.054076 \n",
       "L 181.930914 370.067356 \n",
       "L 188.079675 370.037224 \n",
       "L 194.228435 370.079106 \n",
       "L 200.377195 370.106791 \n",
       "L 206.525956 370.090516 \n",
       "L 212.674716 370.12698 \n",
       "L 218.823476 370.130192 \n",
       "L 224.972237 370.146262 \n",
       "L 231.120997 370.131803 \n",
       "L 237.269757 370.126017 \n",
       "L 243.418518 370.152618 \n",
       "L 249.567278 370.143752 \n",
       "L 255.716038 370.156323 \n",
       "L 261.864799 370.149962 \n",
       "L 268.013559 370.171981 \n",
       "L 274.162319 370.173371 \n",
       "L 280.31108 370.164826 \n",
       "L 286.45984 370.175481 \n",
       "L 292.6086 370.178197 \n",
       "L 298.757361 370.174645 \n",
       "L 304.906121 370.202458 \n",
       "L 311.054881 370.186307 \n",
       "L 317.203642 370.201351 \n",
       "L 323.352402 370.208029 \n",
       "L 329.501162 370.14921 \n",
       "L 335.649923 370.206905 \n",
       "L 341.798683 370.241724 \n",
       "L 347.947443 370.190313 \n",
       "L 354.096204 370.232649 \n",
       "L 360.244964 370.231348 \n",
       "L 366.393724 370.215433 \n",
       "L 372.542485 370.261604 \n",
       "L 378.691245 370.240917 \n",
       "L 384.840005 370.21119 \n",
       "L 390.988765 370.238065 \n",
       "L 397.137526 370.247865 \n",
       "L 403.286286 370.222005 \n",
       "L 409.435046 370.230965 \n",
       "L 415.583807 370.249026 \n",
       "L 421.732567 370.23044 \n",
       "L 427.881327 370.250147 \n",
       "L 434.030088 370.260735 \n",
       "L 440.178848 370.270528 \n",
       "L 446.327608 370.266889 \n",
       "L 452.476369 370.259987 \n",
       "L 458.625129 370.242314 \n",
       "L 464.773889 370.290929 \n",
       "L 470.92265 370.282519 \n",
       "L 477.07141 370.25233 \n",
       "L 483.22017 370.300562 \n",
       "L 489.368931 370.269603 \n",
       "L 495.517691 370.28138 \n",
       "L 501.666451 370.306037 \n",
       "L 507.815212 370.303262 \n",
       "L 513.963972 370.310316 \n",
       "L 520.112732 370.274479 \n",
       "L 526.261493 370.271183 \n",
       "L 532.410253 370.300147 \n",
       "L 538.559013 370.279676 \n",
       "L 544.707774 370.300369 \n",
       "L 550.856534 370.309902 \n",
       "L 557.005294 370.29366 \n",
       "L 563.154055 370.298005 \n",
       "L 569.302815 370.2917 \n",
       "L 575.451575 370.314976 \n",
       "L 581.600336 370.3182 \n",
       "L 587.749096 370.28007 \n",
       "L 593.897856 370.297036 \n",
       "L 600.046617 370.292925 \n",
       "L 606.195377 370.315962 \n",
       "L 612.344137 370.330682 \n",
       "L 618.492898 370.332621 \n",
       "L 624.641658 370.315986 \n",
       "L 630.790418 370.321995 \n",
       "L 636.939179 370.319385 \n",
       "L 643.087939 370.316205 \n",
       "L 649.236699 370.333396 \n",
       "L 655.38546 370.326907 \n",
       "L 661.53422 370.327456 \n",
       "L 667.68298 370.323723 \n",
       "L 673.831741 370.32575 \n",
       "L 679.980501 370.292854 \n",
       "L 686.129261 370.311824 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 196.554203 \n",
       "L 83.550749 317.201569 \n",
       "L 89.699509 336.975154 \n",
       "L 95.84827 344.329461 \n",
       "L 101.99703 348.091259 \n",
       "L 108.14579 349.944659 \n",
       "L 114.294551 351.347366 \n",
       "L 120.443311 352.213998 \n",
       "L 126.592071 352.810934 \n",
       "L 132.740832 353.442854 \n",
       "L 138.889592 353.850786 \n",
       "L 145.038352 354.097918 \n",
       "L 151.187113 354.577593 \n",
       "L 157.335873 354.932187 \n",
       "L 163.484633 355.012104 \n",
       "L 169.633394 355.284045 \n",
       "L 175.782154 355.54056 \n",
       "L 181.930914 355.770984 \n",
       "L 188.079675 355.965335 \n",
       "L 194.228435 356.162712 \n",
       "L 200.377195 356.261861 \n",
       "L 206.525956 356.281869 \n",
       "L 212.674716 356.566615 \n",
       "L 218.823476 356.659388 \n",
       "L 224.972237 356.76242 \n",
       "L 231.120997 356.880604 \n",
       "L 237.269757 357.056623 \n",
       "L 243.418518 356.988884 \n",
       "L 249.567278 357.152319 \n",
       "L 255.716038 357.302801 \n",
       "L 261.864799 357.383348 \n",
       "L 268.013559 357.487855 \n",
       "L 274.162319 357.498756 \n",
       "L 280.31108 357.618981 \n",
       "L 286.45984 357.788979 \n",
       "L 292.6086 357.833347 \n",
       "L 298.757361 357.895442 \n",
       "L 304.906121 357.935107 \n",
       "L 311.054881 358.019774 \n",
       "L 317.203642 358.084274 \n",
       "L 323.352402 358.194419 \n",
       "L 329.501162 358.33772 \n",
       "L 335.649923 358.321481 \n",
       "L 341.798683 358.27911 \n",
       "L 347.947443 358.473187 \n",
       "L 354.096204 358.400392 \n",
       "L 360.244964 358.49906 \n",
       "L 366.393724 358.522345 \n",
       "L 372.542485 358.542581 \n",
       "L 378.691245 358.514101 \n",
       "L 384.840005 358.771355 \n",
       "L 390.988765 358.73495 \n",
       "L 397.137526 358.806769 \n",
       "L 403.286286 358.773234 \n",
       "L 409.435046 358.965141 \n",
       "L 415.583807 358.857439 \n",
       "L 421.732567 358.94 \n",
       "L 427.881327 359.006927 \n",
       "L 434.030088 358.997531 \n",
       "L 440.178848 359.094771 \n",
       "L 446.327608 358.986816 \n",
       "L 452.476369 359.059235 \n",
       "L 458.625129 359.207433 \n",
       "L 464.773889 359.196234 \n",
       "L 470.92265 359.212739 \n",
       "L 477.07141 359.104024 \n",
       "L 483.22017 359.20585 \n",
       "L 489.368931 359.325612 \n",
       "L 495.517691 359.351424 \n",
       "L 501.666451 359.260614 \n",
       "L 507.815212 359.347078 \n",
       "L 513.963972 359.376979 \n",
       "L 520.112732 359.499243 \n",
       "L 526.261493 359.397663 \n",
       "L 532.410253 359.472584 \n",
       "L 538.559013 359.333369 \n",
       "L 544.707774 359.517348 \n",
       "L 550.856534 359.49252 \n",
       "L 557.005294 359.506521 \n",
       "L 563.154055 359.501755 \n",
       "L 569.302815 359.653731 \n",
       "L 575.451575 359.571335 \n",
       "L 581.600336 359.577262 \n",
       "L 587.749096 359.582262 \n",
       "L 593.897856 359.532613 \n",
       "L 600.046617 359.633757 \n",
       "L 606.195377 359.49512 \n",
       "L 612.344137 359.677145 \n",
       "L 618.492898 359.603784 \n",
       "L 624.641658 359.656458 \n",
       "L 630.790418 359.672235 \n",
       "L 636.939179 359.581621 \n",
       "L 643.087939 359.802282 \n",
       "L 649.236699 359.679811 \n",
       "L 655.38546 359.837136 \n",
       "L 661.53422 359.750226 \n",
       "L 667.68298 359.799945 \n",
       "L 673.831741 359.874845 \n",
       "L 679.980501 359.678318 \n",
       "L 686.129261 359.753577 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_32\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.101706 \n",
       "L 83.550749 367.44839 \n",
       "L 89.699509 368.903497 \n",
       "L 95.84827 369.390581 \n",
       "L 101.99703 369.5003 \n",
       "L 108.14579 369.618438 \n",
       "L 114.294551 369.711864 \n",
       "L 120.443311 369.760553 \n",
       "L 126.592071 369.812386 \n",
       "L 132.740832 369.8088 \n",
       "L 138.889592 369.834534 \n",
       "L 145.038352 369.857077 \n",
       "L 151.187113 369.917263 \n",
       "L 157.335873 369.886765 \n",
       "L 163.484633 369.955601 \n",
       "L 169.633394 369.921965 \n",
       "L 175.782154 369.960093 \n",
       "L 181.930914 369.939497 \n",
       "L 188.079675 369.97592 \n",
       "L 194.228435 369.993695 \n",
       "L 200.377195 370.011151 \n",
       "L 206.525956 370.029636 \n",
       "L 212.674716 370.041499 \n",
       "L 218.823476 370.020128 \n",
       "L 224.972237 370.055372 \n",
       "L 231.120997 370.036803 \n",
       "L 237.269757 370.009189 \n",
       "L 243.418518 370.058987 \n",
       "L 249.567278 370.057714 \n",
       "L 255.716038 370.074176 \n",
       "L 261.864799 370.080544 \n",
       "L 268.013559 370.055112 \n",
       "L 274.162319 370.062291 \n",
       "L 280.31108 370.102123 \n",
       "L 286.45984 370.084352 \n",
       "L 292.6086 370.104925 \n",
       "L 298.757361 370.064312 \n",
       "L 304.906121 370.113161 \n",
       "L 311.054881 370.098759 \n",
       "L 317.203642 370.087968 \n",
       "L 323.352402 370.123701 \n",
       "L 329.501162 370.109485 \n",
       "L 335.649923 370.099118 \n",
       "L 341.798683 370.130065 \n",
       "L 347.947443 370.136668 \n",
       "L 354.096204 370.164307 \n",
       "L 360.244964 370.142129 \n",
       "L 366.393724 370.148471 \n",
       "L 372.542485 370.171104 \n",
       "L 378.691245 370.204439 \n",
       "L 384.840005 370.139276 \n",
       "L 390.988765 370.200338 \n",
       "L 397.137526 370.186184 \n",
       "L 403.286286 370.209268 \n",
       "L 409.435046 370.207757 \n",
       "L 415.583807 370.193698 \n",
       "L 421.732567 370.191581 \n",
       "L 427.881327 370.216428 \n",
       "L 434.030088 370.210827 \n",
       "L 440.178848 370.232023 \n",
       "L 446.327608 370.176514 \n",
       "L 452.476369 370.210102 \n",
       "L 458.625129 370.215706 \n",
       "L 464.773889 370.214625 \n",
       "L 470.92265 370.219933 \n",
       "L 477.07141 370.238821 \n",
       "L 483.22017 370.249807 \n",
       "L 489.368931 370.239003 \n",
       "L 495.517691 370.215087 \n",
       "L 501.666451 370.214523 \n",
       "L 507.815212 370.237719 \n",
       "L 513.963972 370.246476 \n",
       "L 520.112732 370.245581 \n",
       "L 526.261493 370.218725 \n",
       "L 532.410253 370.24693 \n",
       "L 538.559013 370.249233 \n",
       "L 544.707774 370.240722 \n",
       "L 550.856534 370.245047 \n",
       "L 557.005294 370.250238 \n",
       "L 563.154055 370.2537 \n",
       "L 569.302815 370.250697 \n",
       "L 575.451575 370.287004 \n",
       "L 581.600336 370.275279 \n",
       "L 587.749096 370.296584 \n",
       "L 593.897856 370.26393 \n",
       "L 600.046617 370.311345 \n",
       "L 606.195377 370.298304 \n",
       "L 612.344137 370.305447 \n",
       "L 618.492898 370.303737 \n",
       "L 624.641658 370.216785 \n",
       "L 630.790418 370.257348 \n",
       "L 636.939179 370.303163 \n",
       "L 643.087939 370.305437 \n",
       "L 649.236699 370.267972 \n",
       "L 655.38546 370.295289 \n",
       "L 661.53422 370.281505 \n",
       "L 667.68298 370.294501 \n",
       "L 673.831741 370.287115 \n",
       "L 679.980501 370.31797 \n",
       "L 686.129261 370.296175 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_33\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 210.576517 \n",
       "L 83.550749 253.887551 \n",
       "L 89.699509 271.572945 \n",
       "L 95.84827 280.988425 \n",
       "L 101.99703 287.173237 \n",
       "L 108.14579 291.098584 \n",
       "L 114.294551 293.952374 \n",
       "L 120.443311 296.323762 \n",
       "L 126.592071 298.509006 \n",
       "L 132.740832 300.563754 \n",
       "L 138.889592 302.557216 \n",
       "L 145.038352 304.548469 \n",
       "L 151.187113 306.375708 \n",
       "L 157.335873 308.0692 \n",
       "L 163.484633 309.638497 \n",
       "L 169.633394 311.046651 \n",
       "L 175.782154 312.303704 \n",
       "L 181.930914 313.412188 \n",
       "L 188.079675 314.538039 \n",
       "L 194.228435 315.515271 \n",
       "L 200.377195 316.38993 \n",
       "L 206.525956 317.220641 \n",
       "L 212.674716 317.998793 \n",
       "L 218.823476 318.769044 \n",
       "L 224.972237 319.437967 \n",
       "L 231.120997 320.09559 \n",
       "L 237.269757 320.692747 \n",
       "L 243.418518 321.307711 \n",
       "L 249.567278 321.784218 \n",
       "L 255.716038 322.365119 \n",
       "L 261.864799 322.900474 \n",
       "L 268.013559 323.353999 \n",
       "L 274.162319 323.875161 \n",
       "L 280.31108 324.341508 \n",
       "L 286.45984 324.842504 \n",
       "L 292.6086 325.28061 \n",
       "L 298.757361 325.781923 \n",
       "L 304.906121 326.282494 \n",
       "L 311.054881 326.700025 \n",
       "L 317.203642 327.20106 \n",
       "L 323.352402 327.64238 \n",
       "L 329.501162 328.098301 \n",
       "L 335.649923 328.516177 \n",
       "L 341.798683 329.009664 \n",
       "L 347.947443 329.493216 \n",
       "L 354.096204 329.92524 \n",
       "L 360.244964 330.460994 \n",
       "L 366.393724 330.916426 \n",
       "L 372.542485 331.395193 \n",
       "L 378.691245 331.846759 \n",
       "L 384.840005 332.340452 \n",
       "L 390.988765 332.783583 \n",
       "L 397.137526 333.172802 \n",
       "L 403.286286 333.629057 \n",
       "L 409.435046 334.047939 \n",
       "L 415.583807 334.482061 \n",
       "L 421.732567 334.840305 \n",
       "L 427.881327 335.218705 \n",
       "L 434.030088 335.634358 \n",
       "L 440.178848 336.002997 \n",
       "L 446.327608 336.322011 \n",
       "L 452.476369 336.529465 \n",
       "L 458.625129 336.988054 \n",
       "L 464.773889 337.265692 \n",
       "L 470.92265 337.542784 \n",
       "L 477.07141 337.778768 \n",
       "L 483.22017 337.920564 \n",
       "L 489.368931 338.299466 \n",
       "L 495.517691 338.601325 \n",
       "L 501.666451 338.794296 \n",
       "L 507.815212 339.082126 \n",
       "L 513.963972 339.1389 \n",
       "L 520.112732 339.486585 \n",
       "L 526.261493 339.637212 \n",
       "L 532.410253 339.846483 \n",
       "L 538.559013 340.062326 \n",
       "L 544.707774 340.303052 \n",
       "L 550.856534 340.497987 \n",
       "L 557.005294 340.613161 \n",
       "L 563.154055 340.818074 \n",
       "L 569.302815 341.030951 \n",
       "L 575.451575 341.206622 \n",
       "L 581.600336 341.344719 \n",
       "L 587.749096 341.401255 \n",
       "L 593.897856 341.722431 \n",
       "L 600.046617 341.846246 \n",
       "L 606.195377 341.92268 \n",
       "L 612.344137 342.074386 \n",
       "L 618.492898 342.355395 \n",
       "L 624.641658 342.162783 \n",
       "L 630.790418 342.66749 \n",
       "L 636.939179 342.851371 \n",
       "L 643.087939 342.790437 \n",
       "L 649.236699 343.137766 \n",
       "L 655.38546 343.323584 \n",
       "L 661.53422 343.365968 \n",
       "L 667.68298 343.564047 \n",
       "L 673.831741 343.695788 \n",
       "L 679.980501 343.88274 \n",
       "L 686.129261 344.017817 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_34\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 361.913916 \n",
       "L 83.550749 364.153816 \n",
       "L 89.699509 365.114341 \n",
       "L 95.84827 365.657441 \n",
       "L 101.99703 365.994814 \n",
       "L 108.14579 366.204395 \n",
       "L 114.294551 366.332519 \n",
       "L 120.443311 366.447659 \n",
       "L 126.592071 366.589742 \n",
       "L 132.740832 366.76196 \n",
       "L 138.889592 366.936268 \n",
       "L 145.038352 367.129434 \n",
       "L 151.187113 367.279589 \n",
       "L 157.335873 367.423907 \n",
       "L 163.484633 367.559961 \n",
       "L 169.633394 367.675833 \n",
       "L 175.782154 367.773429 \n",
       "L 181.930914 367.877077 \n",
       "L 188.079675 367.966347 \n",
       "L 194.228435 368.046171 \n",
       "L 200.377195 368.102005 \n",
       "L 206.525956 368.128778 \n",
       "L 212.674716 368.186178 \n",
       "L 218.823476 368.21323 \n",
       "L 224.972237 368.223296 \n",
       "L 231.120997 368.265716 \n",
       "L 237.269757 368.287737 \n",
       "L 243.418518 368.305617 \n",
       "L 249.567278 368.320354 \n",
       "L 255.716038 368.328705 \n",
       "L 261.864799 368.349259 \n",
       "L 268.013559 368.362275 \n",
       "L 274.162319 368.372402 \n",
       "L 280.31108 368.39155 \n",
       "L 286.45984 368.38976 \n",
       "L 292.6086 368.41133 \n",
       "L 298.757361 368.424742 \n",
       "L 304.906121 368.436898 \n",
       "L 311.054881 368.448843 \n",
       "L 317.203642 368.454302 \n",
       "L 323.352402 368.465893 \n",
       "L 329.501162 368.453035 \n",
       "L 335.649923 368.473427 \n",
       "L 341.798683 368.48578 \n",
       "L 347.947443 368.495506 \n",
       "L 354.096204 368.486679 \n",
       "L 360.244964 368.508314 \n",
       "L 366.393724 368.512954 \n",
       "L 372.542485 368.52799 \n",
       "L 378.691245 368.539477 \n",
       "L 384.840005 368.548625 \n",
       "L 390.988765 368.55854 \n",
       "L 397.137526 368.562122 \n",
       "L 403.286286 368.571382 \n",
       "L 409.435046 368.591012 \n",
       "L 415.583807 368.588872 \n",
       "L 421.732567 368.59132 \n",
       "L 427.881327 368.600198 \n",
       "L 434.030088 368.618519 \n",
       "L 440.178848 368.630372 \n",
       "L 446.327608 368.643015 \n",
       "L 452.476369 368.647315 \n",
       "L 458.625129 368.637363 \n",
       "L 464.773889 368.645885 \n",
       "L 470.92265 368.656186 \n",
       "L 477.07141 368.672414 \n",
       "L 483.22017 368.673343 \n",
       "L 489.368931 368.679051 \n",
       "L 495.517691 368.690218 \n",
       "L 501.666451 368.68311 \n",
       "L 507.815212 368.69755 \n",
       "L 513.963972 368.688503 \n",
       "L 520.112732 368.703023 \n",
       "L 526.261493 368.696704 \n",
       "L 532.410253 368.707872 \n",
       "L 538.559013 368.72733 \n",
       "L 544.707774 368.726078 \n",
       "L 550.856534 368.728242 \n",
       "L 557.005294 368.725037 \n",
       "L 563.154055 368.704272 \n",
       "L 569.302815 368.72068 \n",
       "L 575.451575 368.712866 \n",
       "L 581.600336 368.699904 \n",
       "L 587.749096 368.763078 \n",
       "L 593.897856 368.745774 \n",
       "L 600.046617 368.76577 \n",
       "L 606.195377 368.776484 \n",
       "L 612.344137 368.744592 \n",
       "L 618.492898 368.758152 \n",
       "L 624.641658 368.803958 \n",
       "L 630.790418 368.788364 \n",
       "L 636.939179 368.795894 \n",
       "L 643.087939 368.762829 \n",
       "L 649.236699 368.817365 \n",
       "L 655.38546 368.830643 \n",
       "L 661.53422 368.816252 \n",
       "L 667.68298 368.867295 \n",
       "L 673.831741 368.850116 \n",
       "L 679.980501 368.816542 \n",
       "L 686.129261 368.846765 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_35\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 175.697723 \n",
       "L 83.550749 226.100614 \n",
       "L 89.699509 250.211715 \n",
       "L 95.84827 265.22332 \n",
       "L 101.99703 274.739533 \n",
       "L 108.14579 281.279258 \n",
       "L 114.294551 285.853886 \n",
       "L 120.443311 289.309625 \n",
       "L 126.592071 292.329546 \n",
       "L 132.740832 294.673402 \n",
       "L 138.889592 297.012199 \n",
       "L 145.038352 299.168735 \n",
       "L 151.187113 301.402985 \n",
       "L 157.335873 303.309996 \n",
       "L 163.484633 305.171252 \n",
       "L 169.633394 307.021489 \n",
       "L 175.782154 308.455971 \n",
       "L 181.930914 310.000558 \n",
       "L 188.079675 311.223038 \n",
       "L 194.228435 312.383734 \n",
       "L 200.377195 313.428548 \n",
       "L 206.525956 314.424833 \n",
       "L 212.674716 315.289918 \n",
       "L 218.823476 316.127032 \n",
       "L 224.972237 316.866491 \n",
       "L 231.120997 317.577574 \n",
       "L 237.269757 318.187171 \n",
       "L 243.418518 318.789139 \n",
       "L 249.567278 319.433003 \n",
       "L 255.716038 319.955497 \n",
       "L 261.864799 320.470048 \n",
       "L 268.013559 320.935419 \n",
       "L 274.162319 321.396575 \n",
       "L 280.31108 321.884585 \n",
       "L 286.45984 322.344888 \n",
       "L 292.6086 322.789224 \n",
       "L 298.757361 323.231015 \n",
       "L 304.906121 323.679035 \n",
       "L 311.054881 324.102977 \n",
       "L 317.203642 324.518537 \n",
       "L 323.352402 324.930619 \n",
       "L 329.501162 325.339996 \n",
       "L 335.649923 325.769739 \n",
       "L 341.798683 326.168576 \n",
       "L 347.947443 326.597659 \n",
       "L 354.096204 327.030142 \n",
       "L 360.244964 327.433793 \n",
       "L 366.393724 327.92052 \n",
       "L 372.542485 328.353563 \n",
       "L 378.691245 328.760553 \n",
       "L 384.840005 329.241489 \n",
       "L 390.988765 329.658204 \n",
       "L 397.137526 330.088841 \n",
       "L 403.286286 330.578423 \n",
       "L 409.435046 330.963704 \n",
       "L 415.583807 331.437645 \n",
       "L 421.732567 331.883677 \n",
       "L 427.881327 332.302469 \n",
       "L 434.030088 332.603718 \n",
       "L 440.178848 333.081123 \n",
       "L 446.327608 333.456807 \n",
       "L 452.476369 333.87081 \n",
       "L 458.625129 334.197507 \n",
       "L 464.773889 334.639726 \n",
       "L 470.92265 334.864192 \n",
       "L 477.07141 335.180536 \n",
       "L 483.22017 335.57143 \n",
       "L 489.368931 335.912035 \n",
       "L 495.517691 336.243627 \n",
       "L 501.666451 336.518881 \n",
       "L 507.815212 336.830351 \n",
       "L 513.963972 337.080524 \n",
       "L 520.112732 337.311116 \n",
       "L 526.261493 337.618605 \n",
       "L 532.410253 337.820906 \n",
       "L 538.559013 338.093327 \n",
       "L 544.707774 338.302644 \n",
       "L 550.856534 338.440346 \n",
       "L 557.005294 338.671184 \n",
       "L 563.154055 338.906964 \n",
       "L 569.302815 338.980832 \n",
       "L 575.451575 339.259029 \n",
       "L 581.600336 339.550875 \n",
       "L 587.749096 339.693337 \n",
       "L 593.897856 339.848297 \n",
       "L 600.046617 340.129234 \n",
       "L 606.195377 340.187216 \n",
       "L 612.344137 340.436342 \n",
       "L 618.492898 340.549559 \n",
       "L 624.641658 340.821801 \n",
       "L 630.790418 340.904974 \n",
       "L 636.939179 341.100337 \n",
       "L 643.087939 341.247952 \n",
       "L 649.236699 341.523387 \n",
       "L 655.38546 341.638065 \n",
       "L 661.53422 341.822577 \n",
       "L 667.68298 342.003027 \n",
       "L 673.831741 342.130658 \n",
       "L 679.980501 342.292392 \n",
       "L 686.129261 342.338087 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_36\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.513966 \n",
       "L 83.550749 364.55551 \n",
       "L 89.699509 365.35483 \n",
       "L 95.84827 365.816533 \n",
       "L 101.99703 366.113016 \n",
       "L 108.14579 366.296143 \n",
       "L 114.294551 366.412968 \n",
       "L 120.443311 366.534762 \n",
       "L 126.592071 366.69115 \n",
       "L 132.740832 366.850799 \n",
       "L 138.889592 367.053988 \n",
       "L 145.038352 367.205231 \n",
       "L 151.187113 367.369964 \n",
       "L 157.335873 367.516565 \n",
       "L 163.484633 367.624752 \n",
       "L 169.633394 367.705596 \n",
       "L 175.782154 367.845201 \n",
       "L 181.930914 367.923425 \n",
       "L 188.079675 368.029673 \n",
       "L 194.228435 368.088542 \n",
       "L 200.377195 368.138647 \n",
       "L 206.525956 368.19741 \n",
       "L 212.674716 368.217185 \n",
       "L 218.823476 368.254453 \n",
       "L 224.972237 368.279201 \n",
       "L 231.120997 368.295707 \n",
       "L 237.269757 368.300136 \n",
       "L 243.418518 368.327599 \n",
       "L 249.567278 368.345012 \n",
       "L 255.716038 368.358966 \n",
       "L 261.864799 368.371885 \n",
       "L 268.013559 368.38279 \n",
       "L 274.162319 368.397557 \n",
       "L 280.31108 368.40614 \n",
       "L 286.45984 368.405156 \n",
       "L 292.6086 368.431477 \n",
       "L 298.757361 368.429221 \n",
       "L 304.906121 368.450329 \n",
       "L 311.054881 368.457393 \n",
       "L 317.203642 368.466855 \n",
       "L 323.352402 368.466891 \n",
       "L 329.501162 368.479226 \n",
       "L 335.649923 368.492652 \n",
       "L 341.798683 368.484621 \n",
       "L 347.947443 368.516014 \n",
       "L 354.096204 368.52431 \n",
       "L 360.244964 368.510914 \n",
       "L 366.393724 368.536422 \n",
       "L 372.542485 368.549349 \n",
       "L 378.691245 368.553833 \n",
       "L 384.840005 368.566428 \n",
       "L 390.988765 368.576481 \n",
       "L 397.137526 368.598505 \n",
       "L 403.286286 368.599328 \n",
       "L 409.435046 368.621401 \n",
       "L 415.583807 368.606769 \n",
       "L 421.732567 368.609099 \n",
       "L 427.881327 368.642299 \n",
       "L 434.030088 368.646109 \n",
       "L 440.178848 368.658357 \n",
       "L 446.327608 368.664932 \n",
       "L 452.476369 368.665657 \n",
       "L 458.625129 368.67039 \n",
       "L 464.773889 368.665481 \n",
       "L 470.92265 368.693787 \n",
       "L 477.07141 368.693649 \n",
       "L 483.22017 368.700967 \n",
       "L 489.368931 368.701924 \n",
       "L 495.517691 368.720113 \n",
       "L 501.666451 368.683569 \n",
       "L 507.815212 368.717712 \n",
       "L 513.963972 368.732556 \n",
       "L 520.112732 368.712752 \n",
       "L 526.261493 368.748248 \n",
       "L 532.410253 368.701253 \n",
       "L 538.559013 368.755094 \n",
       "L 544.707774 368.741551 \n",
       "L 550.856534 368.731812 \n",
       "L 557.005294 368.779636 \n",
       "L 563.154055 368.756513 \n",
       "L 569.302815 368.719353 \n",
       "L 575.451575 368.778648 \n",
       "L 581.600336 368.789529 \n",
       "L 587.749096 368.756002 \n",
       "L 593.897856 368.765395 \n",
       "L 600.046617 368.760979 \n",
       "L 606.195377 368.81438 \n",
       "L 612.344137 368.801298 \n",
       "L 618.492898 368.796626 \n",
       "L 624.641658 368.84888 \n",
       "L 630.790418 368.813735 \n",
       "L 636.939179 368.825407 \n",
       "L 643.087939 368.876529 \n",
       "L 649.236699 368.832204 \n",
       "L 655.38546 368.839974 \n",
       "L 661.53422 368.889097 \n",
       "L 667.68298 368.847737 \n",
       "L 673.831741 368.843068 \n",
       "L 679.980501 368.855918 \n",
       "L 686.129261 368.854924 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_37\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 153.416064 \n",
       "L 83.550749 208.118614 \n",
       "L 89.699509 235.649925 \n",
       "L 95.84827 252.429009 \n",
       "L 101.99703 264.352816 \n",
       "L 108.14579 272.262943 \n",
       "L 114.294551 278.281923 \n",
       "L 120.443311 282.793099 \n",
       "L 126.592071 286.633214 \n",
       "L 132.740832 289.376349 \n",
       "L 138.889592 291.917574 \n",
       "L 145.038352 294.130813 \n",
       "L 151.187113 296.341473 \n",
       "L 157.335873 298.284825 \n",
       "L 163.484633 300.229446 \n",
       "L 169.633394 302.120093 \n",
       "L 175.782154 303.88316 \n",
       "L 181.930914 305.606992 \n",
       "L 188.079675 307.099231 \n",
       "L 194.228435 308.536941 \n",
       "L 200.377195 309.847333 \n",
       "L 206.525956 310.996833 \n",
       "L 212.674716 312.073565 \n",
       "L 218.823476 313.094966 \n",
       "L 224.972237 313.955386 \n",
       "L 231.120997 314.827273 \n",
       "L 237.269757 315.562335 \n",
       "L 243.418518 316.277676 \n",
       "L 249.567278 316.959067 \n",
       "L 255.716038 317.546717 \n",
       "L 261.864799 318.101618 \n",
       "L 268.013559 318.696063 \n",
       "L 274.162319 319.199849 \n",
       "L 280.31108 319.700296 \n",
       "L 286.45984 320.173225 \n",
       "L 292.6086 320.683033 \n",
       "L 298.757361 321.154505 \n",
       "L 304.906121 321.534333 \n",
       "L 311.054881 321.943101 \n",
       "L 317.203642 322.397408 \n",
       "L 323.352402 322.800834 \n",
       "L 329.501162 323.204884 \n",
       "L 335.649923 323.609728 \n",
       "L 341.798683 324.011743 \n",
       "L 347.947443 324.383116 \n",
       "L 354.096204 324.788855 \n",
       "L 360.244964 325.238001 \n",
       "L 366.393724 325.581731 \n",
       "L 372.542485 326.00052 \n",
       "L 378.691245 326.427013 \n",
       "L 384.840005 326.764058 \n",
       "L 390.988765 327.230142 \n",
       "L 397.137526 327.600245 \n",
       "L 403.286286 328.067084 \n",
       "L 409.435046 328.466352 \n",
       "L 415.583807 328.904972 \n",
       "L 421.732567 329.314566 \n",
       "L 427.881327 329.695325 \n",
       "L 434.030088 330.070731 \n",
       "L 440.178848 330.538518 \n",
       "L 446.327608 330.925916 \n",
       "L 452.476369 331.344808 \n",
       "L 458.625129 331.704652 \n",
       "L 464.773889 332.130728 \n",
       "L 470.92265 332.467877 \n",
       "L 477.07141 332.828042 \n",
       "L 483.22017 333.144867 \n",
       "L 489.368931 333.498155 \n",
       "L 495.517691 333.86565 \n",
       "L 501.666451 334.238063 \n",
       "L 507.815212 334.538062 \n",
       "L 513.963972 334.855846 \n",
       "L 520.112732 335.109116 \n",
       "L 526.261493 335.442904 \n",
       "L 532.410253 335.704566 \n",
       "L 538.559013 335.966442 \n",
       "L 544.707774 336.21828 \n",
       "L 550.856534 336.520613 \n",
       "L 557.005294 336.771392 \n",
       "L 563.154055 337.008448 \n",
       "L 569.302815 337.253672 \n",
       "L 575.451575 337.46444 \n",
       "L 581.600336 337.704368 \n",
       "L 587.749096 337.924088 \n",
       "L 593.897856 338.045102 \n",
       "L 600.046617 338.377995 \n",
       "L 606.195377 338.538763 \n",
       "L 612.344137 338.631632 \n",
       "L 618.492898 338.953924 \n",
       "L 624.641658 339.037211 \n",
       "L 630.790418 339.29077 \n",
       "L 636.939179 339.476508 \n",
       "L 643.087939 339.617228 \n",
       "L 649.236699 339.719062 \n",
       "L 655.38546 340.037983 \n",
       "L 661.53422 340.234857 \n",
       "L 667.68298 340.338591 \n",
       "L 673.831741 340.580323 \n",
       "L 679.980501 340.71311 \n",
       "L 686.129261 340.791939 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_38\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.535935 \n",
       "L 83.550749 364.641258 \n",
       "L 89.699509 365.438165 \n",
       "L 95.84827 365.889638 \n",
       "L 101.99703 366.155809 \n",
       "L 108.14579 366.292864 \n",
       "L 114.294551 366.400504 \n",
       "L 120.443311 366.527312 \n",
       "L 126.592071 366.674085 \n",
       "L 132.740832 366.847499 \n",
       "L 138.889592 367.002646 \n",
       "L 145.038352 367.189086 \n",
       "L 151.187113 367.339063 \n",
       "L 157.335873 367.443448 \n",
       "L 163.484633 367.583412 \n",
       "L 169.633394 367.698381 \n",
       "L 175.782154 367.80247 \n",
       "L 181.930914 367.908115 \n",
       "L 188.079675 367.978439 \n",
       "L 194.228435 368.058792 \n",
       "L 200.377195 368.106888 \n",
       "L 206.525956 368.151665 \n",
       "L 212.674716 368.205399 \n",
       "L 218.823476 368.226189 \n",
       "L 224.972237 368.261581 \n",
       "L 231.120997 368.264983 \n",
       "L 237.269757 368.302022 \n",
       "L 243.418518 368.304462 \n",
       "L 249.567278 368.335263 \n",
       "L 255.716038 368.351842 \n",
       "L 261.864799 368.366061 \n",
       "L 268.013559 368.373783 \n",
       "L 274.162319 368.389905 \n",
       "L 280.31108 368.389893 \n",
       "L 286.45984 368.414443 \n",
       "L 292.6086 368.403562 \n",
       "L 298.757361 368.43854 \n",
       "L 304.906121 368.447704 \n",
       "L 311.054881 368.456834 \n",
       "L 317.203642 368.457131 \n",
       "L 323.352402 368.456641 \n",
       "L 329.501162 368.477297 \n",
       "L 335.649923 368.483438 \n",
       "L 341.798683 368.487324 \n",
       "L 347.947443 368.487612 \n",
       "L 354.096204 368.505654 \n",
       "L 360.244964 368.51469 \n",
       "L 366.393724 368.522474 \n",
       "L 372.542485 368.534664 \n",
       "L 378.691245 368.544608 \n",
       "L 384.840005 368.541254 \n",
       "L 390.988765 368.546527 \n",
       "L 397.137526 368.571415 \n",
       "L 403.286286 368.581001 \n",
       "L 409.435046 368.578205 \n",
       "L 415.583807 368.602762 \n",
       "L 421.732567 368.614169 \n",
       "L 427.881327 368.623457 \n",
       "L 434.030088 368.620819 \n",
       "L 440.178848 368.638236 \n",
       "L 446.327608 368.637755 \n",
       "L 452.476369 368.649515 \n",
       "L 458.625129 368.651789 \n",
       "L 464.773889 368.660015 \n",
       "L 470.92265 368.663497 \n",
       "L 477.07141 368.651498 \n",
       "L 483.22017 368.675826 \n",
       "L 489.368931 368.679622 \n",
       "L 495.517691 368.671944 \n",
       "L 501.666451 368.702028 \n",
       "L 507.815212 368.668439 \n",
       "L 513.963972 368.698401 \n",
       "L 520.112732 368.706047 \n",
       "L 526.261493 368.722303 \n",
       "L 532.410253 368.733336 \n",
       "L 538.559013 368.725068 \n",
       "L 544.707774 368.738715 \n",
       "L 550.856534 368.736812 \n",
       "L 557.005294 368.703793 \n",
       "L 563.154055 368.742605 \n",
       "L 569.302815 368.756142 \n",
       "L 575.451575 368.7465 \n",
       "L 581.600336 368.74171 \n",
       "L 587.749096 368.772952 \n",
       "L 593.897856 368.752358 \n",
       "L 600.046617 368.777943 \n",
       "L 606.195377 368.798575 \n",
       "L 612.344137 368.794836 \n",
       "L 618.492898 368.75606 \n",
       "L 624.641658 368.789222 \n",
       "L 630.790418 368.818594 \n",
       "L 636.939179 368.780838 \n",
       "L 643.087939 368.828419 \n",
       "L 649.236699 368.850455 \n",
       "L 655.38546 368.815054 \n",
       "L 661.53422 368.801597 \n",
       "L 667.68298 368.808134 \n",
       "L 673.831741 368.865509 \n",
       "L 679.980501 368.822115 \n",
       "L 686.129261 368.84704 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_39\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 312.78721 \n",
       "L 83.550749 344.123652 \n",
       "L 89.699509 349.154352 \n",
       "L 95.84827 351.800851 \n",
       "L 101.99703 353.090566 \n",
       "L 108.14579 353.87074 \n",
       "L 114.294551 354.779994 \n",
       "L 120.443311 355.107268 \n",
       "L 126.592071 355.706511 \n",
       "L 132.740832 355.857811 \n",
       "L 138.889592 356.248999 \n",
       "L 145.038352 356.639372 \n",
       "L 151.187113 356.547066 \n",
       "L 157.335873 356.673321 \n",
       "L 163.484633 357.057677 \n",
       "L 169.633394 357.100169 \n",
       "L 175.782154 357.383665 \n",
       "L 181.930914 357.304243 \n",
       "L 188.079675 357.717921 \n",
       "L 194.228435 357.787021 \n",
       "L 200.377195 357.889648 \n",
       "L 206.525956 358.051177 \n",
       "L 212.674716 358.23326 \n",
       "L 218.823476 358.091498 \n",
       "L 224.972237 358.100748 \n",
       "L 231.120997 358.393626 \n",
       "L 237.269757 358.505391 \n",
       "L 243.418518 358.309299 \n",
       "L 249.567278 358.41135 \n",
       "L 255.716038 358.599881 \n",
       "L 261.864799 358.587167 \n",
       "L 268.013559 358.648172 \n",
       "L 274.162319 358.667733 \n",
       "L 280.31108 358.866106 \n",
       "L 286.45984 358.849166 \n",
       "L 292.6086 359.040133 \n",
       "L 298.757361 358.947119 \n",
       "L 304.906121 359.009449 \n",
       "L 311.054881 359.091002 \n",
       "L 317.203642 359.008123 \n",
       "L 323.352402 359.211678 \n",
       "L 329.501162 359.161192 \n",
       "L 335.649923 359.2327 \n",
       "L 341.798683 359.197323 \n",
       "L 347.947443 359.163473 \n",
       "L 354.096204 359.26526 \n",
       "L 360.244964 359.380659 \n",
       "L 366.393724 359.167132 \n",
       "L 372.542485 359.287197 \n",
       "L 378.691245 359.49185 \n",
       "L 384.840005 359.363492 \n",
       "L 390.988765 359.160523 \n",
       "L 397.137526 359.231762 \n",
       "L 403.286286 359.463018 \n",
       "L 409.435046 359.485353 \n",
       "L 415.583807 359.565497 \n",
       "L 421.732567 359.55312 \n",
       "L 427.881327 359.481554 \n",
       "L 434.030088 359.510509 \n",
       "L 440.178848 359.465145 \n",
       "L 446.327608 359.464887 \n",
       "L 452.476369 359.582861 \n",
       "L 458.625129 359.617906 \n",
       "L 464.773889 359.363464 \n",
       "L 470.92265 359.610992 \n",
       "L 477.07141 359.527024 \n",
       "L 483.22017 359.320623 \n",
       "L 489.368931 359.694561 \n",
       "L 495.517691 359.663121 \n",
       "L 501.666451 359.532386 \n",
       "L 507.815212 359.641261 \n",
       "L 513.963972 359.579772 \n",
       "L 520.112732 359.748554 \n",
       "L 526.261493 359.66902 \n",
       "L 532.410253 359.515384 \n",
       "L 538.559013 359.657389 \n",
       "L 544.707774 359.474236 \n",
       "L 550.856534 359.759197 \n",
       "L 557.005294 359.618472 \n",
       "L 563.154055 359.603633 \n",
       "L 569.302815 359.538271 \n",
       "L 575.451575 359.504413 \n",
       "L 581.600336 359.765381 \n",
       "L 587.749096 359.457003 \n",
       "L 593.897856 359.720113 \n",
       "L 600.046617 359.771416 \n",
       "L 606.195377 359.748141 \n",
       "L 612.344137 359.616389 \n",
       "L 618.492898 359.654707 \n",
       "L 624.641658 359.619996 \n",
       "L 630.790418 359.634101 \n",
       "L 636.939179 359.873076 \n",
       "L 643.087939 360.017685 \n",
       "L 649.236699 359.809129 \n",
       "L 655.38546 359.462651 \n",
       "L 661.53422 359.590325 \n",
       "L 667.68298 359.676872 \n",
       "L 673.831741 360.009273 \n",
       "L 679.980501 359.702123 \n",
       "L 686.129261 359.652165 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_40\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.851714 \n",
       "L 83.550749 369.44639 \n",
       "L 89.699509 369.661694 \n",
       "L 95.84827 369.858371 \n",
       "L 101.99703 369.82763 \n",
       "L 108.14579 369.853349 \n",
       "L 114.294551 369.998021 \n",
       "L 120.443311 369.969373 \n",
       "L 126.592071 370.000717 \n",
       "L 132.740832 370.117421 \n",
       "L 138.889592 369.965769 \n",
       "L 145.038352 370.063035 \n",
       "L 151.187113 370.076666 \n",
       "L 157.335873 370.117771 \n",
       "L 163.484633 370.191383 \n",
       "L 169.633394 370.166904 \n",
       "L 175.782154 370.205468 \n",
       "L 181.930914 370.166009 \n",
       "L 188.079675 370.216022 \n",
       "L 194.228435 370.203187 \n",
       "L 200.377195 370.241441 \n",
       "L 206.525956 370.183099 \n",
       "L 212.674716 370.210315 \n",
       "L 218.823476 370.20676 \n",
       "L 224.972237 370.207281 \n",
       "L 231.120997 370.244221 \n",
       "L 237.269757 370.24185 \n",
       "L 243.418518 370.261804 \n",
       "L 249.567278 370.238902 \n",
       "L 255.716038 370.257475 \n",
       "L 261.864799 370.259273 \n",
       "L 268.013559 370.274266 \n",
       "L 274.162319 370.211822 \n",
       "L 280.31108 370.251194 \n",
       "L 286.45984 370.277872 \n",
       "L 292.6086 370.306679 \n",
       "L 298.757361 370.258656 \n",
       "L 304.906121 370.252788 \n",
       "L 311.054881 370.298692 \n",
       "L 317.203642 370.324944 \n",
       "L 323.352402 370.280818 \n",
       "L 329.501162 370.274756 \n",
       "L 335.649923 370.30084 \n",
       "L 341.798683 370.293802 \n",
       "L 347.947443 370.293607 \n",
       "L 354.096204 370.286676 \n",
       "L 360.244964 370.290133 \n",
       "L 366.393724 370.27023 \n",
       "L 372.542485 370.330628 \n",
       "L 378.691245 370.283869 \n",
       "L 384.840005 370.286954 \n",
       "L 390.988765 370.307759 \n",
       "L 397.137526 370.309895 \n",
       "L 403.286286 370.294615 \n",
       "L 409.435046 370.327761 \n",
       "L 415.583807 370.323821 \n",
       "L 421.732567 370.339666 \n",
       "L 427.881327 370.31325 \n",
       "L 434.030088 370.278662 \n",
       "L 440.178848 370.339903 \n",
       "L 446.327608 370.276501 \n",
       "L 452.476369 370.322318 \n",
       "L 458.625129 370.324984 \n",
       "L 464.773889 370.314686 \n",
       "L 470.92265 370.291796 \n",
       "L 477.07141 370.323615 \n",
       "L 483.22017 370.302743 \n",
       "L 489.368931 370.312633 \n",
       "L 495.517691 370.31152 \n",
       "L 501.666451 370.322859 \n",
       "L 507.815212 370.307631 \n",
       "L 513.963972 370.313478 \n",
       "L 520.112732 370.314501 \n",
       "L 526.261493 370.318027 \n",
       "L 532.410253 370.294472 \n",
       "L 538.559013 370.28929 \n",
       "L 544.707774 370.339701 \n",
       "L 550.856534 370.347135 \n",
       "L 557.005294 370.344438 \n",
       "L 563.154055 370.34277 \n",
       "L 569.302815 370.289433 \n",
       "L 575.451575 370.32034 \n",
       "L 581.600336 370.311536 \n",
       "L 587.749096 370.352128 \n",
       "L 593.897856 370.319019 \n",
       "L 600.046617 370.316831 \n",
       "L 606.195377 370.353523 \n",
       "L 612.344137 370.344021 \n",
       "L 618.492898 370.29862 \n",
       "L 624.641658 370.338763 \n",
       "L 630.790418 370.307654 \n",
       "L 636.939179 370.319184 \n",
       "L 643.087939 370.301589 \n",
       "L 649.236699 370.326502 \n",
       "L 655.38546 370.350566 \n",
       "L 661.53422 370.302909 \n",
       "L 667.68298 370.333682 \n",
       "L 673.831741 370.324588 \n",
       "L 679.980501 370.296977 \n",
       "L 686.129261 370.310634 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_41\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 302.972374 \n",
       "L 83.550749 345.163892 \n",
       "L 89.699509 350.362465 \n",
       "L 95.84827 351.998011 \n",
       "L 101.99703 353.30883 \n",
       "L 108.14579 354.242276 \n",
       "L 114.294551 354.596065 \n",
       "L 120.443311 355.04393 \n",
       "L 126.592071 355.674707 \n",
       "L 132.740832 355.667781 \n",
       "L 138.889592 356.36828 \n",
       "L 145.038352 356.392462 \n",
       "L 151.187113 356.519322 \n",
       "L 157.335873 356.977422 \n",
       "L 163.484633 356.992257 \n",
       "L 169.633394 357.17194 \n",
       "L 175.782154 357.247023 \n",
       "L 181.930914 357.526967 \n",
       "L 188.079675 357.671501 \n",
       "L 194.228435 357.606045 \n",
       "L 200.377195 357.620394 \n",
       "L 206.525956 357.964357 \n",
       "L 212.674716 357.877649 \n",
       "L 218.823476 358.044004 \n",
       "L 224.972237 358.228048 \n",
       "L 231.120997 358.26934 \n",
       "L 237.269757 358.221465 \n",
       "L 243.418518 358.489522 \n",
       "L 249.567278 358.380398 \n",
       "L 255.716038 358.6215 \n",
       "L 261.864799 358.563218 \n",
       "L 268.013559 358.661801 \n",
       "L 274.162319 358.729231 \n",
       "L 280.31108 358.516425 \n",
       "L 286.45984 358.886451 \n",
       "L 292.6086 358.737872 \n",
       "L 298.757361 358.917442 \n",
       "L 304.906121 358.828247 \n",
       "L 311.054881 359.221032 \n",
       "L 317.203642 359.086163 \n",
       "L 323.352402 359.006624 \n",
       "L 329.501162 359.102758 \n",
       "L 335.649923 359.2318 \n",
       "L 341.798683 359.141354 \n",
       "L 347.947443 359.10793 \n",
       "L 354.096204 359.090727 \n",
       "L 360.244964 359.095771 \n",
       "L 366.393724 359.39825 \n",
       "L 372.542485 359.455811 \n",
       "L 378.691245 359.376199 \n",
       "L 384.840005 359.471202 \n",
       "L 390.988765 359.416195 \n",
       "L 397.137526 359.483356 \n",
       "L 403.286286 359.455706 \n",
       "L 409.435046 359.532641 \n",
       "L 415.583807 359.709255 \n",
       "L 421.732567 359.588033 \n",
       "L 427.881327 359.507984 \n",
       "L 434.030088 359.61111 \n",
       "L 440.178848 359.314835 \n",
       "L 446.327608 359.571839 \n",
       "L 452.476369 359.717308 \n",
       "L 458.625129 359.594292 \n",
       "L 464.773889 359.701343 \n",
       "L 470.92265 359.733393 \n",
       "L 477.07141 359.626998 \n",
       "L 483.22017 359.716768 \n",
       "L 489.368931 359.804502 \n",
       "L 495.517691 359.651672 \n",
       "L 501.666451 359.850647 \n",
       "L 507.815212 359.748092 \n",
       "L 513.963972 359.848002 \n",
       "L 520.112732 359.755433 \n",
       "L 526.261493 359.828719 \n",
       "L 532.410253 359.912877 \n",
       "L 538.559013 359.736163 \n",
       "L 544.707774 359.838568 \n",
       "L 550.856534 359.800857 \n",
       "L 557.005294 359.842055 \n",
       "L 563.154055 359.793831 \n",
       "L 569.302815 359.749823 \n",
       "L 575.451575 359.893027 \n",
       "L 581.600336 359.88386 \n",
       "L 587.749096 359.838276 \n",
       "L 593.897856 359.82576 \n",
       "L 600.046617 359.88065 \n",
       "L 606.195377 359.828261 \n",
       "L 612.344137 359.684446 \n",
       "L 618.492898 359.695679 \n",
       "L 624.641658 359.69645 \n",
       "L 630.790418 359.825839 \n",
       "L 636.939179 359.447326 \n",
       "L 643.087939 359.551736 \n",
       "L 649.236699 359.591103 \n",
       "L 655.38546 359.635344 \n",
       "L 661.53422 359.725347 \n",
       "L 667.68298 359.870584 \n",
       "L 673.831741 359.681862 \n",
       "L 679.980501 359.826774 \n",
       "L 686.129261 359.807271 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_42\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.969587 \n",
       "L 83.550749 369.325003 \n",
       "L 89.699509 369.597863 \n",
       "L 95.84827 369.780106 \n",
       "L 101.99703 369.806669 \n",
       "L 108.14579 369.874174 \n",
       "L 114.294551 369.925068 \n",
       "L 120.443311 369.93431 \n",
       "L 126.592071 369.964028 \n",
       "L 132.740832 369.920693 \n",
       "L 138.889592 369.967886 \n",
       "L 145.038352 370.028911 \n",
       "L 151.187113 370.057397 \n",
       "L 157.335873 370.041719 \n",
       "L 163.484633 370.059838 \n",
       "L 169.633394 370.102851 \n",
       "L 175.782154 370.098483 \n",
       "L 181.930914 370.136364 \n",
       "L 188.079675 370.095041 \n",
       "L 194.228435 370.148884 \n",
       "L 200.377195 370.149586 \n",
       "L 206.525956 370.118938 \n",
       "L 212.674716 370.148151 \n",
       "L 218.823476 370.146632 \n",
       "L 224.972237 370.16529 \n",
       "L 231.120997 370.174235 \n",
       "L 237.269757 370.196588 \n",
       "L 243.418518 370.184168 \n",
       "L 249.567278 370.184022 \n",
       "L 255.716038 370.197234 \n",
       "L 261.864799 370.195126 \n",
       "L 268.013559 370.195605 \n",
       "L 274.162319 370.221971 \n",
       "L 280.31108 370.176672 \n",
       "L 286.45984 370.195874 \n",
       "L 292.6086 370.220801 \n",
       "L 298.757361 370.222872 \n",
       "L 304.906121 370.212971 \n",
       "L 311.054881 370.218606 \n",
       "L 317.203642 370.246284 \n",
       "L 323.352402 370.214527 \n",
       "L 329.501162 370.258331 \n",
       "L 335.649923 370.267236 \n",
       "L 341.798683 370.237551 \n",
       "L 347.947443 370.268081 \n",
       "L 354.096204 370.267362 \n",
       "L 360.244964 370.244464 \n",
       "L 366.393724 370.287095 \n",
       "L 372.542485 370.28148 \n",
       "L 378.691245 370.318876 \n",
       "L 384.840005 370.267599 \n",
       "L 390.988765 370.200996 \n",
       "L 397.137526 370.241323 \n",
       "L 403.286286 370.306297 \n",
       "L 409.435046 370.295975 \n",
       "L 415.583807 370.300973 \n",
       "L 421.732567 370.29577 \n",
       "L 427.881327 370.285485 \n",
       "L 434.030088 370.276302 \n",
       "L 440.178848 370.323132 \n",
       "L 446.327608 370.313068 \n",
       "L 452.476369 370.299858 \n",
       "L 458.625129 370.317189 \n",
       "L 464.773889 370.298725 \n",
       "L 470.92265 370.335121 \n",
       "L 477.07141 370.307638 \n",
       "L 483.22017 370.340141 \n",
       "L 489.368931 370.269027 \n",
       "L 495.517691 370.287902 \n",
       "L 501.666451 370.282774 \n",
       "L 507.815212 370.313212 \n",
       "L 513.963972 370.309326 \n",
       "L 520.112732 370.320735 \n",
       "L 526.261493 370.270811 \n",
       "L 532.410253 370.285602 \n",
       "L 538.559013 370.30559 \n",
       "L 544.707774 370.307831 \n",
       "L 550.856534 370.2995 \n",
       "L 557.005294 370.307807 \n",
       "L 563.154055 370.303005 \n",
       "L 569.302815 370.323524 \n",
       "L 575.451575 370.282965 \n",
       "L 581.600336 370.319632 \n",
       "L 587.749096 370.285686 \n",
       "L 593.897856 370.32847 \n",
       "L 600.046617 370.312951 \n",
       "L 606.195377 370.326567 \n",
       "L 612.344137 370.276196 \n",
       "L 618.492898 370.330195 \n",
       "L 624.641658 370.304945 \n",
       "L 630.790418 370.292574 \n",
       "L 636.939179 370.318013 \n",
       "L 643.087939 370.324219 \n",
       "L 649.236699 370.32762 \n",
       "L 655.38546 370.291131 \n",
       "L 661.53422 370.287039 \n",
       "L 667.68298 370.293059 \n",
       "L 673.831741 370.301822 \n",
       "L 679.980501 370.347182 \n",
       "L 686.129261 370.360626 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_43\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 311.272706 \n",
       "L 83.550749 342.859957 \n",
       "L 89.699509 348.175491 \n",
       "L 95.84827 350.194861 \n",
       "L 101.99703 352.387034 \n",
       "L 108.14579 353.351118 \n",
       "L 114.294551 354.169126 \n",
       "L 120.443311 354.770397 \n",
       "L 126.592071 355.269588 \n",
       "L 132.740832 355.767082 \n",
       "L 138.889592 356.126576 \n",
       "L 145.038352 356.488977 \n",
       "L 151.187113 356.650652 \n",
       "L 157.335873 356.852627 \n",
       "L 163.484633 357.14028 \n",
       "L 169.633394 357.375877 \n",
       "L 175.782154 357.381299 \n",
       "L 181.930914 357.738078 \n",
       "L 188.079675 357.89157 \n",
       "L 194.228435 358.046234 \n",
       "L 200.377195 358.100592 \n",
       "L 206.525956 358.393121 \n",
       "L 212.674716 358.509367 \n",
       "L 218.823476 358.574686 \n",
       "L 224.972237 358.343295 \n",
       "L 231.120997 358.729748 \n",
       "L 237.269757 358.752127 \n",
       "L 243.418518 359.043957 \n",
       "L 249.567278 358.988078 \n",
       "L 255.716038 359.074344 \n",
       "L 261.864799 359.101359 \n",
       "L 268.013559 359.182642 \n",
       "L 274.162319 359.318655 \n",
       "L 280.31108 359.426895 \n",
       "L 286.45984 359.262617 \n",
       "L 292.6086 359.19569 \n",
       "L 298.757361 359.388312 \n",
       "L 304.906121 359.294879 \n",
       "L 311.054881 359.532104 \n",
       "L 317.203642 359.674564 \n",
       "L 323.352402 359.401987 \n",
       "L 329.501162 359.65086 \n",
       "L 335.649923 359.714367 \n",
       "L 341.798683 359.728497 \n",
       "L 347.947443 359.871529 \n",
       "L 354.096204 359.77152 \n",
       "L 360.244964 359.815376 \n",
       "L 366.393724 359.857816 \n",
       "L 372.542485 359.692545 \n",
       "L 378.691245 359.832505 \n",
       "L 384.840005 359.976299 \n",
       "L 390.988765 359.753074 \n",
       "L 397.137526 359.769434 \n",
       "L 403.286286 359.897986 \n",
       "L 409.435046 360.07951 \n",
       "L 415.583807 360.218898 \n",
       "L 421.732567 359.980394 \n",
       "L 427.881327 360.001508 \n",
       "L 434.030088 360.082851 \n",
       "L 440.178848 359.908772 \n",
       "L 446.327608 360.208884 \n",
       "L 452.476369 359.971339 \n",
       "L 458.625129 360.135063 \n",
       "L 464.773889 359.971229 \n",
       "L 470.92265 360.248214 \n",
       "L 477.07141 360.029182 \n",
       "L 483.22017 360.052343 \n",
       "L 489.368931 360.00463 \n",
       "L 495.517691 360.219514 \n",
       "L 501.666451 360.255738 \n",
       "L 507.815212 360.36907 \n",
       "L 513.963972 360.291757 \n",
       "L 520.112732 360.051573 \n",
       "L 526.261493 360.16422 \n",
       "L 532.410253 360.402229 \n",
       "L 538.559013 359.865036 \n",
       "L 544.707774 360.392771 \n",
       "L 550.856534 360.387066 \n",
       "L 557.005294 360.309884 \n",
       "L 563.154055 360.23915 \n",
       "L 569.302815 359.808537 \n",
       "L 575.451575 360.105053 \n",
       "L 581.600336 360.477603 \n",
       "L 587.749096 360.032822 \n",
       "L 593.897856 360.311977 \n",
       "L 600.046617 360.098695 \n",
       "L 606.195377 360.421923 \n",
       "L 612.344137 360.306238 \n",
       "L 618.492898 360.309825 \n",
       "L 624.641658 360.148103 \n",
       "L 630.790418 359.513674 \n",
       "L 636.939179 360.038594 \n",
       "L 643.087939 360.24872 \n",
       "L 649.236699 360.309055 \n",
       "L 655.38546 360.358952 \n",
       "L 661.53422 360.217878 \n",
       "L 667.68298 360.25537 \n",
       "L 673.831741 360.025967 \n",
       "L 679.980501 360.276034 \n",
       "L 686.129261 360.249999 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_44\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.925256 \n",
       "L 83.550749 369.465143 \n",
       "L 89.699509 369.701176 \n",
       "L 95.84827 369.848352 \n",
       "L 101.99703 369.858464 \n",
       "L 108.14579 369.763699 \n",
       "L 114.294551 369.886566 \n",
       "L 120.443311 370.010717 \n",
       "L 126.592071 370.067713 \n",
       "L 132.740832 369.892405 \n",
       "L 138.889592 370.035803 \n",
       "L 145.038352 370.051346 \n",
       "L 151.187113 370.086131 \n",
       "L 157.335873 370.072266 \n",
       "L 163.484633 370.150385 \n",
       "L 169.633394 370.086758 \n",
       "L 175.782154 370.0968 \n",
       "L 181.930914 370.118432 \n",
       "L 188.079675 370.062525 \n",
       "L 194.228435 370.16236 \n",
       "L 200.377195 370.10403 \n",
       "L 206.525956 370.194278 \n",
       "L 212.674716 370.197323 \n",
       "L 218.823476 370.187973 \n",
       "L 224.972237 370.207347 \n",
       "L 231.120997 370.23595 \n",
       "L 237.269757 370.24361 \n",
       "L 243.418518 370.239874 \n",
       "L 249.567278 370.238282 \n",
       "L 255.716038 370.256217 \n",
       "L 261.864799 370.228408 \n",
       "L 268.013559 370.231443 \n",
       "L 274.162319 370.237829 \n",
       "L 280.31108 370.252047 \n",
       "L 286.45984 370.286452 \n",
       "L 292.6086 370.287153 \n",
       "L 298.757361 370.260741 \n",
       "L 304.906121 370.283352 \n",
       "L 311.054881 370.225598 \n",
       "L 317.203642 370.273911 \n",
       "L 323.352402 370.277681 \n",
       "L 329.501162 370.264856 \n",
       "L 335.649923 370.270323 \n",
       "L 341.798683 370.303767 \n",
       "L 347.947443 370.272218 \n",
       "L 354.096204 370.28181 \n",
       "L 360.244964 370.24023 \n",
       "L 366.393724 370.271138 \n",
       "L 372.542485 370.264695 \n",
       "L 378.691245 370.302298 \n",
       "L 384.840005 370.294694 \n",
       "L 390.988765 370.314028 \n",
       "L 397.137526 370.280657 \n",
       "L 403.286286 370.294937 \n",
       "L 409.435046 370.289218 \n",
       "L 415.583807 370.315824 \n",
       "L 421.732567 370.352876 \n",
       "L 427.881327 370.249115 \n",
       "L 434.030088 370.277433 \n",
       "L 440.178848 370.310868 \n",
       "L 446.327608 370.2937 \n",
       "L 452.476369 370.323587 \n",
       "L 458.625129 370.321479 \n",
       "L 464.773889 370.300455 \n",
       "L 470.92265 370.240143 \n",
       "L 477.07141 370.280784 \n",
       "L 483.22017 370.322608 \n",
       "L 489.368931 370.346461 \n",
       "L 495.517691 370.327467 \n",
       "L 501.666451 370.286307 \n",
       "L 507.815212 370.315171 \n",
       "L 513.963972 370.308535 \n",
       "L 520.112732 370.278289 \n",
       "L 526.261493 370.271951 \n",
       "L 532.410253 370.340337 \n",
       "L 538.559013 370.298682 \n",
       "L 544.707774 370.324566 \n",
       "L 550.856534 370.313555 \n",
       "L 557.005294 370.32632 \n",
       "L 563.154055 370.260562 \n",
       "L 569.302815 370.328836 \n",
       "L 575.451575 370.322501 \n",
       "L 581.600336 370.265016 \n",
       "L 587.749096 370.297357 \n",
       "L 593.897856 370.318949 \n",
       "L 600.046617 370.271499 \n",
       "L 606.195377 370.292511 \n",
       "L 612.344137 370.304556 \n",
       "L 618.492898 370.347557 \n",
       "L 624.641658 370.296013 \n",
       "L 630.790418 370.287908 \n",
       "L 636.939179 370.2785 \n",
       "L 643.087939 370.308946 \n",
       "L 649.236699 370.311198 \n",
       "L 655.38546 370.268111 \n",
       "L 661.53422 370.309464 \n",
       "L 667.68298 370.324028 \n",
       "L 673.831741 370.328675 \n",
       "L 679.980501 370.301553 \n",
       "L 686.129261 370.290677 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_45\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 281.249945 \n",
       "L 83.550749 291.049778 \n",
       "L 89.699509 293.900966 \n",
       "L 95.84827 296.229749 \n",
       "L 101.99703 298.807558 \n",
       "L 108.14579 302.05208 \n",
       "L 114.294551 305.075165 \n",
       "L 120.443311 308.083205 \n",
       "L 126.592071 310.605458 \n",
       "L 132.740832 312.896927 \n",
       "L 138.889592 314.970387 \n",
       "L 145.038352 316.824195 \n",
       "L 151.187113 318.373974 \n",
       "L 157.335873 319.638839 \n",
       "L 163.484633 320.914391 \n",
       "L 169.633394 321.969047 \n",
       "L 175.782154 322.956328 \n",
       "L 181.930914 323.91463 \n",
       "L 188.079675 324.587352 \n",
       "L 194.228435 325.464965 \n",
       "L 200.377195 326.186871 \n",
       "L 206.525956 326.92195 \n",
       "L 212.674716 327.568302 \n",
       "L 218.823476 328.292071 \n",
       "L 224.972237 328.966421 \n",
       "L 231.120997 329.677985 \n",
       "L 237.269757 330.402531 \n",
       "L 243.418518 331.135971 \n",
       "L 249.567278 331.87212 \n",
       "L 255.716038 332.254579 \n",
       "L 261.864799 333.23919 \n",
       "L 268.013559 333.930549 \n",
       "L 274.162319 334.699172 \n",
       "L 280.31108 335.35341 \n",
       "L 286.45984 335.810367 \n",
       "L 292.6086 336.445262 \n",
       "L 298.757361 337.098641 \n",
       "L 304.906121 337.509166 \n",
       "L 311.054881 338.002439 \n",
       "L 317.203642 338.468394 \n",
       "L 323.352402 338.682993 \n",
       "L 329.501162 338.61807 \n",
       "L 335.649923 339.654402 \n",
       "L 341.798683 339.77424 \n",
       "L 347.947443 340.052291 \n",
       "L 354.096204 340.380299 \n",
       "L 360.244964 340.917043 \n",
       "L 366.393724 341.134429 \n",
       "L 372.542485 341.427422 \n",
       "L 378.691245 341.708181 \n",
       "L 384.840005 341.9505 \n",
       "L 390.988765 342.097834 \n",
       "L 397.137526 342.215281 \n",
       "L 403.286286 342.135005 \n",
       "L 409.435046 342.732736 \n",
       "L 415.583807 343.154974 \n",
       "L 421.732567 343.293159 \n",
       "L 427.881327 343.381167 \n",
       "L 434.030088 343.896689 \n",
       "L 440.178848 344.076804 \n",
       "L 446.327608 344.301209 \n",
       "L 452.476369 344.463688 \n",
       "L 458.625129 344.684732 \n",
       "L 464.773889 344.907053 \n",
       "L 470.92265 345.149085 \n",
       "L 477.07141 345.455977 \n",
       "L 483.22017 345.683672 \n",
       "L 489.368931 345.816864 \n",
       "L 495.517691 345.960413 \n",
       "L 501.666451 346.235801 \n",
       "L 507.815212 346.510103 \n",
       "L 513.963972 346.720367 \n",
       "L 520.112732 346.264254 \n",
       "L 526.261493 347.140814 \n",
       "L 532.410253 347.368145 \n",
       "L 538.559013 347.542042 \n",
       "L 544.707774 347.785129 \n",
       "L 550.856534 347.96588 \n",
       "L 557.005294 348.128909 \n",
       "L 563.154055 348.117728 \n",
       "L 569.302815 348.502222 \n",
       "L 575.451575 348.550532 \n",
       "L 581.600336 348.822664 \n",
       "L 587.749096 348.638999 \n",
       "L 593.897856 349.062869 \n",
       "L 600.046617 349.319656 \n",
       "L 606.195377 349.499286 \n",
       "L 612.344137 349.724437 \n",
       "L 618.492898 349.726881 \n",
       "L 624.641658 350.032298 \n",
       "L 630.790418 350.02786 \n",
       "L 636.939179 350.186454 \n",
       "L 643.087939 350.383674 \n",
       "L 649.236699 350.520397 \n",
       "L 655.38546 350.807286 \n",
       "L 661.53422 350.89928 \n",
       "L 667.68298 350.748195 \n",
       "L 673.831741 351.039152 \n",
       "L 679.980501 351.295036 \n",
       "L 686.129261 351.413213 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_46\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.041225 \n",
       "L 83.550749 366.144722 \n",
       "L 89.699509 366.22869 \n",
       "L 95.84827 366.423185 \n",
       "L 101.99703 366.698214 \n",
       "L 108.14579 367.015937 \n",
       "L 114.294551 367.288029 \n",
       "L 120.443311 367.610983 \n",
       "L 126.592071 367.799285 \n",
       "L 132.740832 368.02087 \n",
       "L 138.889592 368.169074 \n",
       "L 145.038352 368.186819 \n",
       "L 151.187113 368.291744 \n",
       "L 157.335873 368.348854 \n",
       "L 163.484633 368.320892 \n",
       "L 169.633394 368.374221 \n",
       "L 175.782154 368.399166 \n",
       "L 181.930914 368.353847 \n",
       "L 188.079675 368.383586 \n",
       "L 194.228435 368.443504 \n",
       "L 200.377195 368.369711 \n",
       "L 206.525956 368.474584 \n",
       "L 212.674716 368.491342 \n",
       "L 218.823476 368.499261 \n",
       "L 224.972237 368.521704 \n",
       "L 231.120997 368.540246 \n",
       "L 237.269757 368.534072 \n",
       "L 243.418518 368.573656 \n",
       "L 249.567278 368.563352 \n",
       "L 255.716038 368.596781 \n",
       "L 261.864799 368.612861 \n",
       "L 268.013559 368.633183 \n",
       "L 274.162319 368.626623 \n",
       "L 280.31108 368.666082 \n",
       "L 286.45984 368.654158 \n",
       "L 292.6086 368.698557 \n",
       "L 298.757361 368.711549 \n",
       "L 304.906121 368.682593 \n",
       "L 311.054881 368.721312 \n",
       "L 317.203642 368.715993 \n",
       "L 323.352402 368.747058 \n",
       "L 329.501162 368.744526 \n",
       "L 335.649923 368.762154 \n",
       "L 341.798683 368.769022 \n",
       "L 347.947443 368.778675 \n",
       "L 354.096204 368.787365 \n",
       "L 360.244964 368.729367 \n",
       "L 366.393724 368.764849 \n",
       "L 372.542485 368.809936 \n",
       "L 378.691245 368.760925 \n",
       "L 384.840005 368.826632 \n",
       "L 390.988765 368.845053 \n",
       "L 397.137526 368.810314 \n",
       "L 403.286286 368.820735 \n",
       "L 409.435046 368.866358 \n",
       "L 415.583807 368.799938 \n",
       "L 421.732567 368.893072 \n",
       "L 427.881327 368.898953 \n",
       "L 434.030088 368.901905 \n",
       "L 440.178848 368.923007 \n",
       "L 446.327608 368.913892 \n",
       "L 452.476369 368.937081 \n",
       "L 458.625129 368.875882 \n",
       "L 464.773889 368.939689 \n",
       "L 470.92265 368.937323 \n",
       "L 477.07141 368.956547 \n",
       "L 483.22017 368.919678 \n",
       "L 489.368931 368.961347 \n",
       "L 495.517691 368.881179 \n",
       "L 501.666451 368.956117 \n",
       "L 507.815212 368.970467 \n",
       "L 513.963972 368.983547 \n",
       "L 520.112732 368.922206 \n",
       "L 526.261493 368.973031 \n",
       "L 532.410253 369.034625 \n",
       "L 538.559013 369.036337 \n",
       "L 544.707774 369.080126 \n",
       "L 550.856534 369.02644 \n",
       "L 557.005294 369.045722 \n",
       "L 563.154055 369.087905 \n",
       "L 569.302815 368.973941 \n",
       "L 575.451575 369.061445 \n",
       "L 581.600336 369.115971 \n",
       "L 587.749096 369.051979 \n",
       "L 593.897856 369.004099 \n",
       "L 600.046617 369.031471 \n",
       "L 606.195377 369.162543 \n",
       "L 612.344137 369.152185 \n",
       "L 618.492898 369.183505 \n",
       "L 624.641658 369.148744 \n",
       "L 630.790418 369.108198 \n",
       "L 636.939179 369.196763 \n",
       "L 643.087939 369.215205 \n",
       "L 649.236699 369.207154 \n",
       "L 655.38546 369.170698 \n",
       "L 661.53422 369.183109 \n",
       "L 667.68298 369.226047 \n",
       "L 673.831741 369.273513 \n",
       "L 679.980501 369.26765 \n",
       "L 686.129261 369.276986 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_47\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 279.766044 \n",
       "L 83.550749 289.995575 \n",
       "L 89.699509 293.083102 \n",
       "L 95.84827 295.290505 \n",
       "L 101.99703 297.73126 \n",
       "L 108.14579 300.758971 \n",
       "L 114.294551 304.183144 \n",
       "L 120.443311 307.587911 \n",
       "L 126.592071 310.434801 \n",
       "L 132.740832 312.980296 \n",
       "L 138.889592 315.186871 \n",
       "L 145.038352 317.080776 \n",
       "L 151.187113 318.649901 \n",
       "L 157.335873 320.131767 \n",
       "L 163.484633 321.368669 \n",
       "L 169.633394 322.461612 \n",
       "L 175.782154 323.444278 \n",
       "L 181.930914 324.285344 \n",
       "L 188.079675 325.154369 \n",
       "L 194.228435 325.861168 \n",
       "L 200.377195 326.721552 \n",
       "L 206.525956 327.452912 \n",
       "L 212.674716 328.165185 \n",
       "L 218.823476 328.766401 \n",
       "L 224.972237 329.593205 \n",
       "L 231.120997 330.372384 \n",
       "L 237.269757 331.109259 \n",
       "L 243.418518 331.907449 \n",
       "L 249.567278 332.57954 \n",
       "L 255.716038 333.338965 \n",
       "L 261.864799 334.027299 \n",
       "L 268.013559 334.756655 \n",
       "L 274.162319 335.417917 \n",
       "L 280.31108 335.92703 \n",
       "L 286.45984 336.151393 \n",
       "L 292.6086 337.198077 \n",
       "L 298.757361 337.701222 \n",
       "L 304.906121 337.981062 \n",
       "L 311.054881 338.631636 \n",
       "L 317.203642 338.959352 \n",
       "L 323.352402 339.373914 \n",
       "L 329.501162 339.723891 \n",
       "L 335.649923 339.676688 \n",
       "L 341.798683 340.182805 \n",
       "L 347.947443 340.608474 \n",
       "L 354.096204 340.147259 \n",
       "L 360.244964 340.288574 \n",
       "L 366.393724 340.792851 \n",
       "L 372.542485 341.403984 \n",
       "L 378.691245 341.778895 \n",
       "L 384.840005 342.148062 \n",
       "L 390.988765 342.34996 \n",
       "L 397.137526 342.602208 \n",
       "L 403.286286 342.87311 \n",
       "L 409.435046 343.011004 \n",
       "L 415.583807 343.255485 \n",
       "L 421.732567 343.278548 \n",
       "L 427.881327 343.340311 \n",
       "L 434.030088 343.938505 \n",
       "L 440.178848 343.83659 \n",
       "L 446.327608 344.429687 \n",
       "L 452.476369 344.721587 \n",
       "L 458.625129 344.734199 \n",
       "L 464.773889 345.073665 \n",
       "L 470.92265 345.344131 \n",
       "L 477.07141 345.546366 \n",
       "L 483.22017 345.180079 \n",
       "L 489.368931 345.930268 \n",
       "L 495.517691 346.179019 \n",
       "L 501.666451 346.338774 \n",
       "L 507.815212 346.295368 \n",
       "L 513.963972 346.765392 \n",
       "L 520.112732 346.960703 \n",
       "L 526.261493 346.634673 \n",
       "L 532.410253 347.376587 \n",
       "L 538.559013 347.082716 \n",
       "L 544.707774 347.782848 \n",
       "L 550.856534 347.851815 \n",
       "L 557.005294 348.085372 \n",
       "L 563.154055 348.157483 \n",
       "L 569.302815 348.156437 \n",
       "L 575.451575 348.215344 \n",
       "L 581.600336 348.662625 \n",
       "L 587.749096 348.811094 \n",
       "L 593.897856 348.655401 \n",
       "L 600.046617 349.214049 \n",
       "L 606.195377 349.401519 \n",
       "L 612.344137 349.605449 \n",
       "L 618.492898 349.644371 \n",
       "L 624.641658 349.838279 \n",
       "L 630.790418 350.000868 \n",
       "L 636.939179 349.890808 \n",
       "L 643.087939 350.38521 \n",
       "L 649.236699 350.471388 \n",
       "L 655.38546 350.645427 \n",
       "L 661.53422 350.712546 \n",
       "L 667.68298 350.896432 \n",
       "L 673.831741 351.017026 \n",
       "L 679.980501 351.052696 \n",
       "L 686.129261 351.245811 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_48\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 365.953793 \n",
       "L 83.550749 366.151968 \n",
       "L 89.699509 366.241571 \n",
       "L 95.84827 366.389615 \n",
       "L 101.99703 366.66391 \n",
       "L 108.14579 366.918458 \n",
       "L 114.294551 367.256239 \n",
       "L 120.443311 367.499743 \n",
       "L 126.592071 367.697046 \n",
       "L 132.740832 367.944014 \n",
       "L 138.889592 368.02654 \n",
       "L 145.038352 368.076166 \n",
       "L 151.187113 368.267567 \n",
       "L 157.335873 368.331391 \n",
       "L 163.484633 368.318876 \n",
       "L 169.633394 368.321027 \n",
       "L 175.782154 368.384699 \n",
       "L 181.930914 368.364544 \n",
       "L 188.079675 368.401352 \n",
       "L 194.228435 368.436962 \n",
       "L 200.377195 368.390935 \n",
       "L 206.525956 368.460167 \n",
       "L 212.674716 368.47887 \n",
       "L 218.823476 368.509157 \n",
       "L 224.972237 368.516762 \n",
       "L 231.120997 368.486263 \n",
       "L 237.269757 368.525849 \n",
       "L 243.418518 368.56598 \n",
       "L 249.567278 368.585496 \n",
       "L 255.716038 368.598871 \n",
       "L 261.864799 368.604016 \n",
       "L 268.013559 368.644835 \n",
       "L 274.162319 368.603156 \n",
       "L 280.31108 368.672782 \n",
       "L 286.45984 368.667629 \n",
       "L 292.6086 368.667455 \n",
       "L 298.757361 368.696437 \n",
       "L 304.906121 368.731237 \n",
       "L 311.054881 368.720902 \n",
       "L 317.203642 368.742535 \n",
       "L 323.352402 368.753048 \n",
       "L 329.501162 368.761613 \n",
       "L 335.649923 368.768053 \n",
       "L 341.798683 368.774071 \n",
       "L 347.947443 368.702099 \n",
       "L 354.096204 368.792973 \n",
       "L 360.244964 368.80513 \n",
       "L 366.393724 368.807039 \n",
       "L 372.542485 368.820759 \n",
       "L 378.691245 368.833312 \n",
       "L 384.840005 368.841691 \n",
       "L 390.988765 368.782052 \n",
       "L 397.137526 368.77598 \n",
       "L 403.286286 368.850718 \n",
       "L 409.435046 368.862717 \n",
       "L 415.583807 368.816483 \n",
       "L 421.732567 368.858536 \n",
       "L 427.881327 368.893633 \n",
       "L 434.030088 368.849242 \n",
       "L 440.178848 368.710905 \n",
       "L 446.327608 368.877059 \n",
       "L 452.476369 368.853191 \n",
       "L 458.625129 368.879672 \n",
       "L 464.773889 368.955581 \n",
       "L 470.92265 368.937147 \n",
       "L 477.07141 368.966007 \n",
       "L 483.22017 368.778067 \n",
       "L 489.368931 368.909167 \n",
       "L 495.517691 368.985362 \n",
       "L 501.666451 368.979118 \n",
       "L 507.815212 368.980107 \n",
       "L 513.963972 368.91075 \n",
       "L 520.112732 369.034614 \n",
       "L 526.261493 368.919434 \n",
       "L 532.410253 369.054733 \n",
       "L 538.559013 369.021924 \n",
       "L 544.707774 369.062332 \n",
       "L 550.856534 369.050683 \n",
       "L 557.005294 369.005939 \n",
       "L 563.154055 368.99036 \n",
       "L 569.302815 369.080018 \n",
       "L 575.451575 369.093157 \n",
       "L 581.600336 369.120284 \n",
       "L 587.749096 369.117461 \n",
       "L 593.897856 369.130681 \n",
       "L 600.046617 369.072161 \n",
       "L 606.195377 369.097581 \n",
       "L 612.344137 369.163259 \n",
       "L 618.492898 369.167496 \n",
       "L 624.641658 369.158819 \n",
       "L 630.790418 369.16961 \n",
       "L 636.939179 369.192176 \n",
       "L 643.087939 369.194966 \n",
       "L 649.236699 369.160817 \n",
       "L 655.38546 369.075564 \n",
       "L 661.53422 369.207131 \n",
       "L 667.68298 369.228484 \n",
       "L 673.831741 369.238757 \n",
       "L 679.980501 369.199458 \n",
       "L 686.129261 369.246636 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_49\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 284.111787 \n",
       "L 83.550749 290.920829 \n",
       "L 89.699509 293.055157 \n",
       "L 95.84827 294.991995 \n",
       "L 101.99703 297.497372 \n",
       "L 108.14579 300.508355 \n",
       "L 114.294551 303.964479 \n",
       "L 120.443311 307.086424 \n",
       "L 126.592071 309.945437 \n",
       "L 132.740832 312.549331 \n",
       "L 138.889592 314.678428 \n",
       "L 145.038352 316.502584 \n",
       "L 151.187113 318.053425 \n",
       "L 157.335873 319.471785 \n",
       "L 163.484633 320.676455 \n",
       "L 169.633394 321.887482 \n",
       "L 175.782154 322.901774 \n",
       "L 181.930914 323.727481 \n",
       "L 188.079675 324.662767 \n",
       "L 194.228435 325.442512 \n",
       "L 200.377195 326.148809 \n",
       "L 206.525956 326.841208 \n",
       "L 212.674716 327.694023 \n",
       "L 218.823476 328.406182 \n",
       "L 224.972237 329.131476 \n",
       "L 231.120997 329.926195 \n",
       "L 237.269757 330.573241 \n",
       "L 243.418518 331.472731 \n",
       "L 249.567278 332.2224 \n",
       "L 255.716038 332.955534 \n",
       "L 261.864799 333.761054 \n",
       "L 268.013559 334.213756 \n",
       "L 274.162319 334.921924 \n",
       "L 280.31108 335.795654 \n",
       "L 286.45984 336.350433 \n",
       "L 292.6086 336.859967 \n",
       "L 298.757361 337.43972 \n",
       "L 304.906121 337.935609 \n",
       "L 311.054881 338.348407 \n",
       "L 317.203642 338.425604 \n",
       "L 323.352402 338.846652 \n",
       "L 329.501162 339.467791 \n",
       "L 335.649923 339.814294 \n",
       "L 341.798683 340.127706 \n",
       "L 347.947443 340.421835 \n",
       "L 354.096204 340.686077 \n",
       "L 360.244964 340.864146 \n",
       "L 366.393724 341.167092 \n",
       "L 372.542485 341.470579 \n",
       "L 378.691245 341.665329 \n",
       "L 384.840005 341.851687 \n",
       "L 390.988765 342.173096 \n",
       "L 397.137526 341.696382 \n",
       "L 403.286286 342.687887 \n",
       "L 409.435046 342.668751 \n",
       "L 415.583807 343.16064 \n",
       "L 421.732567 343.379872 \n",
       "L 427.881327 343.482738 \n",
       "L 434.030088 343.80029 \n",
       "L 440.178848 343.800217 \n",
       "L 446.327608 344.303887 \n",
       "L 452.476369 344.495883 \n",
       "L 458.625129 344.376831 \n",
       "L 464.773889 344.974733 \n",
       "L 470.92265 345.187364 \n",
       "L 477.07141 345.42335 \n",
       "L 483.22017 345.58627 \n",
       "L 489.368931 345.857663 \n",
       "L 495.517691 346.061329 \n",
       "L 501.666451 346.168199 \n",
       "L 507.815212 346.198829 \n",
       "L 513.963972 346.54499 \n",
       "L 520.112732 346.910306 \n",
       "L 526.261493 347.167621 \n",
       "L 532.410253 347.336284 \n",
       "L 538.559013 347.573377 \n",
       "L 544.707774 347.709607 \n",
       "L 550.856534 347.870473 \n",
       "L 557.005294 348.111742 \n",
       "L 563.154055 348.239282 \n",
       "L 569.302815 348.466118 \n",
       "L 575.451575 348.565661 \n",
       "L 581.600336 348.879239 \n",
       "L 587.749096 348.444854 \n",
       "L 593.897856 349.20626 \n",
       "L 600.046617 349.232979 \n",
       "L 606.195377 349.477196 \n",
       "L 612.344137 348.922712 \n",
       "L 618.492898 349.859968 \n",
       "L 624.641658 349.902062 \n",
       "L 630.790418 350.125192 \n",
       "L 636.939179 350.285167 \n",
       "L 643.087939 350.455361 \n",
       "L 649.236699 350.479794 \n",
       "L 655.38546 350.661718 \n",
       "L 661.53422 350.89838 \n",
       "L 667.68298 350.94443 \n",
       "L 673.831741 350.95755 \n",
       "L 679.980501 351.246725 \n",
       "L 686.129261 351.190115 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_50\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.093386 \n",
       "L 83.550749 366.145026 \n",
       "L 89.699509 366.251706 \n",
       "L 95.84827 366.479013 \n",
       "L 101.99703 366.783935 \n",
       "L 108.14579 367.07165 \n",
       "L 114.294551 367.325732 \n",
       "L 120.443311 367.579243 \n",
       "L 126.592071 367.830599 \n",
       "L 132.740832 367.933063 \n",
       "L 138.889592 368.027763 \n",
       "L 145.038352 368.126107 \n",
       "L 151.187113 368.310258 \n",
       "L 157.335873 368.337915 \n",
       "L 163.484633 368.373042 \n",
       "L 169.633394 368.39322 \n",
       "L 175.782154 368.386137 \n",
       "L 181.930914 368.41508 \n",
       "L 188.079675 368.373436 \n",
       "L 194.228435 368.445446 \n",
       "L 200.377195 368.396926 \n",
       "L 206.525956 368.47703 \n",
       "L 212.674716 368.463015 \n",
       "L 218.823476 368.51201 \n",
       "L 224.972237 368.514145 \n",
       "L 231.120997 368.535478 \n",
       "L 237.269757 368.461147 \n",
       "L 243.418518 368.555031 \n",
       "L 249.567278 368.588911 \n",
       "L 255.716038 368.58945 \n",
       "L 261.864799 368.632091 \n",
       "L 268.013559 368.576115 \n",
       "L 274.162319 368.65844 \n",
       "L 280.31108 368.610215 \n",
       "L 286.45984 368.682769 \n",
       "L 292.6086 368.704093 \n",
       "L 298.757361 368.698915 \n",
       "L 304.906121 368.71545 \n",
       "L 311.054881 368.713257 \n",
       "L 317.203642 368.731481 \n",
       "L 323.352402 368.73466 \n",
       "L 329.501162 368.74979 \n",
       "L 335.649923 368.743911 \n",
       "L 341.798683 368.759975 \n",
       "L 347.947443 368.72664 \n",
       "L 354.096204 368.748505 \n",
       "L 360.244964 368.754691 \n",
       "L 366.393724 368.777899 \n",
       "L 372.542485 368.817598 \n",
       "L 378.691245 368.728197 \n",
       "L 384.840005 368.779576 \n",
       "L 390.988765 368.792831 \n",
       "L 397.137526 368.793807 \n",
       "L 403.286286 368.829365 \n",
       "L 409.435046 368.803473 \n",
       "L 415.583807 368.83968 \n",
       "L 421.732567 368.871388 \n",
       "L 427.881327 368.807597 \n",
       "L 434.030088 368.86554 \n",
       "L 440.178848 368.921902 \n",
       "L 446.327608 368.925439 \n",
       "L 452.476369 368.875378 \n",
       "L 458.625129 368.847773 \n",
       "L 464.773889 368.913695 \n",
       "L 470.92265 368.931834 \n",
       "L 477.07141 368.90986 \n",
       "L 483.22017 368.973827 \n",
       "L 489.368931 368.938457 \n",
       "L 495.517691 369.004958 \n",
       "L 501.666451 368.902955 \n",
       "L 507.815212 368.987517 \n",
       "L 513.963972 369.028142 \n",
       "L 520.112732 368.94805 \n",
       "L 526.261493 369.042877 \n",
       "L 532.410253 369.05559 \n",
       "L 538.559013 369.054833 \n",
       "L 544.707774 368.970456 \n",
       "L 550.856534 369.014868 \n",
       "L 557.005294 368.987384 \n",
       "L 563.154055 369.089728 \n",
       "L 569.302815 369.079581 \n",
       "L 575.451575 369.115467 \n",
       "L 581.600336 369.129324 \n",
       "L 587.749096 369.135766 \n",
       "L 593.897856 369.153523 \n",
       "L 600.046617 369.151652 \n",
       "L 606.195377 369.127832 \n",
       "L 612.344137 369.070369 \n",
       "L 618.492898 369.081824 \n",
       "L 624.641658 369.178808 \n",
       "L 630.790418 369.19928 \n",
       "L 636.939179 369.153747 \n",
       "L 643.087939 369.223953 \n",
       "L 649.236699 369.121877 \n",
       "L 655.38546 369.233293 \n",
       "L 661.53422 369.248094 \n",
       "L 667.68298 369.228387 \n",
       "L 673.831741 369.266188 \n",
       "L 679.980501 369.278495 \n",
       "L 686.129261 369.283977 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_51\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 216.678692 \n",
       "L 83.550749 319.947479 \n",
       "L 89.699509 338.655405 \n",
       "L 95.84827 345.411866 \n",
       "L 101.99703 349.057001 \n",
       "L 108.14579 350.239291 \n",
       "L 114.294551 351.850938 \n",
       "L 120.443311 352.890094 \n",
       "L 126.592071 353.608609 \n",
       "L 132.740832 354.000219 \n",
       "L 138.889592 354.483744 \n",
       "L 145.038352 354.883324 \n",
       "L 151.187113 355.273853 \n",
       "L 157.335873 355.775077 \n",
       "L 163.484633 355.911043 \n",
       "L 169.633394 356.189764 \n",
       "L 175.782154 356.582047 \n",
       "L 181.930914 356.865089 \n",
       "L 188.079675 357.027735 \n",
       "L 194.228435 357.307892 \n",
       "L 200.377195 357.386439 \n",
       "L 206.525956 357.603711 \n",
       "L 212.674716 357.67462 \n",
       "L 218.823476 357.72847 \n",
       "L 224.972237 357.936488 \n",
       "L 231.120997 358.028793 \n",
       "L 237.269757 358.257336 \n",
       "L 243.418518 358.199789 \n",
       "L 249.567278 358.395157 \n",
       "L 255.716038 358.339174 \n",
       "L 261.864799 358.614761 \n",
       "L 268.013559 358.68821 \n",
       "L 274.162319 358.737022 \n",
       "L 280.31108 358.878946 \n",
       "L 286.45984 358.656672 \n",
       "L 292.6086 358.879223 \n",
       "L 298.757361 359.122516 \n",
       "L 304.906121 359.08477 \n",
       "L 311.054881 359.091617 \n",
       "L 317.203642 358.996835 \n",
       "L 323.352402 359.137979 \n",
       "L 329.501162 359.224773 \n",
       "L 335.649923 358.994183 \n",
       "L 341.798683 359.188902 \n",
       "L 347.947443 359.365755 \n",
       "L 354.096204 359.384515 \n",
       "L 360.244964 359.463243 \n",
       "L 366.393724 359.493011 \n",
       "L 372.542485 359.222142 \n",
       "L 378.691245 359.533065 \n",
       "L 384.840005 359.118203 \n",
       "L 390.988765 359.316341 \n",
       "L 397.137526 359.645891 \n",
       "L 403.286286 359.643388 \n",
       "L 409.435046 359.579603 \n",
       "L 415.583807 359.572879 \n",
       "L 421.732567 359.648544 \n",
       "L 427.881327 359.387949 \n",
       "L 434.030088 359.692638 \n",
       "L 440.178848 359.73927 \n",
       "L 446.327608 359.606497 \n",
       "L 452.476369 359.859979 \n",
       "L 458.625129 359.691365 \n",
       "L 464.773889 359.858466 \n",
       "L 470.92265 359.675616 \n",
       "L 477.07141 359.933031 \n",
       "L 483.22017 359.88147 \n",
       "L 489.368931 359.810624 \n",
       "L 495.517691 359.820291 \n",
       "L 501.666451 359.826293 \n",
       "L 507.815212 359.913348 \n",
       "L 513.963972 359.944891 \n",
       "L 520.112732 359.79261 \n",
       "L 526.261493 359.901193 \n",
       "L 532.410253 359.946787 \n",
       "L 538.559013 359.796605 \n",
       "L 544.707774 359.976668 \n",
       "L 550.856534 359.966627 \n",
       "L 557.005294 359.872305 \n",
       "L 563.154055 360.050815 \n",
       "L 569.302815 359.948274 \n",
       "L 575.451575 359.869363 \n",
       "L 581.600336 360.155659 \n",
       "L 587.749096 360.123296 \n",
       "L 593.897856 360.042255 \n",
       "L 600.046617 359.8818 \n",
       "L 606.195377 359.892512 \n",
       "L 612.344137 359.901629 \n",
       "L 618.492898 360.020852 \n",
       "L 624.641658 359.739769 \n",
       "L 630.790418 359.856773 \n",
       "L 636.939179 359.606176 \n",
       "L 643.087939 360.070409 \n",
       "L 649.236699 360.209282 \n",
       "L 655.38546 359.894133 \n",
       "L 661.53422 359.940901 \n",
       "L 667.68298 360.1015 \n",
       "L 673.831741 359.828226 \n",
       "L 679.980501 359.983559 \n",
       "L 686.129261 359.638673 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_52\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.832583 \n",
       "L 83.550749 368.155124 \n",
       "L 89.699509 369.110857 \n",
       "L 95.84827 369.348681 \n",
       "L 101.99703 369.47645 \n",
       "L 108.14579 369.51209 \n",
       "L 114.294551 369.73652 \n",
       "L 120.443311 369.687258 \n",
       "L 126.592071 369.753684 \n",
       "L 132.740832 369.823447 \n",
       "L 138.889592 369.769813 \n",
       "L 145.038352 369.801596 \n",
       "L 151.187113 369.824563 \n",
       "L 157.335873 369.866585 \n",
       "L 163.484633 369.855843 \n",
       "L 169.633394 369.89786 \n",
       "L 175.782154 369.956472 \n",
       "L 181.930914 369.998315 \n",
       "L 188.079675 370.005553 \n",
       "L 194.228435 370.0183 \n",
       "L 200.377195 370.026979 \n",
       "L 206.525956 370.031594 \n",
       "L 212.674716 370.060421 \n",
       "L 218.823476 370.074191 \n",
       "L 224.972237 370.082702 \n",
       "L 231.120997 370.111945 \n",
       "L 237.269757 370.10713 \n",
       "L 243.418518 370.122755 \n",
       "L 249.567278 370.103928 \n",
       "L 255.716038 370.095138 \n",
       "L 261.864799 370.144581 \n",
       "L 268.013559 370.138963 \n",
       "L 274.162319 370.111958 \n",
       "L 280.31108 370.156227 \n",
       "L 286.45984 370.13696 \n",
       "L 292.6086 370.165923 \n",
       "L 298.757361 370.17384 \n",
       "L 304.906121 370.184936 \n",
       "L 311.054881 370.179765 \n",
       "L 317.203642 370.155338 \n",
       "L 323.352402 370.140623 \n",
       "L 329.501162 370.208506 \n",
       "L 335.649923 370.192784 \n",
       "L 341.798683 370.185456 \n",
       "L 347.947443 370.179008 \n",
       "L 354.096204 370.173592 \n",
       "L 360.244964 370.19305 \n",
       "L 366.393724 370.19299 \n",
       "L 372.542485 370.200216 \n",
       "L 378.691245 370.186003 \n",
       "L 384.840005 370.215104 \n",
       "L 390.988765 370.221743 \n",
       "L 397.137526 370.230426 \n",
       "L 403.286286 370.206662 \n",
       "L 409.435046 370.210705 \n",
       "L 415.583807 370.214392 \n",
       "L 421.732567 370.16935 \n",
       "L 427.881327 370.172227 \n",
       "L 434.030088 370.222944 \n",
       "L 440.178848 370.225316 \n",
       "L 446.327608 370.221397 \n",
       "L 452.476369 370.18454 \n",
       "L 458.625129 370.214714 \n",
       "L 464.773889 370.1973 \n",
       "L 470.92265 370.202433 \n",
       "L 477.07141 370.201845 \n",
       "L 483.22017 370.214818 \n",
       "L 489.368931 370.232275 \n",
       "L 495.517691 370.230793 \n",
       "L 501.666451 370.245642 \n",
       "L 507.815212 370.209487 \n",
       "L 513.963972 370.217776 \n",
       "L 520.112732 370.225063 \n",
       "L 526.261493 370.233342 \n",
       "L 532.410253 370.192391 \n",
       "L 538.559013 370.210052 \n",
       "L 544.707774 370.21646 \n",
       "L 550.856534 370.223268 \n",
       "L 557.005294 370.218609 \n",
       "L 563.154055 370.240289 \n",
       "L 569.302815 370.192124 \n",
       "L 575.451575 370.208644 \n",
       "L 581.600336 370.208115 \n",
       "L 587.749096 370.207901 \n",
       "L 593.897856 370.20456 \n",
       "L 600.046617 370.21351 \n",
       "L 606.195377 370.198175 \n",
       "L 612.344137 370.226056 \n",
       "L 618.492898 370.189152 \n",
       "L 624.641658 370.198053 \n",
       "L 630.790418 370.176202 \n",
       "L 636.939179 370.200477 \n",
       "L 643.087939 370.195623 \n",
       "L 649.236699 370.231736 \n",
       "L 655.38546 370.192635 \n",
       "L 661.53422 370.225136 \n",
       "L 667.68298 370.205073 \n",
       "L 673.831741 370.229225 \n",
       "L 679.980501 370.209394 \n",
       "L 686.129261 370.196226 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_53\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 248.008318 \n",
       "L 83.550749 325.440641 \n",
       "L 89.699509 339.327488 \n",
       "L 95.84827 345.195158 \n",
       "L 101.99703 347.779605 \n",
       "L 108.14579 349.319929 \n",
       "L 114.294551 350.979012 \n",
       "L 120.443311 351.952692 \n",
       "L 126.592071 352.036216 \n",
       "L 132.740832 353.055791 \n",
       "L 138.889592 353.947327 \n",
       "L 145.038352 354.382275 \n",
       "L 151.187113 354.716955 \n",
       "L 157.335873 354.929762 \n",
       "L 163.484633 355.578039 \n",
       "L 169.633394 355.795288 \n",
       "L 175.782154 355.99862 \n",
       "L 181.930914 355.968909 \n",
       "L 188.079675 356.592388 \n",
       "L 194.228435 356.625609 \n",
       "L 200.377195 356.688942 \n",
       "L 206.525956 357.010664 \n",
       "L 212.674716 357.05522 \n",
       "L 218.823476 357.396397 \n",
       "L 224.972237 357.582425 \n",
       "L 231.120997 357.721527 \n",
       "L 237.269757 357.819484 \n",
       "L 243.418518 357.905556 \n",
       "L 249.567278 358.157767 \n",
       "L 255.716038 358.129763 \n",
       "L 261.864799 358.337294 \n",
       "L 268.013559 358.424029 \n",
       "L 274.162319 358.483948 \n",
       "L 280.31108 358.622845 \n",
       "L 286.45984 358.714043 \n",
       "L 292.6086 358.810745 \n",
       "L 298.757361 358.829891 \n",
       "L 304.906121 359.129356 \n",
       "L 311.054881 358.643252 \n",
       "L 317.203642 359.04221 \n",
       "L 323.352402 359.158006 \n",
       "L 329.501162 359.289805 \n",
       "L 335.649923 359.099093 \n",
       "L 341.798683 359.57008 \n",
       "L 347.947443 359.575528 \n",
       "L 354.096204 359.508873 \n",
       "L 360.244964 359.660274 \n",
       "L 366.393724 359.467962 \n",
       "L 372.542485 359.682208 \n",
       "L 378.691245 359.774412 \n",
       "L 384.840005 359.827365 \n",
       "L 390.988765 359.640198 \n",
       "L 397.137526 360.112733 \n",
       "L 403.286286 359.936402 \n",
       "L 409.435046 359.752855 \n",
       "L 415.583807 359.967374 \n",
       "L 421.732567 359.898752 \n",
       "L 427.881327 360.083917 \n",
       "L 434.030088 360.223546 \n",
       "L 440.178848 359.97558 \n",
       "L 446.327608 360.051633 \n",
       "L 452.476369 360.163952 \n",
       "L 458.625129 360.084568 \n",
       "L 464.773889 359.916277 \n",
       "L 470.92265 360.317189 \n",
       "L 477.07141 360.18753 \n",
       "L 483.22017 360.31766 \n",
       "L 489.368931 360.153412 \n",
       "L 495.517691 360.40601 \n",
       "L 501.666451 360.445275 \n",
       "L 507.815212 360.414331 \n",
       "L 513.963972 360.267408 \n",
       "L 520.112732 360.154714 \n",
       "L 526.261493 360.284759 \n",
       "L 532.410253 360.489597 \n",
       "L 538.559013 360.123722 \n",
       "L 544.707774 360.45263 \n",
       "L 550.856534 360.518348 \n",
       "L 557.005294 360.362715 \n",
       "L 563.154055 360.501616 \n",
       "L 569.302815 360.316097 \n",
       "L 575.451575 360.404829 \n",
       "L 581.600336 360.62074 \n",
       "L 587.749096 360.530654 \n",
       "L 593.897856 360.260926 \n",
       "L 600.046617 360.4634 \n",
       "L 606.195377 360.676407 \n",
       "L 612.344137 360.410144 \n",
       "L 618.492898 360.531083 \n",
       "L 624.641658 360.37808 \n",
       "L 630.790418 360.494184 \n",
       "L 636.939179 359.552828 \n",
       "L 643.087939 360.647772 \n",
       "L 649.236699 360.306808 \n",
       "L 655.38546 360.626392 \n",
       "L 661.53422 360.479411 \n",
       "L 667.68298 360.518575 \n",
       "L 673.831741 360.477447 \n",
       "L 679.980501 360.614979 \n",
       "L 686.129261 360.686026 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_54\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 361.323981 \n",
       "L 83.550749 366.809445 \n",
       "L 89.699509 368.342073 \n",
       "L 95.84827 369.14292 \n",
       "L 101.99703 369.479117 \n",
       "L 108.14579 369.616575 \n",
       "L 114.294551 369.698698 \n",
       "L 120.443311 369.7784 \n",
       "L 126.592071 369.785584 \n",
       "L 132.740832 369.803258 \n",
       "L 138.889592 369.890349 \n",
       "L 145.038352 369.851935 \n",
       "L 151.187113 369.833017 \n",
       "L 157.335873 369.938944 \n",
       "L 163.484633 369.946022 \n",
       "L 169.633394 369.963141 \n",
       "L 175.782154 369.950471 \n",
       "L 181.930914 369.955175 \n",
       "L 188.079675 370.001526 \n",
       "L 194.228435 369.972901 \n",
       "L 200.377195 370.015554 \n",
       "L 206.525956 369.998671 \n",
       "L 212.674716 370.0358 \n",
       "L 218.823476 370.062832 \n",
       "L 224.972237 370.061961 \n",
       "L 231.120997 370.037838 \n",
       "L 237.269757 370.111633 \n",
       "L 243.418518 370.137216 \n",
       "L 249.567278 370.11356 \n",
       "L 255.716038 370.133317 \n",
       "L 261.864799 370.12367 \n",
       "L 268.013559 370.140648 \n",
       "L 274.162319 370.16202 \n",
       "L 280.31108 370.132873 \n",
       "L 286.45984 370.131067 \n",
       "L 292.6086 370.122437 \n",
       "L 298.757361 370.197775 \n",
       "L 304.906121 370.136245 \n",
       "L 311.054881 370.20181 \n",
       "L 317.203642 370.192227 \n",
       "L 323.352402 370.139844 \n",
       "L 329.501162 370.212436 \n",
       "L 335.649923 370.184008 \n",
       "L 341.798683 370.226516 \n",
       "L 347.947443 370.202163 \n",
       "L 354.096204 370.204192 \n",
       "L 360.244964 370.207793 \n",
       "L 366.393724 370.249126 \n",
       "L 372.542485 370.222616 \n",
       "L 378.691245 370.264488 \n",
       "L 384.840005 370.265263 \n",
       "L 390.988765 370.256784 \n",
       "L 397.137526 370.25456 \n",
       "L 403.286286 370.253391 \n",
       "L 409.435046 370.20835 \n",
       "L 415.583807 370.216463 \n",
       "L 421.732567 370.268169 \n",
       "L 427.881327 370.247552 \n",
       "L 434.030088 370.230119 \n",
       "L 440.178848 370.252511 \n",
       "L 446.327608 370.243389 \n",
       "L 452.476369 370.257213 \n",
       "L 458.625129 370.246882 \n",
       "L 464.773889 370.253277 \n",
       "L 470.92265 370.275268 \n",
       "L 477.07141 370.242222 \n",
       "L 483.22017 370.188826 \n",
       "L 489.368931 370.230508 \n",
       "L 495.517691 370.260118 \n",
       "L 501.666451 370.259554 \n",
       "L 507.815212 370.282156 \n",
       "L 513.963972 370.262415 \n",
       "L 520.112732 370.247128 \n",
       "L 526.261493 370.267926 \n",
       "L 532.410253 370.257896 \n",
       "L 538.559013 370.28602 \n",
       "L 544.707774 370.272247 \n",
       "L 550.856534 370.267784 \n",
       "L 557.005294 370.224796 \n",
       "L 563.154055 370.248171 \n",
       "L 569.302815 370.287899 \n",
       "L 575.451575 370.295648 \n",
       "L 581.600336 370.28303 \n",
       "L 587.749096 370.275996 \n",
       "L 593.897856 370.289787 \n",
       "L 600.046617 370.279299 \n",
       "L 606.195377 370.319571 \n",
       "L 612.344137 370.298095 \n",
       "L 618.492898 370.239256 \n",
       "L 624.641658 370.266396 \n",
       "L 630.790418 370.250706 \n",
       "L 636.939179 370.272022 \n",
       "L 643.087939 370.276202 \n",
       "L 649.236699 370.285983 \n",
       "L 655.38546 370.265657 \n",
       "L 661.53422 370.286781 \n",
       "L 667.68298 370.28439 \n",
       "L 673.831741 370.239927 \n",
       "L 679.980501 370.258824 \n",
       "L 686.129261 370.21837 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_55\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 223.493542 \n",
       "L 83.550749 319.130574 \n",
       "L 89.699509 336.716884 \n",
       "L 95.84827 343.606984 \n",
       "L 101.99703 347.177153 \n",
       "L 108.14579 349.59951 \n",
       "L 114.294551 351.539659 \n",
       "L 120.443311 352.506863 \n",
       "L 126.592071 353.437663 \n",
       "L 132.740832 353.90683 \n",
       "L 138.889592 354.588159 \n",
       "L 145.038352 355.159247 \n",
       "L 151.187113 355.714087 \n",
       "L 157.335873 356.00481 \n",
       "L 163.484633 356.202573 \n",
       "L 169.633394 356.435321 \n",
       "L 175.782154 356.837411 \n",
       "L 181.930914 357.024637 \n",
       "L 188.079675 357.23097 \n",
       "L 194.228435 357.418473 \n",
       "L 200.377195 357.668116 \n",
       "L 206.525956 357.722911 \n",
       "L 212.674716 357.951773 \n",
       "L 218.823476 357.834009 \n",
       "L 224.972237 358.210311 \n",
       "L 231.120997 358.248105 \n",
       "L 237.269757 358.303942 \n",
       "L 243.418518 358.377633 \n",
       "L 249.567278 358.491196 \n",
       "L 255.716038 358.507168 \n",
       "L 261.864799 358.575143 \n",
       "L 268.013559 358.853616 \n",
       "L 274.162319 358.90182 \n",
       "L 280.31108 358.838726 \n",
       "L 286.45984 358.795564 \n",
       "L 292.6086 358.942829 \n",
       "L 298.757361 359.202467 \n",
       "L 304.906121 359.300808 \n",
       "L 311.054881 359.29584 \n",
       "L 317.203642 359.277648 \n",
       "L 323.352402 359.359832 \n",
       "L 329.501162 359.36793 \n",
       "L 335.649923 359.473618 \n",
       "L 341.798683 359.498895 \n",
       "L 347.947443 359.564671 \n",
       "L 354.096204 359.66979 \n",
       "L 360.244964 359.639828 \n",
       "L 366.393724 359.68958 \n",
       "L 372.542485 359.760027 \n",
       "L 378.691245 359.835512 \n",
       "L 384.840005 359.748288 \n",
       "L 390.988765 359.85044 \n",
       "L 397.137526 359.828474 \n",
       "L 403.286286 359.633271 \n",
       "L 409.435046 360.000736 \n",
       "L 415.583807 359.953044 \n",
       "L 421.732567 360.067411 \n",
       "L 427.881327 360.084599 \n",
       "L 434.030088 359.962738 \n",
       "L 440.178848 360.007601 \n",
       "L 446.327608 360.019132 \n",
       "L 452.476369 360.105206 \n",
       "L 458.625129 359.988306 \n",
       "L 464.773889 360.043868 \n",
       "L 470.92265 359.927533 \n",
       "L 477.07141 360.200234 \n",
       "L 483.22017 360.047491 \n",
       "L 489.368931 360.187478 \n",
       "L 495.517691 360.25705 \n",
       "L 501.666451 360.000133 \n",
       "L 507.815212 360.288581 \n",
       "L 513.963972 360.185502 \n",
       "L 520.112732 360.212479 \n",
       "L 526.261493 360.360574 \n",
       "L 532.410253 360.355025 \n",
       "L 538.559013 360.368814 \n",
       "L 544.707774 360.296711 \n",
       "L 550.856534 360.286042 \n",
       "L 557.005294 360.33682 \n",
       "L 563.154055 360.17706 \n",
       "L 569.302815 360.43545 \n",
       "L 575.451575 360.359558 \n",
       "L 581.600336 360.421466 \n",
       "L 587.749096 360.475297 \n",
       "L 593.897856 360.302553 \n",
       "L 600.046617 360.370269 \n",
       "L 606.195377 360.346421 \n",
       "L 612.344137 360.5419 \n",
       "L 618.492898 360.486671 \n",
       "L 624.641658 360.545421 \n",
       "L 630.790418 360.499421 \n",
       "L 636.939179 360.469051 \n",
       "L 643.087939 360.221542 \n",
       "L 649.236699 360.240534 \n",
       "L 655.38546 360.27935 \n",
       "L 661.53422 360.556086 \n",
       "L 667.68298 360.29216 \n",
       "L 673.831741 360.421326 \n",
       "L 679.980501 360.48303 \n",
       "L 686.129261 360.275131 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_56\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.01308 \n",
       "L 83.550749 366.506709 \n",
       "L 89.699509 368.36153 \n",
       "L 95.84827 369.086473 \n",
       "L 101.99703 369.455081 \n",
       "L 108.14579 369.592339 \n",
       "L 114.294551 369.68904 \n",
       "L 120.443311 369.792465 \n",
       "L 126.592071 369.855939 \n",
       "L 132.740832 369.918465 \n",
       "L 138.889592 369.948641 \n",
       "L 145.038352 369.955319 \n",
       "L 151.187113 369.98149 \n",
       "L 157.335873 369.985175 \n",
       "L 163.484633 370.007541 \n",
       "L 169.633394 370.04832 \n",
       "L 175.782154 369.996053 \n",
       "L 181.930914 370.030949 \n",
       "L 188.079675 370.069117 \n",
       "L 194.228435 370.101079 \n",
       "L 200.377195 370.089273 \n",
       "L 206.525956 370.135425 \n",
       "L 212.674716 370.137159 \n",
       "L 218.823476 370.149301 \n",
       "L 224.972237 370.147455 \n",
       "L 231.120997 370.138506 \n",
       "L 237.269757 370.173402 \n",
       "L 243.418518 370.170819 \n",
       "L 249.567278 370.180971 \n",
       "L 255.716038 370.174208 \n",
       "L 261.864799 370.190339 \n",
       "L 268.013559 370.191151 \n",
       "L 274.162319 370.213795 \n",
       "L 280.31108 370.224266 \n",
       "L 286.45984 370.238043 \n",
       "L 292.6086 370.218106 \n",
       "L 298.757361 370.235935 \n",
       "L 304.906121 370.229253 \n",
       "L 311.054881 370.153736 \n",
       "L 317.203642 370.25035 \n",
       "L 323.352402 370.240552 \n",
       "L 329.501162 370.264404 \n",
       "L 335.649923 370.297013 \n",
       "L 341.798683 370.312503 \n",
       "L 347.947443 370.257691 \n",
       "L 354.096204 370.301648 \n",
       "L 360.244964 370.295186 \n",
       "L 366.393724 370.310913 \n",
       "L 372.542485 370.304327 \n",
       "L 378.691245 370.312333 \n",
       "L 384.840005 370.286713 \n",
       "L 390.988765 370.327957 \n",
       "L 397.137526 370.336374 \n",
       "L 403.286286 370.329965 \n",
       "L 409.435046 370.306768 \n",
       "L 415.583807 370.355445 \n",
       "L 421.732567 370.313032 \n",
       "L 427.881327 370.346527 \n",
       "L 434.030088 370.342655 \n",
       "L 440.178848 370.357651 \n",
       "L 446.327608 370.360276 \n",
       "L 452.476369 370.351842 \n",
       "L 458.625129 370.338403 \n",
       "L 464.773889 370.337958 \n",
       "L 470.92265 370.346607 \n",
       "L 477.07141 370.37415 \n",
       "L 483.22017 370.364104 \n",
       "L 489.368931 370.37854 \n",
       "L 495.517691 370.378859 \n",
       "L 501.666451 370.357933 \n",
       "L 507.815212 370.372199 \n",
       "L 513.963972 370.391269 \n",
       "L 520.112732 370.395746 \n",
       "L 526.261493 370.41007 \n",
       "L 532.410253 370.396314 \n",
       "L 538.559013 370.389275 \n",
       "L 544.707774 370.364694 \n",
       "L 550.856534 370.365051 \n",
       "L 557.005294 370.359106 \n",
       "L 563.154055 370.368136 \n",
       "L 569.302815 370.381836 \n",
       "L 575.451575 370.387792 \n",
       "L 581.600336 370.387462 \n",
       "L 587.749096 370.384832 \n",
       "L 593.897856 370.393791 \n",
       "L 600.046617 370.389853 \n",
       "L 606.195377 370.370231 \n",
       "L 612.344137 370.341365 \n",
       "L 618.492898 370.393668 \n",
       "L 624.641658 370.364382 \n",
       "L 630.790418 370.370058 \n",
       "L 636.939179 370.36878 \n",
       "L 643.087939 370.382253 \n",
       "L 649.236699 370.391288 \n",
       "L 655.38546 370.418618 \n",
       "L 661.53422 370.389505 \n",
       "L 667.68298 370.365919 \n",
       "L 673.831741 370.400124 \n",
       "L 679.980501 370.391063 \n",
       "L 686.129261 370.394796 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_57\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 101.361381 \n",
       "L 83.550749 156.050518 \n",
       "L 89.699509 182.049116 \n",
       "L 95.84827 199.939035 \n",
       "L 101.99703 213.769119 \n",
       "L 108.14579 224.959446 \n",
       "L 114.294551 234.14391 \n",
       "L 120.443311 241.805353 \n",
       "L 126.592071 248.117176 \n",
       "L 132.740832 253.591836 \n",
       "L 138.889592 258.279891 \n",
       "L 145.038352 262.129242 \n",
       "L 151.187113 265.761419 \n",
       "L 157.335873 268.879065 \n",
       "L 163.484633 271.488525 \n",
       "L 169.633394 273.916039 \n",
       "L 175.782154 275.900728 \n",
       "L 181.930914 277.701532 \n",
       "L 188.079675 279.407525 \n",
       "L 194.228435 280.681684 \n",
       "L 200.377195 281.826023 \n",
       "L 206.525956 282.845882 \n",
       "L 212.674716 283.744944 \n",
       "L 218.823476 284.528413 \n",
       "L 224.972237 285.258179 \n",
       "L 231.120997 285.919277 \n",
       "L 237.269757 286.444198 \n",
       "L 243.418518 286.937945 \n",
       "L 249.567278 287.340117 \n",
       "L 255.716038 287.738547 \n",
       "L 261.864799 288.12633 \n",
       "L 268.013559 288.419187 \n",
       "L 274.162319 288.746518 \n",
       "L 280.31108 289.029504 \n",
       "L 286.45984 289.271232 \n",
       "L 292.6086 289.530763 \n",
       "L 298.757361 289.817634 \n",
       "L 304.906121 290.112166 \n",
       "L 311.054881 290.387355 \n",
       "L 317.203642 290.755303 \n",
       "L 323.352402 291.161737 \n",
       "L 329.501162 291.655157 \n",
       "L 335.649923 292.243002 \n",
       "L 341.798683 292.969562 \n",
       "L 347.947443 293.790875 \n",
       "L 354.096204 294.545059 \n",
       "L 360.244964 295.410773 \n",
       "L 366.393724 296.287029 \n",
       "L 372.542485 297.140664 \n",
       "L 378.691245 297.965633 \n",
       "L 384.840005 298.815875 \n",
       "L 390.988765 299.712999 \n",
       "L 397.137526 300.60812 \n",
       "L 403.286286 301.557691 \n",
       "L 409.435046 302.542043 \n",
       "L 415.583807 303.477938 \n",
       "L 421.732567 304.528649 \n",
       "L 427.881327 305.626584 \n",
       "L 434.030088 306.656677 \n",
       "L 440.178848 307.734265 \n",
       "L 446.327608 308.848286 \n",
       "L 452.476369 309.888378 \n",
       "L 458.625129 310.923282 \n",
       "L 464.773889 311.920105 \n",
       "L 470.92265 312.941678 \n",
       "L 477.07141 313.890683 \n",
       "L 483.22017 314.742953 \n",
       "L 489.368931 315.614366 \n",
       "L 495.517691 316.394656 \n",
       "L 501.666451 317.15319 \n",
       "L 507.815212 317.860186 \n",
       "L 513.963972 318.552322 \n",
       "L 520.112732 319.260921 \n",
       "L 526.261493 319.85935 \n",
       "L 532.410253 320.467037 \n",
       "L 538.559013 321.046003 \n",
       "L 544.707774 321.657674 \n",
       "L 550.856534 322.167161 \n",
       "L 557.005294 322.721806 \n",
       "L 563.154055 323.230755 \n",
       "L 569.302815 323.714286 \n",
       "L 575.451575 324.190543 \n",
       "L 581.600336 324.747051 \n",
       "L 587.749096 325.17884 \n",
       "L 593.897856 325.602407 \n",
       "L 600.046617 326.091415 \n",
       "L 606.195377 326.548518 \n",
       "L 612.344137 326.944675 \n",
       "L 618.492898 327.433864 \n",
       "L 624.641658 327.750148 \n",
       "L 630.790418 328.19437 \n",
       "L 636.939179 328.558562 \n",
       "L 643.087939 328.922433 \n",
       "L 649.236699 329.276219 \n",
       "L 655.38546 329.648244 \n",
       "L 661.53422 330.075863 \n",
       "L 667.68298 330.457545 \n",
       "L 673.831741 330.793431 \n",
       "L 679.980501 331.087757 \n",
       "L 686.129261 331.389498 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_58\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.956134 \n",
       "L 83.550749 361.111196 \n",
       "L 89.699509 362.211545 \n",
       "L 95.84827 362.970222 \n",
       "L 101.99703 363.565604 \n",
       "L 108.14579 364.039312 \n",
       "L 114.294551 364.394806 \n",
       "L 120.443311 364.681908 \n",
       "L 126.592071 364.898371 \n",
       "L 132.740832 365.090631 \n",
       "L 138.889592 365.251232 \n",
       "L 145.038352 365.393039 \n",
       "L 151.187113 365.515282 \n",
       "L 157.335873 365.613242 \n",
       "L 163.484633 365.702528 \n",
       "L 169.633394 365.788335 \n",
       "L 175.782154 365.857866 \n",
       "L 181.930914 365.913845 \n",
       "L 188.079675 365.970617 \n",
       "L 194.228435 366.007772 \n",
       "L 200.377195 366.028747 \n",
       "L 206.525956 366.043657 \n",
       "L 212.674716 366.053464 \n",
       "L 218.823476 366.063063 \n",
       "L 224.972237 366.071456 \n",
       "L 231.120997 366.074489 \n",
       "L 237.269757 366.07731 \n",
       "L 243.418518 366.079939 \n",
       "L 249.567278 366.08189 \n",
       "L 255.716038 366.08199 \n",
       "L 261.864799 366.084474 \n",
       "L 268.013559 366.089267 \n",
       "L 274.162319 366.09786 \n",
       "L 280.31108 366.105691 \n",
       "L 286.45984 366.119639 \n",
       "L 292.6086 366.140899 \n",
       "L 298.757361 366.171918 \n",
       "L 304.906121 366.231939 \n",
       "L 311.054881 366.311609 \n",
       "L 317.203642 366.382261 \n",
       "L 323.352402 366.465906 \n",
       "L 329.501162 366.547677 \n",
       "L 335.649923 366.628442 \n",
       "L 341.798683 366.711304 \n",
       "L 347.947443 366.817359 \n",
       "L 354.096204 366.871393 \n",
       "L 360.244964 366.989147 \n",
       "L 366.393724 367.103155 \n",
       "L 372.542485 367.19467 \n",
       "L 378.691245 367.310212 \n",
       "L 384.840005 367.385199 \n",
       "L 390.988765 367.505933 \n",
       "L 397.137526 367.572687 \n",
       "L 403.286286 367.659807 \n",
       "L 409.435046 367.73679 \n",
       "L 415.583807 367.824583 \n",
       "L 421.732567 367.89172 \n",
       "L 427.881327 367.917509 \n",
       "L 434.030088 367.961976 \n",
       "L 440.178848 368.011953 \n",
       "L 446.327608 368.045415 \n",
       "L 452.476369 368.06949 \n",
       "L 458.625129 368.090399 \n",
       "L 464.773889 368.117836 \n",
       "L 470.92265 368.135586 \n",
       "L 477.07141 368.162715 \n",
       "L 483.22017 368.176814 \n",
       "L 489.368931 368.197213 \n",
       "L 495.517691 368.220524 \n",
       "L 501.666451 368.235498 \n",
       "L 507.815212 368.253479 \n",
       "L 513.963972 368.288906 \n",
       "L 520.112732 368.281631 \n",
       "L 526.261493 368.31201 \n",
       "L 532.410253 368.329763 \n",
       "L 538.559013 368.340162 \n",
       "L 544.707774 368.357642 \n",
       "L 550.856534 368.360765 \n",
       "L 557.005294 368.379215 \n",
       "L 563.154055 368.391266 \n",
       "L 569.302815 368.402561 \n",
       "L 575.451575 368.412921 \n",
       "L 581.600336 368.409784 \n",
       "L 587.749096 368.435448 \n",
       "L 593.897856 368.438054 \n",
       "L 600.046617 368.458119 \n",
       "L 606.195377 368.467273 \n",
       "L 612.344137 368.471075 \n",
       "L 618.492898 368.488182 \n",
       "L 624.641658 368.48879 \n",
       "L 630.790418 368.514426 \n",
       "L 636.939179 368.5096 \n",
       "L 643.087939 368.528547 \n",
       "L 649.236699 368.513796 \n",
       "L 655.38546 368.548958 \n",
       "L 661.53422 368.554081 \n",
       "L 667.68298 368.569381 \n",
       "L 673.831741 368.570006 \n",
       "L 679.980501 368.579658 \n",
       "L 686.129261 368.591216 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_59\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 46.901278 \n",
       "L 83.550749 107.669213 \n",
       "L 89.699509 136.694353 \n",
       "L 95.84827 157.593879 \n",
       "L 101.99703 174.399262 \n",
       "L 108.14579 187.837244 \n",
       "L 114.294551 199.217636 \n",
       "L 120.443311 208.649208 \n",
       "L 126.592071 217.378525 \n",
       "L 132.740832 224.637005 \n",
       "L 138.889592 231.196735 \n",
       "L 145.038352 237.061892 \n",
       "L 151.187113 242.336531 \n",
       "L 157.335873 247.076828 \n",
       "L 163.484633 251.206407 \n",
       "L 169.633394 254.924472 \n",
       "L 175.782154 258.253621 \n",
       "L 181.930914 261.354412 \n",
       "L 188.079675 263.987541 \n",
       "L 194.228435 266.48852 \n",
       "L 200.377195 268.735327 \n",
       "L 206.525956 270.779228 \n",
       "L 212.674716 272.631055 \n",
       "L 218.823476 274.226814 \n",
       "L 224.972237 275.803594 \n",
       "L 231.120997 277.188592 \n",
       "L 237.269757 278.463705 \n",
       "L 243.418518 279.634279 \n",
       "L 249.567278 280.643683 \n",
       "L 255.716038 281.600823 \n",
       "L 261.864799 282.464514 \n",
       "L 268.013559 283.196076 \n",
       "L 274.162319 283.977193 \n",
       "L 280.31108 284.576677 \n",
       "L 286.45984 285.145251 \n",
       "L 292.6086 285.645235 \n",
       "L 298.757361 286.069208 \n",
       "L 304.906121 286.549813 \n",
       "L 311.054881 286.908261 \n",
       "L 317.203642 287.288945 \n",
       "L 323.352402 287.608151 \n",
       "L 329.501162 287.886483 \n",
       "L 335.649923 288.14362 \n",
       "L 341.798683 288.442827 \n",
       "L 347.947443 288.712401 \n",
       "L 354.096204 288.964648 \n",
       "L 360.244964 289.181688 \n",
       "L 366.393724 289.45764 \n",
       "L 372.542485 289.750112 \n",
       "L 378.691245 290.076182 \n",
       "L 384.840005 290.445733 \n",
       "L 390.988765 290.916004 \n",
       "L 397.137526 291.488013 \n",
       "L 403.286286 292.26417 \n",
       "L 409.435046 293.058393 \n",
       "L 415.583807 293.887133 \n",
       "L 421.732567 294.775775 \n",
       "L 427.881327 295.763313 \n",
       "L 434.030088 296.6477 \n",
       "L 440.178848 297.686923 \n",
       "L 446.327608 298.6885 \n",
       "L 452.476369 299.765625 \n",
       "L 458.625129 300.799545 \n",
       "L 464.773889 301.863833 \n",
       "L 470.92265 302.94976 \n",
       "L 477.07141 304.076239 \n",
       "L 483.22017 305.19919 \n",
       "L 489.368931 306.378174 \n",
       "L 495.517691 307.454407 \n",
       "L 501.666451 308.556205 \n",
       "L 507.815212 309.756528 \n",
       "L 513.963972 310.760671 \n",
       "L 520.112732 311.790436 \n",
       "L 526.261493 312.748924 \n",
       "L 532.410253 313.715896 \n",
       "L 538.559013 314.581554 \n",
       "L 544.707774 315.447643 \n",
       "L 550.856534 316.231963 \n",
       "L 557.005294 316.943684 \n",
       "L 563.154055 317.683485 \n",
       "L 569.302815 318.309838 \n",
       "L 575.451575 318.96171 \n",
       "L 581.600336 319.590935 \n",
       "L 587.749096 320.164202 \n",
       "L 593.897856 320.742505 \n",
       "L 600.046617 321.295545 \n",
       "L 606.195377 321.837062 \n",
       "L 612.344137 322.339885 \n",
       "L 618.492898 322.814015 \n",
       "L 624.641658 323.311483 \n",
       "L 630.790418 323.776922 \n",
       "L 636.939179 324.170032 \n",
       "L 643.087939 324.60348 \n",
       "L 649.236699 325.090432 \n",
       "L 655.38546 325.444593 \n",
       "L 661.53422 325.891298 \n",
       "L 667.68298 326.254841 \n",
       "L 673.831741 326.727713 \n",
       "L 679.980501 327.08305 \n",
       "L 686.129261 327.396572 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_60\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.114295 \n",
       "L 83.550749 360.28671 \n",
       "L 89.699509 361.361792 \n",
       "L 95.84827 362.156515 \n",
       "L 101.99703 362.782787 \n",
       "L 108.14579 363.315554 \n",
       "L 114.294551 363.767417 \n",
       "L 120.443311 364.123726 \n",
       "L 126.592071 364.422446 \n",
       "L 132.740832 364.667521 \n",
       "L 138.889592 364.870306 \n",
       "L 145.038352 365.041895 \n",
       "L 151.187113 365.19646 \n",
       "L 157.335873 365.328337 \n",
       "L 163.484633 365.455974 \n",
       "L 169.633394 365.555397 \n",
       "L 175.782154 365.651883 \n",
       "L 181.930914 365.736233 \n",
       "L 188.079675 365.810985 \n",
       "L 194.228435 365.873058 \n",
       "L 200.377195 365.927626 \n",
       "L 206.525956 365.968963 \n",
       "L 212.674716 366.009623 \n",
       "L 218.823476 366.028603 \n",
       "L 224.972237 366.039368 \n",
       "L 231.120997 366.049373 \n",
       "L 237.269757 366.059352 \n",
       "L 243.418518 366.066673 \n",
       "L 249.567278 366.069629 \n",
       "L 255.716038 366.071817 \n",
       "L 261.864799 366.073186 \n",
       "L 268.013559 366.074227 \n",
       "L 274.162319 366.075181 \n",
       "L 280.31108 366.073551 \n",
       "L 286.45984 366.07553 \n",
       "L 292.6086 366.077464 \n",
       "L 298.757361 366.082926 \n",
       "L 304.906121 366.087236 \n",
       "L 311.054881 366.095801 \n",
       "L 317.203642 366.110901 \n",
       "L 323.352402 366.127919 \n",
       "L 329.501162 366.165878 \n",
       "L 335.649923 366.22845 \n",
       "L 341.798683 366.309748 \n",
       "L 347.947443 366.373179 \n",
       "L 354.096204 366.439219 \n",
       "L 360.244964 366.486986 \n",
       "L 366.393724 366.562767 \n",
       "L 372.542485 366.605537 \n",
       "L 378.691245 366.673561 \n",
       "L 384.840005 366.715054 \n",
       "L 390.988765 366.760858 \n",
       "L 397.137526 366.866471 \n",
       "L 403.286286 366.922781 \n",
       "L 409.435046 367.002022 \n",
       "L 415.583807 367.125103 \n",
       "L 421.732567 367.174793 \n",
       "L 427.881327 367.280713 \n",
       "L 434.030088 367.401752 \n",
       "L 440.178848 367.494513 \n",
       "L 446.327608 367.591617 \n",
       "L 452.476369 367.677508 \n",
       "L 458.625129 367.743887 \n",
       "L 464.773889 367.804417 \n",
       "L 470.92265 367.877149 \n",
       "L 477.07141 367.927155 \n",
       "L 483.22017 367.971749 \n",
       "L 489.368931 368.006457 \n",
       "L 495.517691 368.059921 \n",
       "L 501.666451 368.088565 \n",
       "L 507.815212 368.12153 \n",
       "L 513.963972 368.124681 \n",
       "L 520.112732 368.142425 \n",
       "L 526.261493 368.184698 \n",
       "L 532.410253 368.209943 \n",
       "L 538.559013 368.225975 \n",
       "L 544.707774 368.25616 \n",
       "L 550.856534 368.26695 \n",
       "L 557.005294 368.283491 \n",
       "L 563.154055 368.291761 \n",
       "L 569.302815 368.318045 \n",
       "L 575.451575 368.324193 \n",
       "L 581.600336 368.327166 \n",
       "L 587.749096 368.346452 \n",
       "L 593.897856 368.354354 \n",
       "L 600.046617 368.373323 \n",
       "L 606.195377 368.379992 \n",
       "L 612.344137 368.380917 \n",
       "L 618.492898 368.395784 \n",
       "L 624.641658 368.408019 \n",
       "L 630.790418 368.411173 \n",
       "L 636.939179 368.415876 \n",
       "L 643.087939 368.437865 \n",
       "L 649.236699 368.438561 \n",
       "L 655.38546 368.453248 \n",
       "L 661.53422 368.46754 \n",
       "L 667.68298 368.478279 \n",
       "L 673.831741 368.483226 \n",
       "L 679.980501 368.493015 \n",
       "L 686.129261 368.513107 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_61\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 97.83033 \n",
       "L 83.550749 151.125532 \n",
       "L 89.699509 177.242695 \n",
       "L 95.84827 195.334039 \n",
       "L 101.99703 208.589312 \n",
       "L 108.14579 219.753982 \n",
       "L 114.294551 228.808449 \n",
       "L 120.443311 236.787501 \n",
       "L 126.592071 243.356668 \n",
       "L 132.740832 249.374387 \n",
       "L 138.889592 254.325187 \n",
       "L 145.038352 258.511641 \n",
       "L 151.187113 262.313933 \n",
       "L 157.335873 265.520781 \n",
       "L 163.484633 268.497156 \n",
       "L 169.633394 270.924655 \n",
       "L 175.782154 273.123426 \n",
       "L 181.930914 275.030616 \n",
       "L 188.079675 276.813738 \n",
       "L 194.228435 278.308086 \n",
       "L 200.377195 279.792977 \n",
       "L 206.525956 280.907162 \n",
       "L 212.674716 281.927862 \n",
       "L 218.823476 282.900311 \n",
       "L 224.972237 283.666846 \n",
       "L 231.120997 284.487746 \n",
       "L 237.269757 285.130691 \n",
       "L 243.418518 285.731201 \n",
       "L 249.567278 286.252031 \n",
       "L 255.716038 286.687814 \n",
       "L 261.864799 287.132292 \n",
       "L 268.013559 287.501851 \n",
       "L 274.162319 287.759237 \n",
       "L 280.31108 288.116694 \n",
       "L 286.45984 288.373289 \n",
       "L 292.6086 288.617589 \n",
       "L 298.757361 288.904802 \n",
       "L 304.906121 289.156836 \n",
       "L 311.054881 289.358068 \n",
       "L 317.203642 289.620215 \n",
       "L 323.352402 289.858636 \n",
       "L 329.501162 290.133276 \n",
       "L 335.649923 290.447379 \n",
       "L 341.798683 290.785935 \n",
       "L 347.947443 291.222032 \n",
       "L 354.096204 291.792595 \n",
       "L 360.244964 292.500951 \n",
       "L 366.393724 293.338443 \n",
       "L 372.542485 294.158887 \n",
       "L 378.691245 295.028101 \n",
       "L 384.840005 295.922752 \n",
       "L 390.988765 296.843102 \n",
       "L 397.137526 297.675014 \n",
       "L 403.286286 298.592342 \n",
       "L 409.435046 299.556061 \n",
       "L 415.583807 300.54429 \n",
       "L 421.732567 301.626973 \n",
       "L 427.881327 302.713669 \n",
       "L 434.030088 303.929322 \n",
       "L 440.178848 305.115247 \n",
       "L 446.327608 306.353258 \n",
       "L 452.476369 307.630958 \n",
       "L 458.625129 308.914988 \n",
       "L 464.773889 310.121482 \n",
       "L 470.92265 311.348125 \n",
       "L 477.07141 312.349296 \n",
       "L 483.22017 313.425725 \n",
       "L 489.368931 314.365626 \n",
       "L 495.517691 315.244144 \n",
       "L 501.666451 316.106042 \n",
       "L 507.815212 316.896888 \n",
       "L 513.963972 317.647533 \n",
       "L 520.112732 318.364994 \n",
       "L 526.261493 319.002997 \n",
       "L 532.410253 319.605025 \n",
       "L 538.559013 320.209274 \n",
       "L 544.707774 320.790117 \n",
       "L 550.856534 321.386536 \n",
       "L 557.005294 321.927418 \n",
       "L 563.154055 322.442198 \n",
       "L 569.302815 323.021238 \n",
       "L 575.451575 323.517465 \n",
       "L 581.600336 324.010728 \n",
       "L 587.749096 324.531868 \n",
       "L 593.897856 325.005357 \n",
       "L 600.046617 325.479373 \n",
       "L 606.195377 325.964564 \n",
       "L 612.344137 326.382066 \n",
       "L 618.492898 326.783294 \n",
       "L 624.641658 327.303119 \n",
       "L 630.790418 327.660586 \n",
       "L 636.939179 328.101113 \n",
       "L 643.087939 328.535299 \n",
       "L 649.236699 328.939003 \n",
       "L 655.38546 329.334772 \n",
       "L 661.53422 329.671107 \n",
       "L 667.68298 330.050369 \n",
       "L 673.831741 330.389246 \n",
       "L 679.980501 330.744462 \n",
       "L 686.129261 331.144492 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_62\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.461807 \n",
       "L 83.550749 360.422139 \n",
       "L 89.699509 361.386762 \n",
       "L 95.84827 362.127672 \n",
       "L 101.99703 362.717801 \n",
       "L 108.14579 363.227629 \n",
       "L 114.294551 363.680966 \n",
       "L 120.443311 364.051029 \n",
       "L 126.592071 364.347692 \n",
       "L 132.740832 364.582106 \n",
       "L 138.889592 364.801518 \n",
       "L 145.038352 364.958735 \n",
       "L 151.187113 365.108442 \n",
       "L 157.335873 365.251119 \n",
       "L 163.484633 365.371087 \n",
       "L 169.633394 365.481374 \n",
       "L 175.782154 365.58094 \n",
       "L 181.930914 365.675062 \n",
       "L 188.079675 365.758855 \n",
       "L 194.228435 365.831827 \n",
       "L 200.377195 365.887425 \n",
       "L 206.525956 365.940359 \n",
       "L 212.674716 365.986328 \n",
       "L 218.823476 366.018266 \n",
       "L 224.972237 366.032929 \n",
       "L 231.120997 366.043865 \n",
       "L 237.269757 366.053092 \n",
       "L 243.418518 366.063414 \n",
       "L 249.567278 366.069375 \n",
       "L 255.716038 366.072284 \n",
       "L 261.864799 366.074677 \n",
       "L 268.013559 366.076918 \n",
       "L 274.162319 366.078545 \n",
       "L 280.31108 366.080699 \n",
       "L 286.45984 366.082033 \n",
       "L 292.6086 366.083484 \n",
       "L 298.757361 366.088864 \n",
       "L 304.906121 366.095082 \n",
       "L 311.054881 366.103052 \n",
       "L 317.203642 366.115587 \n",
       "L 323.352402 366.137629 \n",
       "L 329.501162 366.17327 \n",
       "L 335.649923 366.227053 \n",
       "L 341.798683 366.302991 \n",
       "L 347.947443 366.366738 \n",
       "L 354.096204 366.433892 \n",
       "L 360.244964 366.493943 \n",
       "L 366.393724 366.532305 \n",
       "L 372.542485 366.588535 \n",
       "L 378.691245 366.654587 \n",
       "L 384.840005 366.688267 \n",
       "L 390.988765 366.762107 \n",
       "L 397.137526 366.809593 \n",
       "L 403.286286 366.876295 \n",
       "L 409.435046 366.953028 \n",
       "L 415.583807 367.04037 \n",
       "L 421.732567 367.097345 \n",
       "L 427.881327 367.189735 \n",
       "L 434.030088 367.268543 \n",
       "L 440.178848 367.338877 \n",
       "L 446.327608 367.441925 \n",
       "L 452.476369 367.513982 \n",
       "L 458.625129 367.60103 \n",
       "L 464.773889 367.681857 \n",
       "L 470.92265 367.781483 \n",
       "L 477.07141 367.849633 \n",
       "L 483.22017 367.896247 \n",
       "L 489.368931 367.951276 \n",
       "L 495.517691 367.993743 \n",
       "L 501.666451 368.030633 \n",
       "L 507.815212 368.060808 \n",
       "L 513.963972 368.089211 \n",
       "L 520.112732 368.117399 \n",
       "L 526.261493 368.136259 \n",
       "L 532.410253 368.165049 \n",
       "L 538.559013 368.179779 \n",
       "L 544.707774 368.20404 \n",
       "L 550.856534 368.220411 \n",
       "L 557.005294 368.256909 \n",
       "L 563.154055 368.266499 \n",
       "L 569.302815 368.287952 \n",
       "L 575.451575 368.306523 \n",
       "L 581.600336 368.32634 \n",
       "L 587.749096 368.341172 \n",
       "L 593.897856 368.353881 \n",
       "L 600.046617 368.363804 \n",
       "L 606.195377 368.376222 \n",
       "L 612.344137 368.386919 \n",
       "L 618.492898 368.408626 \n",
       "L 624.641658 368.425542 \n",
       "L 630.790418 368.433382 \n",
       "L 636.939179 368.436608 \n",
       "L 643.087939 368.44871 \n",
       "L 649.236699 368.466069 \n",
       "L 655.38546 368.477742 \n",
       "L 661.53422 368.472512 \n",
       "L 667.68298 368.492606 \n",
       "L 673.831741 368.498484 \n",
       "L 679.980501 368.504254 \n",
       "L 686.129261 368.515205 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_63\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 316.642773 \n",
       "L 83.550749 346.059987 \n",
       "L 89.699509 349.858845 \n",
       "L 95.84827 353.087925 \n",
       "L 101.99703 354.224396 \n",
       "L 108.14579 355.087198 \n",
       "L 114.294551 355.463406 \n",
       "L 120.443311 356.232644 \n",
       "L 126.592071 356.19182 \n",
       "L 132.740832 357.006003 \n",
       "L 138.889592 357.272583 \n",
       "L 145.038352 357.491134 \n",
       "L 151.187113 357.545768 \n",
       "L 157.335873 357.951019 \n",
       "L 163.484633 357.663853 \n",
       "L 169.633394 357.752063 \n",
       "L 175.782154 357.979752 \n",
       "L 181.930914 358.483977 \n",
       "L 188.079675 358.41794 \n",
       "L 194.228435 358.879019 \n",
       "L 200.377195 359.131547 \n",
       "L 206.525956 359.199958 \n",
       "L 212.674716 359.144933 \n",
       "L 218.823476 358.802325 \n",
       "L 224.972237 359.470419 \n",
       "L 231.120997 359.1902 \n",
       "L 237.269757 359.574141 \n",
       "L 243.418518 359.6963 \n",
       "L 249.567278 359.507057 \n",
       "L 255.716038 359.522474 \n",
       "L 261.864799 359.493845 \n",
       "L 268.013559 359.635132 \n",
       "L 274.162319 359.846377 \n",
       "L 280.31108 359.557931 \n",
       "L 286.45984 359.64348 \n",
       "L 292.6086 359.925052 \n",
       "L 298.757361 359.945419 \n",
       "L 304.906121 360.039161 \n",
       "L 311.054881 359.781867 \n",
       "L 317.203642 360.106701 \n",
       "L 323.352402 359.902293 \n",
       "L 329.501162 359.927436 \n",
       "L 335.649923 359.987282 \n",
       "L 341.798683 360.04057 \n",
       "L 347.947443 359.898758 \n",
       "L 354.096204 360.099401 \n",
       "L 360.244964 360.201416 \n",
       "L 366.393724 359.623934 \n",
       "L 372.542485 360.144277 \n",
       "L 378.691245 359.612611 \n",
       "L 384.840005 359.87233 \n",
       "L 390.988765 359.933296 \n",
       "L 397.137526 360.164744 \n",
       "L 403.286286 359.957481 \n",
       "L 409.435046 359.935999 \n",
       "L 415.583807 360.138375 \n",
       "L 421.732567 359.897076 \n",
       "L 427.881327 360.000907 \n",
       "L 434.030088 359.81289 \n",
       "L 440.178848 359.814534 \n",
       "L 446.327608 360.264763 \n",
       "L 452.476369 360.10621 \n",
       "L 458.625129 359.790213 \n",
       "L 464.773889 359.770909 \n",
       "L 470.92265 360.249262 \n",
       "L 477.07141 359.833267 \n",
       "L 483.22017 359.855356 \n",
       "L 489.368931 360.001463 \n",
       "L 495.517691 360.095249 \n",
       "L 501.666451 359.59956 \n",
       "L 507.815212 359.734974 \n",
       "L 513.963972 360.132653 \n",
       "L 520.112732 360.171312 \n",
       "L 526.261493 359.749181 \n",
       "L 532.410253 359.483869 \n",
       "L 538.559013 359.564308 \n",
       "L 544.707774 359.68006 \n",
       "L 550.856534 359.797874 \n",
       "L 557.005294 360.082288 \n",
       "L 563.154055 359.47244 \n",
       "L 569.302815 359.388879 \n",
       "L 575.451575 359.751078 \n",
       "L 581.600336 359.575525 \n",
       "L 587.749096 359.9292 \n",
       "L 593.897856 360.033916 \n",
       "L 600.046617 359.804569 \n",
       "L 606.195377 359.661624 \n",
       "L 612.344137 359.63571 \n",
       "L 618.492898 359.714979 \n",
       "L 624.641658 360.064511 \n",
       "L 630.790418 359.923157 \n",
       "L 636.939179 359.904169 \n",
       "L 643.087939 359.325224 \n",
       "L 649.236699 359.747038 \n",
       "L 655.38546 359.529924 \n",
       "L 661.53422 359.732338 \n",
       "L 667.68298 359.812664 \n",
       "L 673.831741 359.687735 \n",
       "L 679.980501 359.812522 \n",
       "L 686.129261 359.738648 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_64\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 367.550938 \n",
       "L 83.550749 369.272813 \n",
       "L 89.699509 369.654474 \n",
       "L 95.84827 369.749444 \n",
       "L 101.99703 369.800505 \n",
       "L 108.14579 369.952257 \n",
       "L 114.294551 369.947948 \n",
       "L 120.443311 370.055601 \n",
       "L 126.592071 370.173091 \n",
       "L 132.740832 370.112075 \n",
       "L 138.889592 370.128126 \n",
       "L 145.038352 370.208283 \n",
       "L 151.187113 370.130407 \n",
       "L 157.335873 370.144724 \n",
       "L 163.484633 370.201268 \n",
       "L 169.633394 370.207847 \n",
       "L 175.782154 370.168393 \n",
       "L 181.930914 370.261471 \n",
       "L 188.079675 370.226379 \n",
       "L 194.228435 370.205643 \n",
       "L 200.377195 370.189007 \n",
       "L 206.525956 370.206882 \n",
       "L 212.674716 370.258558 \n",
       "L 218.823476 370.218799 \n",
       "L 224.972237 370.2698 \n",
       "L 231.120997 370.271472 \n",
       "L 237.269757 370.239214 \n",
       "L 243.418518 370.270206 \n",
       "L 249.567278 370.251124 \n",
       "L 255.716038 370.272413 \n",
       "L 261.864799 370.248999 \n",
       "L 268.013559 370.265157 \n",
       "L 274.162319 370.27119 \n",
       "L 280.31108 370.217553 \n",
       "L 286.45984 370.237118 \n",
       "L 292.6086 370.293628 \n",
       "L 298.757361 370.258153 \n",
       "L 304.906121 370.227118 \n",
       "L 311.054881 370.243611 \n",
       "L 317.203642 370.204098 \n",
       "L 323.352402 370.242253 \n",
       "L 329.501162 370.22215 \n",
       "L 335.649923 370.273604 \n",
       "L 341.798683 370.276848 \n",
       "L 347.947443 370.22417 \n",
       "L 354.096204 370.165112 \n",
       "L 360.244964 370.241095 \n",
       "L 366.393724 370.232285 \n",
       "L 372.542485 370.256897 \n",
       "L 378.691245 370.171235 \n",
       "L 384.840005 370.249093 \n",
       "L 390.988765 370.244704 \n",
       "L 397.137526 370.183289 \n",
       "L 403.286286 370.230311 \n",
       "L 409.435046 370.268328 \n",
       "L 415.583807 370.281596 \n",
       "L 421.732567 370.282386 \n",
       "L 427.881327 370.275437 \n",
       "L 434.030088 370.244317 \n",
       "L 440.178848 370.217255 \n",
       "L 446.327608 370.192934 \n",
       "L 452.476369 370.282167 \n",
       "L 458.625129 370.21725 \n",
       "L 464.773889 370.215502 \n",
       "L 470.92265 370.215959 \n",
       "L 477.07141 370.251832 \n",
       "L 483.22017 370.220752 \n",
       "L 489.368931 370.236598 \n",
       "L 495.517691 370.215296 \n",
       "L 501.666451 370.224147 \n",
       "L 507.815212 370.244117 \n",
       "L 513.963972 370.240248 \n",
       "L 520.112732 370.252272 \n",
       "L 526.261493 370.260469 \n",
       "L 532.410253 370.247599 \n",
       "L 538.559013 370.245322 \n",
       "L 544.707774 370.236192 \n",
       "L 550.856534 370.29523 \n",
       "L 557.005294 370.211332 \n",
       "L 563.154055 370.236823 \n",
       "L 569.302815 370.255764 \n",
       "L 575.451575 370.235893 \n",
       "L 581.600336 370.22489 \n",
       "L 587.749096 370.188297 \n",
       "L 593.897856 370.257 \n",
       "L 600.046617 370.231235 \n",
       "L 606.195377 370.230578 \n",
       "L 612.344137 370.22616 \n",
       "L 618.492898 370.226898 \n",
       "L 624.641658 370.221795 \n",
       "L 630.790418 370.228733 \n",
       "L 636.939179 370.255494 \n",
       "L 643.087939 370.269341 \n",
       "L 649.236699 370.238521 \n",
       "L 655.38546 370.205221 \n",
       "L 661.53422 370.251572 \n",
       "L 667.68298 370.200588 \n",
       "L 673.831741 370.23355 \n",
       "L 679.980501 370.21468 \n",
       "L 686.129261 370.255887 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_65\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 323.185698 \n",
       "L 83.550749 347.370037 \n",
       "L 89.699509 351.481199 \n",
       "L 95.84827 352.944461 \n",
       "L 101.99703 354.121368 \n",
       "L 108.14579 355.054716 \n",
       "L 114.294551 355.319144 \n",
       "L 120.443311 355.918514 \n",
       "L 126.592071 356.249499 \n",
       "L 132.740832 356.784528 \n",
       "L 138.889592 357.191673 \n",
       "L 145.038352 356.816292 \n",
       "L 151.187113 357.361746 \n",
       "L 157.335873 357.760155 \n",
       "L 163.484633 357.633074 \n",
       "L 169.633394 358.124001 \n",
       "L 175.782154 358.503485 \n",
       "L 181.930914 358.337205 \n",
       "L 188.079675 358.2038 \n",
       "L 194.228435 358.224344 \n",
       "L 200.377195 358.467218 \n",
       "L 206.525956 358.983013 \n",
       "L 212.674716 358.87743 \n",
       "L 218.823476 358.752354 \n",
       "L 224.972237 358.861908 \n",
       "L 231.120997 359.253838 \n",
       "L 237.269757 359.409608 \n",
       "L 243.418518 359.656779 \n",
       "L 249.567278 359.776288 \n",
       "L 255.716038 359.654112 \n",
       "L 261.864799 359.924587 \n",
       "L 268.013559 359.905943 \n",
       "L 274.162319 360.106423 \n",
       "L 280.31108 359.640108 \n",
       "L 286.45984 359.677175 \n",
       "L 292.6086 359.876093 \n",
       "L 298.757361 359.776754 \n",
       "L 304.906121 360.060036 \n",
       "L 311.054881 360.156031 \n",
       "L 317.203642 360.062846 \n",
       "L 323.352402 360.088652 \n",
       "L 329.501162 360.237113 \n",
       "L 335.649923 360.635225 \n",
       "L 341.798683 360.585123 \n",
       "L 347.947443 360.189798 \n",
       "L 354.096204 360.179509 \n",
       "L 360.244964 360.52432 \n",
       "L 366.393724 359.988244 \n",
       "L 372.542485 360.593446 \n",
       "L 378.691245 360.303819 \n",
       "L 384.840005 360.459649 \n",
       "L 390.988765 360.128475 \n",
       "L 397.137526 360.550054 \n",
       "L 403.286286 360.496307 \n",
       "L 409.435046 360.054256 \n",
       "L 415.583807 360.166609 \n",
       "L 421.732567 360.39821 \n",
       "L 427.881327 360.565151 \n",
       "L 434.030088 360.636049 \n",
       "L 440.178848 360.535456 \n",
       "L 446.327608 360.108064 \n",
       "L 452.476369 360.274236 \n",
       "L 458.625129 360.459968 \n",
       "L 464.773889 360.540442 \n",
       "L 470.92265 360.378563 \n",
       "L 477.07141 360.475567 \n",
       "L 483.22017 359.725526 \n",
       "L 489.368931 360.272765 \n",
       "L 495.517691 360.215456 \n",
       "L 501.666451 360.267759 \n",
       "L 507.815212 360.249363 \n",
       "L 513.963972 360.335952 \n",
       "L 520.112732 360.568134 \n",
       "L 526.261493 360.436581 \n",
       "L 532.410253 360.470598 \n",
       "L 538.559013 360.207406 \n",
       "L 544.707774 360.305485 \n",
       "L 550.856534 360.327902 \n",
       "L 557.005294 360.383473 \n",
       "L 563.154055 360.429066 \n",
       "L 569.302815 360.420591 \n",
       "L 575.451575 360.338601 \n",
       "L 581.600336 360.278435 \n",
       "L 587.749096 360.330279 \n",
       "L 593.897856 360.171438 \n",
       "L 600.046617 360.55138 \n",
       "L 606.195377 360.200034 \n",
       "L 612.344137 360.291892 \n",
       "L 618.492898 360.413376 \n",
       "L 624.641658 360.267789 \n",
       "L 630.790418 360.211115 \n",
       "L 636.939179 360.117872 \n",
       "L 643.087939 359.518417 \n",
       "L 649.236699 360.12925 \n",
       "L 655.38546 360.113165 \n",
       "L 661.53422 360.104259 \n",
       "L 667.68298 360.25166 \n",
       "L 673.831741 360.081858 \n",
       "L 679.980501 359.814591 \n",
       "L 686.129261 360.040782 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_66\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.703242 \n",
       "L 83.550749 369.375969 \n",
       "L 89.699509 369.699031 \n",
       "L 95.84827 369.816622 \n",
       "L 101.99703 369.970591 \n",
       "L 108.14579 370.009721 \n",
       "L 114.294551 370.008082 \n",
       "L 120.443311 370.082553 \n",
       "L 126.592071 370.125768 \n",
       "L 132.740832 370.020077 \n",
       "L 138.889592 370.0848 \n",
       "L 145.038352 370.138393 \n",
       "L 151.187113 370.179651 \n",
       "L 157.335873 370.188093 \n",
       "L 163.484633 370.180933 \n",
       "L 169.633394 370.161596 \n",
       "L 175.782154 370.193727 \n",
       "L 181.930914 370.195759 \n",
       "L 188.079675 370.160543 \n",
       "L 194.228435 370.219415 \n",
       "L 200.377195 370.17322 \n",
       "L 206.525956 370.203244 \n",
       "L 212.674716 370.182322 \n",
       "L 218.823476 370.226824 \n",
       "L 224.972237 370.191517 \n",
       "L 231.120997 370.207285 \n",
       "L 237.269757 370.23995 \n",
       "L 243.418518 370.15031 \n",
       "L 249.567278 370.17436 \n",
       "L 255.716038 370.244352 \n",
       "L 261.864799 370.153309 \n",
       "L 268.013559 370.256778 \n",
       "L 274.162319 370.26017 \n",
       "L 280.31108 370.140459 \n",
       "L 286.45984 370.193381 \n",
       "L 292.6086 370.198423 \n",
       "L 298.757361 370.228835 \n",
       "L 304.906121 370.24935 \n",
       "L 311.054881 370.233559 \n",
       "L 317.203642 370.138976 \n",
       "L 323.352402 370.244267 \n",
       "L 329.501162 370.192016 \n",
       "L 335.649923 370.197868 \n",
       "L 341.798683 370.150255 \n",
       "L 347.947443 370.197302 \n",
       "L 354.096204 370.226657 \n",
       "L 360.244964 370.197694 \n",
       "L 366.393724 370.202746 \n",
       "L 372.542485 370.112717 \n",
       "L 378.691245 370.267658 \n",
       "L 384.840005 370.184008 \n",
       "L 390.988765 370.212243 \n",
       "L 397.137526 370.161805 \n",
       "L 403.286286 370.134719 \n",
       "L 409.435046 370.189884 \n",
       "L 415.583807 370.245579 \n",
       "L 421.732567 370.211199 \n",
       "L 427.881327 370.116472 \n",
       "L 434.030088 370.169661 \n",
       "L 440.178848 370.163037 \n",
       "L 446.327608 370.177133 \n",
       "L 452.476369 370.19017 \n",
       "L 458.625129 370.178362 \n",
       "L 464.773889 370.132913 \n",
       "L 470.92265 370.109383 \n",
       "L 477.07141 370.165596 \n",
       "L 483.22017 370.148555 \n",
       "L 489.368931 370.207741 \n",
       "L 495.517691 370.143306 \n",
       "L 501.666451 370.134219 \n",
       "L 507.815212 370.199599 \n",
       "L 513.963972 370.214842 \n",
       "L 520.112732 370.219653 \n",
       "L 526.261493 370.207132 \n",
       "L 532.410253 370.11635 \n",
       "L 538.559013 370.233012 \n",
       "L 544.707774 370.164387 \n",
       "L 550.856534 370.158397 \n",
       "L 557.005294 370.181188 \n",
       "L 563.154055 370.211125 \n",
       "L 569.302815 370.144215 \n",
       "L 575.451575 370.183941 \n",
       "L 581.600336 370.168466 \n",
       "L 587.749096 370.213115 \n",
       "L 593.897856 370.151478 \n",
       "L 600.046617 370.195107 \n",
       "L 606.195377 370.197507 \n",
       "L 612.344137 370.136187 \n",
       "L 618.492898 370.163588 \n",
       "L 624.641658 370.132793 \n",
       "L 630.790418 370.114938 \n",
       "L 636.939179 370.13197 \n",
       "L 643.087939 370.167532 \n",
       "L 649.236699 370.185582 \n",
       "L 655.38546 370.20175 \n",
       "L 661.53422 370.132101 \n",
       "L 667.68298 370.146349 \n",
       "L 673.831741 370.116556 \n",
       "L 679.980501 370.202072 \n",
       "L 686.129261 370.166113 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_67\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 314.903977 \n",
       "L 83.550749 344.977149 \n",
       "L 89.699509 350.501031 \n",
       "L 95.84827 352.774636 \n",
       "L 101.99703 353.979973 \n",
       "L 108.14579 354.912801 \n",
       "L 114.294551 354.81734 \n",
       "L 120.443311 355.961964 \n",
       "L 126.592071 356.07486 \n",
       "L 132.740832 356.039973 \n",
       "L 138.889592 356.776305 \n",
       "L 145.038352 355.979327 \n",
       "L 151.187113 357.157205 \n",
       "L 157.335873 357.121187 \n",
       "L 163.484633 357.2947 \n",
       "L 169.633394 358.034856 \n",
       "L 175.782154 357.81111 \n",
       "L 181.930914 357.894003 \n",
       "L 188.079675 357.987837 \n",
       "L 194.228435 358.042197 \n",
       "L 200.377195 358.24494 \n",
       "L 206.525956 358.212317 \n",
       "L 212.674716 358.304557 \n",
       "L 218.823476 358.503754 \n",
       "L 224.972237 358.697049 \n",
       "L 231.120997 358.660191 \n",
       "L 237.269757 358.768069 \n",
       "L 243.418518 358.685549 \n",
       "L 249.567278 358.414819 \n",
       "L 255.716038 359.071236 \n",
       "L 261.864799 359.006402 \n",
       "L 268.013559 358.374721 \n",
       "L 274.162319 359.193534 \n",
       "L 280.31108 359.466982 \n",
       "L 286.45984 359.038749 \n",
       "L 292.6086 358.854802 \n",
       "L 298.757361 359.424777 \n",
       "L 304.906121 359.575972 \n",
       "L 311.054881 359.406015 \n",
       "L 317.203642 359.350357 \n",
       "L 323.352402 359.756282 \n",
       "L 329.501162 359.481551 \n",
       "L 335.649923 359.512015 \n",
       "L 341.798683 359.479902 \n",
       "L 347.947443 359.659271 \n",
       "L 354.096204 359.674525 \n",
       "L 360.244964 359.881858 \n",
       "L 366.393724 359.603145 \n",
       "L 372.542485 359.792878 \n",
       "L 378.691245 359.606345 \n",
       "L 384.840005 359.697784 \n",
       "L 390.988765 359.964002 \n",
       "L 397.137526 359.929697 \n",
       "L 403.286286 359.651867 \n",
       "L 409.435046 359.589074 \n",
       "L 415.583807 359.837234 \n",
       "L 421.732567 359.64043 \n",
       "L 427.881327 359.795935 \n",
       "L 434.030088 359.724085 \n",
       "L 440.178848 359.582442 \n",
       "L 446.327608 359.678984 \n",
       "L 452.476369 359.811293 \n",
       "L 458.625129 359.701938 \n",
       "L 464.773889 359.909931 \n",
       "L 470.92265 359.677563 \n",
       "L 477.07141 359.557795 \n",
       "L 483.22017 359.772267 \n",
       "L 489.368931 359.471284 \n",
       "L 495.517691 359.965119 \n",
       "L 501.666451 359.787371 \n",
       "L 507.815212 359.974203 \n",
       "L 513.963972 359.521178 \n",
       "L 520.112732 359.874942 \n",
       "L 526.261493 359.718621 \n",
       "L 532.410253 359.769206 \n",
       "L 538.559013 359.460549 \n",
       "L 544.707774 359.606012 \n",
       "L 550.856534 359.608694 \n",
       "L 557.005294 359.847983 \n",
       "L 563.154055 359.472012 \n",
       "L 569.302815 359.552174 \n",
       "L 575.451575 359.958756 \n",
       "L 581.600336 359.615462 \n",
       "L 587.749096 359.74447 \n",
       "L 593.897856 359.959742 \n",
       "L 600.046617 359.451638 \n",
       "L 606.195377 359.736656 \n",
       "L 612.344137 359.619067 \n",
       "L 618.492898 359.772118 \n",
       "L 624.641658 359.422833 \n",
       "L 630.790418 359.781644 \n",
       "L 636.939179 359.707199 \n",
       "L 643.087939 359.529312 \n",
       "L 649.236699 359.608632 \n",
       "L 655.38546 359.683151 \n",
       "L 661.53422 359.673723 \n",
       "L 667.68298 359.753204 \n",
       "L 673.831741 359.516734 \n",
       "L 679.980501 359.38066 \n",
       "L 686.129261 359.542149 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_68\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 367.306425 \n",
       "L 83.550749 369.46065 \n",
       "L 89.699509 369.326087 \n",
       "L 95.84827 369.767627 \n",
       "L 101.99703 369.8458 \n",
       "L 108.14579 369.861792 \n",
       "L 114.294551 369.865929 \n",
       "L 120.443311 369.891394 \n",
       "L 126.592071 370.032814 \n",
       "L 132.740832 369.987414 \n",
       "L 138.889592 369.942172 \n",
       "L 145.038352 370.11679 \n",
       "L 151.187113 370.165459 \n",
       "L 157.335873 370.128086 \n",
       "L 163.484633 370.165132 \n",
       "L 169.633394 370.117994 \n",
       "L 175.782154 370.063645 \n",
       "L 181.930914 370.154301 \n",
       "L 188.079675 370.210784 \n",
       "L 194.228435 370.188376 \n",
       "L 200.377195 370.180966 \n",
       "L 206.525956 370.213906 \n",
       "L 212.674716 370.208795 \n",
       "L 218.823476 370.195489 \n",
       "L 224.972237 370.253043 \n",
       "L 231.120997 370.267966 \n",
       "L 237.269757 370.249027 \n",
       "L 243.418518 370.252414 \n",
       "L 249.567278 370.25924 \n",
       "L 255.716038 370.238393 \n",
       "L 261.864799 370.294654 \n",
       "L 268.013559 370.227503 \n",
       "L 274.162319 370.30621 \n",
       "L 280.31108 370.303783 \n",
       "L 286.45984 370.358 \n",
       "L 292.6086 370.266524 \n",
       "L 298.757361 370.305986 \n",
       "L 304.906121 370.324363 \n",
       "L 311.054881 370.307055 \n",
       "L 317.203642 370.271842 \n",
       "L 323.352402 370.300757 \n",
       "L 329.501162 370.288283 \n",
       "L 335.649923 370.244439 \n",
       "L 341.798683 370.31768 \n",
       "L 347.947443 370.31538 \n",
       "L 354.096204 370.266918 \n",
       "L 360.244964 370.273128 \n",
       "L 366.393724 370.236156 \n",
       "L 372.542485 370.325738 \n",
       "L 378.691245 370.293959 \n",
       "L 384.840005 370.354098 \n",
       "L 390.988765 370.250743 \n",
       "L 397.137526 370.35347 \n",
       "L 403.286286 370.241137 \n",
       "L 409.435046 370.326376 \n",
       "L 415.583807 370.320363 \n",
       "L 421.732567 370.35443 \n",
       "L 427.881327 370.296552 \n",
       "L 434.030088 370.355213 \n",
       "L 440.178848 370.3621 \n",
       "L 446.327608 370.337574 \n",
       "L 452.476369 370.305477 \n",
       "L 458.625129 370.332637 \n",
       "L 464.773889 370.282065 \n",
       "L 470.92265 370.381595 \n",
       "L 477.07141 370.322802 \n",
       "L 483.22017 370.322593 \n",
       "L 489.368931 370.34724 \n",
       "L 495.517691 370.332314 \n",
       "L 501.666451 370.364026 \n",
       "L 507.815212 370.357475 \n",
       "L 513.963972 370.267122 \n",
       "L 520.112732 370.353882 \n",
       "L 526.261493 370.376186 \n",
       "L 532.410253 370.368072 \n",
       "L 538.559013 370.377217 \n",
       "L 544.707774 370.39524 \n",
       "L 550.856534 370.3637 \n",
       "L 557.005294 370.326223 \n",
       "L 563.154055 370.333001 \n",
       "L 569.302815 370.348275 \n",
       "L 575.451575 370.359014 \n",
       "L 581.600336 370.360856 \n",
       "L 587.749096 370.359897 \n",
       "L 593.897856 370.363555 \n",
       "L 600.046617 370.321435 \n",
       "L 606.195377 370.399686 \n",
       "L 612.344137 370.372062 \n",
       "L 618.492898 370.36431 \n",
       "L 624.641658 370.350267 \n",
       "L 630.790418 370.366173 \n",
       "L 636.939179 370.400957 \n",
       "L 643.087939 370.333781 \n",
       "L 649.236699 370.319431 \n",
       "L 655.38546 370.349028 \n",
       "L 661.53422 370.336246 \n",
       "L 667.68298 370.3743 \n",
       "L 673.831741 370.312712 \n",
       "L 679.980501 370.345374 \n",
       "L 686.129261 370.345922 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_69\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 198.050682 \n",
       "L 83.550749 237.168727 \n",
       "L 89.699509 256.117546 \n",
       "L 95.84827 267.378787 \n",
       "L 101.99703 274.484399 \n",
       "L 108.14579 279.548171 \n",
       "L 114.294551 282.747408 \n",
       "L 120.443311 284.952892 \n",
       "L 126.592071 286.245724 \n",
       "L 132.740832 287.337145 \n",
       "L 138.889592 287.985136 \n",
       "L 145.038352 288.428937 \n",
       "L 151.187113 288.875638 \n",
       "L 157.335873 289.086706 \n",
       "L 163.484633 289.222811 \n",
       "L 169.633394 289.344747 \n",
       "L 175.782154 289.46523 \n",
       "L 181.930914 289.563334 \n",
       "L 188.079675 289.667303 \n",
       "L 194.228435 289.799624 \n",
       "L 200.377195 289.939727 \n",
       "L 206.525956 290.130882 \n",
       "L 212.674716 290.379402 \n",
       "L 218.823476 290.775088 \n",
       "L 224.972237 291.28517 \n",
       "L 231.120997 292.059246 \n",
       "L 237.269757 293.421587 \n",
       "L 243.418518 295.233495 \n",
       "L 249.567278 297.643291 \n",
       "L 255.716038 300.358295 \n",
       "L 261.864799 303.416887 \n",
       "L 268.013559 306.587958 \n",
       "L 274.162319 309.736387 \n",
       "L 280.31108 312.481838 \n",
       "L 286.45984 314.664623 \n",
       "L 292.6086 316.440504 \n",
       "L 298.757361 318.003657 \n",
       "L 304.906121 319.191129 \n",
       "L 311.054881 320.251722 \n",
       "L 317.203642 321.192991 \n",
       "L 323.352402 322.240926 \n",
       "L 329.501162 323.188577 \n",
       "L 335.649923 324.140625 \n",
       "L 341.798683 325.054726 \n",
       "L 347.947443 325.895015 \n",
       "L 354.096204 326.863277 \n",
       "L 360.244964 327.690809 \n",
       "L 366.393724 328.348186 \n",
       "L 372.542485 329.441321 \n",
       "L 378.691245 330.17531 \n",
       "L 384.840005 330.97871 \n",
       "L 390.988765 331.565369 \n",
       "L 397.137526 332.348317 \n",
       "L 403.286286 333.018416 \n",
       "L 409.435046 333.287433 \n",
       "L 415.583807 334.197977 \n",
       "L 421.732567 334.596831 \n",
       "L 427.881327 335.228017 \n",
       "L 434.030088 335.798062 \n",
       "L 440.178848 336.134541 \n",
       "L 446.327608 336.867946 \n",
       "L 452.476369 337.381955 \n",
       "L 458.625129 337.733194 \n",
       "L 464.773889 338.431954 \n",
       "L 470.92265 338.564061 \n",
       "L 477.07141 339.304033 \n",
       "L 483.22017 339.704559 \n",
       "L 489.368931 339.928954 \n",
       "L 495.517691 340.440372 \n",
       "L 501.666451 340.856406 \n",
       "L 507.815212 341.229689 \n",
       "L 513.963972 341.515761 \n",
       "L 520.112732 341.913621 \n",
       "L 526.261493 342.143134 \n",
       "L 532.410253 342.563754 \n",
       "L 538.559013 342.787172 \n",
       "L 544.707774 343.147895 \n",
       "L 550.856534 343.396208 \n",
       "L 557.005294 343.680335 \n",
       "L 563.154055 344.014572 \n",
       "L 569.302815 344.427021 \n",
       "L 575.451575 344.589432 \n",
       "L 581.600336 344.701038 \n",
       "L 587.749096 345.098973 \n",
       "L 593.897856 345.428937 \n",
       "L 600.046617 345.633172 \n",
       "L 606.195377 345.921421 \n",
       "L 612.344137 346.143988 \n",
       "L 618.492898 346.335237 \n",
       "L 624.641658 346.518718 \n",
       "L 630.790418 346.489539 \n",
       "L 636.939179 347.064628 \n",
       "L 643.087939 347.240461 \n",
       "L 649.236699 347.404794 \n",
       "L 655.38546 347.664197 \n",
       "L 661.53422 347.569374 \n",
       "L 667.68298 347.994475 \n",
       "L 673.831741 348.161711 \n",
       "L 679.980501 348.373883 \n",
       "L 686.129261 348.403877 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_70\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.799802 \n",
       "L 83.550749 364.359353 \n",
       "L 89.699509 365.065212 \n",
       "L 95.84827 365.500527 \n",
       "L 101.99703 365.79294 \n",
       "L 108.14579 365.976356 \n",
       "L 114.294551 366.041962 \n",
       "L 120.443311 366.0647 \n",
       "L 126.592071 366.067669 \n",
       "L 132.740832 366.065524 \n",
       "L 138.889592 366.059131 \n",
       "L 145.038352 366.058241 \n",
       "L 151.187113 366.054512 \n",
       "L 157.335873 366.053712 \n",
       "L 163.484633 366.042987 \n",
       "L 169.633394 366.053396 \n",
       "L 175.782154 366.051845 \n",
       "L 181.930914 366.068968 \n",
       "L 188.079675 366.081761 \n",
       "L 194.228435 366.113572 \n",
       "L 200.377195 366.178029 \n",
       "L 206.525956 366.309596 \n",
       "L 212.674716 366.453087 \n",
       "L 218.823476 366.634199 \n",
       "L 224.972237 366.821528 \n",
       "L 231.120997 366.966821 \n",
       "L 237.269757 367.291099 \n",
       "L 243.418518 367.597147 \n",
       "L 249.567278 367.696317 \n",
       "L 255.716038 367.857974 \n",
       "L 261.864799 368.004285 \n",
       "L 268.013559 368.002508 \n",
       "L 274.162319 368.054175 \n",
       "L 280.31108 368.159744 \n",
       "L 286.45984 368.156422 \n",
       "L 292.6086 368.160405 \n",
       "L 298.757361 368.2447 \n",
       "L 304.906121 368.199941 \n",
       "L 311.054881 368.284166 \n",
       "L 317.203642 368.278383 \n",
       "L 323.352402 368.302387 \n",
       "L 329.501162 368.339122 \n",
       "L 335.649923 368.349597 \n",
       "L 341.798683 368.401165 \n",
       "L 347.947443 368.412713 \n",
       "L 354.096204 368.440401 \n",
       "L 360.244964 368.409648 \n",
       "L 366.393724 368.475139 \n",
       "L 372.542485 368.496309 \n",
       "L 378.691245 368.510979 \n",
       "L 384.840005 368.529348 \n",
       "L 390.988765 368.516104 \n",
       "L 397.137526 368.528587 \n",
       "L 403.286286 368.553361 \n",
       "L 409.435046 368.584273 \n",
       "L 415.583807 368.581713 \n",
       "L 421.732567 368.596665 \n",
       "L 427.881327 368.603463 \n",
       "L 434.030088 368.612507 \n",
       "L 440.178848 368.624178 \n",
       "L 446.327608 368.637525 \n",
       "L 452.476369 368.652869 \n",
       "L 458.625129 368.662815 \n",
       "L 464.773889 368.672417 \n",
       "L 470.92265 368.678307 \n",
       "L 477.07141 368.689378 \n",
       "L 483.22017 368.704486 \n",
       "L 489.368931 368.696244 \n",
       "L 495.517691 368.725096 \n",
       "L 501.666451 368.740943 \n",
       "L 507.815212 368.752158 \n",
       "L 513.963972 368.745047 \n",
       "L 520.112732 368.78013 \n",
       "L 526.261493 368.76745 \n",
       "L 532.410253 368.774644 \n",
       "L 538.559013 368.805781 \n",
       "L 544.707774 368.818229 \n",
       "L 550.856534 368.834867 \n",
       "L 557.005294 368.816907 \n",
       "L 563.154055 368.85001 \n",
       "L 569.302815 368.850116 \n",
       "L 575.451575 368.835447 \n",
       "L 581.600336 368.874217 \n",
       "L 587.749096 368.892659 \n",
       "L 593.897856 368.871254 \n",
       "L 600.046617 368.915065 \n",
       "L 606.195377 368.872951 \n",
       "L 612.344137 368.878317 \n",
       "L 618.492898 368.894518 \n",
       "L 624.641658 368.924942 \n",
       "L 630.790418 368.768661 \n",
       "L 636.939179 368.976577 \n",
       "L 643.087939 368.986387 \n",
       "L 649.236699 368.939383 \n",
       "L 655.38546 368.982907 \n",
       "L 661.53422 368.958149 \n",
       "L 667.68298 369.008163 \n",
       "L 673.831741 369.033713 \n",
       "L 679.980501 368.980887 \n",
       "L 686.129261 368.975847 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_71\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 182.31668 \n",
       "L 83.550749 221.450903 \n",
       "L 89.699509 243.005462 \n",
       "L 95.84827 256.648226 \n",
       "L 101.99703 265.987795 \n",
       "L 108.14579 272.092328 \n",
       "L 114.294551 276.991094 \n",
       "L 120.443311 280.152187 \n",
       "L 126.592071 282.548249 \n",
       "L 132.740832 284.406419 \n",
       "L 138.889592 285.725229 \n",
       "L 145.038352 286.744474 \n",
       "L 151.187113 287.457571 \n",
       "L 157.335873 288.048288 \n",
       "L 163.484633 288.418282 \n",
       "L 169.633394 288.764499 \n",
       "L 175.782154 288.947215 \n",
       "L 181.930914 289.079009 \n",
       "L 188.079675 289.246843 \n",
       "L 194.228435 289.346023 \n",
       "L 200.377195 289.45774 \n",
       "L 206.525956 289.555508 \n",
       "L 212.674716 289.661516 \n",
       "L 218.823476 289.796552 \n",
       "L 224.972237 289.957773 \n",
       "L 231.120997 290.161236 \n",
       "L 237.269757 290.436318 \n",
       "L 243.418518 290.825775 \n",
       "L 249.567278 291.419123 \n",
       "L 255.716038 292.321471 \n",
       "L 261.864799 293.289972 \n",
       "L 268.013559 294.610706 \n",
       "L 274.162319 296.119487 \n",
       "L 280.31108 297.952868 \n",
       "L 286.45984 299.987711 \n",
       "L 292.6086 302.512173 \n",
       "L 298.757361 305.188513 \n",
       "L 304.906121 308.107465 \n",
       "L 311.054881 310.487149 \n",
       "L 317.203642 312.753756 \n",
       "L 323.352402 314.718029 \n",
       "L 329.501162 316.2491 \n",
       "L 335.649923 317.399889 \n",
       "L 341.798683 318.517021 \n",
       "L 347.947443 319.55815 \n",
       "L 354.096204 320.399373 \n",
       "L 360.244964 321.297958 \n",
       "L 366.393724 322.165533 \n",
       "L 372.542485 322.87498 \n",
       "L 378.691245 323.734035 \n",
       "L 384.840005 324.524691 \n",
       "L 390.988765 325.099826 \n",
       "L 397.137526 326.162339 \n",
       "L 403.286286 326.908356 \n",
       "L 409.435046 327.710355 \n",
       "L 415.583807 328.362757 \n",
       "L 421.732567 329.107216 \n",
       "L 427.881327 329.772368 \n",
       "L 434.030088 330.4261 \n",
       "L 440.178848 330.888143 \n",
       "L 446.327608 331.702479 \n",
       "L 452.476369 332.225347 \n",
       "L 458.625129 332.834581 \n",
       "L 464.773889 333.331895 \n",
       "L 470.92265 333.829823 \n",
       "L 477.07141 334.419122 \n",
       "L 483.22017 334.891855 \n",
       "L 489.368931 335.345032 \n",
       "L 495.517691 335.793419 \n",
       "L 501.666451 335.945785 \n",
       "L 507.815212 336.691576 \n",
       "L 513.963972 337.129786 \n",
       "L 520.112732 337.298533 \n",
       "L 526.261493 337.958291 \n",
       "L 532.410253 338.254148 \n",
       "L 538.559013 338.64667 \n",
       "L 544.707774 339.108734 \n",
       "L 550.856534 339.406057 \n",
       "L 557.005294 339.730658 \n",
       "L 563.154055 340.163191 \n",
       "L 569.302815 340.376051 \n",
       "L 575.451575 340.706222 \n",
       "L 581.600336 341.116857 \n",
       "L 587.749096 341.217577 \n",
       "L 593.897856 341.716459 \n",
       "L 600.046617 341.850601 \n",
       "L 606.195377 342.21403 \n",
       "L 612.344137 342.628599 \n",
       "L 618.492898 342.929393 \n",
       "L 624.641658 343.125764 \n",
       "L 630.790418 342.814038 \n",
       "L 636.939179 343.107875 \n",
       "L 643.087939 343.959952 \n",
       "L 649.236699 344.232426 \n",
       "L 655.38546 344.566237 \n",
       "L 661.53422 344.509832 \n",
       "L 667.68298 344.609026 \n",
       "L 673.831741 344.953975 \n",
       "L 679.980501 345.425392 \n",
       "L 686.129261 345.701424 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_72\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 362.513719 \n",
       "L 83.550749 364.244634 \n",
       "L 89.699509 365.01812 \n",
       "L 95.84827 365.47798 \n",
       "L 101.99703 365.737558 \n",
       "L 108.14579 365.948403 \n",
       "L 114.294551 366.028203 \n",
       "L 120.443311 366.059104 \n",
       "L 126.592071 366.065319 \n",
       "L 132.740832 366.065535 \n",
       "L 138.889592 366.060483 \n",
       "L 145.038352 366.057626 \n",
       "L 151.187113 366.053884 \n",
       "L 157.335873 366.048462 \n",
       "L 163.484633 366.05116 \n",
       "L 169.633394 366.043978 \n",
       "L 175.782154 366.049446 \n",
       "L 181.930914 366.049723 \n",
       "L 188.079675 366.05146 \n",
       "L 194.228435 366.063639 \n",
       "L 200.377195 366.083458 \n",
       "L 206.525956 366.119458 \n",
       "L 212.674716 366.200513 \n",
       "L 218.823476 366.348517 \n",
       "L 224.972237 366.460938 \n",
       "L 231.120997 366.592361 \n",
       "L 237.269757 366.753731 \n",
       "L 243.418518 366.936881 \n",
       "L 249.567278 367.289351 \n",
       "L 255.716038 367.547771 \n",
       "L 261.864799 367.615335 \n",
       "L 268.013559 367.835413 \n",
       "L 274.162319 367.96439 \n",
       "L 280.31108 367.95202 \n",
       "L 286.45984 368.071558 \n",
       "L 292.6086 368.104229 \n",
       "L 298.757361 368.12851 \n",
       "L 304.906121 368.185687 \n",
       "L 311.054881 368.204695 \n",
       "L 317.203642 368.13677 \n",
       "L 323.352402 368.251823 \n",
       "L 329.501162 368.228953 \n",
       "L 335.649923 368.312052 \n",
       "L 341.798683 368.337866 \n",
       "L 347.947443 368.313377 \n",
       "L 354.096204 368.355858 \n",
       "L 360.244964 368.363996 \n",
       "L 366.393724 368.407694 \n",
       "L 372.542485 368.416941 \n",
       "L 378.691245 368.433334 \n",
       "L 384.840005 368.438909 \n",
       "L 390.988765 368.425549 \n",
       "L 397.137526 368.473698 \n",
       "L 403.286286 368.454493 \n",
       "L 409.435046 368.501059 \n",
       "L 415.583807 368.507889 \n",
       "L 421.732567 368.514657 \n",
       "L 427.881327 368.54407 \n",
       "L 434.030088 368.560787 \n",
       "L 440.178848 368.55714 \n",
       "L 446.327608 368.593337 \n",
       "L 452.476369 368.605198 \n",
       "L 458.625129 368.61597 \n",
       "L 464.773889 368.630795 \n",
       "L 470.92265 368.648283 \n",
       "L 477.07141 368.656576 \n",
       "L 483.22017 368.658021 \n",
       "L 489.368931 368.669727 \n",
       "L 495.517691 368.681589 \n",
       "L 501.666451 368.68689 \n",
       "L 507.815212 368.701403 \n",
       "L 513.963972 368.719097 \n",
       "L 520.112732 368.726851 \n",
       "L 526.261493 368.728283 \n",
       "L 532.410253 368.753845 \n",
       "L 538.559013 368.748319 \n",
       "L 544.707774 368.767857 \n",
       "L 550.856534 368.790389 \n",
       "L 557.005294 368.784866 \n",
       "L 563.154055 368.797135 \n",
       "L 569.302815 368.801045 \n",
       "L 575.451575 368.813297 \n",
       "L 581.600336 368.842097 \n",
       "L 587.749096 368.838272 \n",
       "L 593.897856 368.835442 \n",
       "L 600.046617 368.857296 \n",
       "L 606.195377 368.816242 \n",
       "L 612.344137 368.805932 \n",
       "L 618.492898 368.848978 \n",
       "L 624.641658 368.873102 \n",
       "L 630.790418 368.868999 \n",
       "L 636.939179 368.91826 \n",
       "L 643.087939 368.910998 \n",
       "L 649.236699 368.936327 \n",
       "L 655.38546 368.940415 \n",
       "L 661.53422 368.956049 \n",
       "L 667.68298 368.974145 \n",
       "L 673.831741 368.940189 \n",
       "L 679.980501 368.981403 \n",
       "L 686.129261 369.004172 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_73\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 205.772705 \n",
       "L 83.550749 243.803605 \n",
       "L 89.699509 261.15323 \n",
       "L 95.84827 271.379432 \n",
       "L 101.99703 277.696073 \n",
       "L 108.14579 281.883403 \n",
       "L 114.294551 284.382836 \n",
       "L 120.443311 286.346685 \n",
       "L 126.592071 287.218957 \n",
       "L 132.740832 287.93757 \n",
       "L 138.889592 288.454031 \n",
       "L 145.038352 288.869431 \n",
       "L 151.187113 289.068567 \n",
       "L 157.335873 289.278879 \n",
       "L 163.484633 289.4436 \n",
       "L 169.633394 289.567795 \n",
       "L 175.782154 289.691842 \n",
       "L 181.930914 289.834033 \n",
       "L 188.079675 290.017277 \n",
       "L 194.228435 290.237424 \n",
       "L 200.377195 290.533852 \n",
       "L 206.525956 290.969663 \n",
       "L 212.674716 291.586288 \n",
       "L 218.823476 292.47074 \n",
       "L 224.972237 293.503819 \n",
       "L 231.120997 294.917333 \n",
       "L 237.269757 296.554699 \n",
       "L 243.418518 298.459558 \n",
       "L 249.567278 300.800108 \n",
       "L 255.716038 303.368673 \n",
       "L 261.864799 306.225384 \n",
       "L 268.013559 309.03041 \n",
       "L 274.162319 311.686809 \n",
       "L 280.31108 313.757774 \n",
       "L 286.45984 315.582668 \n",
       "L 292.6086 317.257676 \n",
       "L 298.757361 318.465051 \n",
       "L 304.906121 319.594377 \n",
       "L 311.054881 320.505719 \n",
       "L 317.203642 321.472777 \n",
       "L 323.352402 322.366319 \n",
       "L 329.501162 323.146403 \n",
       "L 335.649923 324.116443 \n",
       "L 341.798683 324.789407 \n",
       "L 347.947443 325.818823 \n",
       "L 354.096204 326.764746 \n",
       "L 360.244964 327.519189 \n",
       "L 366.393724 328.399019 \n",
       "L 372.542485 329.176327 \n",
       "L 378.691245 330.003944 \n",
       "L 384.840005 330.707002 \n",
       "L 390.988765 331.345955 \n",
       "L 397.137526 331.712125 \n",
       "L 403.286286 332.662117 \n",
       "L 409.435046 333.269633 \n",
       "L 415.583807 333.852259 \n",
       "L 421.732567 334.382083 \n",
       "L 427.881327 335.115851 \n",
       "L 434.030088 335.547219 \n",
       "L 440.178848 336.139213 \n",
       "L 446.327608 336.671314 \n",
       "L 452.476369 337.084797 \n",
       "L 458.625129 337.574182 \n",
       "L 464.773889 338.015325 \n",
       "L 470.92265 338.085826 \n",
       "L 477.07141 338.86226 \n",
       "L 483.22017 338.926916 \n",
       "L 489.368931 339.373034 \n",
       "L 495.517691 339.730658 \n",
       "L 501.666451 340.361227 \n",
       "L 507.815212 340.723872 \n",
       "L 513.963972 341.060325 \n",
       "L 520.112732 341.208928 \n",
       "L 526.261493 341.531537 \n",
       "L 532.410253 342.003622 \n",
       "L 538.559013 341.901894 \n",
       "L 544.707774 342.578885 \n",
       "L 550.856534 343.007874 \n",
       "L 557.005294 343.160856 \n",
       "L 563.154055 343.557944 \n",
       "L 569.302815 343.799446 \n",
       "L 575.451575 343.99341 \n",
       "L 581.600336 344.42946 \n",
       "L 587.749096 344.603936 \n",
       "L 593.897856 344.805916 \n",
       "L 600.046617 345.100206 \n",
       "L 606.195377 345.239905 \n",
       "L 612.344137 345.448863 \n",
       "L 618.492898 345.737132 \n",
       "L 624.641658 345.981647 \n",
       "L 630.790418 346.239968 \n",
       "L 636.939179 346.42097 \n",
       "L 643.087939 346.701637 \n",
       "L 649.236699 346.538932 \n",
       "L 655.38546 347.086686 \n",
       "L 661.53422 346.675912 \n",
       "L 667.68298 347.404073 \n",
       "L 673.831741 347.552933 \n",
       "L 679.980501 347.410972 \n",
       "L 686.129261 347.957201 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_74\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 363.187222 \n",
       "L 83.550749 364.611345 \n",
       "L 89.699509 365.211746 \n",
       "L 95.84827 365.603404 \n",
       "L 101.99703 365.853702 \n",
       "L 108.14579 366.002638 \n",
       "L 114.294551 366.047258 \n",
       "L 120.443311 366.066521 \n",
       "L 126.592071 366.067726 \n",
       "L 132.740832 366.064901 \n",
       "L 138.889592 366.063047 \n",
       "L 145.038352 366.057452 \n",
       "L 151.187113 366.053496 \n",
       "L 157.335873 366.053872 \n",
       "L 163.484633 366.056892 \n",
       "L 169.633394 366.055865 \n",
       "L 175.782154 366.061186 \n",
       "L 181.930914 366.076419 \n",
       "L 188.079675 366.098647 \n",
       "L 194.228435 366.153321 \n",
       "L 200.377195 366.221156 \n",
       "L 206.525956 366.344898 \n",
       "L 212.674716 366.457648 \n",
       "L 218.823476 366.605246 \n",
       "L 224.972237 366.796295 \n",
       "L 231.120997 366.974627 \n",
       "L 237.269757 367.239292 \n",
       "L 243.418518 367.538287 \n",
       "L 249.567278 367.782021 \n",
       "L 255.716038 367.80618 \n",
       "L 261.864799 368.018097 \n",
       "L 268.013559 368.092991 \n",
       "L 274.162319 368.115878 \n",
       "L 280.31108 368.177691 \n",
       "L 286.45984 368.200738 \n",
       "L 292.6086 368.195354 \n",
       "L 298.757361 368.257533 \n",
       "L 304.906121 368.163471 \n",
       "L 311.054881 368.327683 \n",
       "L 317.203642 368.329208 \n",
       "L 323.352402 368.371129 \n",
       "L 329.501162 368.386965 \n",
       "L 335.649923 368.395109 \n",
       "L 341.798683 368.42872 \n",
       "L 347.947443 368.457292 \n",
       "L 354.096204 368.44984 \n",
       "L 360.244964 368.460456 \n",
       "L 366.393724 368.474733 \n",
       "L 372.542485 368.511202 \n",
       "L 378.691245 368.53452 \n",
       "L 384.840005 368.535729 \n",
       "L 390.988765 368.556503 \n",
       "L 397.137526 368.58456 \n",
       "L 403.286286 368.576483 \n",
       "L 409.435046 368.616344 \n",
       "L 415.583807 368.629007 \n",
       "L 421.732567 368.609233 \n",
       "L 427.881327 368.636847 \n",
       "L 434.030088 368.67112 \n",
       "L 440.178848 368.597338 \n",
       "L 446.327608 368.682002 \n",
       "L 452.476369 368.697753 \n",
       "L 458.625129 368.707378 \n",
       "L 464.773889 368.716129 \n",
       "L 470.92265 368.7046 \n",
       "L 477.07141 368.735752 \n",
       "L 483.22017 368.746818 \n",
       "L 489.368931 368.763657 \n",
       "L 495.517691 368.77376 \n",
       "L 501.666451 368.796142 \n",
       "L 507.815212 368.766783 \n",
       "L 513.963972 368.79246 \n",
       "L 520.112732 368.812076 \n",
       "L 526.261493 368.832706 \n",
       "L 532.410253 368.846763 \n",
       "L 538.559013 368.86427 \n",
       "L 544.707774 368.864913 \n",
       "L 550.856534 368.8754 \n",
       "L 557.005294 368.887929 \n",
       "L 563.154055 368.87774 \n",
       "L 569.302815 368.881069 \n",
       "L 575.451575 368.916259 \n",
       "L 581.600336 368.8797 \n",
       "L 587.749096 368.956957 \n",
       "L 593.897856 368.960441 \n",
       "L 600.046617 368.930216 \n",
       "L 606.195377 368.943667 \n",
       "L 612.344137 368.932323 \n",
       "L 618.492898 368.946444 \n",
       "L 624.641658 369.021217 \n",
       "L 630.790418 368.997988 \n",
       "L 636.939179 369.020865 \n",
       "L 643.087939 369.014242 \n",
       "L 649.236699 369.040627 \n",
       "L 655.38546 369.074207 \n",
       "L 661.53422 369.035772 \n",
       "L 667.68298 369.072051 \n",
       "L 673.831741 369.075439 \n",
       "L 679.980501 369.106639 \n",
       "L 686.129261 369.060862 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_75\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 336.560767 \n",
       "L 83.550749 348.707899 \n",
       "L 89.699509 349.95874 \n",
       "L 95.84827 353.599052 \n",
       "L 101.99703 355.102028 \n",
       "L 108.14579 355.945339 \n",
       "L 114.294551 355.934213 \n",
       "L 120.443311 357.451356 \n",
       "L 126.592071 357.697157 \n",
       "L 132.740832 356.750454 \n",
       "L 138.889592 357.777729 \n",
       "L 145.038352 358.799126 \n",
       "L 151.187113 358.412144 \n",
       "L 157.335873 358.414026 \n",
       "L 163.484633 359.36099 \n",
       "L 169.633394 359.104275 \n",
       "L 175.782154 358.925376 \n",
       "L 181.930914 359.246366 \n",
       "L 188.079675 358.747064 \n",
       "L 194.228435 359.610803 \n",
       "L 200.377195 360.250301 \n",
       "L 206.525956 360.049377 \n",
       "L 212.674716 359.118907 \n",
       "L 218.823476 360.444032 \n",
       "L 224.972237 360.227755 \n",
       "L 231.120997 360.43381 \n",
       "L 237.269757 360.411791 \n",
       "L 243.418518 360.35024 \n",
       "L 249.567278 360.223588 \n",
       "L 255.716038 360.41649 \n",
       "L 261.864799 360.520685 \n",
       "L 268.013559 360.362243 \n",
       "L 274.162319 360.525895 \n",
       "L 280.31108 359.507658 \n",
       "L 286.45984 360.827117 \n",
       "L 292.6086 360.323898 \n",
       "L 298.757361 360.711147 \n",
       "L 304.906121 360.917558 \n",
       "L 311.054881 360.699612 \n",
       "L 317.203642 360.602098 \n",
       "L 323.352402 360.261528 \n",
       "L 329.501162 360.605968 \n",
       "L 335.649923 360.774751 \n",
       "L 341.798683 361.048631 \n",
       "L 347.947443 360.453189 \n",
       "L 354.096204 360.547614 \n",
       "L 360.244964 360.829343 \n",
       "L 366.393724 360.315455 \n",
       "L 372.542485 360.773409 \n",
       "L 378.691245 360.724122 \n",
       "L 384.840005 359.741858 \n",
       "L 390.988765 360.459141 \n",
       "L 397.137526 360.526484 \n",
       "L 403.286286 360.248081 \n",
       "L 409.435046 360.363933 \n",
       "L 415.583807 360.715055 \n",
       "L 421.732567 360.484262 \n",
       "L 427.881327 360.371658 \n",
       "L 434.030088 360.380382 \n",
       "L 440.178848 360.461845 \n",
       "L 446.327608 360.332893 \n",
       "L 452.476369 360.570944 \n",
       "L 458.625129 360.450816 \n",
       "L 464.773889 360.856417 \n",
       "L 470.92265 360.376423 \n",
       "L 477.07141 360.68066 \n",
       "L 483.22017 360.325008 \n",
       "L 489.368931 360.488047 \n",
       "L 495.517691 360.087958 \n",
       "L 501.666451 360.527384 \n",
       "L 507.815212 360.10575 \n",
       "L 513.963972 360.199953 \n",
       "L 520.112732 360.569928 \n",
       "L 526.261493 360.120752 \n",
       "L 532.410253 359.834673 \n",
       "L 538.559013 360.193755 \n",
       "L 544.707774 360.680435 \n",
       "L 550.856534 360.595179 \n",
       "L 557.005294 360.102275 \n",
       "L 563.154055 360.438099 \n",
       "L 569.302815 360.43483 \n",
       "L 575.451575 360.128707 \n",
       "L 581.600336 360.321821 \n",
       "L 587.749096 359.787211 \n",
       "L 593.897856 360.361091 \n",
       "L 600.046617 359.907497 \n",
       "L 606.195377 360.483463 \n",
       "L 612.344137 360.217902 \n",
       "L 618.492898 359.889705 \n",
       "L 624.641658 360.2937 \n",
       "L 630.790418 359.97142 \n",
       "L 636.939179 360.033256 \n",
       "L 643.087939 360.397005 \n",
       "L 649.236699 359.571232 \n",
       "L 655.38546 359.903551 \n",
       "L 661.53422 360.312442 \n",
       "L 667.68298 359.700429 \n",
       "L 673.831741 360.226607 \n",
       "L 679.980501 360.302016 \n",
       "L 686.129261 359.829723 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_76\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 369.242708 \n",
       "L 83.550749 369.71578 \n",
       "L 89.699509 369.894305 \n",
       "L 95.84827 369.777559 \n",
       "L 101.99703 369.980036 \n",
       "L 108.14579 370.154098 \n",
       "L 114.294551 370.089472 \n",
       "L 120.443311 370.021081 \n",
       "L 126.592071 370.297323 \n",
       "L 132.740832 370.268954 \n",
       "L 138.889592 370.297567 \n",
       "L 145.038352 370.170518 \n",
       "L 151.187113 370.099736 \n",
       "L 157.335873 370.202668 \n",
       "L 163.484633 370.303239 \n",
       "L 169.633394 370.361684 \n",
       "L 175.782154 370.294306 \n",
       "L 181.930914 370.313342 \n",
       "L 188.079675 370.354726 \n",
       "L 194.228435 370.306013 \n",
       "L 200.377195 370.283145 \n",
       "L 206.525956 370.339673 \n",
       "L 212.674716 370.232027 \n",
       "L 218.823476 370.214832 \n",
       "L 224.972237 370.243006 \n",
       "L 231.120997 370.225649 \n",
       "L 237.269757 370.297648 \n",
       "L 243.418518 370.25557 \n",
       "L 249.567278 370.154598 \n",
       "L 255.716038 370.241677 \n",
       "L 261.864799 370.268725 \n",
       "L 268.013559 370.404288 \n",
       "L 274.162319 370.333451 \n",
       "L 280.31108 370.319982 \n",
       "L 286.45984 370.092266 \n",
       "L 292.6086 370.334329 \n",
       "L 298.757361 370.27539 \n",
       "L 304.906121 370.204748 \n",
       "L 311.054881 370.290807 \n",
       "L 317.203642 370.328619 \n",
       "L 323.352402 370.273471 \n",
       "L 329.501162 370.192733 \n",
       "L 335.649923 370.254799 \n",
       "L 341.798683 370.321138 \n",
       "L 347.947443 370.259615 \n",
       "L 354.096204 370.280655 \n",
       "L 360.244964 370.075218 \n",
       "L 366.393724 370.203566 \n",
       "L 372.542485 370.336156 \n",
       "L 378.691245 370.246385 \n",
       "L 384.840005 370.205487 \n",
       "L 390.988765 370.308154 \n",
       "L 397.137526 370.285586 \n",
       "L 403.286286 370.335067 \n",
       "L 409.435046 370.179121 \n",
       "L 415.583807 370.206872 \n",
       "L 421.732567 370.241307 \n",
       "L 427.881327 370.18988 \n",
       "L 434.030088 370.187103 \n",
       "L 440.178848 370.291902 \n",
       "L 446.327608 370.254263 \n",
       "L 452.476369 370.201343 \n",
       "L 458.625129 370.285159 \n",
       "L 464.773889 370.195542 \n",
       "L 470.92265 370.302019 \n",
       "L 477.07141 370.22404 \n",
       "L 483.22017 370.276989 \n",
       "L 489.368931 370.318641 \n",
       "L 495.517691 370.207749 \n",
       "L 501.666451 370.249216 \n",
       "L 507.815212 370.322063 \n",
       "L 513.963972 370.285995 \n",
       "L 520.112732 370.268195 \n",
       "L 526.261493 370.08596 \n",
       "L 532.410253 370.240933 \n",
       "L 538.559013 370.311392 \n",
       "L 544.707774 370.091775 \n",
       "L 550.856534 370.250255 \n",
       "L 557.005294 370.242683 \n",
       "L 563.154055 370.263437 \n",
       "L 569.302815 370.287043 \n",
       "L 575.451575 370.179303 \n",
       "L 581.600336 370.242413 \n",
       "L 587.749096 370.23925 \n",
       "L 593.897856 370.207092 \n",
       "L 600.046617 370.242925 \n",
       "L 606.195377 370.254907 \n",
       "L 612.344137 370.250838 \n",
       "L 618.492898 370.222255 \n",
       "L 624.641658 370.255275 \n",
       "L 630.790418 370.220715 \n",
       "L 636.939179 370.206018 \n",
       "L 643.087939 370.24848 \n",
       "L 649.236699 370.148586 \n",
       "L 655.38546 370.219165 \n",
       "L 661.53422 370.163009 \n",
       "L 667.68298 370.14062 \n",
       "L 673.831741 370.25497 \n",
       "L 679.980501 370.22309 \n",
       "L 686.129261 370.256813 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_77\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 333.487732 \n",
       "L 83.550749 349.923463 \n",
       "L 89.699509 353.118794 \n",
       "L 95.84827 354.032709 \n",
       "L 101.99703 355.715645 \n",
       "L 108.14579 355.681912 \n",
       "L 114.294551 356.858772 \n",
       "L 120.443311 357.325644 \n",
       "L 126.592071 357.304956 \n",
       "L 132.740832 358.160913 \n",
       "L 138.889592 358.758143 \n",
       "L 145.038352 358.278962 \n",
       "L 151.187113 359.312979 \n",
       "L 157.335873 359.362486 \n",
       "L 163.484633 359.791005 \n",
       "L 169.633394 359.473529 \n",
       "L 175.782154 358.947597 \n",
       "L 181.930914 360.110439 \n",
       "L 188.079675 359.915489 \n",
       "L 194.228435 359.585597 \n",
       "L 200.377195 360.126313 \n",
       "L 206.525956 360.617089 \n",
       "L 212.674716 360.29272 \n",
       "L 218.823476 360.551575 \n",
       "L 224.972237 360.241442 \n",
       "L 231.120997 360.548428 \n",
       "L 237.269757 360.525098 \n",
       "L 243.418518 359.431657 \n",
       "L 249.567278 359.652735 \n",
       "L 255.716038 360.643713 \n",
       "L 261.864799 359.581884 \n",
       "L 268.013559 360.314004 \n",
       "L 274.162319 360.552124 \n",
       "L 280.31108 360.196385 \n",
       "L 286.45984 360.136955 \n",
       "L 292.6086 360.095674 \n",
       "L 298.757361 359.82858 \n",
       "L 304.906121 360.485281 \n",
       "L 311.054881 360.544517 \n",
       "L 317.203642 360.257303 \n",
       "L 323.352402 360.146821 \n",
       "L 329.501162 360.473974 \n",
       "L 335.649923 359.925473 \n",
       "L 341.798683 360.613387 \n",
       "L 347.947443 360.660416 \n",
       "L 354.096204 360.308075 \n",
       "L 360.244964 360.495527 \n",
       "L 366.393724 360.757884 \n",
       "L 372.542485 360.658669 \n",
       "L 378.691245 359.958879 \n",
       "L 384.840005 360.309338 \n",
       "L 390.988765 360.320221 \n",
       "L 397.137526 360.619574 \n",
       "L 403.286286 360.01216 \n",
       "L 409.435046 360.060756 \n",
       "L 415.583807 359.61971 \n",
       "L 421.732567 359.518162 \n",
       "L 427.881327 360.461165 \n",
       "L 434.030088 359.689247 \n",
       "L 440.178848 360.378665 \n",
       "L 446.327608 359.604947 \n",
       "L 452.476369 360.389623 \n",
       "L 458.625129 360.0735 \n",
       "L 464.773889 359.38622 \n",
       "L 470.92265 360.756639 \n",
       "L 477.07141 360.104026 \n",
       "L 483.22017 360.104381 \n",
       "L 489.368931 360.431984 \n",
       "L 495.517691 360.441053 \n",
       "L 501.666451 359.698398 \n",
       "L 507.815212 360.36633 \n",
       "L 513.963972 360.054723 \n",
       "L 520.112732 360.011267 \n",
       "L 526.261493 359.904439 \n",
       "L 532.410253 360.036972 \n",
       "L 538.559013 360.17983 \n",
       "L 544.707774 360.285956 \n",
       "L 550.856534 359.950236 \n",
       "L 557.005294 359.492066 \n",
       "L 563.154055 359.980883 \n",
       "L 569.302815 359.199072 \n",
       "L 575.451575 360.074271 \n",
       "L 581.600336 360.285644 \n",
       "L 587.749096 359.612273 \n",
       "L 593.897856 359.284974 \n",
       "L 600.046617 360.117331 \n",
       "L 606.195377 359.740509 \n",
       "L 612.344137 360.081394 \n",
       "L 618.492898 359.353494 \n",
       "L 624.641658 359.138624 \n",
       "L 630.790418 359.706022 \n",
       "L 636.939179 359.932097 \n",
       "L 643.087939 360.077913 \n",
       "L 649.236699 359.778896 \n",
       "L 655.38546 359.771077 \n",
       "L 661.53422 359.995319 \n",
       "L 667.68298 359.477799 \n",
       "L 673.831741 359.491628 \n",
       "L 679.980501 359.630668 \n",
       "L 686.129261 359.849004 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_78\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 369.529715 \n",
       "L 83.550749 369.827239 \n",
       "L 89.699509 370.130258 \n",
       "L 95.84827 369.853684 \n",
       "L 101.99703 370.015791 \n",
       "L 108.14579 369.916629 \n",
       "L 114.294551 370.023155 \n",
       "L 120.443311 370.220454 \n",
       "L 126.592071 370.001365 \n",
       "L 132.740832 370.298915 \n",
       "L 138.889592 369.9292 \n",
       "L 145.038352 370.339096 \n",
       "L 151.187113 370.250375 \n",
       "L 157.335873 370.189789 \n",
       "L 163.484633 370.258393 \n",
       "L 169.633394 370.293199 \n",
       "L 175.782154 370.362039 \n",
       "L 181.930914 370.233229 \n",
       "L 188.079675 370.391422 \n",
       "L 194.228435 370.125414 \n",
       "L 200.377195 370.240935 \n",
       "L 206.525956 370.252628 \n",
       "L 212.674716 370.271643 \n",
       "L 218.823476 370.313867 \n",
       "L 224.972237 370.079275 \n",
       "L 231.120997 370.339216 \n",
       "L 237.269757 370.194761 \n",
       "L 243.418518 370.240587 \n",
       "L 249.567278 370.214316 \n",
       "L 255.716038 370.299665 \n",
       "L 261.864799 370.315254 \n",
       "L 268.013559 370.220167 \n",
       "L 274.162319 370.200737 \n",
       "L 280.31108 370.325405 \n",
       "L 286.45984 370.166452 \n",
       "L 292.6086 370.331546 \n",
       "L 298.757361 370.194895 \n",
       "L 304.906121 370.283804 \n",
       "L 311.054881 370.267137 \n",
       "L 317.203642 370.077382 \n",
       "L 323.352402 370.311042 \n",
       "L 329.501162 370.33223 \n",
       "L 335.649923 370.272915 \n",
       "L 341.798683 370.234021 \n",
       "L 347.947443 370.269351 \n",
       "L 354.096204 370.22156 \n",
       "L 360.244964 370.28172 \n",
       "L 366.393724 370.265096 \n",
       "L 372.542485 370.220299 \n",
       "L 378.691245 370.172121 \n",
       "L 384.840005 370.276301 \n",
       "L 390.988765 370.240168 \n",
       "L 397.137526 370.389998 \n",
       "L 403.286286 370.187437 \n",
       "L 409.435046 370.198447 \n",
       "L 415.583807 370.275144 \n",
       "L 421.732567 370.266723 \n",
       "L 427.881327 370.206509 \n",
       "L 434.030088 370.249421 \n",
       "L 440.178848 370.090046 \n",
       "L 446.327608 370.128953 \n",
       "L 452.476369 370.295142 \n",
       "L 458.625129 370.329514 \n",
       "L 464.773889 370.282483 \n",
       "L 470.92265 370.240558 \n",
       "L 477.07141 370.237237 \n",
       "L 483.22017 370.242257 \n",
       "L 489.368931 370.22328 \n",
       "L 495.517691 370.230978 \n",
       "L 501.666451 370.318848 \n",
       "L 507.815212 370.231149 \n",
       "L 513.963972 370.181733 \n",
       "L 520.112732 370.222003 \n",
       "L 526.261493 370.232014 \n",
       "L 532.410253 370.303151 \n",
       "L 538.559013 370.314869 \n",
       "L 544.707774 370.196048 \n",
       "L 550.856534 370.290954 \n",
       "L 557.005294 370.316518 \n",
       "L 563.154055 370.255175 \n",
       "L 569.302815 370.140439 \n",
       "L 575.451575 370.254399 \n",
       "L 581.600336 370.20579 \n",
       "L 587.749096 370.232972 \n",
       "L 593.897856 370.310062 \n",
       "L 600.046617 370.244307 \n",
       "L 606.195377 370.188292 \n",
       "L 612.344137 370.162675 \n",
       "L 618.492898 370.182764 \n",
       "L 624.641658 370.207871 \n",
       "L 630.790418 370.21402 \n",
       "L 636.939179 370.216849 \n",
       "L 643.087939 370.216319 \n",
       "L 649.236699 370.127422 \n",
       "L 655.38546 370.24445 \n",
       "L 661.53422 370.207465 \n",
       "L 667.68298 370.186426 \n",
       "L 673.831741 370.228661 \n",
       "L 679.980501 370.192152 \n",
       "L 686.129261 370.259378 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_79\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 340.530248 \n",
       "L 83.550749 350.18304 \n",
       "L 89.699509 354.642141 \n",
       "L 95.84827 355.631986 \n",
       "L 101.99703 356.263342 \n",
       "L 108.14579 357.834271 \n",
       "L 114.294551 358.034777 \n",
       "L 120.443311 357.755308 \n",
       "L 126.592071 357.969803 \n",
       "L 132.740832 358.243325 \n",
       "L 138.889592 358.533251 \n",
       "L 145.038352 358.548985 \n",
       "L 151.187113 359.518427 \n",
       "L 157.335873 359.580608 \n",
       "L 163.484633 359.261602 \n",
       "L 169.633394 359.474925 \n",
       "L 175.782154 359.396892 \n",
       "L 181.930914 359.899943 \n",
       "L 188.079675 360.390939 \n",
       "L 194.228435 360.178157 \n",
       "L 200.377195 359.395582 \n",
       "L 206.525956 360.317129 \n",
       "L 212.674716 360.495783 \n",
       "L 218.823476 360.385657 \n",
       "L 224.972237 359.964941 \n",
       "L 231.120997 360.835754 \n",
       "L 237.269757 360.353783 \n",
       "L 243.418518 360.279211 \n",
       "L 249.567278 360.676566 \n",
       "L 255.716038 360.146432 \n",
       "L 261.864799 360.504053 \n",
       "L 268.013559 360.880957 \n",
       "L 274.162319 360.235589 \n",
       "L 280.31108 359.857829 \n",
       "L 286.45984 360.604501 \n",
       "L 292.6086 360.528274 \n",
       "L 298.757361 360.225336 \n",
       "L 304.906121 360.437616 \n",
       "L 311.054881 360.449786 \n",
       "L 317.203642 360.877677 \n",
       "L 323.352402 360.336735 \n",
       "L 329.501162 360.065354 \n",
       "L 335.649923 360.634924 \n",
       "L 341.798683 360.513866 \n",
       "L 347.947443 359.631909 \n",
       "L 354.096204 359.794469 \n",
       "L 360.244964 359.672694 \n",
       "L 366.393724 360.120976 \n",
       "L 372.542485 359.320613 \n",
       "L 378.691245 359.425442 \n",
       "L 384.840005 359.908858 \n",
       "L 390.988765 359.719789 \n",
       "L 397.137526 360.096175 \n",
       "L 403.286286 359.749274 \n",
       "L 409.435046 359.921438 \n",
       "L 415.583807 360.501124 \n",
       "L 421.732567 360.093148 \n",
       "L 427.881327 359.646594 \n",
       "L 434.030088 360.106809 \n",
       "L 440.178848 359.965955 \n",
       "L 446.327608 360.074084 \n",
       "L 452.476369 359.434815 \n",
       "L 458.625129 360.184735 \n",
       "L 464.773889 359.721926 \n",
       "L 470.92265 359.701772 \n",
       "L 477.07141 360.08829 \n",
       "L 483.22017 359.630794 \n",
       "L 489.368931 360.22235 \n",
       "L 495.517691 359.918416 \n",
       "L 501.666451 359.112809 \n",
       "L 507.815212 359.158047 \n",
       "L 513.963972 359.698009 \n",
       "L 520.112732 359.546583 \n",
       "L 526.261493 359.417649 \n",
       "L 532.410253 358.92916 \n",
       "L 538.559013 359.477386 \n",
       "L 544.707774 359.590964 \n",
       "L 550.856534 359.573993 \n",
       "L 557.005294 359.253923 \n",
       "L 563.154055 359.594188 \n",
       "L 569.302815 359.062804 \n",
       "L 575.451575 359.20685 \n",
       "L 581.600336 359.74383 \n",
       "L 587.749096 359.381159 \n",
       "L 593.897856 359.347375 \n",
       "L 600.046617 359.381187 \n",
       "L 606.195377 359.668722 \n",
       "L 612.344137 359.247282 \n",
       "L 618.492898 358.768584 \n",
       "L 624.641658 358.795247 \n",
       "L 630.790418 359.631313 \n",
       "L 636.939179 359.537423 \n",
       "L 643.087939 359.614789 \n",
       "L 649.236699 359.307977 \n",
       "L 655.38546 358.946575 \n",
       "L 661.53422 358.964835 \n",
       "L 667.68298 359.587514 \n",
       "L 673.831741 359.575738 \n",
       "L 679.980501 359.038865 \n",
       "L 686.129261 359.541595 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_80\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 367.991741 \n",
       "L 83.550749 369.497041 \n",
       "L 89.699509 369.954275 \n",
       "L 95.84827 369.775001 \n",
       "L 101.99703 370.018446 \n",
       "L 108.14579 370.032999 \n",
       "L 114.294551 370.080863 \n",
       "L 120.443311 370.131412 \n",
       "L 126.592071 370.114686 \n",
       "L 132.740832 370.179087 \n",
       "L 138.889592 370.132473 \n",
       "L 145.038352 370.169966 \n",
       "L 151.187113 370.259798 \n",
       "L 157.335873 370.300439 \n",
       "L 163.484633 369.891022 \n",
       "L 169.633394 370.244491 \n",
       "L 175.782154 370.216279 \n",
       "L 181.930914 370.255284 \n",
       "L 188.079675 370.246123 \n",
       "L 194.228435 370.173144 \n",
       "L 200.377195 370.095998 \n",
       "L 206.525956 370.314736 \n",
       "L 212.674716 370.065382 \n",
       "L 218.823476 370.228471 \n",
       "L 224.972237 370.201731 \n",
       "L 231.120997 370.197364 \n",
       "L 237.269757 370.323669 \n",
       "L 243.418518 370.201406 \n",
       "L 249.567278 370.227537 \n",
       "L 255.716038 370.22361 \n",
       "L 261.864799 370.188902 \n",
       "L 268.013559 370.206416 \n",
       "L 274.162319 370.200131 \n",
       "L 280.31108 370.278962 \n",
       "L 286.45984 370.262995 \n",
       "L 292.6086 370.184407 \n",
       "L 298.757361 370.277885 \n",
       "L 304.906121 370.211373 \n",
       "L 311.054881 370.302658 \n",
       "L 317.203642 370.22148 \n",
       "L 323.352402 370.185627 \n",
       "L 329.501162 370.173044 \n",
       "L 335.649923 370.173098 \n",
       "L 341.798683 370.194077 \n",
       "L 347.947443 370.161533 \n",
       "L 354.096204 370.198803 \n",
       "L 360.244964 370.155856 \n",
       "L 366.393724 370.204723 \n",
       "L 372.542485 370.253999 \n",
       "L 378.691245 370.226603 \n",
       "L 384.840005 370.322001 \n",
       "L 390.988765 370.291982 \n",
       "L 397.137526 370.258199 \n",
       "L 403.286286 370.311084 \n",
       "L 409.435046 370.279394 \n",
       "L 415.583807 370.221381 \n",
       "L 421.732567 370.126701 \n",
       "L 427.881327 370.181145 \n",
       "L 434.030088 370.171022 \n",
       "L 440.178848 370.234891 \n",
       "L 446.327608 370.265815 \n",
       "L 452.476369 370.221245 \n",
       "L 458.625129 370.266094 \n",
       "L 464.773889 370.21903 \n",
       "L 470.92265 370.136599 \n",
       "L 477.07141 370.248791 \n",
       "L 483.22017 370.262518 \n",
       "L 489.368931 370.137053 \n",
       "L 495.517691 370.310932 \n",
       "L 501.666451 370.14536 \n",
       "L 507.815212 370.178182 \n",
       "L 513.963972 370.164574 \n",
       "L 520.112732 370.237304 \n",
       "L 526.261493 370.23297 \n",
       "L 532.410253 370.201818 \n",
       "L 538.559013 370.173345 \n",
       "L 544.707774 370.151182 \n",
       "L 550.856534 370.196971 \n",
       "L 557.005294 370.192162 \n",
       "L 563.154055 370.177439 \n",
       "L 569.302815 370.226033 \n",
       "L 575.451575 370.158616 \n",
       "L 581.600336 370.165736 \n",
       "L 587.749096 370.244165 \n",
       "L 593.897856 370.222067 \n",
       "L 600.046617 370.267648 \n",
       "L 606.195377 370.126601 \n",
       "L 612.344137 370.310785 \n",
       "L 618.492898 370.274332 \n",
       "L 624.641658 370.29275 \n",
       "L 630.790418 370.328527 \n",
       "L 636.939179 370.285716 \n",
       "L 643.087939 370.140602 \n",
       "L 649.236699 370.23257 \n",
       "L 655.38546 370.251015 \n",
       "L 661.53422 370.241713 \n",
       "L 667.68298 370.265622 \n",
       "L 673.831741 370.260324 \n",
       "L 679.980501 370.289124 \n",
       "L 686.129261 370.261455 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_81\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 276.296813 \n",
       "L 83.550749 286.971128 \n",
       "L 89.699509 288.631658 \n",
       "L 95.84827 289.098031 \n",
       "L 101.99703 289.134229 \n",
       "L 108.14579 289.222861 \n",
       "L 114.294551 289.264312 \n",
       "L 120.443311 289.280248 \n",
       "L 126.592071 289.296148 \n",
       "L 132.740832 289.310402 \n",
       "L 138.889592 289.338789 \n",
       "L 145.038352 289.371403 \n",
       "L 151.187113 289.409867 \n",
       "L 157.335873 289.441141 \n",
       "L 163.484633 289.534783 \n",
       "L 169.633394 289.631476 \n",
       "L 175.782154 289.787102 \n",
       "L 181.930914 290.069945 \n",
       "L 188.079675 290.563222 \n",
       "L 194.228435 291.48244 \n",
       "L 200.377195 293.489992 \n",
       "L 206.525956 297.684457 \n",
       "L 212.674716 305.102241 \n",
       "L 218.823476 311.4395 \n",
       "L 224.972237 316.112596 \n",
       "L 231.120997 318.887432 \n",
       "L 237.269757 321.151077 \n",
       "L 243.418518 322.830311 \n",
       "L 249.567278 324.471741 \n",
       "L 255.716038 325.348328 \n",
       "L 261.864799 327.376862 \n",
       "L 268.013559 328.989951 \n",
       "L 274.162319 330.14672 \n",
       "L 280.31108 331.887372 \n",
       "L 286.45984 332.837592 \n",
       "L 292.6086 334.573451 \n",
       "L 298.757361 335.632074 \n",
       "L 304.906121 336.526179 \n",
       "L 311.054881 337.311807 \n",
       "L 317.203642 338.409814 \n",
       "L 323.352402 339.191679 \n",
       "L 329.501162 340.121241 \n",
       "L 335.649923 340.301691 \n",
       "L 341.798683 341.559379 \n",
       "L 347.947443 342.193657 \n",
       "L 354.096204 342.717602 \n",
       "L 360.244964 342.132407 \n",
       "L 366.393724 343.692334 \n",
       "L 372.542485 344.38074 \n",
       "L 378.691245 344.64438 \n",
       "L 384.840005 345.305515 \n",
       "L 390.988765 345.636007 \n",
       "L 397.137526 345.942211 \n",
       "L 403.286286 346.600506 \n",
       "L 409.435046 346.870198 \n",
       "L 415.583807 347.251306 \n",
       "L 421.732567 347.392826 \n",
       "L 427.881327 347.862431 \n",
       "L 434.030088 348.103686 \n",
       "L 440.178848 348.03446 \n",
       "L 446.327608 348.844332 \n",
       "L 452.476369 348.903599 \n",
       "L 458.625129 349.317899 \n",
       "L 464.773889 349.437254 \n",
       "L 470.92265 349.880289 \n",
       "L 477.07141 350.029111 \n",
       "L 483.22017 349.343124 \n",
       "L 489.368931 350.396121 \n",
       "L 495.517691 350.190527 \n",
       "L 501.666451 350.200625 \n",
       "L 507.815212 350.781981 \n",
       "L 513.963972 350.571446 \n",
       "L 520.112732 351.169543 \n",
       "L 526.261493 351.403588 \n",
       "L 532.410253 351.543062 \n",
       "L 538.559013 351.701548 \n",
       "L 544.707774 351.794846 \n",
       "L 550.856534 351.959028 \n",
       "L 557.005294 351.629885 \n",
       "L 563.154055 352.199274 \n",
       "L 569.302815 351.461554 \n",
       "L 575.451575 352.286972 \n",
       "L 581.600336 352.402528 \n",
       "L 587.749096 352.100655 \n",
       "L 593.897856 352.744238 \n",
       "L 600.046617 352.793562 \n",
       "L 606.195377 352.811629 \n",
       "L 612.344137 352.371499 \n",
       "L 618.492898 353.083847 \n",
       "L 624.641658 353.072221 \n",
       "L 630.790418 353.236303 \n",
       "L 636.939179 353.292268 \n",
       "L 643.087939 353.310647 \n",
       "L 649.236699 353.287721 \n",
       "L 655.38546 353.472128 \n",
       "L 661.53422 353.570444 \n",
       "L 667.68298 353.634853 \n",
       "L 673.831741 353.712238 \n",
       "L 679.980501 353.07962 \n",
       "L 686.129261 353.522928 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_82\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.061453 \n",
       "L 83.550749 366.02891 \n",
       "L 89.699509 366.025014 \n",
       "L 95.84827 366.020174 \n",
       "L 101.99703 366.006075 \n",
       "L 108.14579 366.021481 \n",
       "L 114.294551 366.026355 \n",
       "L 120.443311 366.006458 \n",
       "L 126.592071 366.025438 \n",
       "L 132.740832 366.006522 \n",
       "L 138.889592 366.038497 \n",
       "L 145.038352 366.056175 \n",
       "L 151.187113 366.067305 \n",
       "L 157.335873 366.133487 \n",
       "L 163.484633 366.268112 \n",
       "L 169.633394 366.71624 \n",
       "L 175.782154 367.206766 \n",
       "L 181.930914 367.964762 \n",
       "L 188.079675 368.102664 \n",
       "L 194.228435 368.184555 \n",
       "L 200.377195 368.261564 \n",
       "L 206.525956 368.296487 \n",
       "L 212.674716 368.365976 \n",
       "L 218.823476 368.402813 \n",
       "L 224.972237 368.408941 \n",
       "L 231.120997 368.40328 \n",
       "L 237.269757 368.500149 \n",
       "L 243.418518 368.541299 \n",
       "L 249.567278 368.560727 \n",
       "L 255.716038 368.522809 \n",
       "L 261.864799 368.653694 \n",
       "L 268.013559 368.639789 \n",
       "L 274.162319 368.712544 \n",
       "L 280.31108 368.742351 \n",
       "L 286.45984 368.773235 \n",
       "L 292.6086 368.797286 \n",
       "L 298.757361 368.797952 \n",
       "L 304.906121 368.804575 \n",
       "L 311.054881 368.867096 \n",
       "L 317.203642 368.883988 \n",
       "L 323.352402 368.911876 \n",
       "L 329.501162 368.936949 \n",
       "L 335.649923 368.951521 \n",
       "L 341.798683 368.965745 \n",
       "L 347.947443 368.980438 \n",
       "L 354.096204 369.023959 \n",
       "L 360.244964 369.038969 \n",
       "L 366.393724 369.051793 \n",
       "L 372.542485 369.066197 \n",
       "L 378.691245 369.121448 \n",
       "L 384.840005 369.147685 \n",
       "L 390.988765 369.144159 \n",
       "L 397.137526 369.157543 \n",
       "L 403.286286 369.199137 \n",
       "L 409.435046 369.16758 \n",
       "L 415.583807 369.128582 \n",
       "L 421.732567 369.246607 \n",
       "L 427.881327 369.258569 \n",
       "L 434.030088 369.305222 \n",
       "L 440.178848 369.30822 \n",
       "L 446.327608 369.345863 \n",
       "L 452.476369 369.326893 \n",
       "L 458.625129 369.341526 \n",
       "L 464.773889 369.320122 \n",
       "L 470.92265 369.401968 \n",
       "L 477.07141 369.439068 \n",
       "L 483.22017 369.415459 \n",
       "L 489.368931 369.445204 \n",
       "L 495.517691 369.364486 \n",
       "L 501.666451 369.479013 \n",
       "L 507.815212 369.490591 \n",
       "L 513.963972 369.489369 \n",
       "L 520.112732 369.442895 \n",
       "L 526.261493 369.462273 \n",
       "L 532.410253 369.540365 \n",
       "L 538.559013 369.406791 \n",
       "L 544.707774 369.565359 \n",
       "L 550.856534 369.572897 \n",
       "L 557.005294 369.459432 \n",
       "L 563.154055 369.600783 \n",
       "L 569.302815 369.595347 \n",
       "L 575.451575 369.62097 \n",
       "L 581.600336 369.591519 \n",
       "L 587.749096 369.622812 \n",
       "L 593.897856 369.642025 \n",
       "L 600.046617 369.650375 \n",
       "L 606.195377 369.627861 \n",
       "L 612.344137 369.671165 \n",
       "L 618.492898 369.674343 \n",
       "L 624.641658 369.673178 \n",
       "L 630.790418 369.70137 \n",
       "L 636.939179 369.715366 \n",
       "L 643.087939 369.681131 \n",
       "L 649.236699 369.722539 \n",
       "L 655.38546 369.730237 \n",
       "L 661.53422 369.749295 \n",
       "L 667.68298 369.748637 \n",
       "L 673.831741 369.749425 \n",
       "L 679.980501 369.75771 \n",
       "L 686.129261 369.762771 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_83\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 281.485636 \n",
       "L 83.550749 288.252663 \n",
       "L 89.699509 289.104616 \n",
       "L 95.84827 289.227493 \n",
       "L 101.99703 289.275002 \n",
       "L 108.14579 289.293255 \n",
       "L 114.294551 289.307715 \n",
       "L 120.443311 289.337962 \n",
       "L 126.592071 289.35789 \n",
       "L 132.740832 289.405705 \n",
       "L 138.889592 289.457711 \n",
       "L 145.038352 289.520842 \n",
       "L 151.187113 289.59217 \n",
       "L 157.335873 289.732608 \n",
       "L 163.484633 289.942507 \n",
       "L 169.633394 290.239861 \n",
       "L 175.782154 290.878608 \n",
       "L 181.930914 292.28059 \n",
       "L 188.079675 295.497966 \n",
       "L 194.228435 301.538185 \n",
       "L 200.377195 309.173343 \n",
       "L 206.525956 314.601602 \n",
       "L 212.674716 318.29434 \n",
       "L 218.823476 320.320783 \n",
       "L 224.972237 322.48362 \n",
       "L 231.120997 323.938135 \n",
       "L 237.269757 325.554905 \n",
       "L 243.418518 327.200579 \n",
       "L 249.567278 328.574006 \n",
       "L 255.716038 330.214701 \n",
       "L 261.864799 331.108817 \n",
       "L 268.013559 332.817686 \n",
       "L 274.162319 334.302374 \n",
       "L 280.31108 334.678212 \n",
       "L 286.45984 336.491403 \n",
       "L 292.6086 337.726359 \n",
       "L 298.757361 337.676712 \n",
       "L 304.906121 339.590526 \n",
       "L 311.054881 340.481994 \n",
       "L 317.203642 341.239642 \n",
       "L 323.352402 341.827145 \n",
       "L 329.501162 342.494586 \n",
       "L 335.649923 342.646312 \n",
       "L 341.798683 343.159861 \n",
       "L 347.947443 343.834538 \n",
       "L 354.096204 344.655416 \n",
       "L 360.244964 344.894598 \n",
       "L 366.393724 345.559029 \n",
       "L 372.542485 345.463707 \n",
       "L 378.691245 346.144954 \n",
       "L 384.840005 346.606968 \n",
       "L 390.988765 346.715401 \n",
       "L 397.137526 347.274601 \n",
       "L 403.286286 347.645631 \n",
       "L 409.435046 348.056876 \n",
       "L 415.583807 348.294723 \n",
       "L 421.732567 348.497691 \n",
       "L 427.881327 348.822399 \n",
       "L 434.030088 349.125172 \n",
       "L 440.178848 348.541265 \n",
       "L 446.327608 349.629487 \n",
       "L 452.476369 349.833573 \n",
       "L 458.625129 350.063162 \n",
       "L 464.773889 350.187816 \n",
       "L 470.92265 350.381135 \n",
       "L 477.07141 350.609181 \n",
       "L 483.22017 350.286265 \n",
       "L 489.368931 350.916158 \n",
       "L 495.517691 350.178969 \n",
       "L 501.666451 350.968777 \n",
       "L 507.815212 351.277913 \n",
       "L 513.963972 351.346691 \n",
       "L 520.112732 351.770698 \n",
       "L 526.261493 351.824174 \n",
       "L 532.410253 351.715679 \n",
       "L 538.559013 351.902591 \n",
       "L 544.707774 351.895373 \n",
       "L 550.856534 352.425449 \n",
       "L 557.005294 352.193298 \n",
       "L 563.154055 352.644844 \n",
       "L 569.302815 352.62914 \n",
       "L 575.451575 352.674008 \n",
       "L 581.600336 352.523339 \n",
       "L 587.749096 352.952878 \n",
       "L 593.897856 352.757658 \n",
       "L 600.046617 352.81473 \n",
       "L 606.195377 353.316678 \n",
       "L 612.344137 353.319408 \n",
       "L 618.492898 353.425535 \n",
       "L 624.641658 352.78987 \n",
       "L 630.790418 353.125041 \n",
       "L 636.939179 353.651902 \n",
       "L 643.087939 353.72689 \n",
       "L 649.236699 353.23899 \n",
       "L 655.38546 353.746747 \n",
       "L 661.53422 353.868691 \n",
       "L 667.68298 353.944476 \n",
       "L 673.831741 353.674957 \n",
       "L 679.980501 353.983224 \n",
       "L 686.129261 354.096225 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_84\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.061822 \n",
       "L 83.550749 365.998803 \n",
       "L 89.699509 366.013013 \n",
       "L 95.84827 366.016291 \n",
       "L 101.99703 366.023617 \n",
       "L 108.14579 366.018032 \n",
       "L 114.294551 366.016737 \n",
       "L 120.443311 366.026537 \n",
       "L 126.592071 366.019783 \n",
       "L 132.740832 366.019477 \n",
       "L 138.889592 366.019487 \n",
       "L 145.038352 366.027162 \n",
       "L 151.187113 366.047718 \n",
       "L 157.335873 366.062998 \n",
       "L 163.484633 366.136159 \n",
       "L 169.633394 366.300037 \n",
       "L 175.782154 366.786545 \n",
       "L 181.930914 367.627665 \n",
       "L 188.079675 367.864691 \n",
       "L 194.228435 368.066646 \n",
       "L 200.377195 368.20902 \n",
       "L 206.525956 368.215333 \n",
       "L 212.674716 368.343161 \n",
       "L 218.823476 368.36618 \n",
       "L 224.972237 368.363448 \n",
       "L 231.120997 368.418474 \n",
       "L 237.269757 368.492125 \n",
       "L 243.418518 368.486387 \n",
       "L 249.567278 368.448158 \n",
       "L 255.716038 368.554721 \n",
       "L 261.864799 368.67507 \n",
       "L 268.013559 368.676173 \n",
       "L 274.162319 368.765273 \n",
       "L 280.31108 368.762519 \n",
       "L 286.45984 368.824354 \n",
       "L 292.6086 368.838231 \n",
       "L 298.757361 368.882822 \n",
       "L 304.906121 368.909904 \n",
       "L 311.054881 368.938392 \n",
       "L 317.203642 368.965512 \n",
       "L 323.352402 368.946644 \n",
       "L 329.501162 369.007019 \n",
       "L 335.649923 369.042392 \n",
       "L 341.798683 369.048836 \n",
       "L 347.947443 369.072211 \n",
       "L 354.096204 369.09914 \n",
       "L 360.244964 369.133671 \n",
       "L 366.393724 369.046602 \n",
       "L 372.542485 369.16076 \n",
       "L 378.691245 369.201529 \n",
       "L 384.840005 369.146501 \n",
       "L 390.988765 369.159258 \n",
       "L 397.137526 369.264285 \n",
       "L 403.286286 369.22253 \n",
       "L 409.435046 369.231895 \n",
       "L 415.583807 369.319405 \n",
       "L 421.732567 369.349517 \n",
       "L 427.881327 369.148764 \n",
       "L 434.030088 369.391283 \n",
       "L 440.178848 369.349092 \n",
       "L 446.327608 369.381317 \n",
       "L 452.476369 369.345146 \n",
       "L 458.625129 369.413294 \n",
       "L 464.773889 369.448526 \n",
       "L 470.92265 369.457326 \n",
       "L 477.07141 369.4962 \n",
       "L 483.22017 369.472412 \n",
       "L 489.368931 369.52076 \n",
       "L 495.517691 369.530508 \n",
       "L 501.666451 369.529713 \n",
       "L 507.815212 369.55711 \n",
       "L 513.963972 369.528776 \n",
       "L 520.112732 369.559364 \n",
       "L 526.261493 369.596061 \n",
       "L 532.410253 369.585519 \n",
       "L 538.559013 369.59986 \n",
       "L 544.707774 369.614606 \n",
       "L 550.856534 369.608881 \n",
       "L 557.005294 369.638569 \n",
       "L 563.154055 369.65314 \n",
       "L 569.302815 369.659488 \n",
       "L 575.451575 369.669031 \n",
       "L 581.600336 369.676204 \n",
       "L 587.749096 369.640246 \n",
       "L 593.897856 369.671533 \n",
       "L 600.046617 369.701323 \n",
       "L 606.195377 369.711388 \n",
       "L 612.344137 369.635325 \n",
       "L 618.492898 369.697723 \n",
       "L 624.641658 369.714735 \n",
       "L 630.790418 369.741177 \n",
       "L 636.939179 369.733029 \n",
       "L 643.087939 369.683315 \n",
       "L 649.236699 369.750393 \n",
       "L 655.38546 369.757383 \n",
       "L 661.53422 369.764049 \n",
       "L 667.68298 369.773795 \n",
       "L 673.831741 369.761936 \n",
       "L 679.980501 369.774435 \n",
       "L 686.129261 369.786277 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_85\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 284.150623 \n",
       "L 83.550749 288.834116 \n",
       "L 89.699509 289.189463 \n",
       "L 95.84827 289.257049 \n",
       "L 101.99703 289.26268 \n",
       "L 108.14579 289.306062 \n",
       "L 114.294551 289.333736 \n",
       "L 120.443311 289.358994 \n",
       "L 126.592071 289.413438 \n",
       "L 132.740832 289.468986 \n",
       "L 138.889592 289.541718 \n",
       "L 145.038352 289.668251 \n",
       "L 151.187113 289.843583 \n",
       "L 157.335873 290.146925 \n",
       "L 163.484633 290.662602 \n",
       "L 169.633394 291.687499 \n",
       "L 175.782154 293.744257 \n",
       "L 181.930914 297.89154 \n",
       "L 188.079675 304.592351 \n",
       "L 194.228435 311.296895 \n",
       "L 200.377195 315.903884 \n",
       "L 206.525956 319.302218 \n",
       "L 212.674716 320.90375 \n",
       "L 218.823476 322.998185 \n",
       "L 224.972237 324.719274 \n",
       "L 231.120997 326.242519 \n",
       "L 237.269757 327.673868 \n",
       "L 243.418518 329.115601 \n",
       "L 249.567278 330.737402 \n",
       "L 255.716038 332.092927 \n",
       "L 261.864799 332.690322 \n",
       "L 268.013559 333.932816 \n",
       "L 274.162319 335.785298 \n",
       "L 280.31108 335.920412 \n",
       "L 286.45984 337.012956 \n",
       "L 292.6086 337.223343 \n",
       "L 298.757361 339.366085 \n",
       "L 304.906121 340.154083 \n",
       "L 311.054881 340.851614 \n",
       "L 317.203642 341.349185 \n",
       "L 323.352402 342.133309 \n",
       "L 329.501162 342.631397 \n",
       "L 335.649923 343.225477 \n",
       "L 341.798683 343.56629 \n",
       "L 347.947443 343.470205 \n",
       "L 354.096204 344.758345 \n",
       "L 360.244964 344.825899 \n",
       "L 366.393724 345.550666 \n",
       "L 372.542485 345.934827 \n",
       "L 378.691245 346.098215 \n",
       "L 384.840005 346.556391 \n",
       "L 390.988765 346.932344 \n",
       "L 397.137526 346.981382 \n",
       "L 403.286286 347.153393 \n",
       "L 409.435046 347.692566 \n",
       "L 415.583807 348.157166 \n",
       "L 421.732567 348.320242 \n",
       "L 427.881327 348.68396 \n",
       "L 434.030088 348.877984 \n",
       "L 440.178848 349.12063 \n",
       "L 446.327608 348.485926 \n",
       "L 452.476369 349.41552 \n",
       "L 458.625129 349.695332 \n",
       "L 464.773889 350.016996 \n",
       "L 470.92265 348.67865 \n",
       "L 477.07141 350.369067 \n",
       "L 483.22017 350.521222 \n",
       "L 489.368931 349.829721 \n",
       "L 495.517691 350.795271 \n",
       "L 501.666451 350.997922 \n",
       "L 507.815212 350.736423 \n",
       "L 513.963972 351.325644 \n",
       "L 520.112732 350.882175 \n",
       "L 526.261493 351.583362 \n",
       "L 532.410253 351.659106 \n",
       "L 538.559013 351.678634 \n",
       "L 544.707774 351.896693 \n",
       "L 550.856534 351.942103 \n",
       "L 557.005294 351.611713 \n",
       "L 563.154055 352.261464 \n",
       "L 569.302815 352.473401 \n",
       "L 575.451575 352.0548 \n",
       "L 581.600336 352.585884 \n",
       "L 587.749096 352.675319 \n",
       "L 593.897856 352.266941 \n",
       "L 600.046617 352.909432 \n",
       "L 606.195377 353.003434 \n",
       "L 612.344137 352.906423 \n",
       "L 618.492898 352.938386 \n",
       "L 624.641658 353.194899 \n",
       "L 630.790418 352.870686 \n",
       "L 636.939179 353.352483 \n",
       "L 643.087939 353.427867 \n",
       "L 649.236699 353.526734 \n",
       "L 655.38546 353.607941 \n",
       "L 661.53422 353.683106 \n",
       "L 667.68298 353.725015 \n",
       "L 673.831741 353.532001 \n",
       "L 679.980501 353.785148 \n",
       "L 686.129261 352.828604 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_86\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.057904 \n",
       "L 83.550749 366.024299 \n",
       "L 89.699509 366.000186 \n",
       "L 95.84827 366.011804 \n",
       "L 101.99703 366.03016 \n",
       "L 108.14579 366.028098 \n",
       "L 114.294551 366.007301 \n",
       "L 120.443311 366.025749 \n",
       "L 126.592071 366.024987 \n",
       "L 132.740832 366.035696 \n",
       "L 138.889592 366.040136 \n",
       "L 145.038352 366.039977 \n",
       "L 151.187113 366.050166 \n",
       "L 157.335873 366.076358 \n",
       "L 163.484633 366.185734 \n",
       "L 169.633394 366.510272 \n",
       "L 175.782154 367.162128 \n",
       "L 181.930914 367.861151 \n",
       "L 188.079675 368.140289 \n",
       "L 194.228435 368.213917 \n",
       "L 200.377195 368.269222 \n",
       "L 206.525956 368.24732 \n",
       "L 212.674716 368.386655 \n",
       "L 218.823476 368.4041 \n",
       "L 224.972237 368.440386 \n",
       "L 231.120997 368.465265 \n",
       "L 237.269757 368.470031 \n",
       "L 243.418518 368.549553 \n",
       "L 249.567278 368.468889 \n",
       "L 255.716038 368.609308 \n",
       "L 261.864799 368.714908 \n",
       "L 268.013559 368.744998 \n",
       "L 274.162319 368.726814 \n",
       "L 280.31108 368.810029 \n",
       "L 286.45984 368.715261 \n",
       "L 292.6086 368.879551 \n",
       "L 298.757361 368.905987 \n",
       "L 304.906121 368.942988 \n",
       "L 311.054881 368.959086 \n",
       "L 317.203642 368.980679 \n",
       "L 323.352402 368.992284 \n",
       "L 329.501162 369.015858 \n",
       "L 335.649923 369.064401 \n",
       "L 341.798683 369.043192 \n",
       "L 347.947443 369.017749 \n",
       "L 354.096204 369.139161 \n",
       "L 360.244964 369.085277 \n",
       "L 366.393724 369.134119 \n",
       "L 372.542485 369.212532 \n",
       "L 378.691245 369.231246 \n",
       "L 384.840005 369.25367 \n",
       "L 390.988765 369.273222 \n",
       "L 397.137526 369.284873 \n",
       "L 403.286286 369.316152 \n",
       "L 409.435046 369.259959 \n",
       "L 415.583807 369.355614 \n",
       "L 421.732567 369.34815 \n",
       "L 427.881327 369.316485 \n",
       "L 434.030088 369.382442 \n",
       "L 440.178848 369.428016 \n",
       "L 446.327608 369.417069 \n",
       "L 452.476369 369.364991 \n",
       "L 458.625129 369.483607 \n",
       "L 464.773889 369.47907 \n",
       "L 470.92265 369.441315 \n",
       "L 477.07141 369.503351 \n",
       "L 483.22017 369.442837 \n",
       "L 489.368931 369.538059 \n",
       "L 495.517691 369.509423 \n",
       "L 501.666451 369.546488 \n",
       "L 507.815212 369.549852 \n",
       "L 513.963972 369.56207 \n",
       "L 520.112732 369.601787 \n",
       "L 526.261493 369.551571 \n",
       "L 532.410253 369.610707 \n",
       "L 538.559013 369.632378 \n",
       "L 544.707774 369.636135 \n",
       "L 550.856534 369.590442 \n",
       "L 557.005294 369.659862 \n",
       "L 563.154055 369.612076 \n",
       "L 569.302815 369.688413 \n",
       "L 575.451575 369.673126 \n",
       "L 581.600336 369.681574 \n",
       "L 587.749096 369.618372 \n",
       "L 593.897856 369.716148 \n",
       "L 600.046617 369.719382 \n",
       "L 606.195377 369.725796 \n",
       "L 612.344137 369.614724 \n",
       "L 618.492898 369.664122 \n",
       "L 624.641658 369.759824 \n",
       "L 630.790418 369.646562 \n",
       "L 636.939179 369.76561 \n",
       "L 643.087939 369.777674 \n",
       "L 649.236699 369.763121 \n",
       "L 655.38546 369.779806 \n",
       "L 661.53422 369.790407 \n",
       "L 667.68298 369.781519 \n",
       "L 673.831741 369.787085 \n",
       "L 679.980501 369.783039 \n",
       "L 686.129261 369.752079 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_87\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 306.907193 \n",
       "L 83.550749 336.21658 \n",
       "L 89.699509 344.944886 \n",
       "L 95.84827 348.364515 \n",
       "L 101.99703 351.551146 \n",
       "L 108.14579 352.860353 \n",
       "L 114.294551 353.961888 \n",
       "L 120.443311 354.826738 \n",
       "L 126.592071 354.795094 \n",
       "L 132.740832 355.570823 \n",
       "L 138.889592 355.76441 \n",
       "L 145.038352 354.78261 \n",
       "L 151.187113 356.279529 \n",
       "L 157.335873 355.940957 \n",
       "L 163.484633 357.008471 \n",
       "L 169.633394 356.879403 \n",
       "L 175.782154 356.942321 \n",
       "L 181.930914 357.430981 \n",
       "L 188.079675 357.465594 \n",
       "L 194.228435 356.588071 \n",
       "L 200.377195 357.912353 \n",
       "L 206.525956 357.49418 \n",
       "L 212.674716 358.026899 \n",
       "L 218.823476 358.378629 \n",
       "L 224.972237 357.659253 \n",
       "L 231.120997 358.731012 \n",
       "L 237.269757 357.914112 \n",
       "L 243.418518 358.761225 \n",
       "L 249.567278 358.967583 \n",
       "L 255.716038 358.837072 \n",
       "L 261.864799 359.13265 \n",
       "L 268.013559 359.063362 \n",
       "L 274.162319 358.852925 \n",
       "L 280.31108 359.33735 \n",
       "L 286.45984 358.988184 \n",
       "L 292.6086 359.404363 \n",
       "L 298.757361 359.32155 \n",
       "L 304.906121 359.221272 \n",
       "L 311.054881 359.552091 \n",
       "L 317.203642 359.496056 \n",
       "L 323.352402 359.824642 \n",
       "L 329.501162 359.435001 \n",
       "L 335.649923 359.710346 \n",
       "L 341.798683 359.592332 \n",
       "L 347.947443 359.878177 \n",
       "L 354.096204 359.761842 \n",
       "L 360.244964 359.390764 \n",
       "L 366.393724 359.746854 \n",
       "L 372.542485 359.592876 \n",
       "L 378.691245 359.642518 \n",
       "L 384.840005 359.724683 \n",
       "L 390.988765 359.954114 \n",
       "L 397.137526 359.568567 \n",
       "L 403.286286 359.312696 \n",
       "L 409.435046 359.627844 \n",
       "L 415.583807 359.588312 \n",
       "L 421.732567 359.870861 \n",
       "L 427.881327 359.801684 \n",
       "L 434.030088 359.479849 \n",
       "L 440.178848 359.82423 \n",
       "L 446.327608 359.72058 \n",
       "L 452.476369 359.501345 \n",
       "L 458.625129 359.725368 \n",
       "L 464.773889 359.693941 \n",
       "L 470.92265 359.791091 \n",
       "L 477.07141 359.669007 \n",
       "L 483.22017 359.513082 \n",
       "L 489.368931 359.6627 \n",
       "L 495.517691 359.645797 \n",
       "L 501.666451 359.555491 \n",
       "L 507.815212 359.465802 \n",
       "L 513.963972 359.195125 \n",
       "L 520.112732 359.433299 \n",
       "L 526.261493 359.245382 \n",
       "L 532.410253 359.131229 \n",
       "L 538.559013 359.132654 \n",
       "L 544.707774 359.0627 \n",
       "L 550.856534 359.50876 \n",
       "L 557.005294 359.423342 \n",
       "L 563.154055 358.871414 \n",
       "L 569.302815 359.344872 \n",
       "L 575.451575 359.112224 \n",
       "L 581.600336 359.541214 \n",
       "L 587.749096 359.106688 \n",
       "L 593.897856 359.207144 \n",
       "L 600.046617 359.299569 \n",
       "L 606.195377 358.97836 \n",
       "L 612.344137 359.691148 \n",
       "L 618.492898 358.592668 \n",
       "L 624.641658 359.201048 \n",
       "L 630.790418 359.006551 \n",
       "L 636.939179 358.985308 \n",
       "L 643.087939 359.050104 \n",
       "L 649.236699 358.859455 \n",
       "L 655.38546 358.806454 \n",
       "L 661.53422 358.256093 \n",
       "L 667.68298 359.000262 \n",
       "L 673.831741 358.494304 \n",
       "L 679.980501 359.085839 \n",
       "L 686.129261 358.467661 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_88\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.772457 \n",
       "L 83.550749 369.363636 \n",
       "L 89.699509 369.781257 \n",
       "L 95.84827 369.809766 \n",
       "L 101.99703 369.878206 \n",
       "L 108.14579 369.837927 \n",
       "L 114.294551 370.000255 \n",
       "L 120.443311 369.882886 \n",
       "L 126.592071 370.097676 \n",
       "L 132.740832 369.971112 \n",
       "L 138.889592 370.081859 \n",
       "L 145.038352 370.142382 \n",
       "L 151.187113 370.163173 \n",
       "L 157.335873 370.240867 \n",
       "L 163.484633 370.187 \n",
       "L 169.633394 370.146876 \n",
       "L 175.782154 370.114152 \n",
       "L 181.930914 370.195631 \n",
       "L 188.079675 370.189598 \n",
       "L 194.228435 370.192889 \n",
       "L 200.377195 370.220592 \n",
       "L 206.525956 370.162694 \n",
       "L 212.674716 370.24097 \n",
       "L 218.823476 370.194502 \n",
       "L 224.972237 370.223933 \n",
       "L 231.120997 370.163848 \n",
       "L 237.269757 370.197052 \n",
       "L 243.418518 370.220623 \n",
       "L 249.567278 370.19123 \n",
       "L 255.716038 370.199053 \n",
       "L 261.864799 370.197995 \n",
       "L 268.013559 370.214087 \n",
       "L 274.162319 370.192048 \n",
       "L 280.31108 370.113842 \n",
       "L 286.45984 370.183491 \n",
       "L 292.6086 370.220227 \n",
       "L 298.757361 370.189618 \n",
       "L 304.906121 370.112797 \n",
       "L 311.054881 370.212591 \n",
       "L 317.203642 370.142401 \n",
       "L 323.352402 370.19334 \n",
       "L 329.501162 370.178301 \n",
       "L 335.649923 370.181957 \n",
       "L 341.798683 370.179572 \n",
       "L 347.947443 370.224492 \n",
       "L 354.096204 370.115739 \n",
       "L 360.244964 370.168731 \n",
       "L 366.393724 370.140075 \n",
       "L 372.542485 370.183004 \n",
       "L 378.691245 370.134331 \n",
       "L 384.840005 370.120845 \n",
       "L 390.988765 370.134753 \n",
       "L 397.137526 370.037502 \n",
       "L 403.286286 370.179483 \n",
       "L 409.435046 370.109385 \n",
       "L 415.583807 370.154335 \n",
       "L 421.732567 370.203375 \n",
       "L 427.881327 370.123546 \n",
       "L 434.030088 370.115115 \n",
       "L 440.178848 370.142349 \n",
       "L 446.327608 370.106352 \n",
       "L 452.476369 370.118587 \n",
       "L 458.625129 370.098898 \n",
       "L 464.773889 370.176235 \n",
       "L 470.92265 370.149228 \n",
       "L 477.07141 370.204302 \n",
       "L 483.22017 370.164601 \n",
       "L 489.368931 370.18289 \n",
       "L 495.517691 370.127669 \n",
       "L 501.666451 370.17833 \n",
       "L 507.815212 370.092825 \n",
       "L 513.963972 370.150778 \n",
       "L 520.112732 370.134323 \n",
       "L 526.261493 370.114255 \n",
       "L 532.410253 370.131779 \n",
       "L 538.559013 370.102604 \n",
       "L 544.707774 370.113939 \n",
       "L 550.856534 370.064928 \n",
       "L 557.005294 370.137082 \n",
       "L 563.154055 370.171753 \n",
       "L 569.302815 370.137948 \n",
       "L 575.451575 370.101775 \n",
       "L 581.600336 370.108005 \n",
       "L 587.749096 370.132355 \n",
       "L 593.897856 370.07935 \n",
       "L 600.046617 370.173117 \n",
       "L 606.195377 370.169435 \n",
       "L 612.344137 370.177574 \n",
       "L 618.492898 370.171957 \n",
       "L 624.641658 370.165254 \n",
       "L 630.790418 370.108926 \n",
       "L 636.939179 370.145095 \n",
       "L 643.087939 370.12313 \n",
       "L 649.236699 370.091215 \n",
       "L 655.38546 370.161325 \n",
       "L 661.53422 370.084649 \n",
       "L 667.68298 370.089382 \n",
       "L 673.831741 370.156397 \n",
       "L 679.980501 370.109046 \n",
       "L 686.129261 370.110808 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_89\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 288.367045 \n",
       "L 83.550749 339.815919 \n",
       "L 89.699509 348.293016 \n",
       "L 95.84827 350.808987 \n",
       "L 101.99703 352.540764 \n",
       "L 108.14579 353.990391 \n",
       "L 114.294551 354.583154 \n",
       "L 120.443311 355.149681 \n",
       "L 126.592071 356.089369 \n",
       "L 132.740832 355.8034 \n",
       "L 138.889592 355.925281 \n",
       "L 145.038352 356.948684 \n",
       "L 151.187113 357.066292 \n",
       "L 157.335873 357.160414 \n",
       "L 163.484633 357.090551 \n",
       "L 169.633394 356.593384 \n",
       "L 175.782154 356.973794 \n",
       "L 181.930914 357.876544 \n",
       "L 188.079675 358.207572 \n",
       "L 194.228435 358.253582 \n",
       "L 200.377195 358.275192 \n",
       "L 206.525956 358.555755 \n",
       "L 212.674716 358.769564 \n",
       "L 218.823476 358.679876 \n",
       "L 224.972237 358.695304 \n",
       "L 231.120997 359.045761 \n",
       "L 237.269757 359.281246 \n",
       "L 243.418518 359.201507 \n",
       "L 249.567278 359.218431 \n",
       "L 255.716038 358.931113 \n",
       "L 261.864799 359.66186 \n",
       "L 268.013559 359.387886 \n",
       "L 274.162319 359.619825 \n",
       "L 280.31108 359.818347 \n",
       "L 286.45984 359.758745 \n",
       "L 292.6086 359.814273 \n",
       "L 298.757361 359.779681 \n",
       "L 304.906121 359.967771 \n",
       "L 311.054881 359.896185 \n",
       "L 317.203642 359.99478 \n",
       "L 323.352402 360.039623 \n",
       "L 329.501162 360.100659 \n",
       "L 335.649923 359.804765 \n",
       "L 341.798683 360.087339 \n",
       "L 347.947443 360.371255 \n",
       "L 354.096204 360.169191 \n",
       "L 360.244964 359.968407 \n",
       "L 366.393724 360.254113 \n",
       "L 372.542485 359.860511 \n",
       "L 378.691245 360.32983 \n",
       "L 384.840005 360.282548 \n",
       "L 390.988765 360.258556 \n",
       "L 397.137526 360.415894 \n",
       "L 403.286286 360.42825 \n",
       "L 409.435046 359.942978 \n",
       "L 415.583807 360.463733 \n",
       "L 421.732567 360.356159 \n",
       "L 427.881327 360.213322 \n",
       "L 434.030088 360.613106 \n",
       "L 440.178848 360.512529 \n",
       "L 446.327608 360.335788 \n",
       "L 452.476369 359.836127 \n",
       "L 458.625129 359.985061 \n",
       "L 464.773889 360.573239 \n",
       "L 470.92265 360.083066 \n",
       "L 477.07141 359.616828 \n",
       "L 483.22017 360.260018 \n",
       "L 489.368931 360.576825 \n",
       "L 495.517691 360.000883 \n",
       "L 501.666451 360.464547 \n",
       "L 507.815212 359.983494 \n",
       "L 513.963972 360.047412 \n",
       "L 520.112732 360.267916 \n",
       "L 526.261493 360.399985 \n",
       "L 532.410253 360.206056 \n",
       "L 538.559013 359.422923 \n",
       "L 544.707774 360.225453 \n",
       "L 550.856534 360.336522 \n",
       "L 557.005294 360.495029 \n",
       "L 563.154055 360.305159 \n",
       "L 569.302815 360.083982 \n",
       "L 575.451575 360.136703 \n",
       "L 581.600336 359.663874 \n",
       "L 587.749096 360.002588 \n",
       "L 593.897856 359.758082 \n",
       "L 600.046617 359.95984 \n",
       "L 606.195377 359.910101 \n",
       "L 612.344137 360.281058 \n",
       "L 618.492898 359.674299 \n",
       "L 624.641658 359.776346 \n",
       "L 630.790418 360.151943 \n",
       "L 636.939179 359.814993 \n",
       "L 643.087939 360.212165 \n",
       "L 649.236699 359.710742 \n",
       "L 655.38546 360.074113 \n",
       "L 661.53422 360.145285 \n",
       "L 667.68298 359.946869 \n",
       "L 673.831741 359.964799 \n",
       "L 679.980501 360.04187 \n",
       "L 686.129261 359.883494 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_90\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 365.917116 \n",
       "L 83.550749 368.876461 \n",
       "L 89.699509 369.363946 \n",
       "L 95.84827 369.544964 \n",
       "L 101.99703 369.711615 \n",
       "L 108.14579 369.821288 \n",
       "L 114.294551 369.938008 \n",
       "L 120.443311 369.870456 \n",
       "L 126.592071 369.960419 \n",
       "L 132.740832 369.996435 \n",
       "L 138.889592 370.03989 \n",
       "L 145.038352 370.08332 \n",
       "L 151.187113 370.09783 \n",
       "L 157.335873 370.055217 \n",
       "L 163.484633 370.147145 \n",
       "L 169.633394 370.18303 \n",
       "L 175.782154 370.038099 \n",
       "L 181.930914 370.156554 \n",
       "L 188.079675 370.164125 \n",
       "L 194.228435 370.215273 \n",
       "L 200.377195 370.176514 \n",
       "L 206.525956 370.216795 \n",
       "L 212.674716 370.262534 \n",
       "L 218.823476 370.220992 \n",
       "L 224.972237 370.268192 \n",
       "L 231.120997 370.298749 \n",
       "L 237.269757 370.223069 \n",
       "L 243.418518 370.216037 \n",
       "L 249.567278 370.304641 \n",
       "L 255.716038 370.316511 \n",
       "L 261.864799 370.291218 \n",
       "L 268.013559 370.321799 \n",
       "L 274.162319 370.274115 \n",
       "L 280.31108 370.276368 \n",
       "L 286.45984 370.299121 \n",
       "L 292.6086 370.326748 \n",
       "L 298.757361 370.220871 \n",
       "L 304.906121 370.334155 \n",
       "L 311.054881 370.286445 \n",
       "L 317.203642 370.329048 \n",
       "L 323.352402 370.333365 \n",
       "L 329.501162 370.231363 \n",
       "L 335.649923 370.348857 \n",
       "L 341.798683 370.329182 \n",
       "L 347.947443 370.344368 \n",
       "L 354.096204 370.143606 \n",
       "L 360.244964 370.307609 \n",
       "L 366.393724 370.310272 \n",
       "L 372.542485 370.313687 \n",
       "L 378.691245 370.300003 \n",
       "L 384.840005 370.348483 \n",
       "L 390.988765 370.297725 \n",
       "L 397.137526 370.309175 \n",
       "L 403.286286 370.359669 \n",
       "L 409.435046 370.305172 \n",
       "L 415.583807 370.340666 \n",
       "L 421.732567 370.295075 \n",
       "L 427.881327 370.287248 \n",
       "L 434.030088 370.327385 \n",
       "L 440.178848 370.252508 \n",
       "L 446.327608 370.317592 \n",
       "L 452.476369 370.230064 \n",
       "L 458.625129 370.322163 \n",
       "L 464.773889 370.32484 \n",
       "L 470.92265 370.291893 \n",
       "L 477.07141 370.286133 \n",
       "L 483.22017 370.333538 \n",
       "L 489.368931 370.299583 \n",
       "L 495.517691 370.273718 \n",
       "L 501.666451 370.387121 \n",
       "L 507.815212 370.235079 \n",
       "L 513.963972 370.319785 \n",
       "L 520.112732 370.280127 \n",
       "L 526.261493 370.296579 \n",
       "L 532.410253 370.283935 \n",
       "L 538.559013 370.30691 \n",
       "L 544.707774 370.301193 \n",
       "L 550.856534 370.298483 \n",
       "L 557.005294 370.124977 \n",
       "L 563.154055 370.309671 \n",
       "L 569.302815 370.312376 \n",
       "L 575.451575 370.321433 \n",
       "L 581.600336 370.305411 \n",
       "L 587.749096 370.265891 \n",
       "L 593.897856 370.335531 \n",
       "L 600.046617 370.297712 \n",
       "L 606.195377 370.343643 \n",
       "L 612.344137 370.25983 \n",
       "L 618.492898 370.288684 \n",
       "L 624.641658 370.266166 \n",
       "L 630.790418 370.265602 \n",
       "L 636.939179 370.235366 \n",
       "L 643.087939 370.324671 \n",
       "L 649.236699 370.210331 \n",
       "L 655.38546 370.238009 \n",
       "L 661.53422 370.212228 \n",
       "L 667.68298 370.236731 \n",
       "L 673.831741 370.27755 \n",
       "L 679.980501 370.272916 \n",
       "L 686.129261 370.15406 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_91\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 306.014046 \n",
       "L 83.550749 340.592831 \n",
       "L 89.699509 349.046003 \n",
       "L 95.84827 350.847341 \n",
       "L 101.99703 353.348668 \n",
       "L 108.14579 353.896435 \n",
       "L 114.294551 353.995825 \n",
       "L 120.443311 355.506735 \n",
       "L 126.592071 355.758822 \n",
       "L 132.740832 356.32472 \n",
       "L 138.889592 356.991792 \n",
       "L 145.038352 357.231576 \n",
       "L 151.187113 357.296624 \n",
       "L 157.335873 357.608877 \n",
       "L 163.484633 358.276539 \n",
       "L 169.633394 358.154271 \n",
       "L 175.782154 358.360012 \n",
       "L 181.930914 358.510679 \n",
       "L 188.079675 358.533273 \n",
       "L 194.228435 358.857333 \n",
       "L 200.377195 358.935956 \n",
       "L 206.525956 359.23552 \n",
       "L 212.674716 359.032691 \n",
       "L 218.823476 359.395885 \n",
       "L 224.972237 359.309565 \n",
       "L 231.120997 359.712564 \n",
       "L 237.269757 359.638654 \n",
       "L 243.418518 359.558294 \n",
       "L 249.567278 359.831733 \n",
       "L 255.716038 359.759736 \n",
       "L 261.864799 359.735945 \n",
       "L 268.013559 359.621808 \n",
       "L 274.162319 359.577784 \n",
       "L 280.31108 359.560103 \n",
       "L 286.45984 359.063566 \n",
       "L 292.6086 359.90982 \n",
       "L 298.757361 359.523173 \n",
       "L 304.906121 359.582029 \n",
       "L 311.054881 359.724976 \n",
       "L 317.203642 359.877084 \n",
       "L 323.352402 360.010896 \n",
       "L 329.501162 359.853112 \n",
       "L 335.649923 359.695001 \n",
       "L 341.798683 359.775071 \n",
       "L 347.947443 359.709506 \n",
       "L 354.096204 359.740913 \n",
       "L 360.244964 359.881824 \n",
       "L 366.393724 359.667929 \n",
       "L 372.542485 359.790662 \n",
       "L 378.691245 358.922968 \n",
       "L 384.840005 359.773829 \n",
       "L 390.988765 359.494781 \n",
       "L 397.137526 359.538267 \n",
       "L 403.286286 359.539128 \n",
       "L 409.435046 359.671537 \n",
       "L 415.583807 359.827534 \n",
       "L 421.732567 359.701484 \n",
       "L 427.881327 359.505741 \n",
       "L 434.030088 359.742519 \n",
       "L 440.178848 359.722844 \n",
       "L 446.327608 359.808956 \n",
       "L 452.476369 359.664982 \n",
       "L 458.625129 359.579529 \n",
       "L 464.773889 359.800973 \n",
       "L 470.92265 359.808047 \n",
       "L 477.07141 359.581579 \n",
       "L 483.22017 359.772784 \n",
       "L 489.368931 359.52863 \n",
       "L 495.517691 359.2151 \n",
       "L 501.666451 359.410218 \n",
       "L 507.815212 359.40766 \n",
       "L 513.963972 359.336024 \n",
       "L 520.112732 359.32494 \n",
       "L 526.261493 358.995019 \n",
       "L 532.410253 359.406621 \n",
       "L 538.559013 359.219145 \n",
       "L 544.707774 359.046207 \n",
       "L 550.856534 358.979135 \n",
       "L 557.005294 359.163245 \n",
       "L 563.154055 359.238486 \n",
       "L 569.302815 359.273819 \n",
       "L 575.451575 359.374242 \n",
       "L 581.600336 358.98682 \n",
       "L 587.749096 358.884533 \n",
       "L 593.897856 359.068678 \n",
       "L 600.046617 359.173422 \n",
       "L 606.195377 359.232683 \n",
       "L 612.344137 359.027675 \n",
       "L 618.492898 358.846201 \n",
       "L 624.641658 359.41318 \n",
       "L 630.790418 359.052514 \n",
       "L 636.939179 358.760228 \n",
       "L 643.087939 359.041841 \n",
       "L 649.236699 359.132231 \n",
       "L 655.38546 358.853104 \n",
       "L 661.53422 359.019589 \n",
       "L 667.68298 359.067831 \n",
       "L 673.831741 358.620299 \n",
       "L 679.980501 358.748478 \n",
       "L 686.129261 358.822869 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_92\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.13905 \n",
       "L 83.550749 369.399134 \n",
       "L 89.699509 369.708245 \n",
       "L 95.84827 369.866906 \n",
       "L 101.99703 369.897182 \n",
       "L 108.14579 369.478698 \n",
       "L 114.294551 369.933734 \n",
       "L 120.443311 369.999405 \n",
       "L 126.592071 369.996107 \n",
       "L 132.740832 369.885473 \n",
       "L 138.889592 370.045046 \n",
       "L 145.038352 370.104497 \n",
       "L 151.187113 370.108327 \n",
       "L 157.335873 370.140758 \n",
       "L 163.484633 370.170044 \n",
       "L 169.633394 370.161408 \n",
       "L 175.782154 370.114823 \n",
       "L 181.930914 370.10123 \n",
       "L 188.079675 370.058277 \n",
       "L 194.228435 370.151084 \n",
       "L 200.377195 370.175885 \n",
       "L 206.525956 370.113826 \n",
       "L 212.674716 370.203465 \n",
       "L 218.823476 370.140326 \n",
       "L 224.972237 370.218746 \n",
       "L 231.120997 370.213465 \n",
       "L 237.269757 370.196673 \n",
       "L 243.418518 370.245505 \n",
       "L 249.567278 370.242993 \n",
       "L 255.716038 370.180406 \n",
       "L 261.864799 370.251583 \n",
       "L 268.013559 370.259404 \n",
       "L 274.162319 370.262495 \n",
       "L 280.31108 370.198183 \n",
       "L 286.45984 370.291771 \n",
       "L 292.6086 370.293048 \n",
       "L 298.757361 370.311709 \n",
       "L 304.906121 370.267193 \n",
       "L 311.054881 370.25863 \n",
       "L 317.203642 370.193198 \n",
       "L 323.352402 370.339284 \n",
       "L 329.501162 370.211594 \n",
       "L 335.649923 370.128859 \n",
       "L 341.798683 370.243965 \n",
       "L 347.947443 370.302193 \n",
       "L 354.096204 370.294259 \n",
       "L 360.244964 370.247986 \n",
       "L 366.393724 370.313702 \n",
       "L 372.542485 370.202944 \n",
       "L 378.691245 370.285009 \n",
       "L 384.840005 370.265503 \n",
       "L 390.988765 370.300875 \n",
       "L 397.137526 370.251085 \n",
       "L 403.286286 370.237297 \n",
       "L 409.435046 370.260556 \n",
       "L 415.583807 370.293469 \n",
       "L 421.732567 370.277353 \n",
       "L 427.881327 370.255304 \n",
       "L 434.030088 370.258209 \n",
       "L 440.178848 370.28907 \n",
       "L 446.327608 370.233843 \n",
       "L 452.476369 370.306996 \n",
       "L 458.625129 370.292495 \n",
       "L 464.773889 370.21256 \n",
       "L 470.92265 370.289598 \n",
       "L 477.07141 370.317306 \n",
       "L 483.22017 370.244979 \n",
       "L 489.368931 370.222861 \n",
       "L 495.517691 370.27519 \n",
       "L 501.666451 370.255184 \n",
       "L 507.815212 370.277191 \n",
       "L 513.963972 370.218851 \n",
       "L 520.112732 370.281904 \n",
       "L 526.261493 370.281195 \n",
       "L 532.410253 370.307253 \n",
       "L 538.559013 370.329163 \n",
       "L 544.707774 370.289696 \n",
       "L 550.856534 370.222193 \n",
       "L 557.005294 370.258415 \n",
       "L 563.154055 370.203153 \n",
       "L 569.302815 370.293633 \n",
       "L 575.451575 370.330941 \n",
       "L 581.600336 370.24037 \n",
       "L 587.749096 370.2913 \n",
       "L 593.897856 370.321203 \n",
       "L 600.046617 370.321439 \n",
       "L 606.195377 370.264332 \n",
       "L 612.344137 370.227628 \n",
       "L 618.492898 370.352714 \n",
       "L 624.641658 370.302978 \n",
       "L 630.790418 370.347338 \n",
       "L 636.939179 370.338448 \n",
       "L 643.087939 370.2488 \n",
       "L 649.236699 370.292546 \n",
       "L 655.38546 370.212461 \n",
       "L 661.53422 370.326063 \n",
       "L 667.68298 370.275136 \n",
       "L 673.831741 370.201725 \n",
       "L 679.980501 370.304604 \n",
       "L 686.129261 370.269776 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_93\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 73.01887 \n",
       "L 83.550749 129.612809 \n",
       "L 89.699509 155.136489 \n",
       "L 95.84827 172.982149 \n",
       "L 101.99703 187.122331 \n",
       "L 108.14579 198.715849 \n",
       "L 114.294551 208.843349 \n",
       "L 120.443311 217.40374 \n",
       "L 126.592071 224.478471 \n",
       "L 132.740832 231.106521 \n",
       "L 138.889592 236.653655 \n",
       "L 145.038352 241.843896 \n",
       "L 151.187113 246.428096 \n",
       "L 157.335873 250.372344 \n",
       "L 163.484633 254.143362 \n",
       "L 169.633394 257.184322 \n",
       "L 175.782154 260.325488 \n",
       "L 181.930914 263.085328 \n",
       "L 188.079675 265.558854 \n",
       "L 194.228435 267.882085 \n",
       "L 200.377195 269.917476 \n",
       "L 206.525956 271.907332 \n",
       "L 212.674716 273.616439 \n",
       "L 218.823476 275.241576 \n",
       "L 224.972237 276.654648 \n",
       "L 231.120997 277.87179 \n",
       "L 237.269757 279.088897 \n",
       "L 243.418518 280.172157 \n",
       "L 249.567278 281.054578 \n",
       "L 255.716038 281.948423 \n",
       "L 261.864799 282.748106 \n",
       "L 268.013559 283.481244 \n",
       "L 274.162319 284.11002 \n",
       "L 280.31108 284.72497 \n",
       "L 286.45984 285.263168 \n",
       "L 292.6086 285.755732 \n",
       "L 298.757361 286.164903 \n",
       "L 304.906121 286.531497 \n",
       "L 311.054881 286.825993 \n",
       "L 317.203642 287.144045 \n",
       "L 323.352402 287.407396 \n",
       "L 329.501162 287.601708 \n",
       "L 335.649923 287.812953 \n",
       "L 341.798683 287.981679 \n",
       "L 347.947443 288.137376 \n",
       "L 354.096204 288.288491 \n",
       "L 360.244964 288.403607 \n",
       "L 366.393724 288.495924 \n",
       "L 372.542485 288.600142 \n",
       "L 378.691245 288.677364 \n",
       "L 384.840005 288.751842 \n",
       "L 390.988765 288.805508 \n",
       "L 397.137526 288.860636 \n",
       "L 403.286286 288.911245 \n",
       "L 409.435046 288.931301 \n",
       "L 415.583807 288.972844 \n",
       "L 421.732567 289.005721 \n",
       "L 427.881327 289.027195 \n",
       "L 434.030088 289.052432 \n",
       "L 440.178848 289.071846 \n",
       "L 446.327608 289.083107 \n",
       "L 452.476369 289.105877 \n",
       "L 458.625129 289.10875 \n",
       "L 464.773889 289.115734 \n",
       "L 470.92265 289.123681 \n",
       "L 477.07141 289.130865 \n",
       "L 483.22017 289.148968 \n",
       "L 489.368931 289.15474 \n",
       "L 495.517691 289.15767 \n",
       "L 501.666451 289.166956 \n",
       "L 507.815212 289.163172 \n",
       "L 513.963972 289.166635 \n",
       "L 520.112732 289.168082 \n",
       "L 526.261493 289.175159 \n",
       "L 532.410253 289.17754 \n",
       "L 538.559013 289.177682 \n",
       "L 544.707774 289.171012 \n",
       "L 550.856534 289.177127 \n",
       "L 557.005294 289.178851 \n",
       "L 563.154055 289.181296 \n",
       "L 569.302815 289.179699 \n",
       "L 575.451575 289.181902 \n",
       "L 581.600336 289.181488 \n",
       "L 587.749096 289.181731 \n",
       "L 593.897856 289.182743 \n",
       "L 600.046617 289.180804 \n",
       "L 606.195377 289.182529 \n",
       "L 612.344137 289.181944 \n",
       "L 618.492898 289.182365 \n",
       "L 624.641658 289.183983 \n",
       "L 630.790418 289.182415 \n",
       "L 636.939179 289.183676 \n",
       "L 643.087939 289.183797 \n",
       "L 649.236699 289.183142 \n",
       "L 655.38546 289.183206 \n",
       "L 661.53422 289.183961 \n",
       "L 667.68298 289.183619 \n",
       "L 673.831741 289.182999 \n",
       "L 679.980501 289.183947 \n",
       "L 686.129261 289.184075 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_94\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.758608 \n",
       "L 83.550749 360.766422 \n",
       "L 89.699509 361.708218 \n",
       "L 95.84827 362.393043 \n",
       "L 101.99703 362.935575 \n",
       "L 108.14579 363.39536 \n",
       "L 114.294551 363.765652 \n",
       "L 120.443311 364.065793 \n",
       "L 126.592071 364.32362 \n",
       "L 132.740832 364.559884 \n",
       "L 138.889592 364.748362 \n",
       "L 145.038352 364.904003 \n",
       "L 151.187113 365.053219 \n",
       "L 157.335873 365.182095 \n",
       "L 163.484633 365.293024 \n",
       "L 169.633394 365.404543 \n",
       "L 175.782154 365.490932 \n",
       "L 181.930914 365.57379 \n",
       "L 188.079675 365.648507 \n",
       "L 194.228435 365.721079 \n",
       "L 200.377195 365.783792 \n",
       "L 206.525956 365.842793 \n",
       "L 212.674716 365.888513 \n",
       "L 218.823476 365.935848 \n",
       "L 224.972237 365.977975 \n",
       "L 231.120997 366.008473 \n",
       "L 237.269757 366.023939 \n",
       "L 243.418518 366.033687 \n",
       "L 249.567278 366.041347 \n",
       "L 255.716038 366.049107 \n",
       "L 261.864799 366.055496 \n",
       "L 268.013559 366.059447 \n",
       "L 274.162319 366.060224 \n",
       "L 280.31108 366.060856 \n",
       "L 286.45984 366.061381 \n",
       "L 292.6086 366.060994 \n",
       "L 298.757361 366.059327 \n",
       "L 304.906121 366.056557 \n",
       "L 311.054881 366.055367 \n",
       "L 317.203642 366.052432 \n",
       "L 323.352402 366.051883 \n",
       "L 329.501162 366.049012 \n",
       "L 335.649923 366.047429 \n",
       "L 341.798683 366.045661 \n",
       "L 347.947443 366.043322 \n",
       "L 354.096204 366.043375 \n",
       "L 360.244964 366.0393 \n",
       "L 366.393724 366.039183 \n",
       "L 372.542485 366.036299 \n",
       "L 378.691245 366.035489 \n",
       "L 384.840005 366.03341 \n",
       "L 390.988765 366.031776 \n",
       "L 397.137526 366.029904 \n",
       "L 403.286286 366.031443 \n",
       "L 409.435046 366.028681 \n",
       "L 415.583807 366.028335 \n",
       "L 421.732567 366.027646 \n",
       "L 427.881327 366.026603 \n",
       "L 434.030088 366.024638 \n",
       "L 440.178848 366.023156 \n",
       "L 446.327608 366.021521 \n",
       "L 452.476369 366.024082 \n",
       "L 458.625129 366.021652 \n",
       "L 464.773889 366.020646 \n",
       "L 470.92265 366.019068 \n",
       "L 477.07141 366.016879 \n",
       "L 483.22017 366.016437 \n",
       "L 489.368931 366.015523 \n",
       "L 495.517691 366.015854 \n",
       "L 501.666451 366.016059 \n",
       "L 507.815212 366.016624 \n",
       "L 513.963972 366.015702 \n",
       "L 520.112732 366.014425 \n",
       "L 526.261493 366.014462 \n",
       "L 532.410253 366.013946 \n",
       "L 538.559013 366.014642 \n",
       "L 544.707774 366.013932 \n",
       "L 550.856534 366.014201 \n",
       "L 557.005294 366.015853 \n",
       "L 563.154055 366.016315 \n",
       "L 569.302815 366.014141 \n",
       "L 575.451575 366.013401 \n",
       "L 581.600336 366.014013 \n",
       "L 587.749096 366.014795 \n",
       "L 593.897856 366.016054 \n",
       "L 600.046617 366.015454 \n",
       "L 606.195377 366.015111 \n",
       "L 612.344137 366.015727 \n",
       "L 618.492898 366.015949 \n",
       "L 624.641658 366.016715 \n",
       "L 630.790418 366.014717 \n",
       "L 636.939179 366.015255 \n",
       "L 643.087939 366.013562 \n",
       "L 649.236699 366.014543 \n",
       "L 655.38546 366.015706 \n",
       "L 661.53422 366.014386 \n",
       "L 667.68298 366.013703 \n",
       "L 673.831741 366.015769 \n",
       "L 679.980501 366.015088 \n",
       "L 686.129261 366.014593 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_95\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 86.381135 \n",
       "L 83.550749 141.390119 \n",
       "L 89.699509 167.03771 \n",
       "L 95.84827 184.635862 \n",
       "L 101.99703 198.42679 \n",
       "L 108.14579 209.423675 \n",
       "L 114.294551 218.438458 \n",
       "L 120.443311 226.094357 \n",
       "L 126.592071 232.922363 \n",
       "L 132.740832 239.032477 \n",
       "L 138.889592 244.184887 \n",
       "L 145.038352 248.851647 \n",
       "L 151.187113 253.110525 \n",
       "L 157.335873 256.878793 \n",
       "L 163.484633 260.422914 \n",
       "L 169.633394 263.581684 \n",
       "L 175.782154 266.317464 \n",
       "L 181.930914 268.740038 \n",
       "L 188.079675 270.765109 \n",
       "L 194.228435 272.891755 \n",
       "L 200.377195 274.754543 \n",
       "L 206.525956 276.358249 \n",
       "L 212.674716 277.862903 \n",
       "L 218.823476 279.076467 \n",
       "L 224.972237 280.318647 \n",
       "L 231.120997 281.366073 \n",
       "L 237.269757 282.244317 \n",
       "L 243.418518 283.100688 \n",
       "L 249.567278 283.791049 \n",
       "L 255.716038 284.442995 \n",
       "L 261.864799 284.980246 \n",
       "L 268.013559 285.502722 \n",
       "L 274.162319 285.999898 \n",
       "L 280.31108 286.388963 \n",
       "L 286.45984 286.691121 \n",
       "L 292.6086 287.055983 \n",
       "L 298.757361 287.315087 \n",
       "L 304.906121 287.545647 \n",
       "L 311.054881 287.766628 \n",
       "L 317.203642 287.940185 \n",
       "L 323.352402 288.124341 \n",
       "L 329.501162 288.245736 \n",
       "L 335.649923 288.384207 \n",
       "L 341.798683 288.490151 \n",
       "L 347.947443 288.597491 \n",
       "L 354.096204 288.677849 \n",
       "L 360.244964 288.753459 \n",
       "L 366.393724 288.807604 \n",
       "L 372.542485 288.866109 \n",
       "L 378.691245 288.909492 \n",
       "L 384.840005 288.957899 \n",
       "L 390.988765 288.98449 \n",
       "L 397.137526 289.020816 \n",
       "L 403.286286 289.044656 \n",
       "L 409.435046 289.066472 \n",
       "L 415.583807 289.077341 \n",
       "L 421.732567 289.094225 \n",
       "L 427.881327 289.106775 \n",
       "L 434.030088 289.118214 \n",
       "L 440.178848 289.126104 \n",
       "L 446.327608 289.133081 \n",
       "L 452.476369 289.14018 \n",
       "L 458.625129 289.155418 \n",
       "L 464.773889 289.154049 \n",
       "L 470.92265 289.157613 \n",
       "L 477.07141 289.165723 \n",
       "L 483.22017 289.167313 \n",
       "L 489.368931 289.168923 \n",
       "L 495.517691 289.170078 \n",
       "L 501.666451 289.175266 \n",
       "L 507.815212 289.175167 \n",
       "L 513.963972 289.177105 \n",
       "L 520.112732 289.175373 \n",
       "L 526.261493 289.178994 \n",
       "L 532.410253 289.175751 \n",
       "L 538.559013 289.179086 \n",
       "L 544.707774 289.182094 \n",
       "L 550.856534 289.180961 \n",
       "L 557.005294 289.180911 \n",
       "L 563.154055 289.182971 \n",
       "L 569.302815 289.182372 \n",
       "L 575.451575 289.18307 \n",
       "L 581.600336 289.180562 \n",
       "L 587.749096 289.183555 \n",
       "L 593.897856 289.182978 \n",
       "L 600.046617 289.183712 \n",
       "L 606.195377 289.182928 \n",
       "L 612.344137 289.181431 \n",
       "L 618.492898 289.183477 \n",
       "L 624.641658 289.183199 \n",
       "L 630.790418 289.184075 \n",
       "L 636.939179 289.184289 \n",
       "L 643.087939 289.184375 \n",
       "L 649.236699 289.184866 \n",
       "L 655.38546 289.184375 \n",
       "L 661.53422 289.183919 \n",
       "L 667.68298 289.184567 \n",
       "L 673.831741 289.183099 \n",
       "L 679.980501 289.184752 \n",
       "L 686.129261 289.185258 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_96\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 358.571829 \n",
       "L 83.550749 360.451878 \n",
       "L 89.699509 361.445842 \n",
       "L 95.84827 362.182193 \n",
       "L 101.99703 362.821444 \n",
       "L 108.14579 363.359227 \n",
       "L 114.294551 363.772295 \n",
       "L 120.443311 364.122415 \n",
       "L 126.592071 364.421892 \n",
       "L 132.740832 364.655354 \n",
       "L 138.889592 364.856916 \n",
       "L 145.038352 365.031841 \n",
       "L 151.187113 365.174103 \n",
       "L 157.335873 365.321048 \n",
       "L 163.484633 365.450166 \n",
       "L 169.633394 365.568701 \n",
       "L 175.782154 365.664347 \n",
       "L 181.930914 365.759241 \n",
       "L 188.079675 365.842946 \n",
       "L 194.228435 365.906453 \n",
       "L 200.377195 365.962958 \n",
       "L 206.525956 366.009499 \n",
       "L 212.674716 366.025352 \n",
       "L 218.823476 366.036524 \n",
       "L 224.972237 366.045514 \n",
       "L 231.120997 366.054005 \n",
       "L 237.269757 366.059065 \n",
       "L 243.418518 366.060279 \n",
       "L 249.567278 366.061187 \n",
       "L 255.716038 366.061016 \n",
       "L 261.864799 366.060471 \n",
       "L 268.013559 366.055788 \n",
       "L 274.162319 366.054756 \n",
       "L 280.31108 366.052679 \n",
       "L 286.45984 366.049468 \n",
       "L 292.6086 366.04904 \n",
       "L 298.757361 366.045849 \n",
       "L 304.906121 366.047139 \n",
       "L 311.054881 366.044022 \n",
       "L 317.203642 366.042032 \n",
       "L 323.352402 366.040615 \n",
       "L 329.501162 366.038213 \n",
       "L 335.649923 366.039106 \n",
       "L 341.798683 366.034574 \n",
       "L 347.947443 366.032417 \n",
       "L 354.096204 366.030314 \n",
       "L 360.244964 366.030108 \n",
       "L 366.393724 366.027491 \n",
       "L 372.542485 366.027077 \n",
       "L 378.691245 366.02382 \n",
       "L 384.840005 366.023005 \n",
       "L 390.988765 366.022851 \n",
       "L 397.137526 366.02004 \n",
       "L 403.286286 366.020965 \n",
       "L 409.435046 366.020769 \n",
       "L 415.583807 366.017153 \n",
       "L 421.732567 366.020046 \n",
       "L 427.881327 366.019166 \n",
       "L 434.030088 366.014474 \n",
       "L 440.178848 366.016021 \n",
       "L 446.327608 366.013488 \n",
       "L 452.476369 366.014646 \n",
       "L 458.625129 366.015255 \n",
       "L 464.773889 366.015198 \n",
       "L 470.92265 366.014837 \n",
       "L 477.07141 366.013917 \n",
       "L 483.22017 366.015438 \n",
       "L 489.368931 366.014939 \n",
       "L 495.517691 366.016552 \n",
       "L 501.666451 366.014764 \n",
       "L 507.815212 366.013904 \n",
       "L 513.963972 366.015933 \n",
       "L 520.112732 366.014835 \n",
       "L 526.261493 366.01419 \n",
       "L 532.410253 366.014413 \n",
       "L 538.559013 366.015357 \n",
       "L 544.707774 366.014485 \n",
       "L 550.856534 366.014568 \n",
       "L 557.005294 366.015115 \n",
       "L 563.154055 366.016955 \n",
       "L 569.302815 366.017508 \n",
       "L 575.451575 366.016892 \n",
       "L 581.600336 366.014367 \n",
       "L 587.749096 366.013653 \n",
       "L 593.897856 366.015431 \n",
       "L 600.046617 366.012534 \n",
       "L 606.195377 366.012036 \n",
       "L 612.344137 366.013227 \n",
       "L 618.492898 366.016703 \n",
       "L 624.641658 366.012974 \n",
       "L 630.790418 366.015725 \n",
       "L 636.939179 366.015348 \n",
       "L 643.087939 366.016058 \n",
       "L 649.236699 366.013572 \n",
       "L 655.38546 366.01287 \n",
       "L 661.53422 366.014575 \n",
       "L 667.68298 366.015856 \n",
       "L 673.831741 366.015802 \n",
       "L 679.980501 366.017006 \n",
       "L 686.129261 366.014964 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_97\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 89.95586 \n",
       "L 83.550749 143.727348 \n",
       "L 89.699509 168.251873 \n",
       "L 95.84827 185.610713 \n",
       "L 101.99703 198.595302 \n",
       "L 108.14579 209.374855 \n",
       "L 114.294551 218.94063 \n",
       "L 120.443311 227.162273 \n",
       "L 126.592071 234.310483 \n",
       "L 132.740832 240.548727 \n",
       "L 138.889592 246.074936 \n",
       "L 145.038352 250.853833 \n",
       "L 151.187113 255.121862 \n",
       "L 157.335873 258.74064 \n",
       "L 163.484633 262.105089 \n",
       "L 169.633394 265.011319 \n",
       "L 175.782154 267.624392 \n",
       "L 181.930914 269.938629 \n",
       "L 188.079675 272.105635 \n",
       "L 194.228435 273.862572 \n",
       "L 200.377195 275.669655 \n",
       "L 206.525956 277.092327 \n",
       "L 212.674716 278.369322 \n",
       "L 218.823476 279.559709 \n",
       "L 224.972237 280.699708 \n",
       "L 231.120997 281.562879 \n",
       "L 237.269757 282.507668 \n",
       "L 243.418518 283.300274 \n",
       "L 249.567278 284.001482 \n",
       "L 255.716038 284.617822 \n",
       "L 261.864799 285.131852 \n",
       "L 268.013559 285.609086 \n",
       "L 274.162319 286.043786 \n",
       "L 280.31108 286.414072 \n",
       "L 286.45984 286.784471 \n",
       "L 292.6086 287.068398 \n",
       "L 298.757361 287.341542 \n",
       "L 304.906121 287.574483 \n",
       "L 311.054881 287.776121 \n",
       "L 317.203642 287.962179 \n",
       "L 323.352402 288.101385 \n",
       "L 329.501162 288.219451 \n",
       "L 335.649923 288.372398 \n",
       "L 341.798683 288.500784 \n",
       "L 347.947443 288.595232 \n",
       "L 354.096204 288.667208 \n",
       "L 360.244964 288.749091 \n",
       "L 366.393724 288.822349 \n",
       "L 372.542485 288.865789 \n",
       "L 378.691245 288.932149 \n",
       "L 384.840005 288.958875 \n",
       "L 390.988765 289.000219 \n",
       "L 397.137526 289.017345 \n",
       "L 403.286286 289.049952 \n",
       "L 409.435046 289.069857 \n",
       "L 415.583807 289.091053 \n",
       "L 421.732567 289.107353 \n",
       "L 427.881327 289.106583 \n",
       "L 434.030088 289.126674 \n",
       "L 440.178848 289.136738 \n",
       "L 446.327608 289.144506 \n",
       "L 452.476369 289.151312 \n",
       "L 458.625129 289.154669 \n",
       "L 464.773889 289.165217 \n",
       "L 470.92265 289.16216 \n",
       "L 477.07141 289.167968 \n",
       "L 483.22017 289.173862 \n",
       "L 489.368931 289.169273 \n",
       "L 495.517691 289.175623 \n",
       "L 501.666451 289.174105 \n",
       "L 507.815212 289.176093 \n",
       "L 513.963972 289.180305 \n",
       "L 520.112732 289.179927 \n",
       "L 526.261493 289.181738 \n",
       "L 532.410253 289.182115 \n",
       "L 538.559013 289.180925 \n",
       "L 544.707774 289.181082 \n",
       "L 550.856534 289.179949 \n",
       "L 557.005294 289.181196 \n",
       "L 563.154055 289.18213 \n",
       "L 569.302815 289.183605 \n",
       "L 575.451575 289.180932 \n",
       "L 581.600336 289.183576 \n",
       "L 587.749096 289.181937 \n",
       "L 593.897856 289.182899 \n",
       "L 600.046617 289.182322 \n",
       "L 606.195377 289.181738 \n",
       "L 612.344137 289.183085 \n",
       "L 618.492898 289.183619 \n",
       "L 624.641658 289.183206 \n",
       "L 630.790418 289.183063 \n",
       "L 636.939179 289.183833 \n",
       "L 643.087939 289.183976 \n",
       "L 649.236699 289.184068 \n",
       "L 655.38546 289.183904 \n",
       "L 661.53422 289.183897 \n",
       "L 667.68298 289.183427 \n",
       "L 673.831741 289.18121 \n",
       "L 679.980501 289.183413 \n",
       "L 686.129261 289.18347 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_98\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 357.339714 \n",
       "L 83.550749 359.477301 \n",
       "L 89.699509 360.555206 \n",
       "L 95.84827 361.354395 \n",
       "L 101.99703 362.018816 \n",
       "L 108.14579 362.561182 \n",
       "L 114.294551 363.031901 \n",
       "L 120.443311 363.438519 \n",
       "L 126.592071 363.795854 \n",
       "L 132.740832 364.092225 \n",
       "L 138.889592 364.337163 \n",
       "L 145.038352 364.557585 \n",
       "L 151.187113 364.744489 \n",
       "L 157.335873 364.909234 \n",
       "L 163.484633 365.053764 \n",
       "L 169.633394 365.178608 \n",
       "L 175.782154 365.298183 \n",
       "L 181.930914 365.403321 \n",
       "L 188.079675 365.491602 \n",
       "L 194.228435 365.580315 \n",
       "L 200.377195 365.661387 \n",
       "L 206.525956 365.732434 \n",
       "L 212.674716 365.805074 \n",
       "L 218.823476 365.85361 \n",
       "L 224.972237 365.905469 \n",
       "L 231.120997 365.947358 \n",
       "L 237.269757 365.98589 \n",
       "L 243.418518 366.011921 \n",
       "L 249.567278 366.023261 \n",
       "L 255.716038 366.033329 \n",
       "L 261.864799 366.041907 \n",
       "L 268.013559 366.05045 \n",
       "L 274.162319 366.055829 \n",
       "L 280.31108 366.059862 \n",
       "L 286.45984 366.060432 \n",
       "L 292.6086 366.061158 \n",
       "L 298.757361 366.061198 \n",
       "L 304.906121 366.060633 \n",
       "L 311.054881 366.059805 \n",
       "L 317.203642 366.056885 \n",
       "L 323.352402 366.053842 \n",
       "L 329.501162 366.051765 \n",
       "L 335.649923 366.051495 \n",
       "L 341.798683 366.047344 \n",
       "L 347.947443 366.04734 \n",
       "L 354.096204 366.044919 \n",
       "L 360.244964 366.041903 \n",
       "L 366.393724 366.041192 \n",
       "L 372.542485 366.03939 \n",
       "L 378.691245 366.039489 \n",
       "L 384.840005 366.037198 \n",
       "L 390.988765 366.034494 \n",
       "L 397.137526 366.033632 \n",
       "L 403.286286 366.031428 \n",
       "L 409.435046 366.030873 \n",
       "L 415.583807 366.027818 \n",
       "L 421.732567 366.025673 \n",
       "L 427.881327 366.025446 \n",
       "L 434.030088 366.025033 \n",
       "L 440.178848 366.021633 \n",
       "L 446.327608 366.021364 \n",
       "L 452.476369 366.021651 \n",
       "L 458.625129 366.019585 \n",
       "L 464.773889 366.018311 \n",
       "L 470.92265 366.016802 \n",
       "L 477.07141 366.015103 \n",
       "L 483.22017 366.017459 \n",
       "L 489.368931 366.01566 \n",
       "L 495.517691 366.014406 \n",
       "L 501.666451 366.014012 \n",
       "L 507.815212 366.013442 \n",
       "L 513.963972 366.016277 \n",
       "L 520.112732 366.016292 \n",
       "L 526.261493 366.015903 \n",
       "L 532.410253 366.014743 \n",
       "L 538.559013 366.014718 \n",
       "L 544.707774 366.017521 \n",
       "L 550.856534 366.016307 \n",
       "L 557.005294 366.017254 \n",
       "L 563.154055 366.013037 \n",
       "L 569.302815 366.015124 \n",
       "L 575.451575 366.013637 \n",
       "L 581.600336 366.01454 \n",
       "L 587.749096 366.013973 \n",
       "L 593.897856 366.014489 \n",
       "L 600.046617 366.015367 \n",
       "L 606.195377 366.015076 \n",
       "L 612.344137 366.012094 \n",
       "L 618.492898 366.013177 \n",
       "L 624.641658 366.014274 \n",
       "L 630.790418 366.015007 \n",
       "L 636.939179 366.013413 \n",
       "L 643.087939 366.015196 \n",
       "L 649.236699 366.014768 \n",
       "L 655.38546 366.016317 \n",
       "L 661.53422 366.016172 \n",
       "L 667.68298 366.01495 \n",
       "L 673.831741 366.013844 \n",
       "L 679.980501 366.01538 \n",
       "L 686.129261 366.016145 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_99\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 337.56197 \n",
       "L 83.550749 348.880447 \n",
       "L 89.699509 353.048062 \n",
       "L 95.84827 354.309744 \n",
       "L 101.99703 355.26539 \n",
       "L 108.14579 354.586862 \n",
       "L 114.294551 355.675721 \n",
       "L 120.443311 357.24842 \n",
       "L 126.592071 357.670582 \n",
       "L 132.740832 357.481824 \n",
       "L 138.889592 356.854772 \n",
       "L 145.038352 358.750546 \n",
       "L 151.187113 358.847861 \n",
       "L 157.335873 358.841463 \n",
       "L 163.484633 359.071348 \n",
       "L 169.633394 358.682369 \n",
       "L 175.782154 358.779158 \n",
       "L 181.930914 359.397755 \n",
       "L 188.079675 358.71231 \n",
       "L 194.228435 360.004721 \n",
       "L 200.377195 358.498659 \n",
       "L 206.525956 359.475435 \n",
       "L 212.674716 359.8782 \n",
       "L 218.823476 358.872153 \n",
       "L 224.972237 359.938624 \n",
       "L 231.120997 360.41833 \n",
       "L 237.269757 360.184738 \n",
       "L 243.418518 360.144133 \n",
       "L 249.567278 360.403162 \n",
       "L 255.716038 360.013807 \n",
       "L 261.864799 360.911301 \n",
       "L 268.013559 360.543662 \n",
       "L 274.162319 360.314226 \n",
       "L 280.31108 360.249635 \n",
       "L 286.45984 360.369931 \n",
       "L 292.6086 360.43401 \n",
       "L 298.757361 359.231642 \n",
       "L 304.906121 360.346411 \n",
       "L 311.054881 360.391931 \n",
       "L 317.203642 360.248257 \n",
       "L 323.352402 360.388921 \n",
       "L 329.501162 359.82706 \n",
       "L 335.649923 360.187979 \n",
       "L 341.798683 360.093562 \n",
       "L 347.947443 360.320426 \n",
       "L 354.096204 359.47664 \n",
       "L 360.244964 360.078891 \n",
       "L 366.393724 359.172037 \n",
       "L 372.542485 359.65799 \n",
       "L 378.691245 359.574138 \n",
       "L 384.840005 359.731528 \n",
       "L 390.988765 359.573597 \n",
       "L 397.137526 360.23056 \n",
       "L 403.286286 359.527167 \n",
       "L 409.435046 360.011087 \n",
       "L 415.583807 359.60993 \n",
       "L 421.732567 359.97097 \n",
       "L 427.881327 359.732004 \n",
       "L 434.030088 359.908238 \n",
       "L 440.178848 358.796679 \n",
       "L 446.327608 359.511976 \n",
       "L 452.476369 359.7116 \n",
       "L 458.625129 359.519292 \n",
       "L 464.773889 359.269906 \n",
       "L 470.92265 359.625972 \n",
       "L 477.07141 358.490409 \n",
       "L 483.22017 359.211922 \n",
       "L 489.368931 358.742348 \n",
       "L 495.517691 359.662231 \n",
       "L 501.666451 358.69642 \n",
       "L 507.815212 359.405815 \n",
       "L 513.963972 359.554335 \n",
       "L 520.112732 359.241807 \n",
       "L 526.261493 358.545207 \n",
       "L 532.410253 358.431324 \n",
       "L 538.559013 359.091905 \n",
       "L 544.707774 358.78612 \n",
       "L 550.856534 358.548643 \n",
       "L 557.005294 359.204265 \n",
       "L 563.154055 359.364997 \n",
       "L 569.302815 359.774482 \n",
       "L 575.451575 359.04645 \n",
       "L 581.600336 359.130949 \n",
       "L 587.749096 359.208322 \n",
       "L 593.897856 359.032904 \n",
       "L 600.046617 359.0682 \n",
       "L 606.195377 358.431823 \n",
       "L 612.344137 359.086014 \n",
       "L 618.492898 358.748144 \n",
       "L 624.641658 359.146004 \n",
       "L 630.790418 358.766155 \n",
       "L 636.939179 359.287672 \n",
       "L 643.087939 358.886074 \n",
       "L 649.236699 359.521479 \n",
       "L 655.38546 359.113255 \n",
       "L 661.53422 358.977218 \n",
       "L 667.68298 358.277973 \n",
       "L 673.831741 359.129066 \n",
       "L 679.980501 359.367911 \n",
       "L 686.129261 358.126023 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_100\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 367.289351 \n",
       "L 83.550749 369.933231 \n",
       "L 89.699509 369.900606 \n",
       "L 95.84827 369.992496 \n",
       "L 101.99703 370.167283 \n",
       "L 108.14579 370.218156 \n",
       "L 114.294551 370.118075 \n",
       "L 120.443311 370.042667 \n",
       "L 126.592071 370.118477 \n",
       "L 132.740832 370.302543 \n",
       "L 138.889592 370.281653 \n",
       "L 145.038352 370.240536 \n",
       "L 151.187113 370.319046 \n",
       "L 157.335873 370.209824 \n",
       "L 163.484633 370.097043 \n",
       "L 169.633394 370.321492 \n",
       "L 175.782154 370.18964 \n",
       "L 181.930914 370.259662 \n",
       "L 188.079675 370.244997 \n",
       "L 194.228435 370.306737 \n",
       "L 200.377195 370.263568 \n",
       "L 206.525956 370.275391 \n",
       "L 212.674716 370.344895 \n",
       "L 218.823476 370.300841 \n",
       "L 224.972237 370.320332 \n",
       "L 231.120997 370.046917 \n",
       "L 237.269757 370.280742 \n",
       "L 243.418518 370.367234 \n",
       "L 249.567278 370.184054 \n",
       "L 255.716038 370.083776 \n",
       "L 261.864799 370.309388 \n",
       "L 268.013559 370.25132 \n",
       "L 274.162319 370.233764 \n",
       "L 280.31108 370.16452 \n",
       "L 286.45984 370.318077 \n",
       "L 292.6086 370.187323 \n",
       "L 298.757361 370.280432 \n",
       "L 304.906121 370.205756 \n",
       "L 311.054881 370.186789 \n",
       "L 317.203642 370.291128 \n",
       "L 323.352402 370.264463 \n",
       "L 329.501162 370.218292 \n",
       "L 335.649923 370.288407 \n",
       "L 341.798683 370.222788 \n",
       "L 347.947443 370.165648 \n",
       "L 354.096204 370.159955 \n",
       "L 360.244964 370.158964 \n",
       "L 366.393724 370.230396 \n",
       "L 372.542485 370.136576 \n",
       "L 378.691245 370.267886 \n",
       "L 384.840005 370.233854 \n",
       "L 390.988765 370.277875 \n",
       "L 397.137526 370.179855 \n",
       "L 403.286286 370.257943 \n",
       "L 409.435046 370.267099 \n",
       "L 415.583807 370.290764 \n",
       "L 421.732567 370.176875 \n",
       "L 427.881327 370.324664 \n",
       "L 434.030088 370.189132 \n",
       "L 440.178848 370.169129 \n",
       "L 446.327608 370.280507 \n",
       "L 452.476369 370.240448 \n",
       "L 458.625129 370.253186 \n",
       "L 464.773889 370.278861 \n",
       "L 470.92265 370.240593 \n",
       "L 477.07141 370.154605 \n",
       "L 483.22017 370.380689 \n",
       "L 489.368931 370.148878 \n",
       "L 495.517691 370.142882 \n",
       "L 501.666451 370.092563 \n",
       "L 507.815212 370.245666 \n",
       "L 513.963972 370.210451 \n",
       "L 520.112732 370.233838 \n",
       "L 526.261493 370.169092 \n",
       "L 532.410253 370.229929 \n",
       "L 538.559013 370.255351 \n",
       "L 544.707774 370.222683 \n",
       "L 550.856534 370.21697 \n",
       "L 557.005294 370.269072 \n",
       "L 563.154055 370.247831 \n",
       "L 569.302815 370.314798 \n",
       "L 575.451575 370.21107 \n",
       "L 581.600336 370.210024 \n",
       "L 587.749096 370.257426 \n",
       "L 593.897856 370.220431 \n",
       "L 600.046617 370.238654 \n",
       "L 606.195377 370.151184 \n",
       "L 612.344137 370.201613 \n",
       "L 618.492898 370.221555 \n",
       "L 624.641658 370.20611 \n",
       "L 630.790418 370.28256 \n",
       "L 636.939179 370.216973 \n",
       "L 643.087939 370.178597 \n",
       "L 649.236699 370.200122 \n",
       "L 655.38546 370.173386 \n",
       "L 661.53422 370.112489 \n",
       "L 667.68298 370.216564 \n",
       "L 673.831741 370.207922 \n",
       "L 679.980501 370.257748 \n",
       "L 686.129261 370.146948 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_101\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 322.249251 \n",
       "L 83.550749 345.44665 \n",
       "L 89.699509 349.887275 \n",
       "L 95.84827 351.532471 \n",
       "L 101.99703 355.017471 \n",
       "L 108.14579 355.672075 \n",
       "L 114.294551 355.588112 \n",
       "L 120.443311 357.472311 \n",
       "L 126.592071 355.852288 \n",
       "L 132.740832 358.141429 \n",
       "L 138.889592 358.310277 \n",
       "L 145.038352 357.934353 \n",
       "L 151.187113 358.751896 \n",
       "L 157.335873 358.779947 \n",
       "L 163.484633 358.456973 \n",
       "L 169.633394 358.867703 \n",
       "L 175.782154 359.630049 \n",
       "L 181.930914 359.882893 \n",
       "L 188.079675 359.194151 \n",
       "L 194.228435 359.831476 \n",
       "L 200.377195 359.740001 \n",
       "L 206.525956 359.920949 \n",
       "L 212.674716 359.718107 \n",
       "L 218.823476 359.428306 \n",
       "L 224.972237 360.096324 \n",
       "L 231.120997 359.267877 \n",
       "L 237.269757 358.623972 \n",
       "L 243.418518 358.203337 \n",
       "L 249.567278 359.944718 \n",
       "L 255.716038 359.056652 \n",
       "L 261.864799 359.809052 \n",
       "L 268.013559 359.992863 \n",
       "L 274.162319 360.030141 \n",
       "L 280.31108 360.300514 \n",
       "L 286.45984 358.914863 \n",
       "L 292.6086 359.498406 \n",
       "L 298.757361 360.25105 \n",
       "L 304.906121 359.347009 \n",
       "L 311.054881 360.025258 \n",
       "L 317.203642 359.541088 \n",
       "L 323.352402 359.22538 \n",
       "L 329.501162 358.881637 \n",
       "L 335.649923 358.968203 \n",
       "L 341.798683 359.386688 \n",
       "L 347.947443 358.927192 \n",
       "L 354.096204 359.154291 \n",
       "L 360.244964 359.077367 \n",
       "L 366.393724 358.688251 \n",
       "L 372.542485 359.201745 \n",
       "L 378.691245 359.14462 \n",
       "L 384.840005 358.651836 \n",
       "L 390.988765 359.372624 \n",
       "L 397.137526 358.713633 \n",
       "L 403.286286 357.984606 \n",
       "L 409.435046 359.238467 \n",
       "L 415.583807 358.995738 \n",
       "L 421.732567 358.745808 \n",
       "L 427.881327 358.742217 \n",
       "L 434.030088 359.243058 \n",
       "L 440.178848 358.633934 \n",
       "L 446.327608 358.386483 \n",
       "L 452.476369 359.15082 \n",
       "L 458.625129 359.19601 \n",
       "L 464.773889 358.753013 \n",
       "L 470.92265 358.410405 \n",
       "L 477.07141 358.570885 \n",
       "L 483.22017 358.050945 \n",
       "L 489.368931 358.487619 \n",
       "L 495.517691 358.126705 \n",
       "L 501.666451 357.651926 \n",
       "L 507.815212 358.191249 \n",
       "L 513.963972 357.958022 \n",
       "L 520.112732 358.234857 \n",
       "L 526.261493 357.16975 \n",
       "L 532.410253 357.843593 \n",
       "L 538.559013 358.36641 \n",
       "L 544.707774 358.29724 \n",
       "L 550.856534 357.337193 \n",
       "L 557.005294 358.43166 \n",
       "L 563.154055 358.362433 \n",
       "L 569.302815 358.121815 \n",
       "L 575.451575 358.067142 \n",
       "L 581.600336 358.01758 \n",
       "L 587.749096 358.169579 \n",
       "L 593.897856 357.947215 \n",
       "L 600.046617 357.902216 \n",
       "L 606.195377 357.785339 \n",
       "L 612.344137 357.57109 \n",
       "L 618.492898 357.910374 \n",
       "L 624.641658 357.572122 \n",
       "L 630.790418 358.285359 \n",
       "L 636.939179 358.478413 \n",
       "L 643.087939 357.826149 \n",
       "L 649.236699 356.893303 \n",
       "L 655.38546 357.163812 \n",
       "L 661.53422 357.566169 \n",
       "L 667.68298 357.277002 \n",
       "L 673.831741 357.920092 \n",
       "L 679.980501 357.864869 \n",
       "L 686.129261 358.386831 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_102\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 368.566865 \n",
       "L 83.550749 369.935385 \n",
       "L 89.699509 369.973502 \n",
       "L 95.84827 369.721362 \n",
       "L 101.99703 370.213552 \n",
       "L 108.14579 369.983457 \n",
       "L 114.294551 370.249165 \n",
       "L 120.443311 370.049575 \n",
       "L 126.592071 370.182745 \n",
       "L 132.740832 370.057875 \n",
       "L 138.889592 370.121164 \n",
       "L 145.038352 370.200527 \n",
       "L 151.187113 370.24441 \n",
       "L 157.335873 370.287125 \n",
       "L 163.484633 370.25046 \n",
       "L 169.633394 370.312068 \n",
       "L 175.782154 370.296842 \n",
       "L 181.930914 370.069394 \n",
       "L 188.079675 370.272245 \n",
       "L 194.228435 370.300507 \n",
       "L 200.377195 370.212533 \n",
       "L 206.525956 370.163379 \n",
       "L 212.674716 370.181498 \n",
       "L 218.823476 370.13439 \n",
       "L 224.972237 370.193138 \n",
       "L 231.120997 370.23461 \n",
       "L 237.269757 370.274926 \n",
       "L 243.418518 370.298526 \n",
       "L 249.567278 370.259293 \n",
       "L 255.716038 370.162994 \n",
       "L 261.864799 370.334544 \n",
       "L 268.013559 370.277173 \n",
       "L 274.162319 370.160707 \n",
       "L 280.31108 370.248188 \n",
       "L 286.45984 370.243537 \n",
       "L 292.6086 370.183325 \n",
       "L 298.757361 370.268943 \n",
       "L 304.906121 370.30803 \n",
       "L 311.054881 370.229566 \n",
       "L 317.203642 370.218216 \n",
       "L 323.352402 370.114372 \n",
       "L 329.501162 370.324429 \n",
       "L 335.649923 370.225828 \n",
       "L 341.798683 370.222239 \n",
       "L 347.947443 370.25956 \n",
       "L 354.096204 370.173004 \n",
       "L 360.244964 370.24036 \n",
       "L 366.393724 370.146832 \n",
       "L 372.542485 370.186861 \n",
       "L 378.691245 370.109458 \n",
       "L 384.840005 370.286212 \n",
       "L 390.988765 370.220352 \n",
       "L 397.137526 370.217134 \n",
       "L 403.286286 370.305845 \n",
       "L 409.435046 370.202939 \n",
       "L 415.583807 370.225051 \n",
       "L 421.732567 370.294267 \n",
       "L 427.881327 370.278923 \n",
       "L 434.030088 370.269172 \n",
       "L 440.178848 370.160366 \n",
       "L 446.327608 370.171338 \n",
       "L 452.476369 370.124242 \n",
       "L 458.625129 370.280597 \n",
       "L 464.773889 370.108181 \n",
       "L 470.92265 370.210142 \n",
       "L 477.07141 370.202233 \n",
       "L 483.22017 370.305009 \n",
       "L 489.368931 370.3252 \n",
       "L 495.517691 370.154307 \n",
       "L 501.666451 370.320316 \n",
       "L 507.815212 370.222891 \n",
       "L 513.963972 370.119925 \n",
       "L 520.112732 370.165206 \n",
       "L 526.261493 370.234869 \n",
       "L 532.410253 370.241818 \n",
       "L 538.559013 370.227079 \n",
       "L 544.707774 370.247886 \n",
       "L 550.856534 370.288593 \n",
       "L 557.005294 370.249189 \n",
       "L 563.154055 370.241594 \n",
       "L 569.302815 370.154723 \n",
       "L 575.451575 370.339614 \n",
       "L 581.600336 370.229617 \n",
       "L 587.749096 370.225521 \n",
       "L 593.897856 370.236687 \n",
       "L 600.046617 370.141169 \n",
       "L 606.195377 370.219563 \n",
       "L 612.344137 370.164869 \n",
       "L 618.492898 370.246694 \n",
       "L 624.641658 370.306215 \n",
       "L 630.790418 370.234697 \n",
       "L 636.939179 370.150167 \n",
       "L 643.087939 370.314395 \n",
       "L 649.236699 370.231602 \n",
       "L 655.38546 370.117483 \n",
       "L 661.53422 370.329651 \n",
       "L 667.68298 370.129741 \n",
       "L 673.831741 370.222311 \n",
       "L 679.980501 370.2768 \n",
       "L 686.129261 370.217718 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_103\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 343.45836 \n",
       "L 83.550749 351.827607 \n",
       "L 89.699509 352.962311 \n",
       "L 95.84827 355.894925 \n",
       "L 101.99703 356.100567 \n",
       "L 108.14579 356.760425 \n",
       "L 114.294551 357.030964 \n",
       "L 120.443311 357.978353 \n",
       "L 126.592071 357.823971 \n",
       "L 132.740832 358.292455 \n",
       "L 138.889592 356.237688 \n",
       "L 145.038352 358.738224 \n",
       "L 151.187113 358.479256 \n",
       "L 157.335873 359.254073 \n",
       "L 163.484633 358.794975 \n",
       "L 169.633394 359.025204 \n",
       "L 175.782154 359.055371 \n",
       "L 181.930914 358.837081 \n",
       "L 188.079675 358.418643 \n",
       "L 194.228435 359.117058 \n",
       "L 200.377195 359.241255 \n",
       "L 206.525956 359.031563 \n",
       "L 212.674716 358.896082 \n",
       "L 218.823476 358.17828 \n",
       "L 224.972237 359.271671 \n",
       "L 231.120997 359.687914 \n",
       "L 237.269757 359.555825 \n",
       "L 243.418518 358.487826 \n",
       "L 249.567278 358.472885 \n",
       "L 255.716038 359.330606 \n",
       "L 261.864799 359.031106 \n",
       "L 268.013559 359.090037 \n",
       "L 274.162319 359.161072 \n",
       "L 280.31108 359.2017 \n",
       "L 286.45984 358.820313 \n",
       "L 292.6086 358.686986 \n",
       "L 298.757361 359.461318 \n",
       "L 304.906121 359.03583 \n",
       "L 311.054881 359.827953 \n",
       "L 317.203642 359.213789 \n",
       "L 323.352402 359.668447 \n",
       "L 329.501162 359.836367 \n",
       "L 335.649923 359.362254 \n",
       "L 341.798683 357.177774 \n",
       "L 347.947443 358.80684 \n",
       "L 354.096204 359.142531 \n",
       "L 360.244964 358.923096 \n",
       "L 366.393724 358.340964 \n",
       "L 372.542485 358.590471 \n",
       "L 378.691245 359.504201 \n",
       "L 384.840005 359.07205 \n",
       "L 390.988765 358.885242 \n",
       "L 397.137526 358.97825 \n",
       "L 403.286286 358.830001 \n",
       "L 409.435046 358.401811 \n",
       "L 415.583807 359.011231 \n",
       "L 421.732567 358.884066 \n",
       "L 427.881327 359.339978 \n",
       "L 434.030088 358.883465 \n",
       "L 440.178848 358.909331 \n",
       "L 446.327608 359.382435 \n",
       "L 452.476369 358.82862 \n",
       "L 458.625129 358.519286 \n",
       "L 464.773889 359.461361 \n",
       "L 470.92265 359.59988 \n",
       "L 477.07141 359.219957 \n",
       "L 483.22017 358.942847 \n",
       "L 489.368931 358.966847 \n",
       "L 495.517691 358.74677 \n",
       "L 501.666451 359.425049 \n",
       "L 507.815212 359.12007 \n",
       "L 513.963972 359.267012 \n",
       "L 520.112732 359.367595 \n",
       "L 526.261493 358.584554 \n",
       "L 532.410253 359.256739 \n",
       "L 538.559013 358.714523 \n",
       "L 544.707774 358.46449 \n",
       "L 550.856534 358.359896 \n",
       "L 557.005294 359.245333 \n",
       "L 563.154055 359.332207 \n",
       "L 569.302815 359.217898 \n",
       "L 575.451575 358.862217 \n",
       "L 581.600336 359.171342 \n",
       "L 587.749096 359.216726 \n",
       "L 593.897856 358.924317 \n",
       "L 600.046617 359.073505 \n",
       "L 606.195377 358.9033 \n",
       "L 612.344137 359.396879 \n",
       "L 618.492898 359.141492 \n",
       "L 624.641658 358.871975 \n",
       "L 630.790418 359.149006 \n",
       "L 636.939179 359.482256 \n",
       "L 643.087939 358.81997 \n",
       "L 649.236699 359.53181 \n",
       "L 655.38546 359.310855 \n",
       "L 661.53422 358.986875 \n",
       "L 667.68298 359.401537 \n",
       "L 673.831741 358.962279 \n",
       "L 679.980501 359.224721 \n",
       "L 686.129261 358.98145 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_104\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 368.366405 \n",
       "L 83.550749 369.703904 \n",
       "L 89.699509 369.814994 \n",
       "L 95.84827 369.72013 \n",
       "L 101.99703 370.100646 \n",
       "L 108.14579 370.180104 \n",
       "L 114.294551 370.128654 \n",
       "L 120.443311 370.07195 \n",
       "L 126.592071 370.206827 \n",
       "L 132.740832 370.216673 \n",
       "L 138.889592 370.283439 \n",
       "L 145.038352 370.319493 \n",
       "L 151.187113 370.151803 \n",
       "L 157.335873 370.21964 \n",
       "L 163.484633 370.255081 \n",
       "L 169.633394 370.076766 \n",
       "L 175.782154 370.270263 \n",
       "L 181.930914 370.249441 \n",
       "L 188.079675 370.253563 \n",
       "L 194.228435 370.057217 \n",
       "L 200.377195 370.269105 \n",
       "L 206.525956 370.261122 \n",
       "L 212.674716 370.214499 \n",
       "L 218.823476 370.321937 \n",
       "L 224.972237 370.226287 \n",
       "L 231.120997 370.179802 \n",
       "L 237.269757 370.326002 \n",
       "L 243.418518 370.294092 \n",
       "L 249.567278 370.30457 \n",
       "L 255.716038 370.278756 \n",
       "L 261.864799 370.060296 \n",
       "L 268.013559 370.225444 \n",
       "L 274.162319 370.262155 \n",
       "L 280.31108 370.21429 \n",
       "L 286.45984 370.344379 \n",
       "L 292.6086 370.283549 \n",
       "L 298.757361 370.319849 \n",
       "L 304.906121 370.283956 \n",
       "L 311.054881 370.216693 \n",
       "L 317.203642 370.277481 \n",
       "L 323.352402 370.33454 \n",
       "L 329.501162 370.282927 \n",
       "L 335.649923 370.248434 \n",
       "L 341.798683 370.296721 \n",
       "L 347.947443 370.372873 \n",
       "L 354.096204 370.28603 \n",
       "L 360.244964 370.303968 \n",
       "L 366.393724 370.320889 \n",
       "L 372.542485 370.35638 \n",
       "L 378.691245 370.214133 \n",
       "L 384.840005 370.341809 \n",
       "L 390.988765 370.209018 \n",
       "L 397.137526 370.250844 \n",
       "L 403.286286 370.316063 \n",
       "L 409.435046 370.341083 \n",
       "L 415.583807 370.328404 \n",
       "L 421.732567 370.395642 \n",
       "L 427.881327 370.394257 \n",
       "L 434.030088 370.391261 \n",
       "L 440.178848 370.371423 \n",
       "L 446.327608 370.380837 \n",
       "L 452.476369 370.249597 \n",
       "L 458.625129 370.339639 \n",
       "L 464.773889 370.317904 \n",
       "L 470.92265 370.366826 \n",
       "L 477.07141 370.404976 \n",
       "L 483.22017 370.357362 \n",
       "L 489.368931 370.347276 \n",
       "L 495.517691 370.337206 \n",
       "L 501.666451 370.29232 \n",
       "L 507.815212 370.31673 \n",
       "L 513.963972 370.3257 \n",
       "L 520.112732 370.244799 \n",
       "L 526.261493 370.285522 \n",
       "L 532.410253 370.2582 \n",
       "L 538.559013 370.331883 \n",
       "L 544.707774 370.423636 \n",
       "L 550.856534 370.35529 \n",
       "L 557.005294 370.308213 \n",
       "L 563.154055 370.30369 \n",
       "L 569.302815 370.121105 \n",
       "L 575.451575 370.208889 \n",
       "L 581.600336 370.29448 \n",
       "L 587.749096 370.264225 \n",
       "L 593.897856 370.314987 \n",
       "L 600.046617 370.313114 \n",
       "L 606.195377 370.247921 \n",
       "L 612.344137 370.30745 \n",
       "L 618.492898 370.327734 \n",
       "L 624.641658 370.371608 \n",
       "L 630.790418 370.265203 \n",
       "L 636.939179 370.362424 \n",
       "L 643.087939 370.313869 \n",
       "L 649.236699 370.35189 \n",
       "L 655.38546 370.310133 \n",
       "L 661.53422 370.346087 \n",
       "L 667.68298 370.275003 \n",
       "L 673.831741 370.2806 \n",
       "L 679.980501 370.352855 \n",
       "L 686.129261 370.332522 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_105\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 188.763218 \n",
       "L 83.550749 228.777631 \n",
       "L 89.699509 248.67635 \n",
       "L 95.84827 261.758109 \n",
       "L 101.99703 270.244308 \n",
       "L 108.14579 275.758608 \n",
       "L 114.294551 279.903717 \n",
       "L 120.443311 282.68903 \n",
       "L 126.592071 284.660263 \n",
       "L 132.740832 286.085522 \n",
       "L 138.889592 286.93972 \n",
       "L 145.038352 287.626396 \n",
       "L 151.187113 288.136215 \n",
       "L 157.335873 288.432229 \n",
       "L 163.484633 288.669653 \n",
       "L 169.633394 288.790969 \n",
       "L 175.782154 288.951613 \n",
       "L 181.930914 289.010639 \n",
       "L 188.079675 289.086221 \n",
       "L 194.228435 289.108586 \n",
       "L 200.377195 289.127202 \n",
       "L 206.525956 289.135804 \n",
       "L 212.674716 289.152118 \n",
       "L 218.823476 289.167719 \n",
       "L 224.972237 289.161091 \n",
       "L 231.120997 289.173093 \n",
       "L 237.269757 289.177846 \n",
       "L 243.418518 289.17935 \n",
       "L 249.567278 289.175858 \n",
       "L 255.716038 289.178637 \n",
       "L 261.864799 289.181267 \n",
       "L 268.013559 289.18218 \n",
       "L 274.162319 289.178794 \n",
       "L 280.31108 289.182429 \n",
       "L 286.45984 289.182286 \n",
       "L 292.6086 289.182073 \n",
       "L 298.757361 289.183484 \n",
       "L 304.906121 289.183021 \n",
       "L 311.054881 289.183498 \n",
       "L 317.203642 289.180205 \n",
       "L 323.352402 289.182971 \n",
       "L 329.501162 289.18213 \n",
       "L 335.649923 289.182258 \n",
       "L 341.798683 289.183805 \n",
       "L 347.947443 289.183847 \n",
       "L 354.096204 289.179186 \n",
       "L 360.244964 289.18255 \n",
       "L 366.393724 289.183726 \n",
       "L 372.542485 289.184082 \n",
       "L 378.691245 289.183919 \n",
       "L 384.840005 289.184225 \n",
       "L 390.988765 289.184018 \n",
       "L 397.137526 289.18441 \n",
       "L 403.286286 289.184489 \n",
       "L 409.435046 289.18374 \n",
       "L 415.583807 289.18441 \n",
       "L 421.732567 289.184104 \n",
       "L 427.881327 289.184881 \n",
       "L 434.030088 289.183983 \n",
       "L 440.178848 289.185187 \n",
       "L 446.327608 289.18466 \n",
       "L 452.476369 289.184809 \n",
       "L 458.625129 289.185551 \n",
       "L 464.773889 289.185636 \n",
       "L 470.92265 289.183833 \n",
       "L 477.07141 289.186385 \n",
       "L 483.22017 289.186042 \n",
       "L 489.368931 289.183776 \n",
       "L 495.517691 289.18694 \n",
       "L 501.666451 289.185258 \n",
       "L 507.815212 289.186399 \n",
       "L 513.963972 289.182871 \n",
       "L 520.112732 289.188166 \n",
       "L 526.261493 289.188451 \n",
       "L 532.410253 289.190247 \n",
       "L 538.559013 289.19101 \n",
       "L 544.707774 289.192293 \n",
       "L 550.856534 289.189891 \n",
       "L 557.005294 289.195586 \n",
       "L 563.154055 289.197232 \n",
       "L 569.302815 289.200546 \n",
       "L 575.451575 289.205328 \n",
       "L 581.600336 289.212106 \n",
       "L 587.749096 289.222754 \n",
       "L 593.897856 289.242881 \n",
       "L 600.046617 289.295927 \n",
       "L 606.195377 289.463976 \n",
       "L 612.344137 290.883298 \n",
       "L 618.492898 300.254996 \n",
       "L 624.641658 307.397904 \n",
       "L 630.790418 310.511125 \n",
       "L 636.939179 312.569515 \n",
       "L 643.087939 314.638146 \n",
       "L 649.236699 316.387764 \n",
       "L 655.38546 317.791139 \n",
       "L 661.53422 319.181461 \n",
       "L 667.68298 320.449352 \n",
       "L 673.831741 321.707752 \n",
       "L 679.980501 322.519031 \n",
       "L 686.129261 324.137137 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_106\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 363.870145 \n",
       "L 83.550749 365.052977 \n",
       "L 89.699509 365.589416 \n",
       "L 95.84827 365.912623 \n",
       "L 101.99703 366.03425 \n",
       "L 108.14579 366.059618 \n",
       "L 114.294551 366.0594 \n",
       "L 120.443311 366.056195 \n",
       "L 126.592071 366.048409 \n",
       "L 132.740832 366.0436 \n",
       "L 138.889592 366.030748 \n",
       "L 145.038352 366.034211 \n",
       "L 151.187113 366.021339 \n",
       "L 157.335873 366.021349 \n",
       "L 163.484633 366.012861 \n",
       "L 169.633394 366.017172 \n",
       "L 175.782154 366.015275 \n",
       "L 181.930914 366.013913 \n",
       "L 188.079675 366.013361 \n",
       "L 194.228435 366.014464 \n",
       "L 200.377195 366.013483 \n",
       "L 206.525956 366.013993 \n",
       "L 212.674716 366.011848 \n",
       "L 218.823476 366.009869 \n",
       "L 224.972237 366.006922 \n",
       "L 231.120997 366.014809 \n",
       "L 237.269757 366.013992 \n",
       "L 243.418518 366.00744 \n",
       "L 249.567278 366.013005 \n",
       "L 255.716038 366.014945 \n",
       "L 261.864799 366.014773 \n",
       "L 268.013559 366.014968 \n",
       "L 274.162319 366.013388 \n",
       "L 280.31108 366.01366 \n",
       "L 286.45984 366.015797 \n",
       "L 292.6086 366.015215 \n",
       "L 298.757361 366.019552 \n",
       "L 304.906121 366.014377 \n",
       "L 311.054881 366.013446 \n",
       "L 317.203642 366.016247 \n",
       "L 323.352402 366.01745 \n",
       "L 329.501162 366.015274 \n",
       "L 335.649923 366.012241 \n",
       "L 341.798683 366.011951 \n",
       "L 347.947443 366.010253 \n",
       "L 354.096204 366.011972 \n",
       "L 360.244964 366.009869 \n",
       "L 366.393724 366.013711 \n",
       "L 372.542485 366.013943 \n",
       "L 378.691245 366.0138 \n",
       "L 384.840005 366.015906 \n",
       "L 390.988765 366.013846 \n",
       "L 397.137526 366.012311 \n",
       "L 403.286286 366.015389 \n",
       "L 409.435046 366.021479 \n",
       "L 415.583807 366.014263 \n",
       "L 421.732567 366.017028 \n",
       "L 427.881327 366.016745 \n",
       "L 434.030088 366.028739 \n",
       "L 440.178848 366.061764 \n",
       "L 446.327608 366.474366 \n",
       "L 452.476369 367.135263 \n",
       "L 458.625129 367.497187 \n",
       "L 464.773889 367.639339 \n",
       "L 470.92265 367.674863 \n",
       "L 477.07141 367.73171 \n",
       "L 483.22017 367.770769 \n",
       "L 489.368931 367.812037 \n",
       "L 495.517691 367.83025 \n",
       "L 501.666451 367.798502 \n",
       "L 507.815212 367.890077 \n",
       "L 513.963972 367.873509 \n",
       "L 520.112732 367.92197 \n",
       "L 526.261493 367.987806 \n",
       "L 532.410253 368.041106 \n",
       "L 538.559013 368.057865 \n",
       "L 544.707774 368.07292 \n",
       "L 550.856534 368.101215 \n",
       "L 557.005294 368.139594 \n",
       "L 563.154055 368.192114 \n",
       "L 569.302815 368.235621 \n",
       "L 575.451575 368.214065 \n",
       "L 581.600336 368.285737 \n",
       "L 587.749096 368.354318 \n",
       "L 593.897856 368.386867 \n",
       "L 600.046617 368.388551 \n",
       "L 606.195377 368.41846 \n",
       "L 612.344137 368.394251 \n",
       "L 618.492898 368.490613 \n",
       "L 624.641658 368.498142 \n",
       "L 630.790418 368.553926 \n",
       "L 636.939179 368.55735 \n",
       "L 643.087939 368.568934 \n",
       "L 649.236699 368.61331 \n",
       "L 655.38546 368.637697 \n",
       "L 661.53422 368.620232 \n",
       "L 667.68298 368.687887 \n",
       "L 673.831741 368.716896 \n",
       "L 679.980501 368.751115 \n",
       "L 686.129261 368.734951 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_107\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 215.434196 \n",
       "L 83.550749 247.706602 \n",
       "L 89.699509 263.674164 \n",
       "L 95.84827 273.028601 \n",
       "L 101.99703 278.303568 \n",
       "L 108.14579 282.265035 \n",
       "L 114.294551 284.71527 \n",
       "L 120.443311 286.169358 \n",
       "L 126.592071 287.271248 \n",
       "L 132.740832 287.863099 \n",
       "L 138.889592 288.274437 \n",
       "L 145.038352 288.566182 \n",
       "L 151.187113 288.787598 \n",
       "L 157.335873 288.900847 \n",
       "L 163.484633 288.989037 \n",
       "L 169.633394 289.058504 \n",
       "L 175.782154 289.092037 \n",
       "L 181.930914 289.122305 \n",
       "L 188.079675 289.149352 \n",
       "L 194.228435 289.169807 \n",
       "L 200.377195 289.157983 \n",
       "L 206.525956 289.18012 \n",
       "L 212.674716 289.166329 \n",
       "L 218.823476 289.176243 \n",
       "L 224.972237 289.177262 \n",
       "L 231.120997 289.178046 \n",
       "L 237.269757 289.175765 \n",
       "L 243.418518 289.180312 \n",
       "L 249.567278 289.182629 \n",
       "L 255.716038 289.18265 \n",
       "L 261.864799 289.179407 \n",
       "L 268.013559 289.183184 \n",
       "L 274.162319 289.183491 \n",
       "L 280.31108 289.180711 \n",
       "L 286.45984 289.182529 \n",
       "L 292.6086 289.182564 \n",
       "L 298.757361 289.183313 \n",
       "L 304.906121 289.18414 \n",
       "L 311.054881 289.184182 \n",
       "L 317.203642 289.184147 \n",
       "L 323.352402 289.183049 \n",
       "L 329.501162 289.184082 \n",
       "L 335.649923 289.184403 \n",
       "L 341.798683 289.184325 \n",
       "L 347.947443 289.18409 \n",
       "L 354.096204 289.182165 \n",
       "L 360.244964 289.184161 \n",
       "L 366.393724 289.184895 \n",
       "L 372.542485 289.18508 \n",
       "L 378.691245 289.183983 \n",
       "L 384.840005 289.185365 \n",
       "L 390.988765 289.184824 \n",
       "L 397.137526 289.185586 \n",
       "L 403.286286 289.18461 \n",
       "L 409.435046 289.18503 \n",
       "L 415.583807 289.183477 \n",
       "L 421.732567 289.186014 \n",
       "L 427.881327 289.18699 \n",
       "L 434.030088 289.18632 \n",
       "L 440.178848 289.18791 \n",
       "L 446.327608 289.188366 \n",
       "L 452.476369 289.188801 \n",
       "L 458.625129 289.186741 \n",
       "L 464.773889 289.190012 \n",
       "L 470.92265 289.190276 \n",
       "L 477.07141 289.190604 \n",
       "L 483.22017 289.190782 \n",
       "L 489.368931 289.193654 \n",
       "L 495.517691 289.195129 \n",
       "L 501.666451 289.196206 \n",
       "L 507.815212 289.198436 \n",
       "L 513.963972 289.202128 \n",
       "L 520.112732 289.205307 \n",
       "L 526.261493 289.211807 \n",
       "L 532.410253 289.220131 \n",
       "L 538.559013 289.230879 \n",
       "L 544.707774 289.261397 \n",
       "L 550.856534 289.323103 \n",
       "L 557.005294 289.550662 \n",
       "L 563.154055 290.928776 \n",
       "L 569.302815 300.268145 \n",
       "L 575.451575 307.272325 \n",
       "L 581.600336 309.844618 \n",
       "L 587.749096 312.482607 \n",
       "L 593.897856 314.475956 \n",
       "L 600.046617 316.170018 \n",
       "L 606.195377 317.623522 \n",
       "L 612.344137 318.930133 \n",
       "L 618.492898 319.957568 \n",
       "L 624.641658 321.278394 \n",
       "L 630.790418 322.473581 \n",
       "L 636.939179 323.622318 \n",
       "L 643.087939 324.528397 \n",
       "L 649.236699 326.079163 \n",
       "L 655.38546 327.234999 \n",
       "L 661.53422 328.233757 \n",
       "L 667.68298 329.69024 \n",
       "L 673.831741 330.789761 \n",
       "L 679.980501 332.012776 \n",
       "L 686.129261 333.18253 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_108\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 363.50494 \n",
       "L 83.550749 364.933616 \n",
       "L 89.699509 365.543522 \n",
       "L 95.84827 365.888198 \n",
       "L 101.99703 366.023125 \n",
       "L 108.14579 366.05945 \n",
       "L 114.294551 366.060808 \n",
       "L 120.443311 366.052374 \n",
       "L 126.592071 366.044139 \n",
       "L 132.740832 366.040554 \n",
       "L 138.889592 366.031377 \n",
       "L 145.038352 366.02858 \n",
       "L 151.187113 366.022576 \n",
       "L 157.335873 366.025986 \n",
       "L 163.484633 366.016407 \n",
       "L 169.633394 366.021901 \n",
       "L 175.782154 366.01824 \n",
       "L 181.930914 366.015601 \n",
       "L 188.079675 366.013408 \n",
       "L 194.228435 366.012317 \n",
       "L 200.377195 366.014966 \n",
       "L 206.525956 366.007809 \n",
       "L 212.674716 366.014604 \n",
       "L 218.823476 366.00816 \n",
       "L 224.972237 366.014576 \n",
       "L 231.120997 366.014688 \n",
       "L 237.269757 366.014519 \n",
       "L 243.418518 366.01534 \n",
       "L 249.567278 366.008029 \n",
       "L 255.716038 366.011954 \n",
       "L 261.864799 366.009009 \n",
       "L 268.013559 366.007559 \n",
       "L 274.162319 366.015221 \n",
       "L 280.31108 366.011093 \n",
       "L 286.45984 366.013726 \n",
       "L 292.6086 366.016032 \n",
       "L 298.757361 366.01268 \n",
       "L 304.906121 366.011785 \n",
       "L 311.054881 366.012004 \n",
       "L 317.203642 366.011819 \n",
       "L 323.352402 366.011849 \n",
       "L 329.501162 366.01172 \n",
       "L 335.649923 366.014955 \n",
       "L 341.798683 366.014898 \n",
       "L 347.947443 366.0152 \n",
       "L 354.096204 366.012645 \n",
       "L 360.244964 366.014517 \n",
       "L 366.393724 366.016442 \n",
       "L 372.542485 366.020797 \n",
       "L 378.691245 366.012656 \n",
       "L 384.840005 366.014803 \n",
       "L 390.988765 366.016866 \n",
       "L 397.137526 366.01496 \n",
       "L 403.286286 366.01452 \n",
       "L 409.435046 366.012862 \n",
       "L 415.583807 366.011207 \n",
       "L 421.732567 366.014346 \n",
       "L 427.881327 366.013621 \n",
       "L 434.030088 366.015432 \n",
       "L 440.178848 366.013962 \n",
       "L 446.327608 366.014782 \n",
       "L 452.476369 366.022502 \n",
       "L 458.625129 366.017115 \n",
       "L 464.773889 366.015031 \n",
       "L 470.92265 366.018422 \n",
       "L 477.07141 366.02852 \n",
       "L 483.22017 366.106627 \n",
       "L 489.368931 366.849506 \n",
       "L 495.517691 367.454411 \n",
       "L 501.666451 367.410181 \n",
       "L 507.815212 367.636346 \n",
       "L 513.963972 367.687647 \n",
       "L 520.112732 367.701659 \n",
       "L 526.261493 367.760648 \n",
       "L 532.410253 367.776947 \n",
       "L 538.559013 367.793843 \n",
       "L 544.707774 367.793066 \n",
       "L 550.856534 367.834733 \n",
       "L 557.005294 367.857522 \n",
       "L 563.154055 367.892927 \n",
       "L 569.302815 367.880417 \n",
       "L 575.451575 367.916759 \n",
       "L 581.600336 367.993569 \n",
       "L 587.749096 367.948178 \n",
       "L 593.897856 368.038045 \n",
       "L 600.046617 368.072638 \n",
       "L 606.195377 368.083513 \n",
       "L 612.344137 367.994848 \n",
       "L 618.492898 368.11285 \n",
       "L 624.641658 368.190219 \n",
       "L 630.790418 368.261908 \n",
       "L 636.939179 368.264588 \n",
       "L 643.087939 368.256439 \n",
       "L 649.236699 368.345284 \n",
       "L 655.38546 368.372915 \n",
       "L 661.53422 368.40415 \n",
       "L 667.68298 368.429569 \n",
       "L 673.831741 368.44806 \n",
       "L 679.980501 368.467807 \n",
       "L 686.129261 368.463319 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_109\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 208.516531 \n",
       "L 83.550749 242.562216 \n",
       "L 89.699509 258.155453 \n",
       "L 95.84827 268.895358 \n",
       "L 101.99703 275.472942 \n",
       "L 108.14579 279.977268 \n",
       "L 114.294551 282.871575 \n",
       "L 120.443311 284.826651 \n",
       "L 126.592071 286.160413 \n",
       "L 132.740832 287.165576 \n",
       "L 138.889592 287.843956 \n",
       "L 145.038352 288.211647 \n",
       "L 151.187113 288.54334 \n",
       "L 157.335873 288.739248 \n",
       "L 163.484633 288.893684 \n",
       "L 169.633394 288.956659 \n",
       "L 175.782154 288.993455 \n",
       "L 181.930914 289.05457 \n",
       "L 188.079675 289.10344 \n",
       "L 194.228435 289.135198 \n",
       "L 200.377195 289.145903 \n",
       "L 206.525956 289.156066 \n",
       "L 212.674716 289.174404 \n",
       "L 218.823476 289.176264 \n",
       "L 224.972237 289.179172 \n",
       "L 231.120997 289.169201 \n",
       "L 237.269757 289.179564 \n",
       "L 243.418518 289.179322 \n",
       "L 249.567278 289.175744 \n",
       "L 255.716038 289.175815 \n",
       "L 261.864799 289.181837 \n",
       "L 268.013559 289.178901 \n",
       "L 274.162319 289.182066 \n",
       "L 280.31108 289.180234 \n",
       "L 286.45984 289.183755 \n",
       "L 292.6086 289.182757 \n",
       "L 298.757361 289.183512 \n",
       "L 304.906121 289.18322 \n",
       "L 311.054881 289.183626 \n",
       "L 317.203642 289.183983 \n",
       "L 323.352402 289.182251 \n",
       "L 329.501162 289.18027 \n",
       "L 335.649923 289.182009 \n",
       "L 341.798683 289.184218 \n",
       "L 347.947443 289.182778 \n",
       "L 354.096204 289.184289 \n",
       "L 360.244964 289.184033 \n",
       "L 366.393724 289.182358 \n",
       "L 372.542485 289.184332 \n",
       "L 378.691245 289.184068 \n",
       "L 384.840005 289.185038 \n",
       "L 390.988765 289.183156 \n",
       "L 397.137526 289.185116 \n",
       "L 403.286286 289.184567 \n",
       "L 409.435046 289.184731 \n",
       "L 415.583807 289.18585 \n",
       "L 421.732567 289.18466 \n",
       "L 427.881327 289.185829 \n",
       "L 434.030088 289.185287 \n",
       "L 440.178848 289.186634 \n",
       "L 446.327608 289.186769 \n",
       "L 452.476369 289.18714 \n",
       "L 458.625129 289.187062 \n",
       "L 464.773889 289.187404 \n",
       "L 470.92265 289.188394 \n",
       "L 477.07141 289.188972 \n",
       "L 483.22017 289.189492 \n",
       "L 489.368931 289.190283 \n",
       "L 495.517691 289.189962 \n",
       "L 501.666451 289.191074 \n",
       "L 507.815212 289.193055 \n",
       "L 513.963972 289.194274 \n",
       "L 520.112732 289.195842 \n",
       "L 526.261493 289.197652 \n",
       "L 532.410253 289.199954 \n",
       "L 538.559013 289.201893 \n",
       "L 544.707774 289.208101 \n",
       "L 550.856534 289.215135 \n",
       "L 557.005294 289.225947 \n",
       "L 563.154055 289.246359 \n",
       "L 569.302815 289.290789 \n",
       "L 575.451575 289.383212 \n",
       "L 581.600336 289.811198 \n",
       "L 587.749096 293.59305 \n",
       "L 593.897856 303.068204 \n",
       "L 600.046617 308.308954 \n",
       "L 606.195377 310.753159 \n",
       "L 612.344137 313.010233 \n",
       "L 618.492898 314.702571 \n",
       "L 624.641658 316.317163 \n",
       "L 630.790418 318.051283 \n",
       "L 636.939179 319.18397 \n",
       "L 643.087939 320.733482 \n",
       "L 649.236699 321.846056 \n",
       "L 655.38546 322.681142 \n",
       "L 661.53422 324.238779 \n",
       "L 667.68298 325.400312 \n",
       "L 673.831741 326.778654 \n",
       "L 679.980501 328.091299 \n",
       "L 686.129261 329.214724 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_110\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 363.036759 \n",
       "L 83.550749 364.547068 \n",
       "L 89.699509 365.222178 \n",
       "L 95.84827 365.608679 \n",
       "L 101.99703 365.868152 \n",
       "L 108.14579 366.011331 \n",
       "L 114.294551 366.050546 \n",
       "L 120.443311 366.060748 \n",
       "L 126.592071 366.060523 \n",
       "L 132.740832 366.053524 \n",
       "L 138.889592 366.045191 \n",
       "L 145.038352 366.040824 \n",
       "L 151.187113 366.036106 \n",
       "L 157.335873 366.032017 \n",
       "L 163.484633 366.028799 \n",
       "L 169.633394 366.023679 \n",
       "L 175.782154 366.024055 \n",
       "L 181.930914 366.021548 \n",
       "L 188.079675 366.021679 \n",
       "L 194.228435 366.017795 \n",
       "L 200.377195 366.014933 \n",
       "L 206.525956 366.016476 \n",
       "L 212.674716 366.011857 \n",
       "L 218.823476 366.015292 \n",
       "L 224.972237 366.016486 \n",
       "L 231.120997 366.013893 \n",
       "L 237.269757 366.012543 \n",
       "L 243.418518 366.011781 \n",
       "L 249.567278 366.01416 \n",
       "L 255.716038 366.01643 \n",
       "L 261.864799 366.016263 \n",
       "L 268.013559 366.013148 \n",
       "L 274.162319 366.014582 \n",
       "L 280.31108 366.0164 \n",
       "L 286.45984 366.014491 \n",
       "L 292.6086 366.02002 \n",
       "L 298.757361 366.013829 \n",
       "L 304.906121 366.016997 \n",
       "L 311.054881 366.017824 \n",
       "L 317.203642 366.010948 \n",
       "L 323.352402 366.014883 \n",
       "L 329.501162 366.014704 \n",
       "L 335.649923 366.011305 \n",
       "L 341.798683 366.009739 \n",
       "L 347.947443 366.015316 \n",
       "L 354.096204 366.011234 \n",
       "L 360.244964 366.014294 \n",
       "L 366.393724 366.014571 \n",
       "L 372.542485 366.011804 \n",
       "L 378.691245 366.0133 \n",
       "L 384.840005 366.016602 \n",
       "L 390.988765 366.015733 \n",
       "L 397.137526 366.018376 \n",
       "L 403.286286 366.019147 \n",
       "L 409.435046 366.015819 \n",
       "L 415.583807 366.017949 \n",
       "L 421.732567 366.018356 \n",
       "L 427.881327 366.014337 \n",
       "L 434.030088 366.015044 \n",
       "L 440.178848 366.016044 \n",
       "L 446.327608 366.015584 \n",
       "L 452.476369 366.011249 \n",
       "L 458.625129 366.013547 \n",
       "L 464.773889 366.015586 \n",
       "L 470.92265 366.018144 \n",
       "L 477.07141 366.019162 \n",
       "L 483.22017 366.017691 \n",
       "L 489.368931 366.02435 \n",
       "L 495.517691 366.059396 \n",
       "L 501.666451 366.546757 \n",
       "L 507.815212 367.334577 \n",
       "L 513.963972 367.617601 \n",
       "L 520.112732 367.685194 \n",
       "L 526.261493 367.751296 \n",
       "L 532.410253 367.821767 \n",
       "L 538.559013 367.866231 \n",
       "L 544.707774 367.921116 \n",
       "L 550.856534 367.960065 \n",
       "L 557.005294 367.933552 \n",
       "L 563.154055 368.009713 \n",
       "L 569.302815 368.055041 \n",
       "L 575.451575 368.064221 \n",
       "L 581.600336 368.138009 \n",
       "L 587.749096 368.085856 \n",
       "L 593.897856 368.19386 \n",
       "L 600.046617 368.211148 \n",
       "L 606.195377 368.278725 \n",
       "L 612.344137 368.332128 \n",
       "L 618.492898 368.203221 \n",
       "L 624.641658 368.357318 \n",
       "L 630.790418 368.394007 \n",
       "L 636.939179 368.433556 \n",
       "L 643.087939 368.397576 \n",
       "L 649.236699 368.452207 \n",
       "L 655.38546 368.513359 \n",
       "L 661.53422 368.551838 \n",
       "L 667.68298 368.523071 \n",
       "L 673.831741 368.582005 \n",
       "L 679.980501 368.584667 \n",
       "L 686.129261 368.586916 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_111\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 341.377208 \n",
       "L 83.550749 353.270743 \n",
       "L 89.699509 355.975783 \n",
       "L 95.84827 354.343735 \n",
       "L 101.99703 356.360036 \n",
       "L 108.14579 359.172566 \n",
       "L 114.294551 359.069243 \n",
       "L 120.443311 357.83457 \n",
       "L 126.592071 359.467787 \n",
       "L 132.740832 360.11543 \n",
       "L 138.889592 359.980395 \n",
       "L 145.038352 358.045797 \n",
       "L 151.187113 360.460589 \n",
       "L 157.335873 360.185432 \n",
       "L 163.484633 359.615379 \n",
       "L 169.633394 360.215398 \n",
       "L 175.782154 360.338565 \n",
       "L 181.930914 360.528527 \n",
       "L 188.079675 359.642913 \n",
       "L 194.228435 360.281856 \n",
       "L 200.377195 360.380268 \n",
       "L 206.525956 360.592864 \n",
       "L 212.674716 360.17591 \n",
       "L 218.823476 359.574035 \n",
       "L 224.972237 360.081104 \n",
       "L 231.120997 360.189086 \n",
       "L 237.269757 360.113678 \n",
       "L 243.418518 359.613681 \n",
       "L 249.567278 359.359916 \n",
       "L 255.716038 360.520385 \n",
       "L 261.864799 360.734593 \n",
       "L 268.013559 359.61859 \n",
       "L 274.162319 359.880296 \n",
       "L 280.31108 360.467228 \n",
       "L 286.45984 359.633337 \n",
       "L 292.6086 360.157038 \n",
       "L 298.757361 360.297076 \n",
       "L 304.906121 359.509621 \n",
       "L 311.054881 360.754443 \n",
       "L 317.203642 359.370902 \n",
       "L 323.352402 359.263369 \n",
       "L 329.501162 358.858475 \n",
       "L 335.649923 359.340567 \n",
       "L 341.798683 360.45567 \n",
       "L 347.947443 360.555918 \n",
       "L 354.096204 360.681782 \n",
       "L 360.244964 360.193086 \n",
       "L 366.393724 360.029677 \n",
       "L 372.542485 360.426682 \n",
       "L 378.691245 360.050971 \n",
       "L 384.840005 360.102067 \n",
       "L 390.988765 360.246786 \n",
       "L 397.137526 357.860143 \n",
       "L 403.286286 360.077491 \n",
       "L 409.435046 360.381568 \n",
       "L 415.583807 359.83694 \n",
       "L 421.732567 359.013638 \n",
       "L 427.881327 359.987304 \n",
       "L 434.030088 359.705181 \n",
       "L 440.178848 360.833525 \n",
       "L 446.327608 359.798053 \n",
       "L 452.476369 360.214819 \n",
       "L 458.625129 360.881385 \n",
       "L 464.773889 360.322601 \n",
       "L 470.92265 359.399039 \n",
       "L 477.07141 359.881999 \n",
       "L 483.22017 359.398162 \n",
       "L 489.368931 359.410578 \n",
       "L 495.517691 359.892454 \n",
       "L 501.666451 359.73714 \n",
       "L 507.815212 359.587865 \n",
       "L 513.963972 360.737506 \n",
       "L 520.112732 359.782069 \n",
       "L 526.261493 360.123221 \n",
       "L 532.410253 360.102712 \n",
       "L 538.559013 360.30483 \n",
       "L 544.707774 360.043689 \n",
       "L 550.856534 358.709235 \n",
       "L 557.005294 360.818341 \n",
       "L 563.154055 359.89859 \n",
       "L 569.302815 358.972748 \n",
       "L 575.451575 359.297906 \n",
       "L 581.600336 359.391761 \n",
       "L 587.749096 359.646797 \n",
       "L 593.897856 359.749398 \n",
       "L 600.046617 359.671553 \n",
       "L 606.195377 360.683726 \n",
       "L 612.344137 360.111835 \n",
       "L 618.492898 360.188659 \n",
       "L 624.641658 360.419466 \n",
       "L 630.790418 359.43802 \n",
       "L 636.939179 359.6029 \n",
       "L 643.087939 359.65542 \n",
       "L 649.236699 359.636405 \n",
       "L 655.38546 359.717756 \n",
       "L 661.53422 360.154133 \n",
       "L 667.68298 359.419801 \n",
       "L 673.831741 360.13511 \n",
       "L 679.980501 359.435492 \n",
       "L 686.129261 358.897595 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_112\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 369.199495 \n",
       "L 83.550749 369.733764 \n",
       "L 89.699509 369.875297 \n",
       "L 95.84827 370.007256 \n",
       "L 101.99703 369.513513 \n",
       "L 108.14579 370.001132 \n",
       "L 114.294551 370.037092 \n",
       "L 120.443311 370.010046 \n",
       "L 126.592071 370.185687 \n",
       "L 132.740832 370.006565 \n",
       "L 138.889592 369.98854 \n",
       "L 145.038352 369.986787 \n",
       "L 151.187113 370.26532 \n",
       "L 157.335873 370.231758 \n",
       "L 163.484633 370.336515 \n",
       "L 169.633394 370.132765 \n",
       "L 175.782154 370.112411 \n",
       "L 181.930914 370.185753 \n",
       "L 188.079675 370.172369 \n",
       "L 194.228435 370.311629 \n",
       "L 200.377195 370.292126 \n",
       "L 206.525956 370.203283 \n",
       "L 212.674716 370.311895 \n",
       "L 218.823476 370.196132 \n",
       "L 224.972237 370.119319 \n",
       "L 231.120997 370.19073 \n",
       "L 237.269757 370.172082 \n",
       "L 243.418518 370.213642 \n",
       "L 249.567278 370.306747 \n",
       "L 255.716038 370.227999 \n",
       "L 261.864799 370.163884 \n",
       "L 268.013559 370.163399 \n",
       "L 274.162319 370.148841 \n",
       "L 280.31108 370.223719 \n",
       "L 286.45984 370.290898 \n",
       "L 292.6086 370.306982 \n",
       "L 298.757361 370.164233 \n",
       "L 304.906121 370.223474 \n",
       "L 311.054881 370.120006 \n",
       "L 317.203642 370.277916 \n",
       "L 323.352402 370.345791 \n",
       "L 329.501162 370.010507 \n",
       "L 335.649923 370.271589 \n",
       "L 341.798683 370.190627 \n",
       "L 347.947443 370.180332 \n",
       "L 354.096204 370.215229 \n",
       "L 360.244964 370.251153 \n",
       "L 366.393724 370.216366 \n",
       "L 372.542485 370.21235 \n",
       "L 378.691245 370.140519 \n",
       "L 384.840005 370.224371 \n",
       "L 390.988765 370.172109 \n",
       "L 397.137526 370.210713 \n",
       "L 403.286286 370.203655 \n",
       "L 409.435046 370.276689 \n",
       "L 415.583807 370.101187 \n",
       "L 421.732567 370.206292 \n",
       "L 427.881327 370.27116 \n",
       "L 434.030088 370.215548 \n",
       "L 440.178848 369.96976 \n",
       "L 446.327608 370.258317 \n",
       "L 452.476369 370.223538 \n",
       "L 458.625129 370.186592 \n",
       "L 464.773889 370.301132 \n",
       "L 470.92265 370.184154 \n",
       "L 477.07141 370.221627 \n",
       "L 483.22017 370.212341 \n",
       "L 489.368931 370.214695 \n",
       "L 495.517691 370.189347 \n",
       "L 501.666451 369.991271 \n",
       "L 507.815212 370.185722 \n",
       "L 513.963972 370.242157 \n",
       "L 520.112732 370.315214 \n",
       "L 526.261493 370.007882 \n",
       "L 532.410253 370.146057 \n",
       "L 538.559013 370.266855 \n",
       "L 544.707774 370.280049 \n",
       "L 550.856534 370.103328 \n",
       "L 557.005294 370.242129 \n",
       "L 563.154055 370.250593 \n",
       "L 569.302815 370.181492 \n",
       "L 575.451575 370.249701 \n",
       "L 581.600336 370.222219 \n",
       "L 587.749096 370.196794 \n",
       "L 593.897856 370.236915 \n",
       "L 600.046617 370.14316 \n",
       "L 606.195377 370.097436 \n",
       "L 612.344137 370.174765 \n",
       "L 618.492898 370.160226 \n",
       "L 624.641658 370.125108 \n",
       "L 630.790418 370.264647 \n",
       "L 636.939179 370.139679 \n",
       "L 643.087939 370.058744 \n",
       "L 649.236699 370.133006 \n",
       "L 655.38546 370.137175 \n",
       "L 661.53422 370.173234 \n",
       "L 667.68298 370.210953 \n",
       "L 673.831741 370.072697 \n",
       "L 679.980501 370.142433 \n",
       "L 686.129261 370.213052 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_113\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 346.405004 \n",
       "L 83.550749 350.128319 \n",
       "L 89.699509 355.386678 \n",
       "L 95.84827 355.566424 \n",
       "L 101.99703 356.87746 \n",
       "L 108.14579 356.994767 \n",
       "L 114.294551 357.701072 \n",
       "L 120.443311 359.376032 \n",
       "L 126.592071 358.445067 \n",
       "L 132.740832 359.037627 \n",
       "L 138.889592 359.398433 \n",
       "L 145.038352 360.203367 \n",
       "L 151.187113 359.583693 \n",
       "L 157.335873 359.928534 \n",
       "L 163.484633 359.631916 \n",
       "L 169.633394 359.507346 \n",
       "L 175.782154 360.387667 \n",
       "L 181.930914 360.427458 \n",
       "L 188.079675 360.57983 \n",
       "L 194.228435 360.691252 \n",
       "L 200.377195 361.206236 \n",
       "L 206.525956 360.373589 \n",
       "L 212.674716 360.946964 \n",
       "L 218.823476 360.174095 \n",
       "L 224.972237 361.181222 \n",
       "L 231.120997 360.81725 \n",
       "L 237.269757 361.002164 \n",
       "L 243.418518 360.4555 \n",
       "L 249.567278 360.385378 \n",
       "L 255.716038 359.608931 \n",
       "L 261.864799 360.124076 \n",
       "L 268.013559 361.082286 \n",
       "L 274.162319 359.659623 \n",
       "L 280.31108 360.770409 \n",
       "L 286.45984 360.991299 \n",
       "L 292.6086 359.486042 \n",
       "L 298.757361 360.108226 \n",
       "L 304.906121 360.830475 \n",
       "L 311.054881 360.204463 \n",
       "L 317.203642 360.438232 \n",
       "L 323.352402 358.976939 \n",
       "L 329.501162 360.525086 \n",
       "L 335.649923 361.531127 \n",
       "L 341.798683 359.950145 \n",
       "L 347.947443 358.87476 \n",
       "L 354.096204 360.64169 \n",
       "L 360.244964 360.391236 \n",
       "L 366.393724 358.424563 \n",
       "L 372.542485 360.999867 \n",
       "L 378.691245 360.194897 \n",
       "L 384.840005 359.311207 \n",
       "L 390.988765 360.559214 \n",
       "L 397.137526 360.949499 \n",
       "L 403.286286 360.589365 \n",
       "L 409.435046 360.467422 \n",
       "L 415.583807 360.363316 \n",
       "L 421.732567 360.181906 \n",
       "L 427.881327 360.460736 \n",
       "L 434.030088 360.446472 \n",
       "L 440.178848 360.414773 \n",
       "L 446.327608 361.233417 \n",
       "L 452.476369 358.611592 \n",
       "L 458.625129 359.785063 \n",
       "L 464.773889 360.749548 \n",
       "L 470.92265 360.71443 \n",
       "L 477.07141 360.210672 \n",
       "L 483.22017 359.494769 \n",
       "L 489.368931 360.490699 \n",
       "L 495.517691 360.437654 \n",
       "L 501.666451 360.558915 \n",
       "L 507.815212 360.242485 \n",
       "L 513.963972 360.537946 \n",
       "L 520.112732 359.992556 \n",
       "L 526.261493 359.551649 \n",
       "L 532.410253 360.348875 \n",
       "L 538.559013 360.400167 \n",
       "L 544.707774 361.208057 \n",
       "L 550.856534 360.239245 \n",
       "L 557.005294 358.014402 \n",
       "L 563.154055 360.583526 \n",
       "L 569.302815 360.656267 \n",
       "L 575.451575 358.960462 \n",
       "L 581.600336 359.685403 \n",
       "L 587.749096 359.288969 \n",
       "L 593.897856 359.849787 \n",
       "L 600.046617 359.723596 \n",
       "L 606.195377 360.223133 \n",
       "L 612.344137 359.951956 \n",
       "L 618.492898 359.500816 \n",
       "L 624.641658 359.397338 \n",
       "L 630.790418 359.802296 \n",
       "L 636.939179 359.966541 \n",
       "L 643.087939 360.238104 \n",
       "L 649.236699 359.616414 \n",
       "L 655.38546 359.507795 \n",
       "L 661.53422 360.081223 \n",
       "L 667.68298 359.455093 \n",
       "L 673.831741 360.07207 \n",
       "L 679.980501 360.389111 \n",
       "L 686.129261 359.370797 \n",
       "\" style=\"fill:none;stroke:#bcbd22;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_114\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 369.47435 \n",
       "L 83.550749 369.943873 \n",
       "L 89.699509 369.854607 \n",
       "L 95.84827 370.167558 \n",
       "L 101.99703 370.253564 \n",
       "L 108.14579 369.805491 \n",
       "L 114.294551 370.19541 \n",
       "L 120.443311 370.00404 \n",
       "L 126.592071 370.032644 \n",
       "L 132.740832 370.266155 \n",
       "L 138.889592 370.183459 \n",
       "L 145.038352 369.986381 \n",
       "L 151.187113 370.080806 \n",
       "L 157.335873 370.19285 \n",
       "L 163.484633 370.264315 \n",
       "L 169.633394 370.125424 \n",
       "L 175.782154 370.215379 \n",
       "L 181.930914 370.286084 \n",
       "L 188.079675 370.23969 \n",
       "L 194.228435 370.006268 \n",
       "L 200.377195 370.151443 \n",
       "L 206.525956 370.111904 \n",
       "L 212.674716 370.094227 \n",
       "L 218.823476 370.341652 \n",
       "L 224.972237 370.091804 \n",
       "L 231.120997 369.826445 \n",
       "L 237.269757 370.065136 \n",
       "L 243.418518 369.983052 \n",
       "L 249.567278 370.233578 \n",
       "L 255.716038 370.197018 \n",
       "L 261.864799 370.278445 \n",
       "L 268.013559 370.052774 \n",
       "L 274.162319 370.292887 \n",
       "L 280.31108 370.272937 \n",
       "L 286.45984 370.296175 \n",
       "L 292.6086 370.202279 \n",
       "L 298.757361 370.245824 \n",
       "L 304.906121 370.246212 \n",
       "L 311.054881 370.305021 \n",
       "L 317.203642 370.103616 \n",
       "L 323.352402 370.229399 \n",
       "L 329.501162 370.221298 \n",
       "L 335.649923 370.225642 \n",
       "L 341.798683 370.239045 \n",
       "L 347.947443 370.310944 \n",
       "L 354.096204 370.148636 \n",
       "L 360.244964 370.13553 \n",
       "L 366.393724 370.209389 \n",
       "L 372.542485 370.180284 \n",
       "L 378.691245 370.333578 \n",
       "L 384.840005 370.330574 \n",
       "L 390.988765 370.331708 \n",
       "L 397.137526 370.230876 \n",
       "L 403.286286 370.246868 \n",
       "L 409.435046 370.331676 \n",
       "L 415.583807 370.135535 \n",
       "L 421.732567 370.172578 \n",
       "L 427.881327 370.318363 \n",
       "L 434.030088 370.26339 \n",
       "L 440.178848 370.376478 \n",
       "L 446.327608 370.2081 \n",
       "L 452.476369 370.235294 \n",
       "L 458.625129 370.174568 \n",
       "L 464.773889 370.263547 \n",
       "L 470.92265 370.294829 \n",
       "L 477.07141 370.210818 \n",
       "L 483.22017 370.277672 \n",
       "L 489.368931 370.23816 \n",
       "L 495.517691 370.240575 \n",
       "L 501.666451 370.259494 \n",
       "L 507.815212 370.27002 \n",
       "L 513.963972 370.247879 \n",
       "L 520.112732 370.111527 \n",
       "L 526.261493 370.19496 \n",
       "L 532.410253 370.225154 \n",
       "L 538.559013 370.301828 \n",
       "L 544.707774 370.232298 \n",
       "L 550.856534 370.321736 \n",
       "L 557.005294 370.252908 \n",
       "L 563.154055 370.250924 \n",
       "L 569.302815 370.334045 \n",
       "L 575.451575 370.151174 \n",
       "L 581.600336 370.208556 \n",
       "L 587.749096 370.138458 \n",
       "L 593.897856 370.287245 \n",
       "L 600.046617 370.316624 \n",
       "L 606.195377 370.256284 \n",
       "L 612.344137 370.247375 \n",
       "L 618.492898 370.332872 \n",
       "L 624.641658 370.345657 \n",
       "L 630.790418 370.127023 \n",
       "L 636.939179 370.227238 \n",
       "L 643.087939 370.2838 \n",
       "L 649.236699 370.307691 \n",
       "L 655.38546 370.317695 \n",
       "L 661.53422 370.301353 \n",
       "L 667.68298 370.293343 \n",
       "L 673.831741 370.232825 \n",
       "L 679.980501 370.245904 \n",
       "L 686.129261 370.174802 \n",
       "\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_115\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 342.228818 \n",
       "L 83.550749 347.185996 \n",
       "L 89.699509 351.734535 \n",
       "L 95.84827 356.90061 \n",
       "L 101.99703 356.110709 \n",
       "L 108.14579 357.373961 \n",
       "L 114.294551 358.103312 \n",
       "L 120.443311 359.097063 \n",
       "L 126.592071 359.652806 \n",
       "L 132.740832 360.399862 \n",
       "L 138.889592 359.352101 \n",
       "L 145.038352 358.950886 \n",
       "L 151.187113 359.193451 \n",
       "L 157.335873 358.979674 \n",
       "L 163.484633 357.33472 \n",
       "L 169.633394 360.186759 \n",
       "L 175.782154 360.237018 \n",
       "L 181.930914 359.613006 \n",
       "L 188.079675 358.828248 \n",
       "L 194.228435 359.994254 \n",
       "L 200.377195 360.953465 \n",
       "L 206.525956 360.404738 \n",
       "L 212.674716 358.785063 \n",
       "L 218.823476 359.499411 \n",
       "L 224.972237 360.260787 \n",
       "L 231.120997 360.117699 \n",
       "L 237.269757 359.295871 \n",
       "L 243.418518 360.106803 \n",
       "L 249.567278 360.54116 \n",
       "L 255.716038 360.346787 \n",
       "L 261.864799 356.695896 \n",
       "L 268.013559 361.646816 \n",
       "L 274.162319 359.216107 \n",
       "L 280.31108 360.526281 \n",
       "L 286.45984 359.527817 \n",
       "L 292.6086 359.804848 \n",
       "L 298.757361 359.199191 \n",
       "L 304.906121 360.393307 \n",
       "L 311.054881 359.486238 \n",
       "L 317.203642 359.960217 \n",
       "L 323.352402 358.92343 \n",
       "L 329.501162 359.480765 \n",
       "L 335.649923 359.861379 \n",
       "L 341.798683 359.798933 \n",
       "L 347.947443 360.270452 \n",
       "L 354.096204 359.765134 \n",
       "L 360.244964 360.583353 \n",
       "L 366.393724 359.052769 \n",
       "L 372.542485 358.934661 \n",
       "L 378.691245 359.484743 \n",
       "L 384.840005 359.851179 \n",
       "L 390.988765 360.051144 \n",
       "L 397.137526 359.68168 \n",
       "L 403.286286 358.572965 \n",
       "L 409.435046 359.81146 \n",
       "L 415.583807 359.709268 \n",
       "L 421.732567 359.564388 \n",
       "L 427.881327 359.834399 \n",
       "L 434.030088 359.565071 \n",
       "L 440.178848 357.899652 \n",
       "L 446.327608 359.869973 \n",
       "L 452.476369 359.843334 \n",
       "L 458.625129 360.009179 \n",
       "L 464.773889 357.796553 \n",
       "L 470.92265 359.586667 \n",
       "L 477.07141 359.296158 \n",
       "L 483.22017 358.632096 \n",
       "L 489.368931 360.0166 \n",
       "L 495.517691 359.529203 \n",
       "L 501.666451 357.996565 \n",
       "L 507.815212 358.696587 \n",
       "L 513.963972 358.138658 \n",
       "L 520.112732 359.636764 \n",
       "L 526.261493 359.140273 \n",
       "L 532.410253 358.846228 \n",
       "L 538.559013 358.403787 \n",
       "L 544.707774 357.018905 \n",
       "L 550.856534 359.054536 \n",
       "L 557.005294 360.08315 \n",
       "L 563.154055 359.762673 \n",
       "L 569.302815 359.038721 \n",
       "L 575.451575 359.524013 \n",
       "L 581.600336 358.158692 \n",
       "L 587.749096 358.569885 \n",
       "L 593.897856 359.598917 \n",
       "L 600.046617 358.653725 \n",
       "L 606.195377 358.076773 \n",
       "L 612.344137 359.108607 \n",
       "L 618.492898 358.617157 \n",
       "L 624.641658 359.195621 \n",
       "L 630.790418 357.673697 \n",
       "L 636.939179 359.944028 \n",
       "L 643.087939 358.426603 \n",
       "L 649.236699 358.745383 \n",
       "L 655.38546 358.370191 \n",
       "L 661.53422 359.733978 \n",
       "L 667.68298 359.026754 \n",
       "L 673.831741 357.054501 \n",
       "L 679.980501 358.801671 \n",
       "L 686.129261 357.721224 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_116\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 367.499568 \n",
       "L 83.550749 369.513305 \n",
       "L 89.699509 369.914249 \n",
       "L 95.84827 369.965133 \n",
       "L 101.99703 370.122119 \n",
       "L 108.14579 370.050766 \n",
       "L 114.294551 369.825729 \n",
       "L 120.443311 370.162651 \n",
       "L 126.592071 370.235424 \n",
       "L 132.740832 370.259025 \n",
       "L 138.889592 370.286723 \n",
       "L 145.038352 370.294187 \n",
       "L 151.187113 370.213277 \n",
       "L 157.335873 370.159645 \n",
       "L 163.484633 370.193925 \n",
       "L 169.633394 370.030114 \n",
       "L 175.782154 370.274283 \n",
       "L 181.930914 370.192329 \n",
       "L 188.079675 370.226672 \n",
       "L 194.228435 370.110591 \n",
       "L 200.377195 370.142089 \n",
       "L 206.525956 370.191472 \n",
       "L 212.674716 370.142235 \n",
       "L 218.823476 370.216433 \n",
       "L 224.972237 370.053178 \n",
       "L 231.120997 370.170706 \n",
       "L 237.269757 370.135926 \n",
       "L 243.418518 370.209297 \n",
       "L 249.567278 370.259056 \n",
       "L 255.716038 370.213971 \n",
       "L 261.864799 370.216768 \n",
       "L 268.013559 370.239982 \n",
       "L 274.162319 370.297886 \n",
       "L 280.31108 370.190965 \n",
       "L 286.45984 370.328044 \n",
       "L 292.6086 370.179202 \n",
       "L 298.757361 370.113793 \n",
       "L 304.906121 370.131332 \n",
       "L 311.054881 370.259881 \n",
       "L 317.203642 370.276623 \n",
       "L 323.352402 370.286668 \n",
       "L 329.501162 370.155393 \n",
       "L 335.649923 370.211215 \n",
       "L 341.798683 370.295009 \n",
       "L 347.947443 370.136857 \n",
       "L 354.096204 370.328325 \n",
       "L 360.244964 370.177271 \n",
       "L 366.393724 370.23028 \n",
       "L 372.542485 370.136977 \n",
       "L 378.691245 370.229083 \n",
       "L 384.840005 370.268089 \n",
       "L 390.988765 370.241078 \n",
       "L 397.137526 370.186111 \n",
       "L 403.286286 370.349714 \n",
       "L 409.435046 369.968931 \n",
       "L 415.583807 370.200579 \n",
       "L 421.732567 370.148965 \n",
       "L 427.881327 370.280086 \n",
       "L 434.030088 370.073364 \n",
       "L 440.178848 370.25526 \n",
       "L 446.327608 370.248839 \n",
       "L 452.476369 370.350251 \n",
       "L 458.625129 370.287196 \n",
       "L 464.773889 370.124719 \n",
       "L 470.92265 370.333433 \n",
       "L 477.07141 370.311064 \n",
       "L 483.22017 370.32673 \n",
       "L 489.368931 370.227168 \n",
       "L 495.517691 370.210427 \n",
       "L 501.666451 370.273782 \n",
       "L 507.815212 370.257594 \n",
       "L 513.963972 370.377535 \n",
       "L 520.112732 370.250708 \n",
       "L 526.261493 370.243659 \n",
       "L 532.410253 370.283405 \n",
       "L 538.559013 370.190814 \n",
       "L 544.707774 370.274427 \n",
       "L 550.856534 370.2995 \n",
       "L 557.005294 370.31199 \n",
       "L 563.154055 370.162178 \n",
       "L 569.302815 370.133323 \n",
       "L 575.451575 370.235078 \n",
       "L 581.600336 370.21616 \n",
       "L 587.749096 370.318378 \n",
       "L 593.897856 370.243247 \n",
       "L 600.046617 370.309285 \n",
       "L 606.195377 370.307655 \n",
       "L 612.344137 370.251309 \n",
       "L 618.492898 370.252944 \n",
       "L 624.641658 370.243076 \n",
       "L 630.790418 370.290445 \n",
       "L 636.939179 370.277006 \n",
       "L 643.087939 370.302448 \n",
       "L 649.236699 370.127132 \n",
       "L 655.38546 370.232924 \n",
       "L 661.53422 370.308599 \n",
       "L 667.68298 370.25549 \n",
       "L 673.831741 370.281236 \n",
       "L 679.980501 370.256769 \n",
       "L 686.129261 370.215973 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_117\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 280.673502 \n",
       "L 83.550749 288.26014 \n",
       "L 89.699509 289.031428 \n",
       "L 95.84827 289.153579 \n",
       "L 101.99703 289.169422 \n",
       "L 108.14579 289.179842 \n",
       "L 114.294551 289.167334 \n",
       "L 120.443311 289.182465 \n",
       "L 126.592071 289.180134 \n",
       "L 132.740832 289.173228 \n",
       "L 138.889592 289.180676 \n",
       "L 145.038352 289.17052 \n",
       "L 151.187113 289.176856 \n",
       "L 157.335873 289.174425 \n",
       "L 163.484633 289.166422 \n",
       "L 169.633394 289.171888 \n",
       "L 175.782154 289.1827 \n",
       "L 181.930914 289.180768 \n",
       "L 188.079675 289.18275 \n",
       "L 194.228435 289.178759 \n",
       "L 200.377195 289.180719 \n",
       "L 206.525956 289.1828 \n",
       "L 212.674716 289.181175 \n",
       "L 218.823476 289.170028 \n",
       "L 224.972237 289.182258 \n",
       "L 231.120997 289.182728 \n",
       "L 237.269757 289.182279 \n",
       "L 243.418518 289.182643 \n",
       "L 249.567278 289.182971 \n",
       "L 255.716038 289.178409 \n",
       "L 261.864799 289.181403 \n",
       "L 268.013559 289.183028 \n",
       "L 274.162319 289.182486 \n",
       "L 280.31108 289.182051 \n",
       "L 286.45984 289.182429 \n",
       "L 292.6086 289.177184 \n",
       "L 298.757361 289.183206 \n",
       "L 304.906121 289.168645 \n",
       "L 311.054881 289.176364 \n",
       "L 317.203642 289.18322 \n",
       "L 323.352402 289.183242 \n",
       "L 329.501162 289.18307 \n",
       "L 335.649923 289.183142 \n",
       "L 341.798683 289.179372 \n",
       "L 347.947443 289.174653 \n",
       "L 354.096204 289.183341 \n",
       "L 360.244964 289.183762 \n",
       "L 366.393724 289.175993 \n",
       "L 372.542485 289.182222 \n",
       "L 378.691245 289.184154 \n",
       "L 384.840005 289.184467 \n",
       "L 390.988765 289.183085 \n",
       "L 397.137526 289.184539 \n",
       "L 403.286286 289.184988 \n",
       "L 409.435046 289.184353 \n",
       "L 415.583807 289.17444 \n",
       "L 421.732567 289.185472 \n",
       "L 427.881327 289.18704 \n",
       "L 434.030088 289.18714 \n",
       "L 440.178848 289.1858 \n",
       "L 446.327608 289.18833 \n",
       "L 452.476369 289.192906 \n",
       "L 458.625129 289.195493 \n",
       "L 464.773889 289.201551 \n",
       "L 470.92265 289.206625 \n",
       "L 477.07141 289.229539 \n",
       "L 483.22017 289.265381 \n",
       "L 489.368931 289.365295 \n",
       "L 495.517691 289.714363 \n",
       "L 501.666451 293.01903 \n",
       "L 507.815212 305.607242 \n",
       "L 513.963972 311.969924 \n",
       "L 520.112732 314.727523 \n",
       "L 526.261493 316.972794 \n",
       "L 532.410253 318.621988 \n",
       "L 538.559013 321.255662 \n",
       "L 544.707774 323.277095 \n",
       "L 550.856534 325.485128 \n",
       "L 557.005294 327.56326 \n",
       "L 563.154055 329.235193 \n",
       "L 569.302815 331.316695 \n",
       "L 575.451575 333.833792 \n",
       "L 581.600336 335.174664 \n",
       "L 587.749096 337.031793 \n",
       "L 593.897856 339.013731 \n",
       "L 600.046617 340.562911 \n",
       "L 606.195377 341.379881 \n",
       "L 612.344137 342.697976 \n",
       "L 618.492898 343.197385 \n",
       "L 624.641658 343.784666 \n",
       "L 630.790418 344.763022 \n",
       "L 636.939179 345.439327 \n",
       "L 643.087939 345.626257 \n",
       "L 649.236699 345.954899 \n",
       "L 655.38546 346.811037 \n",
       "L 661.53422 346.647065 \n",
       "L 667.68298 347.307442 \n",
       "L 673.831741 347.354059 \n",
       "L 679.980501 347.569149 \n",
       "L 686.129261 348.464145 \n",
       "\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_118\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 365.957081 \n",
       "L 83.550749 366.045285 \n",
       "L 89.699509 366.02967 \n",
       "L 95.84827 366.030098 \n",
       "L 101.99703 366.012331 \n",
       "L 108.14579 366.008556 \n",
       "L 114.294551 366.01827 \n",
       "L 120.443311 366.019138 \n",
       "L 126.592071 366.003527 \n",
       "L 132.740832 366.013949 \n",
       "L 138.889592 366.01477 \n",
       "L 145.038352 366.012615 \n",
       "L 151.187113 366.016899 \n",
       "L 157.335873 366.021889 \n",
       "L 163.484633 366.013463 \n",
       "L 169.633394 366.021174 \n",
       "L 175.782154 366.014635 \n",
       "L 181.930914 366.011206 \n",
       "L 188.079675 366.011466 \n",
       "L 194.228435 366.015289 \n",
       "L 200.377195 366.017172 \n",
       "L 206.525956 366.014616 \n",
       "L 212.674716 366.01889 \n",
       "L 218.823476 366.016658 \n",
       "L 224.972237 366.012848 \n",
       "L 231.120997 366.01501 \n",
       "L 237.269757 366.010184 \n",
       "L 243.418518 366.013947 \n",
       "L 249.567278 366.006485 \n",
       "L 255.716038 366.013112 \n",
       "L 261.864799 366.014586 \n",
       "L 268.013559 366.01646 \n",
       "L 274.162319 366.00642 \n",
       "L 280.31108 366.007564 \n",
       "L 286.45984 366.009831 \n",
       "L 292.6086 366.017301 \n",
       "L 298.757361 366.020835 \n",
       "L 304.906121 366.012531 \n",
       "L 311.054881 366.007767 \n",
       "L 317.203642 366.006592 \n",
       "L 323.352402 366.007535 \n",
       "L 329.501162 366.008555 \n",
       "L 335.649923 366.012584 \n",
       "L 341.798683 366.005009 \n",
       "L 347.947443 366.002539 \n",
       "L 354.096204 366.009044 \n",
       "L 360.244964 366.004157 \n",
       "L 366.393724 366.0109 \n",
       "L 372.542485 366.01066 \n",
       "L 378.691245 366.008039 \n",
       "L 384.840005 366.007387 \n",
       "L 390.988765 366.014965 \n",
       "L 397.137526 366.01396 \n",
       "L 403.286286 366.013041 \n",
       "L 409.435046 366.011406 \n",
       "L 415.583807 366.007054 \n",
       "L 421.732567 366.007358 \n",
       "L 427.881327 366.004849 \n",
       "L 434.030088 366.010902 \n",
       "L 440.178848 366.009435 \n",
       "L 446.327608 366.016723 \n",
       "L 452.476369 366.021239 \n",
       "L 458.625129 366.010155 \n",
       "L 464.773889 366.020484 \n",
       "L 470.92265 366.008763 \n",
       "L 477.07141 366.011979 \n",
       "L 483.22017 366.010953 \n",
       "L 489.368931 366.016401 \n",
       "L 495.517691 366.019226 \n",
       "L 501.666451 366.014115 \n",
       "L 507.815212 366.00969 \n",
       "L 513.963972 366.015932 \n",
       "L 520.112732 366.015691 \n",
       "L 526.261493 366.015683 \n",
       "L 532.410253 366.022005 \n",
       "L 538.559013 366.033643 \n",
       "L 544.707774 366.432691 \n",
       "L 550.856534 367.461173 \n",
       "L 557.005294 367.705486 \n",
       "L 563.154055 367.721115 \n",
       "L 569.302815 367.817581 \n",
       "L 575.451575 367.868691 \n",
       "L 581.600336 367.736207 \n",
       "L 587.749096 367.910687 \n",
       "L 593.897856 368.275927 \n",
       "L 600.046617 368.35763 \n",
       "L 606.195377 368.301356 \n",
       "L 612.344137 368.470548 \n",
       "L 618.492898 368.458788 \n",
       "L 624.641658 368.597659 \n",
       "L 630.790418 368.469517 \n",
       "L 636.939179 368.67882 \n",
       "L 643.087939 368.559762 \n",
       "L 649.236699 368.7881 \n",
       "L 655.38546 368.85352 \n",
       "L 661.53422 368.916717 \n",
       "L 667.68298 368.916746 \n",
       "L 673.831741 368.820257 \n",
       "L 679.980501 369.062222 \n",
       "L 686.129261 369.117486 \n",
       "\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_119\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 282.631586 \n",
       "L 83.550749 288.408582 \n",
       "L 89.699509 289.101387 \n",
       "L 95.84827 289.17687 \n",
       "L 101.99703 289.181118 \n",
       "L 108.14579 289.18265 \n",
       "L 114.294551 289.182529 \n",
       "L 120.443311 289.179842 \n",
       "L 126.592071 289.182386 \n",
       "L 132.740832 289.175808 \n",
       "L 138.889592 289.179044 \n",
       "L 145.038352 289.180576 \n",
       "L 151.187113 289.180562 \n",
       "L 157.335873 289.181966 \n",
       "L 163.484633 289.180825 \n",
       "L 169.633394 289.177055 \n",
       "L 175.782154 289.182158 \n",
       "L 181.930914 289.177012 \n",
       "L 188.079675 289.182258 \n",
       "L 194.228435 289.182365 \n",
       "L 200.377195 289.182671 \n",
       "L 206.525956 289.181189 \n",
       "L 212.674716 289.182415 \n",
       "L 218.823476 289.182842 \n",
       "L 224.972237 289.182821 \n",
       "L 231.120997 289.182515 \n",
       "L 237.269757 289.182222 \n",
       "L 243.418518 289.177804 \n",
       "L 249.567278 289.182871 \n",
       "L 255.716038 289.179393 \n",
       "L 261.864799 289.182985 \n",
       "L 268.013559 289.177412 \n",
       "L 274.162319 289.181381 \n",
       "L 280.31108 289.181225 \n",
       "L 286.45984 289.180954 \n",
       "L 292.6086 289.18265 \n",
       "L 298.757361 289.18322 \n",
       "L 304.906121 289.180077 \n",
       "L 311.054881 289.183341 \n",
       "L 317.203642 289.182479 \n",
       "L 323.352402 289.18218 \n",
       "L 329.501162 289.183227 \n",
       "L 335.649923 289.177005 \n",
       "L 341.798683 289.183548 \n",
       "L 347.947443 289.183733 \n",
       "L 354.096204 289.182714 \n",
       "L 360.244964 289.183284 \n",
       "L 366.393724 289.183712 \n",
       "L 372.542485 289.184147 \n",
       "L 378.691245 289.181488 \n",
       "L 384.840005 289.179735 \n",
       "L 390.988765 289.184795 \n",
       "L 397.137526 289.185016 \n",
       "L 403.286286 289.178573 \n",
       "L 409.435046 289.18508 \n",
       "L 415.583807 289.183028 \n",
       "L 421.732567 289.185016 \n",
       "L 427.881327 289.186641 \n",
       "L 434.030088 289.187646 \n",
       "L 440.178848 289.182286 \n",
       "L 446.327608 289.190932 \n",
       "L 452.476369 289.194894 \n",
       "L 458.625129 289.200261 \n",
       "L 464.773889 289.191837 \n",
       "L 470.92265 289.220979 \n",
       "L 477.07141 289.240101 \n",
       "L 483.22017 289.309248 \n",
       "L 489.368931 289.513159 \n",
       "L 495.517691 290.847328 \n",
       "L 501.666451 304.75087 \n",
       "L 507.815212 311.059914 \n",
       "L 513.963972 314.389825 \n",
       "L 520.112732 317.072669 \n",
       "L 526.261493 317.781436 \n",
       "L 532.410253 321.882204 \n",
       "L 538.559013 323.731722 \n",
       "L 544.707774 325.628716 \n",
       "L 550.856534 328.319492 \n",
       "L 557.005294 330.184436 \n",
       "L 563.154055 332.674155 \n",
       "L 569.302815 334.778763 \n",
       "L 575.451575 334.333943 \n",
       "L 581.600336 337.325074 \n",
       "L 587.749096 339.27855 \n",
       "L 593.897856 340.426838 \n",
       "L 600.046617 341.766665 \n",
       "L 606.195377 342.385699 \n",
       "L 612.344137 343.29499 \n",
       "L 618.492898 343.952273 \n",
       "L 624.641658 344.936327 \n",
       "L 630.790418 345.341902 \n",
       "L 636.939179 345.337936 \n",
       "L 643.087939 346.469846 \n",
       "L 649.236699 346.049927 \n",
       "L 655.38546 347.11601 \n",
       "L 661.53422 347.481137 \n",
       "L 667.68298 347.552709 \n",
       "L 673.831741 348.21691 \n",
       "L 679.980501 348.26657 \n",
       "L 686.129261 348.84035 \n",
       "\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_120\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 365.926994 \n",
       "L 83.550749 366.036613 \n",
       "L 89.699509 366.014453 \n",
       "L 95.84827 366.01991 \n",
       "L 101.99703 366.017973 \n",
       "L 108.14579 366.015477 \n",
       "L 114.294551 366.006069 \n",
       "L 120.443311 366.017671 \n",
       "L 126.592071 366.014271 \n",
       "L 132.740832 366.012591 \n",
       "L 138.889592 366.009899 \n",
       "L 145.038352 366.00921 \n",
       "L 151.187113 366.02402 \n",
       "L 157.335873 366.019203 \n",
       "L 163.484633 366.018721 \n",
       "L 169.633394 366.013112 \n",
       "L 175.782154 366.017331 \n",
       "L 181.930914 366.012947 \n",
       "L 188.079675 366.010301 \n",
       "L 194.228435 366.013841 \n",
       "L 200.377195 366.017343 \n",
       "L 206.525956 366.008999 \n",
       "L 212.674716 366.009262 \n",
       "L 218.823476 366.014913 \n",
       "L 224.972237 366.010573 \n",
       "L 231.120997 366.005648 \n",
       "L 237.269757 366.01477 \n",
       "L 243.418518 366.009563 \n",
       "L 249.567278 366.004754 \n",
       "L 255.716038 366.016257 \n",
       "L 261.864799 366.014809 \n",
       "L 268.013559 366.014129 \n",
       "L 274.162319 366.011988 \n",
       "L 280.31108 366.008165 \n",
       "L 286.45984 366.012793 \n",
       "L 292.6086 366.016687 \n",
       "L 298.757361 366.012466 \n",
       "L 304.906121 366.015225 \n",
       "L 311.054881 366.011322 \n",
       "L 317.203642 366.01123 \n",
       "L 323.352402 366.004738 \n",
       "L 329.501162 366.010834 \n",
       "L 335.649923 366.016011 \n",
       "L 341.798683 366.014457 \n",
       "L 347.947443 366.010182 \n",
       "L 354.096204 366.012794 \n",
       "L 360.244964 366.011326 \n",
       "L 366.393724 366.017513 \n",
       "L 372.542485 366.008453 \n",
       "L 378.691245 366.012714 \n",
       "L 384.840005 366.017633 \n",
       "L 390.988765 366.009003 \n",
       "L 397.137526 366.014981 \n",
       "L 403.286286 366.015374 \n",
       "L 409.435046 366.0159 \n",
       "L 415.583807 366.009882 \n",
       "L 421.732567 366.010735 \n",
       "L 427.881327 366.006938 \n",
       "L 434.030088 366.015186 \n",
       "L 440.178848 366.012122 \n",
       "L 446.327608 366.021212 \n",
       "L 452.476369 366.014018 \n",
       "L 458.625129 366.017154 \n",
       "L 464.773889 366.012947 \n",
       "L 470.92265 366.012868 \n",
       "L 477.07141 366.014392 \n",
       "L 483.22017 366.010986 \n",
       "L 489.368931 366.01689 \n",
       "L 495.517691 366.006596 \n",
       "L 501.666451 366.007691 \n",
       "L 507.815212 366.012047 \n",
       "L 513.963972 366.019355 \n",
       "L 520.112732 366.014345 \n",
       "L 526.261493 366.01671 \n",
       "L 532.410253 366.010799 \n",
       "L 538.559013 366.011195 \n",
       "L 544.707774 366.018175 \n",
       "L 550.856534 366.014402 \n",
       "L 557.005294 366.021773 \n",
       "L 563.154055 366.066262 \n",
       "L 569.302815 366.701749 \n",
       "L 575.451575 367.527805 \n",
       "L 581.600336 367.712372 \n",
       "L 587.749096 367.611036 \n",
       "L 593.897856 367.777889 \n",
       "L 600.046617 367.78537 \n",
       "L 606.195377 367.872777 \n",
       "L 612.344137 367.803475 \n",
       "L 618.492898 367.993575 \n",
       "L 624.641658 368.149114 \n",
       "L 630.790418 368.251823 \n",
       "L 636.939179 368.336674 \n",
       "L 643.087939 368.384678 \n",
       "L 649.236699 368.46317 \n",
       "L 655.38546 368.539867 \n",
       "L 661.53422 368.512638 \n",
       "L 667.68298 368.586256 \n",
       "L 673.831741 368.670728 \n",
       "L 679.980501 368.752183 \n",
       "L 686.129261 368.732279 \n",
       "\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_121\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 281.352774 \n",
       "L 83.550749 287.904693 \n",
       "L 89.699509 289.048084 \n",
       "L 95.84827 289.17037 \n",
       "L 101.99703 289.182137 \n",
       "L 108.14579 289.169301 \n",
       "L 114.294551 289.182244 \n",
       "L 120.443311 289.181089 \n",
       "L 126.592071 289.180975 \n",
       "L 132.740832 289.18255 \n",
       "L 138.889592 289.179493 \n",
       "L 145.038352 289.182422 \n",
       "L 151.187113 289.182657 \n",
       "L 157.335873 289.182614 \n",
       "L 163.484633 289.177982 \n",
       "L 169.633394 289.181752 \n",
       "L 175.782154 289.182415 \n",
       "L 181.930914 289.181802 \n",
       "L 188.079675 289.182686 \n",
       "L 194.228435 289.181096 \n",
       "L 200.377195 289.180483 \n",
       "L 206.525956 289.176464 \n",
       "L 212.674716 289.179963 \n",
       "L 218.823476 289.181182 \n",
       "L 224.972237 289.180355 \n",
       "L 231.120997 289.181431 \n",
       "L 237.269757 289.18285 \n",
       "L 243.418518 289.169422 \n",
       "L 249.567278 289.181481 \n",
       "L 255.716038 289.182614 \n",
       "L 261.864799 289.182871 \n",
       "L 268.013559 289.182593 \n",
       "L 274.162319 289.17496 \n",
       "L 280.31108 289.179122 \n",
       "L 286.45984 289.182123 \n",
       "L 292.6086 289.182956 \n",
       "L 298.757361 289.17439 \n",
       "L 304.906121 289.183092 \n",
       "L 311.054881 289.18285 \n",
       "L 317.203642 289.183149 \n",
       "L 323.352402 289.179322 \n",
       "L 329.501162 289.181902 \n",
       "L 335.649923 289.181168 \n",
       "L 341.798683 289.181674 \n",
       "L 347.947443 289.183512 \n",
       "L 354.096204 289.182536 \n",
       "L 360.244964 289.183291 \n",
       "L 366.393724 289.179835 \n",
       "L 372.542485 289.18317 \n",
       "L 378.691245 289.183569 \n",
       "L 384.840005 289.183833 \n",
       "L 390.988765 289.175281 \n",
       "L 397.137526 289.179015 \n",
       "L 403.286286 289.184382 \n",
       "L 409.435046 289.182244 \n",
       "L 415.583807 289.184731 \n",
       "L 421.732567 289.184303 \n",
       "L 427.881327 289.184489 \n",
       "L 434.030088 289.185601 \n",
       "L 440.178848 289.186278 \n",
       "L 446.327608 289.187432 \n",
       "L 452.476369 289.177967 \n",
       "L 458.625129 289.186891 \n",
       "L 464.773889 289.191537 \n",
       "L 470.92265 289.190996 \n",
       "L 477.07141 289.197524 \n",
       "L 483.22017 289.20567 \n",
       "L 489.368931 289.216945 \n",
       "L 495.517691 289.242332 \n",
       "L 501.666451 289.303938 \n",
       "L 507.815212 289.484537 \n",
       "L 513.963972 290.290463 \n",
       "L 520.112732 300.092129 \n",
       "L 526.261493 310.203065 \n",
       "L 532.410253 314.518412 \n",
       "L 538.559013 317.562536 \n",
       "L 544.707774 319.197494 \n",
       "L 550.856534 322.884962 \n",
       "L 557.005294 325.087763 \n",
       "L 563.154055 326.368878 \n",
       "L 569.302815 329.916513 \n",
       "L 575.451575 331.979999 \n",
       "L 581.600336 333.708756 \n",
       "L 587.749096 335.570193 \n",
       "L 593.897856 337.698699 \n",
       "L 600.046617 338.70497 \n",
       "L 606.195377 339.89571 \n",
       "L 612.344137 340.997828 \n",
       "L 618.492898 342.232489 \n",
       "L 624.641658 342.855102 \n",
       "L 630.790418 343.977421 \n",
       "L 636.939179 344.241738 \n",
       "L 643.087939 345.055094 \n",
       "L 649.236699 345.310274 \n",
       "L 655.38546 343.893838 \n",
       "L 661.53422 346.561282 \n",
       "L 667.68298 345.912584 \n",
       "L 673.831741 347.095119 \n",
       "L 679.980501 347.201731 \n",
       "L 686.129261 347.87434 \n",
       "\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_122\">\n",
       "    <path clip-path=\"url(#pea33e34ace)\" d=\"M 77.401989 366.032719 \n",
       "L 83.550749 366.010078 \n",
       "L 89.699509 366.006498 \n",
       "L 95.84827 366.009197 \n",
       "L 101.99703 366.022535 \n",
       "L 108.14579 366.006657 \n",
       "L 114.294551 366.015524 \n",
       "L 120.443311 366.021535 \n",
       "L 126.592071 366.011597 \n",
       "L 132.740832 366.003148 \n",
       "L 138.889592 366.016425 \n",
       "L 145.038352 366.017618 \n",
       "L 151.187113 366.017539 \n",
       "L 157.335873 366.014608 \n",
       "L 163.484633 366.00908 \n",
       "L 169.633394 366.012003 \n",
       "L 175.782154 366.023997 \n",
       "L 181.930914 366.006249 \n",
       "L 188.079675 366.013685 \n",
       "L 194.228435 366.006327 \n",
       "L 200.377195 366.001219 \n",
       "L 206.525956 366.010657 \n",
       "L 212.674716 366.01277 \n",
       "L 218.823476 366.013947 \n",
       "L 224.972237 366.013627 \n",
       "L 231.120997 366.008637 \n",
       "L 237.269757 366.00853 \n",
       "L 243.418518 366.013965 \n",
       "L 249.567278 366.019723 \n",
       "L 255.716038 366.01811 \n",
       "L 261.864799 366.011062 \n",
       "L 268.013559 366.011355 \n",
       "L 274.162319 366.016147 \n",
       "L 280.31108 366.013676 \n",
       "L 286.45984 366.01066 \n",
       "L 292.6086 366.014445 \n",
       "L 298.757361 366.015004 \n",
       "L 304.906121 366.015139 \n",
       "L 311.054881 366.011183 \n",
       "L 317.203642 366.020324 \n",
       "L 323.352402 366.0087 \n",
       "L 329.501162 366.007971 \n",
       "L 335.649923 366.011209 \n",
       "L 341.798683 366.017888 \n",
       "L 347.947443 366.013286 \n",
       "L 354.096204 366.005861 \n",
       "L 360.244964 366.012286 \n",
       "L 366.393724 366.007134 \n",
       "L 372.542485 366.00896 \n",
       "L 378.691245 366.008755 \n",
       "L 384.840005 366.009163 \n",
       "L 390.988765 366.014764 \n",
       "L 397.137526 366.012611 \n",
       "L 403.286286 366.01177 \n",
       "L 409.435046 366.016183 \n",
       "L 415.583807 366.01398 \n",
       "L 421.732567 366.030707 \n",
       "L 427.881327 366.019715 \n",
       "L 434.030088 366.092223 \n",
       "L 440.178848 366.78897 \n",
       "L 446.327608 367.644251 \n",
       "L 452.476369 367.739547 \n",
       "L 458.625129 367.760408 \n",
       "L 464.773889 367.741495 \n",
       "L 470.92265 367.852371 \n",
       "L 477.07141 367.81923 \n",
       "L 483.22017 367.961596 \n",
       "L 489.368931 368.018395 \n",
       "L 495.517691 367.956222 \n",
       "L 501.666451 368.049487 \n",
       "L 507.815212 368.077365 \n",
       "L 513.963972 368.269768 \n",
       "L 520.112732 368.285419 \n",
       "L 526.261493 368.405336 \n",
       "L 532.410253 368.468164 \n",
       "L 538.559013 368.474137 \n",
       "L 544.707774 368.547345 \n",
       "L 550.856534 368.590555 \n",
       "L 557.005294 368.496897 \n",
       "L 563.154055 368.678122 \n",
       "L 569.302815 368.703865 \n",
       "L 575.451575 368.830782 \n",
       "L 581.600336 368.80301 \n",
       "L 587.749096 368.947838 \n",
       "L 593.897856 368.933357 \n",
       "L 600.046617 369.013111 \n",
       "L 606.195377 369.068095 \n",
       "L 612.344137 369.126525 \n",
       "L 618.492898 369.176185 \n",
       "L 624.641658 369.23782 \n",
       "L 630.790418 369.19826 \n",
       "L 636.939179 369.297789 \n",
       "L 643.087939 369.365758 \n",
       "L 649.236699 369.408156 \n",
       "L 655.38546 369.40311 \n",
       "L 661.53422 369.444486 \n",
       "L 667.68298 369.454108 \n",
       "L 673.831741 369.380481 \n",
       "L 679.980501 369.48031 \n",
       "L 686.129261 369.518856 \n",
       "\" style=\"fill:none;stroke:#7f7f7f;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 387.72 \n",
       "L 46.965625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 716.565625 387.72 \n",
       "L 716.565625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 387.72 \n",
       "L 716.565625 387.72 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 7.2 \n",
       "L 716.565625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pea33e34ace\">\n",
       "   <rect height=\"380.52\" width=\"669.6\" x=\"46.965625\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize=[12, 7])\n",
    "\n",
    "for key, item in dict_history_model_boston_house_train.items():\n",
    "    plt.plot(item['val_loss'], label=key)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_MODEL:MODEL_BOSTON_HOUSE_5_512_nadam_relu_mae: 3.016777276992798\n"
     ]
    }
   ],
   "source": [
    "# best model\n",
    "\n",
    "list_metrics = []\n",
    "list_name_model = []\n",
    "for key, item in dict_eval.items():\n",
    "    list_metrics.append(item[1])\n",
    "    list_name_model.append(key)\n",
    "\n",
    "best_name_model = list_name_model[np.argmin(np.array(list_metrics))]\n",
    "best_metrics = np.min(np.array(list_metrics))\n",
    "print('BEST_MODEL:' + str(best_name_model) + \": \" + str(best_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"331.674375pt\" version=\"1.1\" viewBox=\"0 0 605.308437 331.674375\" width=\"605.308437pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 331.674375 \n",
       "L 605.308437 331.674375 \n",
       "L 605.308437 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 294.118125 \n",
       "L 592.240625 294.118125 \n",
       "L 592.240625 22.318125 \n",
       "L 34.240625 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 59.604261 294.118125 \n",
       "L 59.604261 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m368753078f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.604261\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(56.423011 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 162.0836 294.118125 \n",
       "L 162.0836 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"162.0836\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(155.7211 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 264.562939 294.118125 \n",
       "L 264.562939 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"264.562939\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(258.200439 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 367.042278 294.118125 \n",
       "L 367.042278 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"367.042278\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(360.679778 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 469.521617 294.118125 \n",
       "L 469.521617 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"469.521617\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(463.159117 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 572.000956 294.118125 \n",
       "L 572.000956 22.318125 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"572.000956\" xlink:href=\"#m368753078f\" y=\"294.118125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(562.457206 308.716563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(297.929688 322.394687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 34.240625 243.781268 \n",
       "L 592.240625 243.781268 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"md669cf9070\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#md669cf9070\" y=\"243.781268\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(20.878125 247.580487)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 34.240625 184.92715 \n",
       "L 592.240625 184.92715 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#md669cf9070\" y=\"184.92715\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(20.878125 188.726368)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 34.240625 126.073031 \n",
       "L 592.240625 126.073031 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#md669cf9070\" y=\"126.073031\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(20.878125 129.87225)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#p75ec9b3249)\" d=\"M 34.240625 67.218912 \n",
       "L 592.240625 67.218912 \n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#md669cf9070\" y=\"67.218912\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(20.878125 71.018131)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- Loss -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 169.185313)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path clip-path=\"url(#p75ec9b3249)\" d=\"M 59.604261 34.67267 \n",
       "L 64.728228 191.299106 \n",
       "L 69.852195 219.88519 \n",
       "L 74.976162 218.507951 \n",
       "L 80.100129 227.134576 \n",
       "L 85.224096 229.13404 \n",
       "L 90.348063 228.711889 \n",
       "L 95.47203 234.345977 \n",
       "L 100.595997 235.137756 \n",
       "L 105.719964 238.006279 \n",
       "L 110.843931 241.858966 \n",
       "L 115.967898 244.891737 \n",
       "L 121.091865 244.662711 \n",
       "L 126.215832 242.197037 \n",
       "L 131.339799 245.479772 \n",
       "L 136.463765 246.659698 \n",
       "L 141.587732 246.498251 \n",
       "L 146.711699 251.756132 \n",
       "L 151.835666 251.21355 \n",
       "L 156.959633 254.72397 \n",
       "L 162.0836 255.748149 \n",
       "L 167.207567 251.759633 \n",
       "L 172.331534 255.506418 \n",
       "L 177.455501 256.844161 \n",
       "L 182.579468 257.687928 \n",
       "L 187.703435 260.741385 \n",
       "L 192.827402 257.384831 \n",
       "L 197.951369 261.541611 \n",
       "L 203.075336 261.513375 \n",
       "L 208.199303 263.354755 \n",
       "L 213.32327 262.401995 \n",
       "L 218.447237 263.00314 \n",
       "L 223.571204 264.410924 \n",
       "L 228.69517 263.990331 \n",
       "L 233.819137 264.518492 \n",
       "L 238.943104 266.379938 \n",
       "L 244.067071 264.923888 \n",
       "L 249.191038 266.273517 \n",
       "L 254.315005 268.519062 \n",
       "L 259.438972 269.324837 \n",
       "L 264.562939 268.634983 \n",
       "L 269.686906 269.700279 \n",
       "L 274.810873 268.872775 \n",
       "L 279.93484 266.34509 \n",
       "L 285.058807 270.299494 \n",
       "L 290.182774 270.412869 \n",
       "L 295.306741 267.348877 \n",
       "L 300.430708 269.088992 \n",
       "L 305.554675 270.922515 \n",
       "L 310.678642 272.799315 \n",
       "L 315.802608 273.441123 \n",
       "L 320.926575 271.933311 \n",
       "L 326.050542 270.438284 \n",
       "L 331.174509 271.797517 \n",
       "L 336.298476 272.556237 \n",
       "L 341.422443 269.765825 \n",
       "L 346.54641 270.84516 \n",
       "L 351.670377 271.962388 \n",
       "L 356.794344 272.465825 \n",
       "L 361.918311 272.242178 \n",
       "L 367.042278 268.217768 \n",
       "L 372.166245 274.817711 \n",
       "L 377.290212 274.284244 \n",
       "L 382.414179 273.579067 \n",
       "L 387.538146 274.170635 \n",
       "L 392.662113 274.303131 \n",
       "L 397.78608 277.612353 \n",
       "L 402.910046 274.965529 \n",
       "L 408.034013 277.608465 \n",
       "L 413.15798 276.969544 \n",
       "L 418.281947 276.679334 \n",
       "L 423.405914 278.952476 \n",
       "L 428.529881 276.384206 \n",
       "L 433.653848 276.891211 \n",
       "L 438.777815 276.692637 \n",
       "L 443.901782 276.738314 \n",
       "L 449.025749 276.337091 \n",
       "L 454.149716 275.998344 \n",
       "L 459.273683 277.90802 \n",
       "L 464.39765 276.154027 \n",
       "L 469.521617 272.642631 \n",
       "L 474.645584 276.408674 \n",
       "L 479.769551 279.479731 \n",
       "L 484.893518 279.668636 \n",
       "L 490.017485 280.089865 \n",
       "L 495.141451 277.006841 \n",
       "L 500.265418 278.957161 \n",
       "L 505.389385 280.189014 \n",
       "L 510.513352 281.326571 \n",
       "L 515.637319 280.582694 \n",
       "L 520.761286 278.353636 \n",
       "L 525.885253 279.883584 \n",
       "L 531.00922 281.498929 \n",
       "L 536.133187 280.249246 \n",
       "L 541.257154 281.290464 \n",
       "L 546.381121 280.250541 \n",
       "L 551.505088 280.726484 \n",
       "L 556.629055 280.417177 \n",
       "L 561.753022 281.73446 \n",
       "L 566.876989 281.76358 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path clip-path=\"url(#p75ec9b3249)\" d=\"M 59.604261 144.30961 \n",
       "L 64.728228 207.744805 \n",
       "L 69.852195 220.375037 \n",
       "L 74.976162 221.977938 \n",
       "L 80.100129 226.923213 \n",
       "L 85.224096 224.675476 \n",
       "L 90.348063 217.586538 \n",
       "L 95.47203 228.200019 \n",
       "L 100.595997 230.492448 \n",
       "L 105.719964 231.235901 \n",
       "L 110.843931 232.108434 \n",
       "L 115.967898 232.343538 \n",
       "L 121.091865 229.794788 \n",
       "L 126.215832 228.105311 \n",
       "L 131.339799 229.185186 \n",
       "L 136.463765 224.024942 \n",
       "L 141.587732 231.71655 \n",
       "L 146.711699 229.134895 \n",
       "L 151.835666 230.216735 \n",
       "L 156.959633 226.560039 \n",
       "L 162.0836 227.552285 \n",
       "L 167.207567 229.107891 \n",
       "L 172.331534 227.556873 \n",
       "L 177.455501 229.894198 \n",
       "L 182.579468 224.751465 \n",
       "L 187.703435 228.453751 \n",
       "L 192.827402 227.358146 \n",
       "L 197.951369 229.66942 \n",
       "L 203.075336 231.236869 \n",
       "L 208.199303 229.816664 \n",
       "L 213.32327 229.904757 \n",
       "L 218.447237 230.636023 \n",
       "L 223.571204 232.460067 \n",
       "L 228.69517 229.09193 \n",
       "L 233.819137 233.410097 \n",
       "L 238.943104 228.721382 \n",
       "L 244.067071 226.660907 \n",
       "L 249.191038 227.213435 \n",
       "L 254.315005 231.262864 \n",
       "L 259.438972 231.790274 \n",
       "L 264.562939 232.10668 \n",
       "L 269.686906 227.971369 \n",
       "L 274.810873 229.729821 \n",
       "L 279.93484 232.369441 \n",
       "L 285.058807 227.387459 \n",
       "L 290.182774 233.418952 \n",
       "L 295.306741 228.66054 \n",
       "L 300.430708 230.330408 \n",
       "L 305.554675 227.391241 \n",
       "L 310.678642 230.292683 \n",
       "L 315.802608 231.521423 \n",
       "L 320.926575 230.670555 \n",
       "L 326.050542 228.939024 \n",
       "L 331.174509 234.092729 \n",
       "L 336.298476 222.097574 \n",
       "L 341.422443 229.394788 \n",
       "L 346.54641 227.768896 \n",
       "L 351.670377 231.899365 \n",
       "L 356.794344 225.387371 \n",
       "L 361.918311 231.11731 \n",
       "L 367.042278 230.915033 \n",
       "L 372.166245 234.109637 \n",
       "L 377.290212 232.123315 \n",
       "L 382.414179 227.00511 \n",
       "L 387.538146 233.579862 \n",
       "L 392.662113 232.875215 \n",
       "L 397.78608 233.368703 \n",
       "L 402.910046 230.232374 \n",
       "L 408.034013 229.705005 \n",
       "L 413.15798 231.700765 \n",
       "L 418.281947 231.190831 \n",
       "L 423.405914 234.96912 \n",
       "L 428.529881 230.973925 \n",
       "L 433.653848 230.75187 \n",
       "L 438.777815 232.003917 \n",
       "L 443.901782 229.087173 \n",
       "L 449.025749 231.721097 \n",
       "L 454.149716 232.510918 \n",
       "L 459.273683 232.904366 \n",
       "L 464.39765 228.185103 \n",
       "L 469.521617 227.276137 \n",
       "L 474.645584 230.481545 \n",
       "L 479.769551 229.885603 \n",
       "L 484.893518 233.105584 \n",
       "L 490.017485 230.738891 \n",
       "L 495.141451 232.81915 \n",
       "L 500.265418 232.767807 \n",
       "L 505.389385 230.992833 \n",
       "L 510.513352 231.044359 \n",
       "L 515.637319 230.733502 \n",
       "L 520.761286 232.225677 \n",
       "L 525.885253 231.802321 \n",
       "L 531.00922 232.603774 \n",
       "L 536.133187 227.0811 \n",
       "L 541.257154 230.41368 \n",
       "L 546.381121 232.797555 \n",
       "L 551.505088 231.124565 \n",
       "L 556.629055 231.935596 \n",
       "L 561.753022 231.16483 \n",
       "L 566.876989 229.879731 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 294.118125 \n",
       "L 34.240625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 592.240625 294.118125 \n",
       "L 592.240625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 294.118125 \n",
       "L 592.240625 294.118125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 22.318125 \n",
       "L 592.240625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- Потери от эпох на лучшей мдели: MODEL_BOSTON_HOUSE_5_512_nadam_relu_mae: 3.0168 -->\n",
       "    <defs>\n",
       "     <path d=\"M 65.375 72.90625 \n",
       "L 65.375 0 \n",
       "L 55.515625 0 \n",
       "L 55.515625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "z\n",
       "\" id=\"DejaVuSans-1055\"/>\n",
       "     <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-1086\"/>\n",
       "     <path d=\"M 2.9375 54.6875 \n",
       "L 55.328125 54.6875 \n",
       "L 55.328125 47.515625 \n",
       "L 33.546875 47.515625 \n",
       "L 33.546875 0 \n",
       "L 24.703125 0 \n",
       "L 24.703125 47.515625 \n",
       "L 2.9375 47.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-1090\"/>\n",
       "     <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1077\"/>\n",
       "     <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1088\"/>\n",
       "     <path d=\"M 55.90625 54.6875 \n",
       "L 55.90625 0 \n",
       "L 46.96875 0 \n",
       "L 46.96875 43.890625 \n",
       "L 20.609375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.015625 54.6875 \n",
       "L 18.015625 10.890625 \n",
       "L 44.34375 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1080\"/>\n",
       "     <path id=\"DejaVuSans-32\"/>\n",
       "     <path d=\"M 5.515625 10.40625 \n",
       "Q 13.234375 6.203125 20.90625 6.203125 \n",
       "Q 28.078125 6.203125 33.203125 10.375 \n",
       "Q 38.328125 14.546875 39.265625 25.203125 \n",
       "L 11.53125 25.203125 \n",
       "L 11.53125 32.375 \n",
       "L 38.96875 32.375 \n",
       "Q 38.375 37.5 34.484375 42.9375 \n",
       "Q 30.609375 48.390625 20.90625 48.390625 \n",
       "Q 13.375 48.390625 5.515625 44.1875 \n",
       "L 5.515625 52.59375 \n",
       "Q 13.1875 56 21.296875 56 \n",
       "Q 34.078125 56 41.421875 48.265625 \n",
       "Q 48.78125 40.53125 48.78125 27.296875 \n",
       "Q 48.78125 14.109375 41.625 6.34375 \n",
       "Q 34.46875 -1.421875 21.921875 -1.421875 \n",
       "Q 12.703125 -1.421875 5.515625 2.09375 \n",
       "z\n",
       "\" id=\"DejaVuSans-1101\"/>\n",
       "     <path d=\"M 56.296875 54.6875 \n",
       "L 56.296875 0 \n",
       "L 47.265625 0 \n",
       "L 47.265625 47.515625 \n",
       "L 18.109375 47.515625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1087\"/>\n",
       "     <path d=\"M 54.890625 54.6875 \n",
       "L 35.109375 28.078125 \n",
       "L 55.90625 0 \n",
       "L 45.3125 0 \n",
       "L 29.390625 21.484375 \n",
       "L 13.484375 0 \n",
       "L 2.875 0 \n",
       "L 24.125 28.609375 \n",
       "L 4.6875 54.6875 \n",
       "L 15.28125 54.6875 \n",
       "L 29.78125 35.203125 \n",
       "L 44.28125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1093\"/>\n",
       "     <path d=\"M 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 32.375 \n",
       "L 47.265625 32.375 \n",
       "L 47.265625 54.6875 \n",
       "L 56.296875 54.6875 \n",
       "L 56.296875 0 \n",
       "L 47.265625 0 \n",
       "L 47.265625 25.203125 \n",
       "L 18.109375 25.203125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1085\"/>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-1072\"/>\n",
       "     <path d=\"M 3.71875 0 \n",
       "L 3.71875 7.46875 \n",
       "Q 12.59375 8.84375 15.328125 14.984375 \n",
       "Q 18.65625 23.640625 18.65625 45.75 \n",
       "L 18.65625 54.6875 \n",
       "L 55.609375 54.6875 \n",
       "L 55.609375 0 \n",
       "L 46.625 0 \n",
       "L 46.625 47.515625 \n",
       "L 27.640625 47.515625 \n",
       "L 27.640625 42.09375 \n",
       "Q 27.640625 21 23.34375 11.53125 \n",
       "Q 18.75 1.421875 3.71875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1083\"/>\n",
       "     <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1091\"/>\n",
       "     <path d=\"M 41.015625 0 \n",
       "L 41.015625 23 \n",
       "L 24.265625 23 \n",
       "Q 16.796875 23 11.8125 27.640625 \n",
       "Q 7.328125 31.84375 7.328125 40.828125 \n",
       "L 7.328125 54.6875 \n",
       "L 16.3125 54.6875 \n",
       "L 16.3125 41.65625 \n",
       "Q 16.3125 35.9375 18.84375 33.0625 \n",
       "Q 21.4375 30.171875 26.515625 30.171875 \n",
       "L 41.015625 30.171875 \n",
       "L 41.015625 54.6875 \n",
       "L 50 54.6875 \n",
       "L 50 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1095\"/>\n",
       "     <path d=\"M 50.25 7.171875 \n",
       "L 73.390625 7.171875 \n",
       "L 73.390625 54.6875 \n",
       "L 82.421875 54.6875 \n",
       "L 82.421875 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 7.171875 \n",
       "L 41.21875 7.171875 \n",
       "L 41.21875 54.6875 \n",
       "L 50.25 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1096\"/>\n",
       "     <path d=\"M 55.90625 54.6875 \n",
       "L 55.90625 0 \n",
       "L 46.96875 0 \n",
       "L 46.96875 43.890625 \n",
       "L 20.609375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.015625 54.6875 \n",
       "L 18.015625 10.890625 \n",
       "L 44.34375 54.6875 \n",
       "z\n",
       "M 17.234375 75.96875 \n",
       "L 23 75.96875 \n",
       "Q 23.53125 72.3125 25.890625 70.46875 \n",
       "Q 28.265625 68.640625 32.515625 68.640625 \n",
       "Q 36.71875 68.640625 39.0625 70.453125 \n",
       "Q 41.40625 72.265625 42.046875 75.96875 \n",
       "L 47.796875 75.96875 \n",
       "Q 47.3125 68.984375 43.453125 65.46875 \n",
       "Q 39.59375 61.953125 32.515625 61.953125 \n",
       "Q 25.4375 61.953125 21.578125 65.46875 \n",
       "Q 17.71875 68.984375 17.234375 75.96875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1081\"/>\n",
       "     <path d=\"M 9.078125 54.6875 \n",
       "L 22.21875 54.6875 \n",
       "L 37.75 18.0625 \n",
       "L 53.328125 54.6875 \n",
       "L 66.359375 54.6875 \n",
       "L 66.359375 0 \n",
       "L 57.328125 0 \n",
       "L 57.328125 46.09375 \n",
       "L 42.234375 10.5 \n",
       "L 33.25 10.5 \n",
       "L 18.109375 46.09375 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1084\"/>\n",
       "     <path d=\"M 21.625 7.171875 \n",
       "L 47.703125 7.171875 \n",
       "L 47.703125 47.515625 \n",
       "L 28.8125 47.515625 \n",
       "L 28.8125 40.671875 \n",
       "Q 28.8125 20.5625 23.046875 9.8125 \n",
       "z\n",
       "M 8.59375 7.171875 \n",
       "Q 13.03125 9.125 14.984375 13.28125 \n",
       "Q 19.78125 23.578125 19.78125 44.34375 \n",
       "L 19.78125 54.6875 \n",
       "L 56.734375 54.6875 \n",
       "L 56.734375 7.171875 \n",
       "L 63.921875 7.171875 \n",
       "L 63.921875 -13.8125 \n",
       "L 56.734375 -13.8125 \n",
       "L 56.734375 0 \n",
       "L 12.40625 0 \n",
       "L 12.40625 -13.8125 \n",
       "L 5.21875 -13.8125 \n",
       "L 5.21875 7.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-1076\"/>\n",
       "     <path d=\"M 11.71875 12.40625 \n",
       "L 22.015625 12.40625 \n",
       "L 22.015625 0 \n",
       "L 11.71875 0 \n",
       "z\n",
       "M 11.71875 51.703125 \n",
       "L 22.015625 51.703125 \n",
       "L 22.015625 39.3125 \n",
       "L 11.71875 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-58\"/>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 24.515625 72.90625 \n",
       "L 43.109375 23.296875 \n",
       "L 61.8125 72.90625 \n",
       "L 76.515625 72.90625 \n",
       "L 76.515625 0 \n",
       "L 66.890625 0 \n",
       "L 66.890625 64.015625 \n",
       "L 48.09375 14.015625 \n",
       "L 38.1875 14.015625 \n",
       "L 19.390625 64.015625 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-77\"/>\n",
       "     <path d=\"M 39.40625 66.21875 \n",
       "Q 28.65625 66.21875 22.328125 58.203125 \n",
       "Q 16.015625 50.203125 16.015625 36.375 \n",
       "Q 16.015625 22.609375 22.328125 14.59375 \n",
       "Q 28.65625 6.59375 39.40625 6.59375 \n",
       "Q 50.140625 6.59375 56.421875 14.59375 \n",
       "Q 62.703125 22.609375 62.703125 36.375 \n",
       "Q 62.703125 50.203125 56.421875 58.203125 \n",
       "Q 50.140625 66.21875 39.40625 66.21875 \n",
       "z\n",
       "M 39.40625 74.21875 \n",
       "Q 54.734375 74.21875 63.90625 63.9375 \n",
       "Q 73.09375 53.65625 73.09375 36.375 \n",
       "Q 73.09375 19.140625 63.90625 8.859375 \n",
       "Q 54.734375 -1.421875 39.40625 -1.421875 \n",
       "Q 24.03125 -1.421875 14.8125 8.828125 \n",
       "Q 5.609375 19.09375 5.609375 36.375 \n",
       "Q 5.609375 53.65625 14.8125 63.9375 \n",
       "Q 24.03125 74.21875 39.40625 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-79\"/>\n",
       "     <path d=\"M 19.671875 64.796875 \n",
       "L 19.671875 8.109375 \n",
       "L 31.59375 8.109375 \n",
       "Q 46.6875 8.109375 53.6875 14.9375 \n",
       "Q 60.6875 21.78125 60.6875 36.53125 \n",
       "Q 60.6875 51.171875 53.6875 57.984375 \n",
       "Q 46.6875 64.796875 31.59375 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 30.078125 72.90625 \n",
       "Q 51.265625 72.90625 61.171875 64.09375 \n",
       "Q 71.09375 55.28125 71.09375 36.53125 \n",
       "Q 71.09375 17.671875 61.125 8.828125 \n",
       "Q 51.171875 0 30.078125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-68\"/>\n",
       "     <path d=\"M 50.984375 -16.609375 \n",
       "L 50.984375 -23.578125 \n",
       "L -0.984375 -23.578125 \n",
       "L -0.984375 -16.609375 \n",
       "z\n",
       "\" id=\"DejaVuSans-95\"/>\n",
       "     <path d=\"M 19.671875 34.8125 \n",
       "L 19.671875 8.109375 \n",
       "L 35.5 8.109375 \n",
       "Q 43.453125 8.109375 47.28125 11.40625 \n",
       "Q 51.125 14.703125 51.125 21.484375 \n",
       "Q 51.125 28.328125 47.28125 31.5625 \n",
       "Q 43.453125 34.8125 35.5 34.8125 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 42.828125 \n",
       "L 34.28125 42.828125 \n",
       "Q 41.5 42.828125 45.03125 45.53125 \n",
       "Q 48.578125 48.25 48.578125 53.8125 \n",
       "Q 48.578125 59.328125 45.03125 62.0625 \n",
       "Q 41.5 64.796875 34.28125 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 35.015625 72.90625 \n",
       "Q 46.296875 72.90625 52.390625 68.21875 \n",
       "Q 58.5 63.53125 58.5 54.890625 \n",
       "Q 58.5 48.1875 55.375 44.234375 \n",
       "Q 52.25 40.28125 46.1875 39.3125 \n",
       "Q 53.46875 37.75 57.5 32.78125 \n",
       "Q 61.53125 27.828125 61.53125 20.40625 \n",
       "Q 61.53125 10.640625 54.890625 5.3125 \n",
       "Q 48.25 0 35.984375 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-66\"/>\n",
       "     <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "     <path d=\"M -0.296875 72.90625 \n",
       "L 61.375 72.90625 \n",
       "L 61.375 64.59375 \n",
       "L 35.5 64.59375 \n",
       "L 35.5 0 \n",
       "L 25.59375 0 \n",
       "L 25.59375 64.59375 \n",
       "L -0.296875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-84\"/>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 23.09375 72.90625 \n",
       "L 55.421875 11.921875 \n",
       "L 55.421875 72.90625 \n",
       "L 64.984375 72.90625 \n",
       "L 64.984375 0 \n",
       "L 51.703125 0 \n",
       "L 19.390625 60.984375 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-78\"/>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 43.015625 \n",
       "L 55.515625 43.015625 \n",
       "L 55.515625 72.90625 \n",
       "L 65.375 72.90625 \n",
       "L 65.375 0 \n",
       "L 55.515625 0 \n",
       "L 55.515625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-72\"/>\n",
       "     <path d=\"M 8.6875 72.90625 \n",
       "L 18.609375 72.90625 \n",
       "L 18.609375 28.609375 \n",
       "Q 18.609375 16.890625 22.84375 11.734375 \n",
       "Q 27.09375 6.59375 36.625 6.59375 \n",
       "Q 46.09375 6.59375 50.34375 11.734375 \n",
       "Q 54.59375 16.890625 54.59375 28.609375 \n",
       "L 54.59375 72.90625 \n",
       "L 64.5 72.90625 \n",
       "L 64.5 27.390625 \n",
       "Q 64.5 13.140625 57.4375 5.859375 \n",
       "Q 50.390625 -1.421875 36.625 -1.421875 \n",
       "Q 22.796875 -1.421875 15.734375 5.859375 \n",
       "Q 8.6875 13.140625 8.6875 27.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-85\"/>\n",
       "     <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "     <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "     <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "     <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(28.372813 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-1055\"/>\n",
       "     <use x=\"75.195312\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "     <use x=\"136.376953\" xlink:href=\"#DejaVuSans-1090\"/>\n",
       "     <use x=\"194.628906\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "     <use x=\"256.152344\" xlink:href=\"#DejaVuSans-1088\"/>\n",
       "     <use x=\"319.628906\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "     <use x=\"384.619141\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"416.40625\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "     <use x=\"477.587891\" xlink:href=\"#DejaVuSans-1090\"/>\n",
       "     <use x=\"535.839844\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"567.626953\" xlink:href=\"#DejaVuSans-1101\"/>\n",
       "     <use x=\"622.509766\" xlink:href=\"#DejaVuSans-1087\"/>\n",
       "     <use x=\"687.890625\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "     <use x=\"749.072266\" xlink:href=\"#DejaVuSans-1093\"/>\n",
       "     <use x=\"808.251953\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"840.039062\" xlink:href=\"#DejaVuSans-1085\"/>\n",
       "     <use x=\"905.419922\" xlink:href=\"#DejaVuSans-1072\"/>\n",
       "     <use x=\"966.699219\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"998.486328\" xlink:href=\"#DejaVuSans-1083\"/>\n",
       "     <use x=\"1062.402344\" xlink:href=\"#DejaVuSans-1091\"/>\n",
       "     <use x=\"1121.582031\" xlink:href=\"#DejaVuSans-1095\"/>\n",
       "     <use x=\"1180.664062\" xlink:href=\"#DejaVuSans-1096\"/>\n",
       "     <use x=\"1272.167969\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "     <use x=\"1333.691406\" xlink:href=\"#DejaVuSans-1081\"/>\n",
       "     <use x=\"1398.681641\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1430.46875\" xlink:href=\"#DejaVuSans-1084\"/>\n",
       "     <use x=\"1505.908203\" xlink:href=\"#DejaVuSans-1076\"/>\n",
       "     <use x=\"1575.048828\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "     <use x=\"1636.572266\" xlink:href=\"#DejaVuSans-1083\"/>\n",
       "     <use x=\"1700.488281\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "     <use x=\"1765.478516\" xlink:href=\"#DejaVuSans-58\"/>\n",
       "     <use x=\"1799.169922\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1830.957031\" xlink:href=\"#DejaVuSans-77\"/>\n",
       "     <use x=\"1917.236328\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     <use x=\"1995.947266\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "     <use x=\"2072.949219\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "     <use x=\"2136.132812\" xlink:href=\"#DejaVuSans-76\"/>\n",
       "     <use x=\"2191.845703\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"2241.845703\" xlink:href=\"#DejaVuSans-66\"/>\n",
       "     <use x=\"2308.699219\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     <use x=\"2387.410156\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "     <use x=\"2450.886719\" xlink:href=\"#DejaVuSans-84\"/>\n",
       "     <use x=\"2511.970703\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     <use x=\"2590.681641\" xlink:href=\"#DejaVuSans-78\"/>\n",
       "     <use x=\"2665.486328\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"2715.486328\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "     <use x=\"2790.681641\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     <use x=\"2869.392578\" xlink:href=\"#DejaVuSans-85\"/>\n",
       "     <use x=\"2942.585938\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "     <use x=\"3006.0625\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "     <use x=\"3069.246094\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"3119.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use x=\"3182.869141\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"3232.869141\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use x=\"3296.492188\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "     <use x=\"3360.115234\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "     <use x=\"3423.738281\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"3473.738281\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"3537.117188\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"3598.396484\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"3661.873047\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"3723.152344\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"3820.564453\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"3870.564453\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"3909.427734\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"3970.951172\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"3998.734375\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"4062.113281\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "     <use x=\"4112.113281\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"4209.525391\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"4270.804688\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"4332.328125\" xlink:href=\"#DejaVuSans-58\"/>\n",
       "     <use x=\"4366.019531\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"4397.806641\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "     <use x=\"4461.429688\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "     <use x=\"4493.216797\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "     <use x=\"4556.839844\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "     <use x=\"4620.462891\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "     <use x=\"4684.085938\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 433.8375 59.674375 \n",
       "L 585.240625 59.674375 \n",
       "Q 587.240625 59.674375 587.240625 57.674375 \n",
       "L 587.240625 29.318125 \n",
       "Q 587.240625 27.318125 585.240625 27.318125 \n",
       "L 433.8375 27.318125 \n",
       "Q 431.8375 27.318125 431.8375 29.318125 \n",
       "L 431.8375 57.674375 \n",
       "Q 431.8375 59.674375 433.8375 59.674375 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_23\">\n",
       "     <path d=\"M 435.8375 35.416562 \n",
       "L 455.8375 35.416562 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_24\"/>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Потери на тренировке -->\n",
       "     <defs>\n",
       "      <path d=\"M 18.0625 25.203125 \n",
       "L 18.0625 7.171875 \n",
       "L 30.859375 7.171875 \n",
       "Q 37.015625 7.171875 40.234375 9.484375 \n",
       "Q 43.453125 11.8125 43.453125 16.21875 \n",
       "Q 43.453125 20.609375 40.234375 22.90625 \n",
       "Q 37.015625 25.203125 30.859375 25.203125 \n",
       "z\n",
       "M 18.0625 47.515625 \n",
       "L 18.0625 32.375 \n",
       "L 29.890625 32.375 \n",
       "Q 34.96875 32.375 38.1875 34.390625 \n",
       "Q 41.40625 36.421875 41.40625 40.046875 \n",
       "Q 41.40625 43.65625 38.1875 45.578125 \n",
       "Q 34.96875 47.515625 29.890625 47.515625 \n",
       "z\n",
       "M 9.078125 54.6875 \n",
       "L 30.46875 54.6875 \n",
       "Q 40.09375 54.6875 45.265625 51.171875 \n",
       "Q 50.4375 47.65625 50.4375 41.15625 \n",
       "Q 50.4375 36.140625 47.796875 33.171875 \n",
       "Q 45.171875 30.21875 39.984375 29.5 \n",
       "Q 46.1875 28.328125 49.609375 24.609375 \n",
       "Q 53.03125 20.90625 53.03125 15.328125 \n",
       "Q 53.03125 8.015625 47.390625 4 \n",
       "Q 41.75 0 31.296875 0 \n",
       "L 9.078125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1074\"/>\n",
       "      <path d=\"M 9.078125 54.6875 \n",
       "L 18.015625 54.6875 \n",
       "L 18.015625 29 \n",
       "L 43.359375 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "L 33.5 33.546875 \n",
       "L 57.078125 0 \n",
       "L 47.015625 0 \n",
       "L 27.640625 27.59375 \n",
       "L 18.015625 17.828125 \n",
       "L 18.015625 0 \n",
       "L 9.078125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-1082\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(463.8375 38.916562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-1055\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "      <use x=\"136.376953\" xlink:href=\"#DejaVuSans-1090\"/>\n",
       "      <use x=\"194.628906\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "      <use x=\"256.152344\" xlink:href=\"#DejaVuSans-1088\"/>\n",
       "      <use x=\"319.628906\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "      <use x=\"384.619141\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"416.40625\" xlink:href=\"#DejaVuSans-1085\"/>\n",
       "      <use x=\"481.787109\" xlink:href=\"#DejaVuSans-1072\"/>\n",
       "      <use x=\"543.066406\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"574.853516\" xlink:href=\"#DejaVuSans-1090\"/>\n",
       "      <use x=\"633.105469\" xlink:href=\"#DejaVuSans-1088\"/>\n",
       "      <use x=\"696.582031\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "      <use x=\"758.105469\" xlink:href=\"#DejaVuSans-1085\"/>\n",
       "      <use x=\"823.486328\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "      <use x=\"888.476562\" xlink:href=\"#DejaVuSans-1088\"/>\n",
       "      <use x=\"951.953125\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "      <use x=\"1013.134766\" xlink:href=\"#DejaVuSans-1074\"/>\n",
       "      <use x=\"1072.070312\" xlink:href=\"#DejaVuSans-1082\"/>\n",
       "      <use x=\"1132.470703\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_25\">\n",
       "     <path d=\"M 435.8375 50.094688 \n",
       "L 455.8375 50.094688 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_26\"/>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Потери на валидации -->\n",
       "     <defs>\n",
       "      <path d=\"M 56.296875 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 7.171875 \n",
       "L 47.265625 7.171875 \n",
       "L 47.265625 54.6875 \n",
       "L 56.296875 54.6875 \n",
       "L 56.296875 7.171875 \n",
       "L 63.484375 7.171875 \n",
       "L 63.484375 -13.8125 \n",
       "L 56.296875 -13.8125 \n",
       "z\n",
       "\" id=\"DejaVuSans-1094\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(463.8375 53.594688)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-1055\"/>\n",
       "      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-1086\"/>\n",
       "      <use x=\"136.376953\" xlink:href=\"#DejaVuSans-1090\"/>\n",
       "      <use x=\"194.628906\" xlink:href=\"#DejaVuSans-1077\"/>\n",
       "      <use x=\"256.152344\" xlink:href=\"#DejaVuSans-1088\"/>\n",
       "      <use x=\"319.628906\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "      <use x=\"384.619141\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"416.40625\" xlink:href=\"#DejaVuSans-1085\"/>\n",
       "      <use x=\"481.787109\" xlink:href=\"#DejaVuSans-1072\"/>\n",
       "      <use x=\"543.066406\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"574.853516\" xlink:href=\"#DejaVuSans-1074\"/>\n",
       "      <use x=\"633.789062\" xlink:href=\"#DejaVuSans-1072\"/>\n",
       "      <use x=\"695.068359\" xlink:href=\"#DejaVuSans-1083\"/>\n",
       "      <use x=\"758.984375\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "      <use x=\"823.974609\" xlink:href=\"#DejaVuSans-1076\"/>\n",
       "      <use x=\"893.115234\" xlink:href=\"#DejaVuSans-1072\"/>\n",
       "      <use x=\"954.394531\" xlink:href=\"#DejaVuSans-1094\"/>\n",
       "      <use x=\"1022.460938\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "      <use x=\"1087.451172\" xlink:href=\"#DejaVuSans-1080\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p75ec9b3249\">\n",
       "   <rect height=\"271.8\" width=\"558\" x=\"34.240625\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 5])\n",
    "plt.plot(dict_history_model_boston_house_train[best_name_model]['loss'], label='Потери на тренировке')\n",
    "plt.plot(dict_history_model_boston_house_train[best_name_model]['val_loss'], label='Потери на валидации')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid('On')\n",
    "plt.title('Потери от эпох на лучшей мдели: ' + str(best_name_model) + \": \" + str(round(best_metrics, 4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 2s 23ms/step - loss: 3.6718 - mae: 3.6718 - val_loss: 7.2381 - val_mae: 7.2381\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2603 - mae: 3.2603 - val_loss: 3.6444 - val_mae: 3.6444\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9223 - mae: 2.9223 - val_loss: 4.0873 - val_mae: 4.0873\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7234 - mae: 2.7234 - val_loss: 3.7798 - val_mae: 3.7798\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9393 - mae: 2.9393 - val_loss: 4.6942 - val_mae: 4.6942\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9084 - mae: 2.9084 - val_loss: 2.9971 - val_mae: 2.9971\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8827 - mae: 2.8827 - val_loss: 3.2343 - val_mae: 3.2343\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5808 - mae: 2.5808 - val_loss: 3.1671 - val_mae: 3.1671\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.4737 - mae: 2.4737 - val_loss: 3.1867 - val_mae: 3.1867\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5298 - mae: 2.5298 - val_loss: 3.7297 - val_mae: 3.7297\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.2242 - mae: 2.2242 - val_loss: 3.8476 - val_mae: 3.8476\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.3537 - mae: 2.3537 - val_loss: 4.4978 - val_mae: 4.4978\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.2115 - mae: 2.2115 - val_loss: 3.0908 - val_mae: 3.0908\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.4751 - mae: 2.4751 - val_loss: 5.0891 - val_mae: 5.0891\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.1309 - mae: 2.1309 - val_loss: 3.3565 - val_mae: 3.3565\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9707 - mae: 1.9707 - val_loss: 2.4143 - val_mae: 2.4143\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9917 - mae: 1.9917 - val_loss: 3.6038 - val_mae: 3.6038\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.1752 - mae: 2.1752 - val_loss: 2.7591 - val_mae: 2.7591\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.0240 - mae: 2.0240 - val_loss: 2.6618 - val_mae: 2.6618\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7935 - mae: 1.7935 - val_loss: 2.6734 - val_mae: 2.6734\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.0633 - mae: 2.0633 - val_loss: 2.6320 - val_mae: 2.6320\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8658 - mae: 1.8658 - val_loss: 2.6698 - val_mae: 2.6698\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.8687 - mae: 1.8687 - val_loss: 2.9214 - val_mae: 2.9214\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9444 - mae: 1.9444 - val_loss: 2.8112 - val_mae: 2.8112\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.7806 - mae: 1.7806 - val_loss: 2.8802 - val_mae: 2.8802\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.8998 - mae: 1.8998 - val_loss: 3.1524 - val_mae: 3.1524\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.8541 - mae: 1.8541 - val_loss: 2.8886 - val_mae: 2.8886\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7525 - mae: 1.7525 - val_loss: 2.4946 - val_mae: 2.4946\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.7856 - mae: 1.7856 - val_loss: 2.7378 - val_mae: 2.7378\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.8548 - mae: 1.8548 - val_loss: 2.7148 - val_mae: 2.7148\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.7622 - mae: 1.7622 - val_loss: 2.4263 - val_mae: 2.4263\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6022 - mae: 1.6022 - val_loss: 2.8743 - val_mae: 2.8743\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.6911 - mae: 1.6911 - val_loss: 2.5529 - val_mae: 2.5529\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.5962 - mae: 1.5962 - val_loss: 3.6631 - val_mae: 3.6631\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.6930 - mae: 1.6930 - val_loss: 2.7591 - val_mae: 2.7591\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.4975 - mae: 1.4975 - val_loss: 2.8727 - val_mae: 2.8727\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.6498 - mae: 1.6498 - val_loss: 3.6187 - val_mae: 3.6187\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.5119 - mae: 1.5119 - val_loss: 2.8399 - val_mae: 2.8399\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.5407 - mae: 1.5407 - val_loss: 2.9401 - val_mae: 2.9401\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.5665 - mae: 1.5665 - val_loss: 2.6275 - val_mae: 2.6275\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.5509 - mae: 1.5509 - val_loss: 2.8182 - val_mae: 2.8182\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 1.5830 - mae: 1.5830 - val_loss: 3.3845 - val_mae: 3.3845\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 1.5590 - mae: 1.5590 - val_loss: 3.0282 - val_mae: 3.0282\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.5407 - mae: 1.5407 - val_loss: 2.9333 - val_mae: 2.9333\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.4929 - mae: 1.4929 - val_loss: 2.5406 - val_mae: 2.5406\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.4879 - mae: 1.4879 - val_loss: 2.4781 - val_mae: 2.4781\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.4490 - mae: 1.4490 - val_loss: 3.2268 - val_mae: 3.2268\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.3039 - mae: 1.3039 - val_loss: 2.3275 - val_mae: 2.3275\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.3728 - mae: 1.3728 - val_loss: 2.8109 - val_mae: 2.8109\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.4766 - mae: 1.4766 - val_loss: 2.4506 - val_mae: 2.4506\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.4635 - mae: 1.4635 - val_loss: 2.5260 - val_mae: 2.5260\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.4168 - mae: 1.4168 - val_loss: 3.2774 - val_mae: 3.2774\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6086 - mae: 1.6086 - val_loss: 2.7497 - val_mae: 2.7497\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.3242 - mae: 1.3242 - val_loss: 3.2947 - val_mae: 3.2947\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.3560 - mae: 1.3560 - val_loss: 2.9325 - val_mae: 2.9325\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.2569 - mae: 1.2569 - val_loss: 2.6629 - val_mae: 2.6629\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.3319 - mae: 1.3319 - val_loss: 2.6139 - val_mae: 2.6139\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.2897 - mae: 1.2897 - val_loss: 2.4338 - val_mae: 2.4338\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.3084 - mae: 1.3084 - val_loss: 2.5370 - val_mae: 2.5370\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.2201 - mae: 1.2201 - val_loss: 2.3657 - val_mae: 2.3657\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.1327 - mae: 1.1327 - val_loss: 2.8667 - val_mae: 2.8667\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 18ms/step - loss: 1.2150 - mae: 1.2150 - val_loss: 2.7070 - val_mae: 2.7070\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 1.2050 - mae: 1.2050 - val_loss: 2.5250 - val_mae: 2.5250\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.3143 - mae: 1.3143 - val_loss: 3.2542 - val_mae: 3.2542\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.2557 - mae: 1.2557 - val_loss: 2.4669 - val_mae: 2.4669\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.1598 - mae: 1.1598 - val_loss: 2.8532 - val_mae: 2.8532\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.3226 - mae: 1.3226 - val_loss: 2.4816 - val_mae: 2.4816\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.2244 - mae: 1.2244 - val_loss: 2.8413 - val_mae: 2.8413\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.2442 - mae: 1.2442 - val_loss: 2.1959 - val_mae: 2.1959\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.2100 - mae: 1.2100 - val_loss: 2.3688 - val_mae: 2.3688\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.1640 - mae: 1.1640 - val_loss: 2.5140 - val_mae: 2.5140\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 1.1390 - mae: 1.1390 - val_loss: 2.5296 - val_mae: 2.5296\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 1.1206 - mae: 1.1206 - val_loss: 2.9016 - val_mae: 2.9016\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.1195 - mae: 1.1195 - val_loss: 2.6371 - val_mae: 2.6371\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.2274 - mae: 1.2274 - val_loss: 3.3440 - val_mae: 3.3440\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.1869 - mae: 1.1869 - val_loss: 3.0422 - val_mae: 3.0422\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0751 - mae: 1.0751 - val_loss: 2.3353 - val_mae: 2.3353\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.1026 - mae: 1.1026 - val_loss: 2.4825 - val_mae: 2.4825\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.0910 - mae: 1.0910 - val_loss: 2.5021 - val_mae: 2.5021\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.0800 - mae: 1.0800 - val_loss: 2.4469 - val_mae: 2.4469\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.9860 - mae: 0.9860 - val_loss: 2.6440 - val_mae: 2.6440\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.0478 - mae: 1.0478 - val_loss: 2.5475 - val_mae: 2.5475\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.9642 - mae: 0.9642 - val_loss: 2.6836 - val_mae: 2.6836\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.1597 - mae: 1.1597 - val_loss: 2.5157 - val_mae: 2.5157\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.1101 - mae: 1.1101 - val_loss: 2.5129 - val_mae: 2.5129\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.0243 - mae: 1.0243 - val_loss: 2.5067 - val_mae: 2.5067\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0379 - mae: 1.0379 - val_loss: 2.3438 - val_mae: 2.3438\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 1.0718 - mae: 1.0718 - val_loss: 2.4265 - val_mae: 2.4265\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.1229 - mae: 1.1229 - val_loss: 2.2679 - val_mae: 2.2679\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.9885 - mae: 0.9885 - val_loss: 2.3980 - val_mae: 2.3980\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.0438 - mae: 1.0438 - val_loss: 2.5993 - val_mae: 2.5993\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.9682 - mae: 0.9682 - val_loss: 2.8364 - val_mae: 2.8364\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.1812 - mae: 1.1812 - val_loss: 2.2438 - val_mae: 2.2438\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 1.0856 - mae: 1.0856 - val_loss: 2.4799 - val_mae: 2.4799\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.9739 - mae: 0.9739 - val_loss: 2.5242 - val_mae: 2.5242\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.9813 - mae: 0.9813 - val_loss: 2.4108 - val_mae: 2.4108\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.9700 - mae: 0.9700 - val_loss: 2.5389 - val_mae: 2.5389\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.9058 - mae: 0.9058 - val_loss: 2.6588 - val_mae: 2.6588\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.9962 - mae: 0.9962 - val_loss: 2.7143 - val_mae: 2.7143\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 1.0024 - mae: 1.0024 - val_loss: 2.5050 - val_mae: 2.5050\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0720 - mae: 3.0720\n"
     ]
    }
   ],
   "source": [
    "inputs_ = Input(shape=(13,))\n",
    "x = inputs_\n",
    "\n",
    "for i in range(int(best_name_model.split('_')[3])):\n",
    "    x = Dense(int(best_name_model.split('_')[4]), activation=best_name_model.split('_')[6],\n",
    "              name='layer' + str(i))(x)\n",
    "\n",
    "outputs_ = Dense(1, activation=None, name='predictions')(x) \n",
    "\n",
    "model_boston_house = Model(inputs=inputs_, outputs=outputs_) \n",
    "\n",
    "model_boston_house.load_weights(best_name_model + '.h5')\n",
    "\n",
    "model_boston_house.compile(optimizer=best_name_model.split('_')[5], \n",
    "                           loss=best_name_model.split('_')[7], metrics=['mae'])\n",
    "\n",
    "history_model_boston_house = model_boston_house.fit(X_train, y_train, batch_size=batch_size_, \n",
    "                                                    validation_split=validation_split_, epochs=epochs_)\n",
    "\n",
    "\n",
    "loss_mae = model_boston_house.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_2_128_adam_relu_mse</th>\n",
       "      <td>20.729889</td>\n",
       "      <td>3.769304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_2_128_adam_relu_mae</th>\n",
       "      <td>3.754302</td>\n",
       "      <td>3.754302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_2_128_rmsprop_relu_mse</th>\n",
       "      <td>23.560982</td>\n",
       "      <td>4.070885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_2_128_rmsprop_relu_mae</th>\n",
       "      <td>3.854431</td>\n",
       "      <td>3.854431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_2_128_nadam_relu_mse</th>\n",
       "      <td>21.523045</td>\n",
       "      <td>3.853274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_5_512_adam_sigmoid_mae</th>\n",
       "      <td>5.011573</td>\n",
       "      <td>5.011573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_5_512_rmsprop_sigmoid_mse</th>\n",
       "      <td>31.046057</td>\n",
       "      <td>3.734796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_5_512_rmsprop_sigmoid_mae</th>\n",
       "      <td>5.367845</td>\n",
       "      <td>5.367845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_5_512_nadam_sigmoid_mse</th>\n",
       "      <td>32.969383</td>\n",
       "      <td>3.730303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODEL_BOSTON_HOUSE_5_512_nadam_sigmoid_mae</th>\n",
       "      <td>4.423237</td>\n",
       "      <td>4.423237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   loss   metrics\n",
       "MODEL_BOSTON_HOUSE_2_128_adam_relu_mse        20.729889  3.769304\n",
       "MODEL_BOSTON_HOUSE_2_128_adam_relu_mae         3.754302  3.754302\n",
       "MODEL_BOSTON_HOUSE_2_128_rmsprop_relu_mse     23.560982  4.070885\n",
       "MODEL_BOSTON_HOUSE_2_128_rmsprop_relu_mae      3.854431  3.854431\n",
       "MODEL_BOSTON_HOUSE_2_128_nadam_relu_mse       21.523045  3.853274\n",
       "...                                                 ...       ...\n",
       "MODEL_BOSTON_HOUSE_5_512_adam_sigmoid_mae      5.011573  5.011573\n",
       "MODEL_BOSTON_HOUSE_5_512_rmsprop_sigmoid_mse  31.046057  3.734796\n",
       "MODEL_BOSTON_HOUSE_5_512_rmsprop_sigmoid_mae   5.367845  5.367845\n",
       "MODEL_BOSTON_HOUSE_5_512_nadam_sigmoid_mse    32.969383  3.730303\n",
       "MODEL_BOSTON_HOUSE_5_512_nadam_sigmoid_mae     4.423237  4.423237\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "models = pd.DataFrame.from_dict(dict_eval, orient='index', columns=['loss', 'metrics'])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nadam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.004,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_boston_house.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_boston_house.predict(X_test)\n",
    "y_test\n",
    "y_pred = y_pred.reshape(1, 51)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.829849</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.829849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.737297</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.762703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.370014</td>\n",
       "      <td>20.7</td>\n",
       "      <td>6.670014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.803146</td>\n",
       "      <td>19.3</td>\n",
       "      <td>1.496854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.393314</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.293314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.638802</td>\n",
       "      <td>34.9</td>\n",
       "      <td>1.738802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.917850</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.182150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.063522</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.336478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.920290</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1.279710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.121502</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.721502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.795227</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.304773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.722200</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.318516</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.718516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.153038</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.253038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.388142</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.711858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.178076</td>\n",
       "      <td>22.9</td>\n",
       "      <td>2.721924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.386871</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.713129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.461903</td>\n",
       "      <td>30.7</td>\n",
       "      <td>1.238097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>42.402927</td>\n",
       "      <td>41.3</td>\n",
       "      <td>1.102927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28.119522</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.580478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.531893</td>\n",
       "      <td>18.1</td>\n",
       "      <td>2.568107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26.021984</td>\n",
       "      <td>23.7</td>\n",
       "      <td>2.321984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.014063</td>\n",
       "      <td>16.3</td>\n",
       "      <td>4.285937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.277687</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.922313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.724907</td>\n",
       "      <td>21.8</td>\n",
       "      <td>1.075093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.371490</td>\n",
       "      <td>26.4</td>\n",
       "      <td>1.028510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.483839</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.483839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.107979</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.992021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.973278</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.573278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21.248915</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.448915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24.632889</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.032889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24.110229</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.610229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21.279917</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1.520083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.726818</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.626818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.744045</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.855955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22.826109</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.026109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13.061413</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.138587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19.359724</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.159724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>51.771832</td>\n",
       "      <td>41.7</td>\n",
       "      <td>10.071832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19.339777</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1.260223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20.128670</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.828670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>26.250492</td>\n",
       "      <td>23.6</td>\n",
       "      <td>2.650492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14.612632</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.312632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15.870209</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.629791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>35.284355</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.284355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.904668</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.595332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17.643755</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22.407883</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.007883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20.956863</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.043137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19.488304</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.511696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>25.206341</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.006341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred  y_test      Error\n",
       "0   58.829849    50.0   8.829849\n",
       "1   17.737297    19.5   1.762703\n",
       "2   27.370014    20.7   6.670014\n",
       "3   17.803146    19.3   1.496854\n",
       "4   24.393314    24.1   0.293314\n",
       "5   36.638802    34.9   1.738802\n",
       "6   22.917850    23.1   0.182150\n",
       "7   15.063522    17.4   2.336478\n",
       "8   11.920290    13.2   1.279710\n",
       "9   34.121502    33.4   0.721502\n",
       "10  19.795227    20.1   0.304773\n",
       "11  13.722200    14.5   0.777800\n",
       "12  18.318516    17.6   0.718516\n",
       "13  24.153038    23.9   0.253038\n",
       "14  20.388142    21.1   0.711858\n",
       "15  20.178076    22.9   2.721924\n",
       "16  23.386871    24.1   0.713129\n",
       "17  29.461903    30.7   1.238097\n",
       "18  42.402927    41.3   1.102927\n",
       "19  28.119522    28.7   0.580478\n",
       "20  15.531893    18.1   2.568107\n",
       "21  26.021984    23.7   2.321984\n",
       "22  12.014063    16.3   4.285937\n",
       "23  20.277687    21.2   0.922313\n",
       "24  20.724907    21.8   1.075093\n",
       "25  25.371490    26.4   1.028510\n",
       "26  26.483839    24.0   2.483839\n",
       "27  28.107979    29.1   0.992021\n",
       "28  13.973278    13.4   0.573278\n",
       "29  21.248915    20.8   0.448915\n",
       "30  24.632889    22.6   2.032889\n",
       "31  24.110229    21.5   2.610229\n",
       "32  21.279917    22.8   1.520083\n",
       "33  12.726818    12.1   0.626818\n",
       "34  13.744045    14.6   0.855955\n",
       "35  22.826109    22.8   0.026109\n",
       "36  13.061413    15.2   2.138587\n",
       "37  19.359724    19.2   0.159724\n",
       "38  51.771832    41.7  10.071832\n",
       "39  19.339777    20.6   1.260223\n",
       "40  20.128670    19.3   0.828670\n",
       "41  26.250492    23.6   2.650492\n",
       "42  14.612632    13.3   1.312632\n",
       "43  15.870209    17.5   1.629791\n",
       "44  35.284355    29.0   6.284355\n",
       "45   3.904668     8.5   4.595332\n",
       "46  17.643755    18.2   0.556245\n",
       "47  22.407883    22.4   0.007883\n",
       "48  20.956863    21.0   0.043137\n",
       "49  19.488304    21.0   1.511696\n",
       "50  25.206341    24.2   1.006341"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pd.DataFrame({'y_pred': y_pred, 'y_test': y_test})\n",
    "pred_test['Error'] = np.abs(y_pred - y_test)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 1.820841848149019\n",
      "R2 0.8665278057559501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "print('mae', mean_absolute_error(y_test, y_pred))\n",
    "print('R2', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. Поработайте с документацией TensorFlow 2. Найти 2-3 полезные команды TensorFlow, не разобранные на уроке (полезные для Вас)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Разработка для нескольких графических процессоров позволит масштабировать модель с дополнительными ресурсами. При разработке в системе с одним графическим процессором мы можем моделировать несколько графических процессоров с помощью виртуальных устройств. Это позволяет легко тестировать конфигурации с несколькими графическими процессорами, не требуя дополнительных ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    " gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 1GB memory each\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
    "         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Когда у нас есть несколько логических графических процессоров, доступных для среды выполнения, мы можем использовать несколько графических процессоров с tf.distribute.Strategy или с ручным размещением. Лучшая практика для использования нескольких графических процессоров - использовать tf.distribute.Strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "  inputs = tf.keras.layers.Input(shape=(1,))\n",
    "  predictions = tf.keras.layers.Dense(1)(inputs)\n",
    "  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Ручное размещение\n",
    "tf.distribute.Strategy работает под капотом, реплицируя вычисления между устройствами. Вы можете вручную реализовать репликацию, построив свою модель на каждом графическом процессоре. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "if gpus:\n",
    "  # Replicate your computation on multiple GPUs\n",
    "  c = []\n",
    "  for gpu in gpus:\n",
    "    with tf.device(gpu.name):\n",
    "      a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "      b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "      c.append(tf.matmul(a, b))\n",
    "\n",
    "  with tf.device('/CPU:0'):\n",
    "    matmul_sum = tf.add_n(c)\n",
    "\n",
    "  print(matmul_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
